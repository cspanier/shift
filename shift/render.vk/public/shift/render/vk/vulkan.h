////////////////////////////////////////////////////////////////
// WARNING! Automatically generated file.                     //
// Do not touch anything or your changes will be overwritten! //
////////////////////////////////////////////////////////////////
//
// Copyright (c) 2015-2018 The Khronos Group Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// ---- Exceptions to the Apache 2.0 License: ----
//
// As an exception, if you use this Software to generate code and portions of
// this Software are embedded into the generated code as a result, you may
// redistribute such product without providing attribution as would otherwise
// be required by Sections 4(a), 4(b) and 4(d) of the License.
//
// In addition, if you combine or link code generated by this Software with
// software that is licensed under the GPLv2 or the LGPL v2.0 or 2.1
// ("`Combined Software`") and if a court of competent jurisdiction determines
// that the patent provision (Section 3), the indemnity provision (Section 9)
// or other Section of the License conflicts with the conditions of the
// applicable GPL or LGPL license, you may retroactively and prospectively
// choose to deem waived or otherwise exclude such Section(s) of the License,
// but only in their entirety and only with respect to the Combined Software.
//

#ifndef SHIFT_RENDER_VK_VULKAN_H
#define SHIFT_RENDER_VK_VULKAN_H

#include <cstdint>
#include <array>
#include <vector>
#include <vulkan/vulkan.h>
#include <shift/core/bit_field.h>

namespace shift::render::vk
{
enum class pipeline_cache_header_version
{
  /// @see VK_PIPELINE_CACHE_HEADER_VERSION_ONE
  one = 1,
};
enum class structure_type
{
  /// @see VK_STRUCTURE_TYPE_APPLICATION_INFO
  application_info = 0,
  /// @see VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO
  instance_create_info = 1,
  /// @see VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO
  device_queue_create_info = 2,
  /// @see VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO
  device_create_info = 3,
  /// @see VK_STRUCTURE_TYPE_SUBMIT_INFO
  submit_info = 4,
  /// @see VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO
  memory_allocate_info = 5,
  /// @see VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE
  mapped_memory_range = 6,
  /// @see VK_STRUCTURE_TYPE_BIND_SPARSE_INFO
  bind_sparse_info = 7,
  /// @see VK_STRUCTURE_TYPE_FENCE_CREATE_INFO
  fence_create_info = 8,
  /// @see VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO
  semaphore_create_info = 9,
  /// @see VK_STRUCTURE_TYPE_EVENT_CREATE_INFO
  event_create_info = 10,
  /// @see VK_STRUCTURE_TYPE_QUERY_POOL_CREATE_INFO
  query_pool_create_info = 11,
  /// @see VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO
  buffer_create_info = 12,
  /// @see VK_STRUCTURE_TYPE_BUFFER_VIEW_CREATE_INFO
  buffer_view_create_info = 13,
  /// @see VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO
  image_create_info = 14,
  /// @see VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO
  image_view_create_info = 15,
  /// @see VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO
  shader_module_create_info = 16,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_CACHE_CREATE_INFO
  pipeline_cache_create_info = 17,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO
  pipeline_shader_stage_create_info = 18,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO
  pipeline_vertex_input_state_create_info = 19,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO
  pipeline_input_assembly_state_create_info = 20,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_STATE_CREATE_INFO
  pipeline_tessellation_state_create_info = 21,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO
  pipeline_viewport_state_create_info = 22,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO
  pipeline_rasterization_state_create_info = 23,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO
  pipeline_multisample_state_create_info = 24,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_DEPTH_STENCIL_STATE_CREATE_INFO
  pipeline_depth_stencil_state_create_info = 25,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO
  pipeline_color_blend_state_create_info = 26,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_DYNAMIC_STATE_CREATE_INFO
  pipeline_dynamic_state_create_info = 27,
  /// @see VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO
  graphics_pipeline_create_info = 28,
  /// @see VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_CREATE_INFO
  compute_pipeline_create_info = 29,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO
  pipeline_layout_create_info = 30,
  /// @see VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO
  sampler_create_info = 31,
  /// @see VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO
  descriptor_set_layout_create_info = 32,
  /// @see VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO
  descriptor_pool_create_info = 33,
  /// @see VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO
  descriptor_set_allocate_info = 34,
  /// @see VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET
  write_descriptor_set = 35,
  /// @see VK_STRUCTURE_TYPE_COPY_DESCRIPTOR_SET
  copy_descriptor_set = 36,
  /// @see VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO
  framebuffer_create_info = 37,
  /// @see VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO
  render_pass_create_info = 38,
  /// @see VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO
  command_pool_create_info = 39,
  /// @see VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO
  command_buffer_allocate_info = 40,
  /// @see VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_INFO
  command_buffer_inheritance_info = 41,
  /// @see VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO
  command_buffer_begin_info = 42,
  /// @see VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO
  render_pass_begin_info = 43,
  /// @see VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER
  buffer_memory_barrier = 44,
  /// @see VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER
  image_memory_barrier = 45,
  /// @see VK_STRUCTURE_TYPE_MEMORY_BARRIER
  memory_barrier = 46,
  /// Reserved for internal use by the loader, layers, and ICDs
  /// @see VK_STRUCTURE_TYPE_LOADER_INSTANCE_CREATE_INFO
  loader_instance_create_info = 47,
  /// Reserved for internal use by the loader, layers, and ICDs
  /// @see VK_STRUCTURE_TYPE_LOADER_DEVICE_CREATE_INFO
  loader_device_create_info = 48,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_PROPERTIES
  physical_device_subgroup_properties = 1000094000,
  /// @see VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_INFO
  bind_buffer_memory_info = 1000157000,
  /// @see VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_INFO
  bind_image_memory_info = 1000157001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_16BIT_STORAGE_FEATURES
  physical_device_16_bit_storage_features = 1000083000,
  /// @see VK_STRUCTURE_TYPE_MEMORY_DEDICATED_REQUIREMENTS
  memory_dedicated_requirements = 1000127000,
  /// @see VK_STRUCTURE_TYPE_MEMORY_DEDICATED_ALLOCATE_INFO
  memory_dedicated_allocate_info = 1000127001,
  /// @see VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_FLAGS_INFO
  memory_allocate_flags_info = 1000060000,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GROUP_RENDER_PASS_BEGIN_INFO
  device_group_render_pass_begin_info = 1000060003,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GROUP_COMMAND_BUFFER_BEGIN_INFO
  device_group_command_buffer_begin_info = 1000060004,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GROUP_SUBMIT_INFO
  device_group_submit_info = 1000060005,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GROUP_BIND_SPARSE_INFO
  device_group_bind_sparse_info = 1000060006,
  /// @see VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_DEVICE_GROUP_INFO
  bind_buffer_memory_device_group_info = 1000060013,
  /// @see VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_DEVICE_GROUP_INFO
  bind_image_memory_device_group_info = 1000060014,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GROUP_PROPERTIES
  physical_device_group_properties = 1000070000,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GROUP_DEVICE_CREATE_INFO
  device_group_device_create_info = 1000070001,
  /// @see VK_STRUCTURE_TYPE_BUFFER_MEMORY_REQUIREMENTS_INFO_2
  buffer_memory_requirements_info_2 = 1000146000,
  /// @see VK_STRUCTURE_TYPE_IMAGE_MEMORY_REQUIREMENTS_INFO_2
  image_memory_requirements_info_2 = 1000146001,
  /// @see VK_STRUCTURE_TYPE_IMAGE_SPARSE_MEMORY_REQUIREMENTS_INFO_2
  image_sparse_memory_requirements_info_2 = 1000146002,
  /// @see VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2
  memory_requirements_2 = 1000146003,
  /// @see VK_STRUCTURE_TYPE_SPARSE_IMAGE_MEMORY_REQUIREMENTS_2
  sparse_image_memory_requirements_2 = 1000146004,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2
  physical_device_features_2 = 1000059000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROPERTIES_2
  physical_device_properties_2 = 1000059001,
  /// @see VK_STRUCTURE_TYPE_FORMAT_PROPERTIES_2
  format_properties_2 = 1000059002,
  /// @see VK_STRUCTURE_TYPE_IMAGE_FORMAT_PROPERTIES_2
  image_format_properties_2 = 1000059003,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_FORMAT_INFO_2
  physical_device_image_format_info_2 = 1000059004,
  /// @see VK_STRUCTURE_TYPE_QUEUE_FAMILY_PROPERTIES_2
  queue_family_properties_2 = 1000059005,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PROPERTIES_2
  physical_device_memory_properties_2 = 1000059006,
  /// @see VK_STRUCTURE_TYPE_SPARSE_IMAGE_FORMAT_PROPERTIES_2
  sparse_image_format_properties_2 = 1000059007,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SPARSE_IMAGE_FORMAT_INFO_2
  physical_device_sparse_image_format_info_2 = 1000059008,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_POINT_CLIPPING_PROPERTIES
  physical_device_point_clipping_properties = 1000117000,
  /// @see VK_STRUCTURE_TYPE_RENDER_PASS_INPUT_ATTACHMENT_ASPECT_CREATE_INFO
  render_pass_input_attachment_aspect_create_info = 1000117001,
  /// @see VK_STRUCTURE_TYPE_IMAGE_VIEW_USAGE_CREATE_INFO
  image_view_usage_create_info = 1000117002,
  /// @see
  /// VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_DOMAIN_ORIGIN_STATE_CREATE_INFO
  pipeline_tessellation_domain_origin_state_create_info = 1000117003,
  /// @see VK_STRUCTURE_TYPE_RENDER_PASS_MULTIVIEW_CREATE_INFO
  render_pass_multiview_create_info = 1000053000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_FEATURES
  physical_device_multiview_features = 1000053001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PROPERTIES
  physical_device_multiview_properties = 1000053002,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTER_FEATURES
  physical_device_variable_pointer_features = 1000120000,
  /// @see VK_STRUCTURE_TYPE_PROTECTED_SUBMIT_INFO
  protected_submit_info = 1000145000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROTECTED_MEMORY_FEATURES
  physical_device_protected_memory_features = 1000145001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROTECTED_MEMORY_PROPERTIES
  physical_device_protected_memory_properties = 1000145002,
  /// @see VK_STRUCTURE_TYPE_DEVICE_QUEUE_INFO_2
  device_queue_info_2 = 1000145003,
  /// @see VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_CREATE_INFO
  sampler_ycbcr_conversion_create_info = 1000156000,
  /// @see VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_INFO
  sampler_ycbcr_conversion_info = 1000156001,
  /// @see VK_STRUCTURE_TYPE_BIND_IMAGE_PLANE_MEMORY_INFO
  bind_image_plane_memory_info = 1000156002,
  /// @see VK_STRUCTURE_TYPE_IMAGE_PLANE_MEMORY_REQUIREMENTS_INFO
  image_plane_memory_requirements_info = 1000156003,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_YCBCR_CONVERSION_FEATURES
  physical_device_sampler_ycbcr_conversion_features = 1000156004,
  /// @see VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_IMAGE_FORMAT_PROPERTIES
  sampler_ycbcr_conversion_image_format_properties = 1000156005,
  /// @see VK_STRUCTURE_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_CREATE_INFO
  descriptor_update_template_create_info = 1000085000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_IMAGE_FORMAT_INFO
  physical_device_external_image_format_info = 1000071000,
  /// @see VK_STRUCTURE_TYPE_EXTERNAL_IMAGE_FORMAT_PROPERTIES
  external_image_format_properties = 1000071001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_BUFFER_INFO
  physical_device_external_buffer_info = 1000071002,
  /// @see VK_STRUCTURE_TYPE_EXTERNAL_BUFFER_PROPERTIES
  external_buffer_properties = 1000071003,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ID_PROPERTIES
  physical_device_id_properties = 1000071004,
  /// @see VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO
  external_memory_buffer_create_info = 1000072000,
  /// @see VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO
  external_memory_image_create_info = 1000072001,
  /// @see VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO
  export_memory_allocate_info = 1000072002,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_FENCE_INFO
  physical_device_external_fence_info = 1000112000,
  /// @see VK_STRUCTURE_TYPE_EXTERNAL_FENCE_PROPERTIES
  external_fence_properties = 1000112001,
  /// @see VK_STRUCTURE_TYPE_EXPORT_FENCE_CREATE_INFO
  export_fence_create_info = 1000113000,
  /// @see VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO
  export_semaphore_create_info = 1000077000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_SEMAPHORE_INFO
  physical_device_external_semaphore_info = 1000076000,
  /// @see VK_STRUCTURE_TYPE_EXTERNAL_SEMAPHORE_PROPERTIES
  external_semaphore_properties = 1000076001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_3_PROPERTIES
  physical_device_maintenance_3_properties = 1000168000,
  /// @see VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_SUPPORT
  descriptor_set_layout_support = 1000168001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DRAW_PARAMETER_FEATURES
  physical_device_shader_draw_parameter_features = 1000063000,
  /// @see VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR
  swapchain_create_info_khr = 1000001000,
  /// @see VK_STRUCTURE_TYPE_PRESENT_INFO_KHR
  present_info_khr = 1000001001,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GROUP_PRESENT_CAPABILITIES_KHR
  device_group_present_capabilities_khr = 1000001007,
  /// @see VK_STRUCTURE_TYPE_IMAGE_SWAPCHAIN_CREATE_INFO_KHR
  image_swapchain_create_info_khr = 1000001008,
  /// @see VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_SWAPCHAIN_INFO_KHR
  bind_image_memory_swapchain_info_khr = 1000001009,
  /// @see VK_STRUCTURE_TYPE_ACQUIRE_NEXT_IMAGE_INFO_KHR
  acquire_next_image_info_khr = 1000001010,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GROUP_PRESENT_INFO_KHR
  device_group_present_info_khr = 1000001011,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GROUP_SWAPCHAIN_CREATE_INFO_KHR
  device_group_swapchain_create_info_khr = 1000001012,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_MODE_CREATE_INFO_KHR
  display_mode_create_info_khr = 1000002000,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_SURFACE_CREATE_INFO_KHR
  display_surface_create_info_khr = 1000002001,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_PRESENT_INFO_KHR
  display_present_info_khr = 1000003000,
  /// @see VK_STRUCTURE_TYPE_XLIB_SURFACE_CREATE_INFO_KHR
  xlib_surface_create_info_khr = 1000004000,
  /// @see VK_STRUCTURE_TYPE_XCB_SURFACE_CREATE_INFO_KHR
  xcb_surface_create_info_khr = 1000005000,
  /// @see VK_STRUCTURE_TYPE_WAYLAND_SURFACE_CREATE_INFO_KHR
  wayland_surface_create_info_khr = 1000006000,
  /// @see VK_STRUCTURE_TYPE_MIR_SURFACE_CREATE_INFO_KHR
  mir_surface_create_info_khr = 1000007000,
  /// @see VK_STRUCTURE_TYPE_ANDROID_SURFACE_CREATE_INFO_KHR
  android_surface_create_info_khr = 1000008000,
  /// @see VK_STRUCTURE_TYPE_WIN32_SURFACE_CREATE_INFO_KHR
  win32_surface_create_info_khr = 1000009000,
  /// @see VK_STRUCTURE_TYPE_DEBUG_REPORT_CALLBACK_CREATE_INFO_EXT
  debug_report_callback_create_info_ext = 1000011000,
  /// @see
  /// VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_RASTERIZATION_ORDER_AMD
  pipeline_rasterization_state_rasterization_order_amd = 1000018000,
  /// @see VK_STRUCTURE_TYPE_DEBUG_MARKER_OBJECT_NAME_INFO_EXT
  debug_marker_object_name_info_ext = 1000022000,
  /// @see VK_STRUCTURE_TYPE_DEBUG_MARKER_OBJECT_TAG_INFO_EXT
  debug_marker_object_tag_info_ext = 1000022001,
  /// @see VK_STRUCTURE_TYPE_DEBUG_MARKER_MARKER_INFO_EXT
  debug_marker_marker_info_ext = 1000022002,
  /// @see VK_STRUCTURE_TYPE_DEDICATED_ALLOCATION_IMAGE_CREATE_INFO_NV
  dedicated_allocation_image_create_info_nv = 1000026000,
  /// @see VK_STRUCTURE_TYPE_DEDICATED_ALLOCATION_BUFFER_CREATE_INFO_NV
  dedicated_allocation_buffer_create_info_nv = 1000026001,
  /// @see VK_STRUCTURE_TYPE_DEDICATED_ALLOCATION_MEMORY_ALLOCATE_INFO_NV
  dedicated_allocation_memory_allocate_info_nv = 1000026002,
  /// @see VK_STRUCTURE_TYPE_TEXTURE_LOD_GATHER_FORMAT_PROPERTIES_AMD
  texture_lod_gather_format_properties_amd = 1000041000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CORNER_SAMPLED_IMAGE_FEATURES_NV
  physical_device_corner_sampled_image_features_nv = 1000050000,
  /// @see VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO_NV
  external_memory_image_create_info_nv = 1000056000,
  /// @see VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO_NV
  export_memory_allocate_info_nv = 1000056001,
  /// @see VK_STRUCTURE_TYPE_IMPORT_MEMORY_WIN32_HANDLE_INFO_NV
  import_memory_win32_handle_info_nv = 1000057000,
  /// @see VK_STRUCTURE_TYPE_EXPORT_MEMORY_WIN32_HANDLE_INFO_NV
  export_memory_win32_handle_info_nv = 1000057001,
  /// @see VK_STRUCTURE_TYPE_WIN32_KEYED_MUTEX_ACQUIRE_RELEASE_INFO_NV
  win32_keyed_mutex_acquire_release_info_nv = 1000058000,
  /// @see VK_STRUCTURE_TYPE_VALIDATION_FLAGS_EXT
  validation_flags_ext = 1000061000,
  /// @see VK_STRUCTURE_TYPE_VI_SURFACE_CREATE_INFO_NN
  vi_surface_create_info_nn = 1000062000,
  /// @see VK_STRUCTURE_TYPE_IMAGE_VIEW_ASTC_DECODE_MODE_EXT
  image_view_astc_decode_mode_ext = 1000067000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ASTC_DECODE_FEATURES_EXT
  physical_device_astc_decode_features_ext = 1000067001,
  /// @see VK_STRUCTURE_TYPE_IMPORT_MEMORY_WIN32_HANDLE_INFO_KHR
  import_memory_win32_handle_info_khr = 1000073000,
  /// @see VK_STRUCTURE_TYPE_EXPORT_MEMORY_WIN32_HANDLE_INFO_KHR
  export_memory_win32_handle_info_khr = 1000073001,
  /// @see VK_STRUCTURE_TYPE_MEMORY_WIN32_HANDLE_PROPERTIES_KHR
  memory_win32_handle_properties_khr = 1000073002,
  /// @see VK_STRUCTURE_TYPE_MEMORY_GET_WIN32_HANDLE_INFO_KHR
  memory_get_win32_handle_info_khr = 1000073003,
  /// @see VK_STRUCTURE_TYPE_IMPORT_MEMORY_FD_INFO_KHR
  import_memory_fd_info_khr = 1000074000,
  /// @see VK_STRUCTURE_TYPE_MEMORY_FD_PROPERTIES_KHR
  memory_fd_properties_khr = 1000074001,
  /// @see VK_STRUCTURE_TYPE_MEMORY_GET_FD_INFO_KHR
  memory_get_fd_info_khr = 1000074002,
  /// @see VK_STRUCTURE_TYPE_WIN32_KEYED_MUTEX_ACQUIRE_RELEASE_INFO_KHR
  win32_keyed_mutex_acquire_release_info_khr = 1000075000,
  /// @see VK_STRUCTURE_TYPE_IMPORT_SEMAPHORE_WIN32_HANDLE_INFO_KHR
  import_semaphore_win32_handle_info_khr = 1000078000,
  /// @see VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_WIN32_HANDLE_INFO_KHR
  export_semaphore_win32_handle_info_khr = 1000078001,
  /// @see VK_STRUCTURE_TYPE_D3D12_FENCE_SUBMIT_INFO_KHR
  d3d_12_fence_submit_info_khr = 1000078002,
  /// @see VK_STRUCTURE_TYPE_SEMAPHORE_GET_WIN32_HANDLE_INFO_KHR
  semaphore_get_win32_handle_info_khr = 1000078003,
  /// @see VK_STRUCTURE_TYPE_IMPORT_SEMAPHORE_FD_INFO_KHR
  import_semaphore_fd_info_khr = 1000079000,
  /// @see VK_STRUCTURE_TYPE_SEMAPHORE_GET_FD_INFO_KHR
  semaphore_get_fd_info_khr = 1000079001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PUSH_DESCRIPTOR_PROPERTIES_KHR
  physical_device_push_descriptor_properties_khr = 1000080000,
  /// @see
  /// VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_CONDITIONAL_RENDERING_INFO_EXT
  command_buffer_inheritance_conditional_rendering_info_ext = 1000081000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CONDITIONAL_RENDERING_FEATURES_EXT
  physical_device_conditional_rendering_features_ext = 1000081001,
  /// @see VK_STRUCTURE_TYPE_CONDITIONAL_RENDERING_BEGIN_INFO_EXT
  conditional_rendering_begin_info_ext = 1000081002,
  /// @see VK_STRUCTURE_TYPE_PRESENT_REGIONS_KHR
  present_regions_khr = 1000084000,
  /// @see VK_STRUCTURE_TYPE_OBJECT_TABLE_CREATE_INFO_NVX
  object_table_create_info_nvx = 1000086000,
  /// @see VK_STRUCTURE_TYPE_INDIRECT_COMMANDS_LAYOUT_CREATE_INFO_NVX
  indirect_commands_layout_create_info_nvx = 1000086001,
  /// @see VK_STRUCTURE_TYPE_CMD_PROCESS_COMMANDS_INFO_NVX
  cmd_process_commands_info_nvx = 1000086002,
  /// @see VK_STRUCTURE_TYPE_CMD_RESERVE_SPACE_FOR_COMMANDS_INFO_NVX
  cmd_reserve_space_for_commands_info_nvx = 1000086003,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GENERATED_COMMANDS_LIMITS_NVX
  device_generated_commands_limits_nvx = 1000086004,
  /// @see VK_STRUCTURE_TYPE_DEVICE_GENERATED_COMMANDS_FEATURES_NVX
  device_generated_commands_features_nvx = 1000086005,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_W_SCALING_STATE_CREATE_INFO_NV
  pipeline_viewport_w_scaling_state_create_info_nv = 1000087000,
  /// @see VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_2_EXT
  surface_capabilities_2_ext = 1000090000,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_POWER_INFO_EXT
  display_power_info_ext = 1000091000,
  /// @see VK_STRUCTURE_TYPE_DEVICE_EVENT_INFO_EXT
  device_event_info_ext = 1000091001,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_EVENT_INFO_EXT
  display_event_info_ext = 1000091002,
  /// @see VK_STRUCTURE_TYPE_SWAPCHAIN_COUNTER_CREATE_INFO_EXT
  swapchain_counter_create_info_ext = 1000091003,
  /// @see VK_STRUCTURE_TYPE_PRESENT_TIMES_INFO_GOOGLE
  present_times_info_google = 1000092000,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PER_VIEW_ATTRIBUTES_PROPERTIES_NVX
  physical_device_multiview_per_view_attributes_properties_nvx = 1000097000,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_SWIZZLE_STATE_CREATE_INFO_NV
  pipeline_viewport_swizzle_state_create_info_nv = 1000098000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DISCARD_RECTANGLE_PROPERTIES_EXT
  physical_device_discard_rectangle_properties_ext = 1000099000,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_DISCARD_RECTANGLE_STATE_CREATE_INFO_EXT
  pipeline_discard_rectangle_state_create_info_ext = 1000099001,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CONSERVATIVE_RASTERIZATION_PROPERTIES_EXT
  physical_device_conservative_rasterization_properties_ext = 1000101000,
  /// @see
  /// VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_CONSERVATIVE_STATE_CREATE_INFO_EXT
  pipeline_rasterization_conservative_state_create_info_ext = 1000101001,
  /// @see VK_STRUCTURE_TYPE_HDR_METADATA_EXT
  hdr_metadata_ext = 1000105000,
  /// @see VK_STRUCTURE_TYPE_ATTACHMENT_DESCRIPTION_2_KHR
  attachment_description_2_khr = 1000109000,
  /// @see VK_STRUCTURE_TYPE_ATTACHMENT_REFERENCE_2_KHR
  attachment_reference_2_khr = 1000109001,
  /// @see VK_STRUCTURE_TYPE_SUBPASS_DESCRIPTION_2_KHR
  subpass_description_2_khr = 1000109002,
  /// @see VK_STRUCTURE_TYPE_SUBPASS_DEPENDENCY_2_KHR
  subpass_dependency_2_khr = 1000109003,
  /// @see VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO_2_KHR
  render_pass_create_info_2_khr = 1000109004,
  /// @see VK_STRUCTURE_TYPE_SUBPASS_BEGIN_INFO_KHR
  subpass_begin_info_khr = 1000109005,
  /// @see VK_STRUCTURE_TYPE_SUBPASS_END_INFO_KHR
  subpass_end_info_khr = 1000109006,
  /// @see VK_STRUCTURE_TYPE_SHARED_PRESENT_SURFACE_CAPABILITIES_KHR
  shared_present_surface_capabilities_khr = 1000111000,
  /// @see VK_STRUCTURE_TYPE_IMPORT_FENCE_WIN32_HANDLE_INFO_KHR
  import_fence_win32_handle_info_khr = 1000114000,
  /// @see VK_STRUCTURE_TYPE_EXPORT_FENCE_WIN32_HANDLE_INFO_KHR
  export_fence_win32_handle_info_khr = 1000114001,
  /// @see VK_STRUCTURE_TYPE_FENCE_GET_WIN32_HANDLE_INFO_KHR
  fence_get_win32_handle_info_khr = 1000114002,
  /// @see VK_STRUCTURE_TYPE_IMPORT_FENCE_FD_INFO_KHR
  import_fence_fd_info_khr = 1000115000,
  /// @see VK_STRUCTURE_TYPE_FENCE_GET_FD_INFO_KHR
  fence_get_fd_info_khr = 1000115001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SURFACE_INFO_2_KHR
  physical_device_surface_info_2_khr = 1000119000,
  /// @see VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_2_KHR
  surface_capabilities_2_khr = 1000119001,
  /// @see VK_STRUCTURE_TYPE_SURFACE_FORMAT_2_KHR
  surface_format_2_khr = 1000119002,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_PROPERTIES_2_KHR
  display_properties_2_khr = 1000121000,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_PLANE_PROPERTIES_2_KHR
  display_plane_properties_2_khr = 1000121001,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_MODE_PROPERTIES_2_KHR
  display_mode_properties_2_khr = 1000121002,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_PLANE_INFO_2_KHR
  display_plane_info_2_khr = 1000121003,
  /// @see VK_STRUCTURE_TYPE_DISPLAY_PLANE_CAPABILITIES_2_KHR
  display_plane_capabilities_2_khr = 1000121004,
  /// @see VK_STRUCTURE_TYPE_IOS_SURFACE_CREATE_INFO_MVK
  ios_surface_create_info_mvk = 1000122000,
  /// @see VK_STRUCTURE_TYPE_MACOS_SURFACE_CREATE_INFO_MVK
  macos_surface_create_info_mvk = 1000123000,
  /// @see VK_STRUCTURE_TYPE_DEBUG_UTILS_OBJECT_NAME_INFO_EXT
  debug_utils_object_name_info_ext = 1000128000,
  /// @see VK_STRUCTURE_TYPE_DEBUG_UTILS_OBJECT_TAG_INFO_EXT
  debug_utils_object_tag_info_ext = 1000128001,
  /// @see VK_STRUCTURE_TYPE_DEBUG_UTILS_LABEL_EXT
  debug_utils_label_ext = 1000128002,
  /// @see VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CALLBACK_DATA_EXT
  debug_utils_messenger_callback_data_ext = 1000128003,
  /// @see VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT
  debug_utils_messenger_create_info_ext = 1000128004,
  /// @see VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_USAGE_ANDROID
  android_hardware_buffer_usage_android = 1000129000,
  /// @see VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_PROPERTIES_ANDROID
  android_hardware_buffer_properties_android = 1000129001,
  /// @see VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_FORMAT_PROPERTIES_ANDROID
  android_hardware_buffer_format_properties_android = 1000129002,
  /// @see VK_STRUCTURE_TYPE_IMPORT_ANDROID_HARDWARE_BUFFER_INFO_ANDROID
  import_android_hardware_buffer_info_android = 1000129003,
  /// @see VK_STRUCTURE_TYPE_MEMORY_GET_ANDROID_HARDWARE_BUFFER_INFO_ANDROID
  memory_get_android_hardware_buffer_info_android = 1000129004,
  /// @see VK_STRUCTURE_TYPE_EXTERNAL_FORMAT_ANDROID
  external_format_android = 1000129005,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_FILTER_MINMAX_PROPERTIES_EXT
  physical_device_sampler_filter_minmax_properties_ext = 1000130000,
  /// @see VK_STRUCTURE_TYPE_SAMPLER_REDUCTION_MODE_CREATE_INFO_EXT
  sampler_reduction_mode_create_info_ext = 1000130001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_FEATURES_EXT
  physical_device_inline_uniform_block_features_ext = 1000138000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_PROPERTIES_EXT
  physical_device_inline_uniform_block_properties_ext = 1000138001,
  /// @see VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_INLINE_UNIFORM_BLOCK_EXT
  write_descriptor_set_inline_uniform_block_ext = 1000138002,
  /// @see
  /// VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_INLINE_UNIFORM_BLOCK_CREATE_INFO_EXT
  descriptor_pool_inline_uniform_block_create_info_ext = 1000138003,
  /// @see VK_STRUCTURE_TYPE_SAMPLE_LOCATIONS_INFO_EXT
  sample_locations_info_ext = 1000143000,
  /// @see VK_STRUCTURE_TYPE_RENDER_PASS_SAMPLE_LOCATIONS_BEGIN_INFO_EXT
  render_pass_sample_locations_begin_info_ext = 1000143001,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_SAMPLE_LOCATIONS_STATE_CREATE_INFO_EXT
  pipeline_sample_locations_state_create_info_ext = 1000143002,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLE_LOCATIONS_PROPERTIES_EXT
  physical_device_sample_locations_properties_ext = 1000143003,
  /// @see VK_STRUCTURE_TYPE_MULTISAMPLE_PROPERTIES_EXT
  multisample_properties_ext = 1000143004,
  /// @see VK_STRUCTURE_TYPE_IMAGE_FORMAT_LIST_CREATE_INFO_KHR
  image_format_list_create_info_khr = 1000147000,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BLEND_OPERATION_ADVANCED_FEATURES_EXT
  physical_device_blend_operation_advanced_features_ext = 1000148000,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BLEND_OPERATION_ADVANCED_PROPERTIES_EXT
  physical_device_blend_operation_advanced_properties_ext = 1000148001,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_ADVANCED_STATE_CREATE_INFO_EXT
  pipeline_color_blend_advanced_state_create_info_ext = 1000148002,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_COVERAGE_TO_COLOR_STATE_CREATE_INFO_NV
  pipeline_coverage_to_color_state_create_info_nv = 1000149000,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_COVERAGE_MODULATION_STATE_CREATE_INFO_NV
  pipeline_coverage_modulation_state_create_info_nv = 1000152000,
  /// @see VK_STRUCTURE_TYPE_VALIDATION_CACHE_CREATE_INFO_EXT
  validation_cache_create_info_ext = 1000160000,
  /// @see VK_STRUCTURE_TYPE_SHADER_MODULE_VALIDATION_CACHE_CREATE_INFO_EXT
  shader_module_validation_cache_create_info_ext = 1000160001,
  /// @see VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_BINDING_FLAGS_CREATE_INFO_EXT
  descriptor_set_layout_binding_flags_create_info_ext = 1000161000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_FEATURES_EXT
  physical_device_descriptor_indexing_features_ext = 1000161001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_PROPERTIES_EXT
  physical_device_descriptor_indexing_properties_ext = 1000161002,
  /// @see
  /// VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_ALLOCATE_INFO_EXT
  descriptor_set_variable_descriptor_count_allocate_info_ext = 1000161003,
  /// @see
  /// VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_LAYOUT_SUPPORT_EXT
  descriptor_set_variable_descriptor_count_layout_support_ext = 1000161004,
  /// @see
  /// VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_SHADING_RATE_IMAGE_STATE_CREATE_INFO_NV
  pipeline_viewport_shading_rate_image_state_create_info_nv = 1000164000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADING_RATE_IMAGE_FEATURES_NV
  physical_device_shading_rate_image_features_nv = 1000164001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADING_RATE_IMAGE_PROPERTIES_NV
  physical_device_shading_rate_image_properties_nv = 1000164002,
  /// @see
  /// VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_COARSE_SAMPLE_ORDER_STATE_CREATE_INFO_NV
  pipeline_viewport_coarse_sample_order_state_create_info_nv = 1000164005,
  /// @see VK_STRUCTURE_TYPE_RAYTRACING_PIPELINE_CREATE_INFO_NVX
  raytracing_pipeline_create_info_nvx = 1000165000,
  /// @see VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_CREATE_INFO_NVX
  acceleration_structure_create_info_nvx = 1000165001,
  /// @see VK_STRUCTURE_TYPE_GEOMETRY_INSTANCE_NVX
  geometry_instance_nvx = 1000165002,
  /// @see VK_STRUCTURE_TYPE_GEOMETRY_NVX
  geometry_nvx = 1000165003,
  /// @see VK_STRUCTURE_TYPE_GEOMETRY_TRIANGLES_NVX
  geometry_triangles_nvx = 1000165004,
  /// @see VK_STRUCTURE_TYPE_GEOMETRY_AABB_NVX
  geometry_aabb_nvx = 1000165005,
  /// @see VK_STRUCTURE_TYPE_BIND_ACCELERATION_STRUCTURE_MEMORY_INFO_NVX
  bind_acceleration_structure_memory_info_nvx = 1000165006,
  /// @see VK_STRUCTURE_TYPE_DESCRIPTOR_ACCELERATION_STRUCTURE_INFO_NVX
  descriptor_acceleration_structure_info_nvx = 1000165007,
  /// @see VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_INFO_NVX
  acceleration_structure_memory_requirements_info_nvx = 1000165008,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAYTRACING_PROPERTIES_NVX
  physical_device_raytracing_properties_nvx = 1000165009,
  /// @see VK_STRUCTURE_TYPE_HIT_SHADER_MODULE_CREATE_INFO_NVX
  hit_shader_module_create_info_nvx = 1000165010,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_REPRESENTATIVE_FRAGMENT_TEST_FEATURES_NV
  physical_device_representative_fragment_test_features_nv = 1000166000,
  /// @see
  /// VK_STRUCTURE_TYPE_PIPELINE_REPRESENTATIVE_FRAGMENT_TEST_STATE_CREATE_INFO_NV
  pipeline_representative_fragment_test_state_create_info_nv = 1000166001,
  /// @see VK_STRUCTURE_TYPE_DEVICE_QUEUE_GLOBAL_PRIORITY_CREATE_INFO_EXT
  device_queue_global_priority_create_info_ext = 1000174000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_8BIT_STORAGE_FEATURES_KHR
  physical_device_8_bit_storage_features_khr = 1000177000,
  /// @see VK_STRUCTURE_TYPE_IMPORT_MEMORY_HOST_POINTER_INFO_EXT
  import_memory_host_pointer_info_ext = 1000178000,
  /// @see VK_STRUCTURE_TYPE_MEMORY_HOST_POINTER_PROPERTIES_EXT
  memory_host_pointer_properties_ext = 1000178001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_MEMORY_HOST_PROPERTIES_EXT
  physical_device_external_memory_host_properties_ext = 1000178002,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CORE_PROPERTIES_AMD
  physical_device_shader_core_properties_amd = 1000185000,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_PROPERTIES_EXT
  physical_device_vertex_attribute_divisor_properties_ext = 1000190000,
  /// @see VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_DIVISOR_STATE_CREATE_INFO_EXT
  pipeline_vertex_input_divisor_state_create_info_ext = 1000190001,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_FEATURES_EXT
  physical_device_vertex_attribute_divisor_features_ext = 1000190002,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COMPUTE_SHADER_DERIVATIVES_FEATURES_NV
  physical_device_compute_shader_derivatives_features_nv = 1000201000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MESH_SHADER_FEATURES_NV
  physical_device_mesh_shader_features_nv = 1000202000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MESH_SHADER_PROPERTIES_NV
  physical_device_mesh_shader_properties_nv = 1000202001,
  /// @see
  /// VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADER_BARYCENTRIC_FEATURES_NV
  physical_device_fragment_shader_barycentric_features_nv = 1000203000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_IMAGE_FOOTPRINT_FEATURES_NV
  physical_device_shader_image_footprint_features_nv = 1000204000,
  /// @see
  /// VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_EXCLUSIVE_SCISSOR_STATE_CREATE_INFO_NV
  pipeline_viewport_exclusive_scissor_state_create_info_nv = 1000205000,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXCLUSIVE_SCISSOR_FEATURES_NV
  physical_device_exclusive_scissor_features_nv = 1000205002,
  /// @see VK_STRUCTURE_TYPE_CHECKPOINT_DATA_NV
  checkpoint_data_nv = 1000206000,
  /// @see VK_STRUCTURE_TYPE_QUEUE_FAMILY_CHECKPOINT_PROPERTIES_NV
  queue_family_checkpoint_properties_nv = 1000206001,
  /// @see VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_MEMORY_MODEL_FEATURES_KHR
  physical_device_vulkan_memory_model_features_khr = 1000211000,
};
enum class access_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Controls coherency of indirect command reads
  /// @see VK_ACCESS_INDIRECT_COMMAND_READ_BIT
  indirect_command_read_bit = 1 << 0,
  /// Controls coherency of index reads
  /// @see VK_ACCESS_INDEX_READ_BIT
  index_read_bit = 1 << 1,
  /// Controls coherency of vertex attribute reads
  /// @see VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT
  vertex_attribute_read_bit = 1 << 2,
  /// Controls coherency of uniform buffer reads
  /// @see VK_ACCESS_UNIFORM_READ_BIT
  uniform_read_bit = 1 << 3,
  /// Controls coherency of input attachment reads
  /// @see VK_ACCESS_INPUT_ATTACHMENT_READ_BIT
  input_attachment_read_bit = 1 << 4,
  /// Controls coherency of shader reads
  /// @see VK_ACCESS_SHADER_READ_BIT
  shader_read_bit = 1 << 5,
  /// Controls coherency of shader writes
  /// @see VK_ACCESS_SHADER_WRITE_BIT
  shader_write_bit = 1 << 6,
  /// Controls coherency of color attachment reads
  /// @see VK_ACCESS_COLOR_ATTACHMENT_READ_BIT
  color_attachment_read_bit = 1 << 7,
  /// Controls coherency of color attachment writes
  /// @see VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT
  color_attachment_write_bit = 1 << 8,
  /// Controls coherency of depth/stencil attachment reads
  /// @see VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT
  depth_stencil_attachment_read_bit = 1 << 9,
  /// Controls coherency of depth/stencil attachment writes
  /// @see VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT
  depth_stencil_attachment_write_bit = 1 << 10,
  /// Controls coherency of transfer reads
  /// @see VK_ACCESS_TRANSFER_READ_BIT
  transfer_read_bit = 1 << 11,
  /// Controls coherency of transfer writes
  /// @see VK_ACCESS_TRANSFER_WRITE_BIT
  transfer_write_bit = 1 << 12,
  /// Controls coherency of host reads
  /// @see VK_ACCESS_HOST_READ_BIT
  host_read_bit = 1 << 13,
  /// Controls coherency of host writes
  /// @see VK_ACCESS_HOST_WRITE_BIT
  host_write_bit = 1 << 14,
  /// Controls coherency of memory reads
  /// @see VK_ACCESS_MEMORY_READ_BIT
  memory_read_bit = 1 << 15,
  /// Controls coherency of memory writes
  /// @see VK_ACCESS_MEMORY_WRITE_BIT
  memory_write_bit = 1 << 16,
  /// read access flag for reading conditional rendering predicate
  /// @see VK_ACCESS_CONDITIONAL_RENDERING_READ_BIT_EXT
  conditional_rendering_read_bit_ext = 1 << 20,
  /// @see VK_ACCESS_COMMAND_PROCESS_READ_BIT_NVX
  command_process_read_bit_nvx = 1 << 17,
  /// @see VK_ACCESS_COMMAND_PROCESS_WRITE_BIT_NVX
  command_process_write_bit_nvx = 1 << 18,
  /// @see VK_ACCESS_COLOR_ATTACHMENT_READ_NONCOHERENT_BIT_EXT
  color_attachment_read_noncoherent_bit_ext = 1 << 19,
  /// @see VK_ACCESS_SHADING_RATE_IMAGE_READ_BIT_NV
  shading_rate_image_read_bit_nv = 1 << 23,
  /// @see VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_NVX
  acceleration_structure_read_bit_nvx = 1 << 21,
  /// @see VK_ACCESS_ACCELERATION_STRUCTURE_WRITE_BIT_NVX
  acceleration_structure_write_bit_nvx = 1 << 22,
};
using access_flags = shift::core::bit_field<access_flag, VkAccessFlags>;
inline constexpr access_flags operator|(access_flag lhs, access_flag rhs)
{
  return access_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkBufferMemoryBarrier.
class buffer_memory_barrier
{
public:
  /// Default constructor.
  constexpr buffer_memory_barrier() = default;

  /// Constructor.
  constexpr buffer_memory_barrier(const void* initial_next,
                                  vk::access_flags initial_src_access_mask,
                                  vk::access_flags initial_dst_access_mask,
                                  uint32_t initial_src_queue_family_index,
                                  uint32_t initial_dst_queue_family_index,
                                  VkBuffer initial_buffer,
                                  VkDeviceSize initial_offset,
                                  VkDeviceSize initial_size) noexcept
  : _next(std::move(initial_next)),
    _src_access_mask(std::move(initial_src_access_mask)),
    _dst_access_mask(std::move(initial_dst_access_mask)),
    _src_queue_family_index(std::move(initial_src_queue_family_index)),
    _dst_queue_family_index(std::move(initial_dst_queue_family_index)),
    _buffer(std::move(initial_buffer)),
    _offset(std::move(initial_offset)),
    _size(std::move(initial_size))
  {
  }

  /// Copy constructor.
  constexpr buffer_memory_barrier(const buffer_memory_barrier& other) noexcept
  : _next(other._next),
    _src_access_mask(other._src_access_mask),
    _dst_access_mask(other._dst_access_mask),
    _src_queue_family_index(other._src_queue_family_index),
    _dst_queue_family_index(other._dst_queue_family_index),
    _buffer(other._buffer),
    _offset(other._offset),
    _size(other._size)
  {
  }

  /// Move constructor.
  constexpr buffer_memory_barrier(buffer_memory_barrier&& other) noexcept
  : _next(std::move(other._next)),
    _src_access_mask(std::move(other._src_access_mask)),
    _dst_access_mask(std::move(other._dst_access_mask)),
    _src_queue_family_index(std::move(other._src_queue_family_index)),
    _dst_queue_family_index(std::move(other._dst_queue_family_index)),
    _buffer(std::move(other._buffer)),
    _offset(std::move(other._offset)),
    _size(std::move(other._size))
  {
  }

  /// Copy assignment operator.
  constexpr buffer_memory_barrier& operator=(
    const buffer_memory_barrier& other) noexcept
  {
    _next = other._next;
    _src_access_mask = other._src_access_mask;
    _dst_access_mask = other._dst_access_mask;
    _src_queue_family_index = other._src_queue_family_index;
    _dst_queue_family_index = other._dst_queue_family_index;
    _buffer = other._buffer;
    _offset = other._offset;
    _size = other._size;
    return *this;
  }

  /// Move assignment operator.
  constexpr buffer_memory_barrier& operator=(
    buffer_memory_barrier&& other) noexcept
  {
    _next = std::move(other._next);
    _src_access_mask = std::move(other._src_access_mask);
    _dst_access_mask = std::move(other._dst_access_mask);
    _src_queue_family_index = std::move(other._src_queue_family_index);
    _dst_queue_family_index = std::move(other._dst_queue_family_index);
    _buffer = std::move(other._buffer);
    _offset = std::move(other._offset);
    _size = std::move(other._size);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBufferMemoryBarrier&() const
  {
    return *reinterpret_cast<const VkBufferMemoryBarrier*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::access_flags& src_access_mask()
  {
    return _src_access_mask;
  }

  constexpr const vk::access_flags& src_access_mask() const
  {
    return _src_access_mask;
  }

  void src_access_mask(vk::access_flags new_src_access_mask)
  {
    _src_access_mask = new_src_access_mask;
  }

  vk::access_flags& dst_access_mask()
  {
    return _dst_access_mask;
  }

  constexpr const vk::access_flags& dst_access_mask() const
  {
    return _dst_access_mask;
  }

  void dst_access_mask(vk::access_flags new_dst_access_mask)
  {
    _dst_access_mask = new_dst_access_mask;
  }

  uint32_t& src_queue_family_index()
  {
    return _src_queue_family_index;
  }

  constexpr const uint32_t& src_queue_family_index() const
  {
    return _src_queue_family_index;
  }

  void src_queue_family_index(uint32_t new_src_queue_family_index)
  {
    _src_queue_family_index = new_src_queue_family_index;
  }

  uint32_t& dst_queue_family_index()
  {
    return _dst_queue_family_index;
  }

  constexpr const uint32_t& dst_queue_family_index() const
  {
    return _dst_queue_family_index;
  }

  void dst_queue_family_index(uint32_t new_dst_queue_family_index)
  {
    _dst_queue_family_index = new_dst_queue_family_index;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

  VkDeviceSize& offset()
  {
    return _offset;
  }

  constexpr const VkDeviceSize& offset() const
  {
    return _offset;
  }

  void offset(VkDeviceSize new_offset)
  {
    _offset = new_offset;
  }

  VkDeviceSize& size()
  {
    return _size;
  }

  constexpr const VkDeviceSize& size() const
  {
    return _size;
  }

  void size(VkDeviceSize new_size)
  {
    _size = new_size;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::buffer_memory_barrier;
  const void* _next = nullptr;
  /// Memory accesses from the source of the dependency to synchronize
  vk::access_flags _src_access_mask = vk::access_flag::none;
  /// Memory accesses from the destination of the dependency to synchronize
  vk::access_flags _dst_access_mask = vk::access_flag::none;
  /// Queue family to transition ownership from
  uint32_t _src_queue_family_index = 0;
  /// Queue family to transition ownership to
  uint32_t _dst_queue_family_index = 0;
  /// Buffer to sync
  VkBuffer _buffer = nullptr;
  /// Offset within the buffer to sync
  VkDeviceSize _offset = 0;
  /// Amount of bytes to sync
  VkDeviceSize _size = 0;
};
static_assert(sizeof(buffer_memory_barrier) == sizeof(::VkBufferMemoryBarrier),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDispatchIndirectCommand.
class dispatch_indirect_command
{
public:
  /// Default constructor.
  constexpr dispatch_indirect_command() = default;

  /// Constructor.
  constexpr dispatch_indirect_command(uint32_t initial_x, uint32_t initial_y,
                                      uint32_t initial_z) noexcept
  : _x(std::move(initial_x)), _y(std::move(initial_y)), _z(std::move(initial_z))
  {
  }

  /// Copy constructor.
  constexpr dispatch_indirect_command(const dispatch_indirect_command& other) =
    default;

  /// Move constructor.
  constexpr dispatch_indirect_command(dispatch_indirect_command&& other) =
    default;

  /// Copy assignment operator.
  constexpr dispatch_indirect_command& operator=(
    const dispatch_indirect_command& other) = default;

  /// Move assignment operator.
  constexpr dispatch_indirect_command& operator=(
    dispatch_indirect_command&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkDispatchIndirectCommand&() const
  {
    return *reinterpret_cast<const VkDispatchIndirectCommand*>(this);
  }

  uint32_t& x()
  {
    return _x;
  }

  constexpr const uint32_t& x() const
  {
    return _x;
  }

  void x(uint32_t new_x)
  {
    _x = new_x;
  }

  uint32_t& y()
  {
    return _y;
  }

  constexpr const uint32_t& y() const
  {
    return _y;
  }

  void y(uint32_t new_y)
  {
    _y = new_y;
  }

  uint32_t& z()
  {
    return _z;
  }

  constexpr const uint32_t& z() const
  {
    return _z;
  }

  void z(uint32_t new_z)
  {
    _z = new_z;
  }

private:
  uint32_t _x = 0;
  uint32_t _y = 0;
  uint32_t _z = 0;
};
static_assert(sizeof(dispatch_indirect_command) ==
                sizeof(::VkDispatchIndirectCommand),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDrawIndexedIndirectCommand.
class draw_indexed_indirect_command
{
public:
  /// Default constructor.
  constexpr draw_indexed_indirect_command() = default;

  /// Constructor.
  constexpr draw_indexed_indirect_command(
    uint32_t initial_index_count, uint32_t initial_instance_count,
    uint32_t initial_first_index, int32_t initial_vertex_offset,
    uint32_t initial_first_instance) noexcept
  : _index_count(std::move(initial_index_count)),
    _instance_count(std::move(initial_instance_count)),
    _first_index(std::move(initial_first_index)),
    _vertex_offset(std::move(initial_vertex_offset)),
    _first_instance(std::move(initial_first_instance))
  {
  }

  /// Copy constructor.
  constexpr draw_indexed_indirect_command(
    const draw_indexed_indirect_command& other) = default;

  /// Move constructor.
  constexpr draw_indexed_indirect_command(
    draw_indexed_indirect_command&& other) = default;

  /// Copy assignment operator.
  constexpr draw_indexed_indirect_command& operator=(
    const draw_indexed_indirect_command& other) = default;

  /// Move assignment operator.
  constexpr draw_indexed_indirect_command& operator=(
    draw_indexed_indirect_command&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkDrawIndexedIndirectCommand&() const
  {
    return *reinterpret_cast<const VkDrawIndexedIndirectCommand*>(this);
  }

  uint32_t& index_count()
  {
    return _index_count;
  }

  constexpr const uint32_t& index_count() const
  {
    return _index_count;
  }

  void index_count(uint32_t new_index_count)
  {
    _index_count = new_index_count;
  }

  uint32_t& instance_count()
  {
    return _instance_count;
  }

  constexpr const uint32_t& instance_count() const
  {
    return _instance_count;
  }

  void instance_count(uint32_t new_instance_count)
  {
    _instance_count = new_instance_count;
  }

  uint32_t& first_index()
  {
    return _first_index;
  }

  constexpr const uint32_t& first_index() const
  {
    return _first_index;
  }

  void first_index(uint32_t new_first_index)
  {
    _first_index = new_first_index;
  }

  int32_t& vertex_offset()
  {
    return _vertex_offset;
  }

  constexpr const int32_t& vertex_offset() const
  {
    return _vertex_offset;
  }

  void vertex_offset(int32_t new_vertex_offset)
  {
    _vertex_offset = new_vertex_offset;
  }

  uint32_t& first_instance()
  {
    return _first_instance;
  }

  constexpr const uint32_t& first_instance() const
  {
    return _first_instance;
  }

  void first_instance(uint32_t new_first_instance)
  {
    _first_instance = new_first_instance;
  }

private:
  uint32_t _index_count = 0;
  uint32_t _instance_count = 0;
  uint32_t _first_index = 0;
  int32_t _vertex_offset = 0;
  uint32_t _first_instance = 0;
};
static_assert(sizeof(draw_indexed_indirect_command) ==
                sizeof(::VkDrawIndexedIndirectCommand),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDrawIndirectCommand.
class draw_indirect_command
{
public:
  /// Default constructor.
  constexpr draw_indirect_command() = default;

  /// Constructor.
  constexpr draw_indirect_command(uint32_t initial_vertex_count,
                                  uint32_t initial_instance_count,
                                  uint32_t initial_first_vertex,
                                  uint32_t initial_first_instance) noexcept
  : _vertex_count(std::move(initial_vertex_count)),
    _instance_count(std::move(initial_instance_count)),
    _first_vertex(std::move(initial_first_vertex)),
    _first_instance(std::move(initial_first_instance))
  {
  }

  /// Copy constructor.
  constexpr draw_indirect_command(const draw_indirect_command& other) = default;

  /// Move constructor.
  constexpr draw_indirect_command(draw_indirect_command&& other) = default;

  /// Copy assignment operator.
  constexpr draw_indirect_command& operator=(
    const draw_indirect_command& other) = default;

  /// Move assignment operator.
  constexpr draw_indirect_command& operator=(draw_indirect_command&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkDrawIndirectCommand&() const
  {
    return *reinterpret_cast<const VkDrawIndirectCommand*>(this);
  }

  uint32_t& vertex_count()
  {
    return _vertex_count;
  }

  constexpr const uint32_t& vertex_count() const
  {
    return _vertex_count;
  }

  void vertex_count(uint32_t new_vertex_count)
  {
    _vertex_count = new_vertex_count;
  }

  uint32_t& instance_count()
  {
    return _instance_count;
  }

  constexpr const uint32_t& instance_count() const
  {
    return _instance_count;
  }

  void instance_count(uint32_t new_instance_count)
  {
    _instance_count = new_instance_count;
  }

  uint32_t& first_vertex()
  {
    return _first_vertex;
  }

  constexpr const uint32_t& first_vertex() const
  {
    return _first_vertex;
  }

  void first_vertex(uint32_t new_first_vertex)
  {
    _first_vertex = new_first_vertex;
  }

  uint32_t& first_instance()
  {
    return _first_instance;
  }

  constexpr const uint32_t& first_instance() const
  {
    return _first_instance;
  }

  void first_instance(uint32_t new_first_instance)
  {
    _first_instance = new_first_instance;
  }

private:
  uint32_t _vertex_count = 0;
  uint32_t _instance_count = 0;
  uint32_t _first_vertex = 0;
  uint32_t _first_instance = 0;
};
static_assert(sizeof(draw_indirect_command) == sizeof(::VkDrawIndirectCommand),
              "struct and wrapper have different size!");

enum class image_layout
{
  /// Implicit layout an image is when its contents are undefined due to various
  /// reasons (e.g. right after creation)
  /// @see VK_IMAGE_LAYOUT_UNDEFINED
  undefined = 0,
  /// General layout when image can be used for any kind of access
  /// @see VK_IMAGE_LAYOUT_GENERAL
  general = 1,
  /// Optimal layout when image is only used for color attachment read/write
  /// @see VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL
  color_attachment_optimal = 2,
  /// Optimal layout when image is only used for depth/stencil attachment
  /// read/write
  /// @see VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL
  depth_stencil_attachment_optimal = 3,
  /// Optimal layout when image is used for read only depth/stencil attachment
  /// and shader access
  /// @see VK_IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL
  depth_stencil_read_only_optimal = 4,
  /// Optimal layout when image is used for read only shader access
  /// @see VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL
  shader_read_only_optimal = 5,
  /// Optimal layout when image is used only as source of transfer operations
  /// @see VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL
  transfer_src_optimal = 6,
  /// Optimal layout when image is used only as destination of transfer
  /// operations
  /// @see VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL
  transfer_dst_optimal = 7,
  /// Initial layout used when the data is populated by the CPU
  /// @see VK_IMAGE_LAYOUT_PREINITIALIZED
  preinitialized = 8,
  /// @see VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL
  depth_read_only_stencil_attachment_optimal = 1000117000,
  /// @see VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL
  depth_attachment_stencil_read_only_optimal = 1000117001,
  /// @see VK_IMAGE_LAYOUT_PRESENT_SRC_KHR
  present_src_khr = 1000001002,
  /// @see VK_IMAGE_LAYOUT_SHARED_PRESENT_KHR
  shared_present_khr = 1000111000,
  /// @see VK_IMAGE_LAYOUT_SHADING_RATE_OPTIMAL_NV
  shading_rate_optimal_nv = 1000164003,
};
enum class image_aspect_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_IMAGE_ASPECT_COLOR_BIT
  color_bit = 1 << 0,
  /// @see VK_IMAGE_ASPECT_DEPTH_BIT
  depth_bit = 1 << 1,
  /// @see VK_IMAGE_ASPECT_STENCIL_BIT
  stencil_bit = 1 << 2,
  /// @see VK_IMAGE_ASPECT_METADATA_BIT
  metadata_bit = 1 << 3,
  /// @see VK_IMAGE_ASPECT_PLANE_0_BIT
  plane_0_bit = 1 << 4,
  /// @see VK_IMAGE_ASPECT_PLANE_1_BIT
  plane_1_bit = 1 << 5,
  /// @see VK_IMAGE_ASPECT_PLANE_2_BIT
  plane_2_bit = 1 << 6,
};
using image_aspect_flags =
  shift::core::bit_field<image_aspect_flag, VkImageAspectFlags>;
inline constexpr image_aspect_flags operator|(image_aspect_flag lhs,
                                              image_aspect_flag rhs)
{
  return image_aspect_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkImageSubresourceRange.
class image_subresource_range
{
public:
  /// Default constructor.
  constexpr image_subresource_range() = default;

  /// Constructor.
  constexpr image_subresource_range(vk::image_aspect_flags initial_aspect_mask,
                                    uint32_t initial_base_mip_level,
                                    uint32_t initial_level_count,
                                    uint32_t initial_base_array_layer,
                                    uint32_t initial_layer_count) noexcept
  : _aspect_mask(std::move(initial_aspect_mask)),
    _base_mip_level(std::move(initial_base_mip_level)),
    _level_count(std::move(initial_level_count)),
    _base_array_layer(std::move(initial_base_array_layer)),
    _layer_count(std::move(initial_layer_count))
  {
  }

  /// Copy constructor.
  constexpr image_subresource_range(const image_subresource_range& other) =
    default;

  /// Move constructor.
  constexpr image_subresource_range(image_subresource_range&& other) = default;

  /// Copy assignment operator.
  constexpr image_subresource_range& operator=(
    const image_subresource_range& other) = default;

  /// Move assignment operator.
  constexpr image_subresource_range& operator=(
    image_subresource_range&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkImageSubresourceRange&() const
  {
    return *reinterpret_cast<const VkImageSubresourceRange*>(this);
  }

  vk::image_aspect_flags& aspect_mask()
  {
    return _aspect_mask;
  }

  constexpr const vk::image_aspect_flags& aspect_mask() const
  {
    return _aspect_mask;
  }

  void aspect_mask(vk::image_aspect_flags new_aspect_mask)
  {
    _aspect_mask = new_aspect_mask;
  }

  uint32_t& base_mip_level()
  {
    return _base_mip_level;
  }

  constexpr const uint32_t& base_mip_level() const
  {
    return _base_mip_level;
  }

  void base_mip_level(uint32_t new_base_mip_level)
  {
    _base_mip_level = new_base_mip_level;
  }

  uint32_t& level_count()
  {
    return _level_count;
  }

  constexpr const uint32_t& level_count() const
  {
    return _level_count;
  }

  void level_count(uint32_t new_level_count)
  {
    _level_count = new_level_count;
  }

  uint32_t& base_array_layer()
  {
    return _base_array_layer;
  }

  constexpr const uint32_t& base_array_layer() const
  {
    return _base_array_layer;
  }

  void base_array_layer(uint32_t new_base_array_layer)
  {
    _base_array_layer = new_base_array_layer;
  }

  uint32_t& layer_count()
  {
    return _layer_count;
  }

  constexpr const uint32_t& layer_count() const
  {
    return _layer_count;
  }

  void layer_count(uint32_t new_layer_count)
  {
    _layer_count = new_layer_count;
  }

private:
  vk::image_aspect_flags _aspect_mask = vk::image_aspect_flag::none;
  uint32_t _base_mip_level = 0;
  uint32_t _level_count = 0;
  uint32_t _base_array_layer = 0;
  uint32_t _layer_count = 0;
};
static_assert(sizeof(image_subresource_range) ==
                sizeof(::VkImageSubresourceRange),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImageMemoryBarrier.
class image_memory_barrier
{
public:
  /// Default constructor.
  constexpr image_memory_barrier() = default;

  /// Constructor.
  constexpr image_memory_barrier(
    const void* initial_next, vk::access_flags initial_src_access_mask,
    vk::access_flags initial_dst_access_mask,
    vk::image_layout initial_old_layout, vk::image_layout initial_new_layout,
    uint32_t initial_src_queue_family_index,
    uint32_t initial_dst_queue_family_index, VkImage initial_image,
    vk::image_subresource_range initial_subresource_range) noexcept
  : _next(std::move(initial_next)),
    _src_access_mask(std::move(initial_src_access_mask)),
    _dst_access_mask(std::move(initial_dst_access_mask)),
    _old_layout(std::move(initial_old_layout)),
    _new_layout(std::move(initial_new_layout)),
    _src_queue_family_index(std::move(initial_src_queue_family_index)),
    _dst_queue_family_index(std::move(initial_dst_queue_family_index)),
    _image(std::move(initial_image)),
    _subresource_range(std::move(initial_subresource_range))
  {
  }

  /// Copy constructor.
  constexpr image_memory_barrier(const image_memory_barrier& other) noexcept
  : _next(other._next),
    _src_access_mask(other._src_access_mask),
    _dst_access_mask(other._dst_access_mask),
    _old_layout(other._old_layout),
    _new_layout(other._new_layout),
    _src_queue_family_index(other._src_queue_family_index),
    _dst_queue_family_index(other._dst_queue_family_index),
    _image(other._image),
    _subresource_range(other._subresource_range)
  {
  }

  /// Move constructor.
  constexpr image_memory_barrier(image_memory_barrier&& other) noexcept
  : _next(std::move(other._next)),
    _src_access_mask(std::move(other._src_access_mask)),
    _dst_access_mask(std::move(other._dst_access_mask)),
    _old_layout(std::move(other._old_layout)),
    _new_layout(std::move(other._new_layout)),
    _src_queue_family_index(std::move(other._src_queue_family_index)),
    _dst_queue_family_index(std::move(other._dst_queue_family_index)),
    _image(std::move(other._image)),
    _subresource_range(std::move(other._subresource_range))
  {
  }

  /// Copy assignment operator.
  constexpr image_memory_barrier& operator=(
    const image_memory_barrier& other) noexcept
  {
    _next = other._next;
    _src_access_mask = other._src_access_mask;
    _dst_access_mask = other._dst_access_mask;
    _old_layout = other._old_layout;
    _new_layout = other._new_layout;
    _src_queue_family_index = other._src_queue_family_index;
    _dst_queue_family_index = other._dst_queue_family_index;
    _image = other._image;
    _subresource_range = other._subresource_range;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_memory_barrier& operator=(
    image_memory_barrier&& other) noexcept
  {
    _next = std::move(other._next);
    _src_access_mask = std::move(other._src_access_mask);
    _dst_access_mask = std::move(other._dst_access_mask);
    _old_layout = std::move(other._old_layout);
    _new_layout = std::move(other._new_layout);
    _src_queue_family_index = std::move(other._src_queue_family_index);
    _dst_queue_family_index = std::move(other._dst_queue_family_index);
    _image = std::move(other._image);
    _subresource_range = std::move(other._subresource_range);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageMemoryBarrier&() const
  {
    return *reinterpret_cast<const VkImageMemoryBarrier*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::access_flags& src_access_mask()
  {
    return _src_access_mask;
  }

  constexpr const vk::access_flags& src_access_mask() const
  {
    return _src_access_mask;
  }

  void src_access_mask(vk::access_flags new_src_access_mask)
  {
    _src_access_mask = new_src_access_mask;
  }

  vk::access_flags& dst_access_mask()
  {
    return _dst_access_mask;
  }

  constexpr const vk::access_flags& dst_access_mask() const
  {
    return _dst_access_mask;
  }

  void dst_access_mask(vk::access_flags new_dst_access_mask)
  {
    _dst_access_mask = new_dst_access_mask;
  }

  vk::image_layout& old_layout()
  {
    return _old_layout;
  }

  constexpr const vk::image_layout& old_layout() const
  {
    return _old_layout;
  }

  void old_layout(vk::image_layout new_old_layout)
  {
    _old_layout = new_old_layout;
  }

  vk::image_layout& new_layout()
  {
    return _new_layout;
  }

  constexpr const vk::image_layout& new_layout() const
  {
    return _new_layout;
  }

  void new_layout(vk::image_layout new_new_layout)
  {
    _new_layout = new_new_layout;
  }

  uint32_t& src_queue_family_index()
  {
    return _src_queue_family_index;
  }

  constexpr const uint32_t& src_queue_family_index() const
  {
    return _src_queue_family_index;
  }

  void src_queue_family_index(uint32_t new_src_queue_family_index)
  {
    _src_queue_family_index = new_src_queue_family_index;
  }

  uint32_t& dst_queue_family_index()
  {
    return _dst_queue_family_index;
  }

  constexpr const uint32_t& dst_queue_family_index() const
  {
    return _dst_queue_family_index;
  }

  void dst_queue_family_index(uint32_t new_dst_queue_family_index)
  {
    _dst_queue_family_index = new_dst_queue_family_index;
  }

  VkImage& image()
  {
    return _image;
  }

  constexpr const VkImage& image() const
  {
    return _image;
  }

  void image(VkImage new_image)
  {
    _image = new_image;
  }

  vk::image_subresource_range& subresource_range()
  {
    return _subresource_range;
  }

  constexpr const vk::image_subresource_range& subresource_range() const
  {
    return _subresource_range;
  }

  void subresource_range(vk::image_subresource_range new_subresource_range)
  {
    _subresource_range = new_subresource_range;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_memory_barrier;
  const void* _next = nullptr;
  /// Memory accesses from the source of the dependency to synchronize
  vk::access_flags _src_access_mask = vk::access_flag::none;
  /// Memory accesses from the destination of the dependency to synchronize
  vk::access_flags _dst_access_mask = vk::access_flag::none;
  /// Current layout of the image
  vk::image_layout _old_layout = vk::image_layout::undefined;
  /// New layout to transition the image to
  vk::image_layout _new_layout = vk::image_layout::undefined;
  /// Queue family to transition ownership from
  uint32_t _src_queue_family_index = 0;
  /// Queue family to transition ownership to
  uint32_t _dst_queue_family_index = 0;
  /// Image to sync
  VkImage _image = nullptr;
  /// Subresource range to sync
  vk::image_subresource_range _subresource_range =
    vk::image_subresource_range{};
};
static_assert(sizeof(image_memory_barrier) == sizeof(::VkImageMemoryBarrier),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkMemoryBarrier.
class memory_barrier
{
public:
  /// Default constructor.
  constexpr memory_barrier() = default;

  /// Constructor.
  constexpr memory_barrier(const void* initial_next,
                           vk::access_flags initial_src_access_mask,
                           vk::access_flags initial_dst_access_mask) noexcept
  : _next(std::move(initial_next)),
    _src_access_mask(std::move(initial_src_access_mask)),
    _dst_access_mask(std::move(initial_dst_access_mask))
  {
  }

  /// Copy constructor.
  constexpr memory_barrier(const memory_barrier& other) noexcept
  : _next(other._next),
    _src_access_mask(other._src_access_mask),
    _dst_access_mask(other._dst_access_mask)
  {
  }

  /// Move constructor.
  constexpr memory_barrier(memory_barrier&& other) noexcept
  : _next(std::move(other._next)),
    _src_access_mask(std::move(other._src_access_mask)),
    _dst_access_mask(std::move(other._dst_access_mask))
  {
  }

  /// Copy assignment operator.
  constexpr memory_barrier& operator=(const memory_barrier& other) noexcept
  {
    _next = other._next;
    _src_access_mask = other._src_access_mask;
    _dst_access_mask = other._dst_access_mask;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_barrier& operator=(memory_barrier&& other) noexcept
  {
    _next = std::move(other._next);
    _src_access_mask = std::move(other._src_access_mask);
    _dst_access_mask = std::move(other._dst_access_mask);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryBarrier&() const
  {
    return *reinterpret_cast<const VkMemoryBarrier*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::access_flags& src_access_mask()
  {
    return _src_access_mask;
  }

  constexpr const vk::access_flags& src_access_mask() const
  {
    return _src_access_mask;
  }

  void src_access_mask(vk::access_flags new_src_access_mask)
  {
    _src_access_mask = new_src_access_mask;
  }

  vk::access_flags& dst_access_mask()
  {
    return _dst_access_mask;
  }

  constexpr const vk::access_flags& dst_access_mask() const
  {
    return _dst_access_mask;
  }

  void dst_access_mask(vk::access_flags new_dst_access_mask)
  {
    _dst_access_mask = new_dst_access_mask;
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::memory_barrier;
  const void* _next = nullptr;
  /// Memory accesses from the source of the dependency to synchronize
  vk::access_flags _src_access_mask = vk::access_flag::none;
  /// Memory accesses from the destination of the dependency to synchronize
  vk::access_flags _dst_access_mask = vk::access_flag::none;
};
static_assert(sizeof(memory_barrier) == sizeof(::VkMemoryBarrier),
              "struct and wrapper have different size!");

enum class object_type
{
  /// @see VK_OBJECT_TYPE_UNKNOWN
  unknown = 0,
  /// VkInstance
  /// @see VK_OBJECT_TYPE_INSTANCE
  instance = 1,
  /// VkPhysicalDevice
  /// @see VK_OBJECT_TYPE_PHYSICAL_DEVICE
  physical_device = 2,
  /// VkDevice
  /// @see VK_OBJECT_TYPE_DEVICE
  device = 3,
  /// VkQueue
  /// @see VK_OBJECT_TYPE_QUEUE
  queue = 4,
  /// VkSemaphore
  /// @see VK_OBJECT_TYPE_SEMAPHORE
  semaphore = 5,
  /// VkCommandBuffer
  /// @see VK_OBJECT_TYPE_COMMAND_BUFFER
  command_buffer = 6,
  /// VkFence
  /// @see VK_OBJECT_TYPE_FENCE
  fence = 7,
  /// VkDeviceMemory
  /// @see VK_OBJECT_TYPE_DEVICE_MEMORY
  device_memory = 8,
  /// VkBuffer
  /// @see VK_OBJECT_TYPE_BUFFER
  buffer = 9,
  /// VkImage
  /// @see VK_OBJECT_TYPE_IMAGE
  image = 10,
  /// VkEvent
  /// @see VK_OBJECT_TYPE_EVENT
  event = 11,
  /// VkQueryPool
  /// @see VK_OBJECT_TYPE_QUERY_POOL
  query_pool = 12,
  /// VkBufferView
  /// @see VK_OBJECT_TYPE_BUFFER_VIEW
  buffer_view = 13,
  /// VkImageView
  /// @see VK_OBJECT_TYPE_IMAGE_VIEW
  image_view = 14,
  /// VkShaderModule
  /// @see VK_OBJECT_TYPE_SHADER_MODULE
  shader_module = 15,
  /// VkPipelineCache
  /// @see VK_OBJECT_TYPE_PIPELINE_CACHE
  pipeline_cache = 16,
  /// VkPipelineLayout
  /// @see VK_OBJECT_TYPE_PIPELINE_LAYOUT
  pipeline_layout = 17,
  /// VkRenderPass
  /// @see VK_OBJECT_TYPE_RENDER_PASS
  render_pass = 18,
  /// VkPipeline
  /// @see VK_OBJECT_TYPE_PIPELINE
  pipeline = 19,
  /// VkDescriptorSetLayout
  /// @see VK_OBJECT_TYPE_DESCRIPTOR_SET_LAYOUT
  descriptor_set_layout = 20,
  /// VkSampler
  /// @see VK_OBJECT_TYPE_SAMPLER
  sampler = 21,
  /// VkDescriptorPool
  /// @see VK_OBJECT_TYPE_DESCRIPTOR_POOL
  descriptor_pool = 22,
  /// VkDescriptorSet
  /// @see VK_OBJECT_TYPE_DESCRIPTOR_SET
  descriptor_set = 23,
  /// VkFramebuffer
  /// @see VK_OBJECT_TYPE_FRAMEBUFFER
  framebuffer = 24,
  /// VkCommandPool
  /// @see VK_OBJECT_TYPE_COMMAND_POOL
  command_pool = 25,
  /// @see VK_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION
  sampler_ycbcr_conversion = 1000156000,
  /// @see VK_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE
  descriptor_update_template = 1000085000,
  /// VkSurfaceKHR
  /// @see VK_OBJECT_TYPE_SURFACE_KHR
  surface_khr = 1000000000,
  /// VkSwapchainKHR
  /// @see VK_OBJECT_TYPE_SWAPCHAIN_KHR
  swapchain_khr = 1000001000,
  /// VkDisplayKHR
  /// @see VK_OBJECT_TYPE_DISPLAY_KHR
  display_khr = 1000002000,
  /// VkDisplayModeKHR
  /// @see VK_OBJECT_TYPE_DISPLAY_MODE_KHR
  display_mode_khr = 1000002001,
  /// VkobjectTableNVX
  /// @see VK_OBJECT_TYPE_OBJECT_TABLE_NVX
  object_table_nvx = 1000086000,
  /// VkIndirectCommandsLayoutNVX
  /// @see VK_OBJECT_TYPE_INDIRECT_COMMANDS_LAYOUT_NVX
  indirect_commands_layout_nvx = 1000086001,
  /// VkDebugUtilsMessengerEXT
  /// @see VK_OBJECT_TYPE_DEBUG_UTILS_MESSENGER_EXT
  debug_utils_messenger_ext = 1000128000,
  /// VkValidationCacheEXT
  /// @see VK_OBJECT_TYPE_VALIDATION_CACHE_EXT
  validation_cache_ext = 1000160000,
  /// @see VK_OBJECT_TYPE_ACCELERATION_STRUCTURE_NVX
  acceleration_structure_nvx = 1000165000,
};
enum class vendor_id
{
  /// Vivante vendor ID
  /// @see VK_VENDOR_ID_VIV
  viv = 0x10001,
  /// VeriSilicon vendor ID
  /// @see VK_VENDOR_ID_VSI
  vsi = 0x10002,
  /// Kazan Software Renderer
  /// @see VK_VENDOR_ID_KAZAN
  kazan = 0x10003,
};
enum class result
{
  /// Command completed successfully
  /// @see VK_SUCCESS
  success = 0,
  /// A fence or query has not yet completed
  /// @see VK_NOT_READY
  not_ready = 1,
  /// A wait operation has not completed in the specified time
  /// @see VK_TIMEOUT
  timeout = 2,
  /// An event is signaled
  /// @see VK_EVENT_SET
  event_set = 3,
  /// An event is unsignaled
  /// @see VK_EVENT_RESET
  event_reset = 4,
  /// A return array was too small for the result
  /// @see VK_INCOMPLETE
  incomplete = 5,
  /// A host memory allocation has failed
  /// @see VK_ERROR_OUT_OF_HOST_MEMORY
  error_out_of_host_memory = -1,
  /// A device memory allocation has failed
  /// @see VK_ERROR_OUT_OF_DEVICE_MEMORY
  error_out_of_device_memory = -2,
  /// Initialization of a object has failed
  /// @see VK_ERROR_INITIALIZATION_FAILED
  error_initialization_failed = -3,
  /// The logical device has been lost. See <<devsandqueues-lost-device>>
  /// @see VK_ERROR_DEVICE_LOST
  error_device_lost = -4,
  /// Mapping of a memory object has failed
  /// @see VK_ERROR_MEMORY_MAP_FAILED
  error_memory_map_failed = -5,
  /// Layer specified does not exist
  /// @see VK_ERROR_LAYER_NOT_PRESENT
  error_layer_not_present = -6,
  /// Extension specified does not exist
  /// @see VK_ERROR_EXTENSION_NOT_PRESENT
  error_extension_not_present = -7,
  /// Requested feature is not available on this device
  /// @see VK_ERROR_FEATURE_NOT_PRESENT
  error_feature_not_present = -8,
  /// Unable to find a Vulkan driver
  /// @see VK_ERROR_INCOMPATIBLE_DRIVER
  error_incompatible_driver = -9,
  /// Too many objects of the type have already been created
  /// @see VK_ERROR_TOO_MANY_OBJECTS
  error_too_many_objects = -10,
  /// Requested format is not supported on this device
  /// @see VK_ERROR_FORMAT_NOT_SUPPORTED
  error_format_not_supported = -11,
  /// A requested pool allocation has failed due to fragmentation of the pool's
  /// memory
  /// @see VK_ERROR_FRAGMENTED_POOL
  error_fragmented_pool = -12,
  /// @see VK_ERROR_OUT_OF_POOL_MEMORY
  error_out_of_pool_memory = -1000069000,
  /// @see VK_ERROR_INVALID_EXTERNAL_HANDLE
  error_invalid_external_handle = -1000072003,
  /// @see VK_ERROR_SURFACE_LOST_KHR
  error_surface_lost_khr = -1000000000,
  /// @see VK_ERROR_NATIVE_WINDOW_IN_USE_KHR
  error_native_window_in_use_khr = -1000000001,
  /// @see VK_SUBOPTIMAL_KHR
  suboptimal_khr = 1000001003,
  /// @see VK_ERROR_OUT_OF_DATE_KHR
  error_out_of_date_khr = -1000001004,
  /// @see VK_ERROR_INCOMPATIBLE_DISPLAY_KHR
  error_incompatible_display_khr = -1000003001,
  /// @see VK_ERROR_INVALID_SHADER_NV
  error_invalid_shader_nv = -1000012000,
  /// @see VK_ERROR_FRAGMENTATION_EXT
  error_fragmentation_ext = -1000161000,
  /// @see VK_ERROR_NOT_PERMITTED_EXT
  error_not_permitted_ext = -1000174001,
};
enum class instance_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using instance_create_flags =
  shift::core::bit_field<instance_create_flag, VkInstanceCreateFlags>;
inline constexpr instance_create_flags operator|(instance_create_flag lhs,
                                                 instance_create_flag rhs)
{
  return instance_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkApplicationInfo.
class application_info
{
public:
  /// Default constructor.
  constexpr application_info() = default;

  /// Constructor.
  constexpr application_info(const void* initial_next,
                             const char* initial_application_name,
                             uint32_t initial_application_version,
                             const char* initial_engine_name,
                             uint32_t initial_engine_version,
                             uint32_t initial_api_version) noexcept
  : _next(std::move(initial_next)),
    _application_name(std::move(initial_application_name)),
    _application_version(std::move(initial_application_version)),
    _engine_name(std::move(initial_engine_name)),
    _engine_version(std::move(initial_engine_version)),
    _api_version(std::move(initial_api_version))
  {
  }

  /// Copy constructor.
  constexpr application_info(const application_info& other) noexcept
  : _next(other._next),
    _application_name(other._application_name),
    _application_version(other._application_version),
    _engine_name(other._engine_name),
    _engine_version(other._engine_version),
    _api_version(other._api_version)
  {
  }

  /// Move constructor.
  constexpr application_info(application_info&& other) noexcept
  : _next(std::move(other._next)),
    _application_name(std::move(other._application_name)),
    _application_version(std::move(other._application_version)),
    _engine_name(std::move(other._engine_name)),
    _engine_version(std::move(other._engine_version)),
    _api_version(std::move(other._api_version))
  {
  }

  /// Copy assignment operator.
  constexpr application_info& operator=(const application_info& other) noexcept
  {
    _next = other._next;
    _application_name = other._application_name;
    _application_version = other._application_version;
    _engine_name = other._engine_name;
    _engine_version = other._engine_version;
    _api_version = other._api_version;
    return *this;
  }

  /// Move assignment operator.
  constexpr application_info& operator=(application_info&& other) noexcept
  {
    _next = std::move(other._next);
    _application_name = std::move(other._application_name);
    _application_version = std::move(other._application_version);
    _engine_name = std::move(other._engine_name);
    _engine_version = std::move(other._engine_version);
    _api_version = std::move(other._api_version);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkApplicationInfo&() const
  {
    return *reinterpret_cast<const VkApplicationInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  const char* application_name()
  {
    return _application_name;
  }

  constexpr const char* application_name() const
  {
    return _application_name;
  }

  void application_name(const char* new_application_name)
  {
    _application_name = new_application_name;
  }

  uint32_t& application_version()
  {
    return _application_version;
  }

  constexpr const uint32_t& application_version() const
  {
    return _application_version;
  }

  void application_version(uint32_t new_application_version)
  {
    _application_version = new_application_version;
  }

  const char* engine_name()
  {
    return _engine_name;
  }

  constexpr const char* engine_name() const
  {
    return _engine_name;
  }

  void engine_name(const char* new_engine_name)
  {
    _engine_name = new_engine_name;
  }

  uint32_t& engine_version()
  {
    return _engine_version;
  }

  constexpr const uint32_t& engine_version() const
  {
    return _engine_version;
  }

  void engine_version(uint32_t new_engine_version)
  {
    _engine_version = new_engine_version;
  }

  uint32_t& api_version()
  {
    return _api_version;
  }

  constexpr const uint32_t& api_version() const
  {
    return _api_version;
  }

  void api_version(uint32_t new_api_version)
  {
    _api_version = new_api_version;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::application_info;
  const void* _next = nullptr;
  const char* _application_name = nullptr;
  uint32_t _application_version = 0;
  const char* _engine_name = nullptr;
  uint32_t _engine_version = 0;
  uint32_t _api_version = 0;
};
static_assert(sizeof(application_info) == sizeof(::VkApplicationInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkInstanceCreateInfo.
class instance_create_info
{
public:
  /// Default constructor.
  constexpr instance_create_info() = default;

  /// Constructor.
  constexpr instance_create_info(
    const void* initial_next, vk::instance_create_flags initial_flags,
    const vk::application_info* initial_application_info,
    uint32_t initial_enabled_layer_count,
    const char* const* initial_enabled_layer_names,
    uint32_t initial_enabled_extension_count,
    const char* const* initial_enabled_extension_names) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _application_info(std::move(initial_application_info)),
    _enabled_layer_count(std::move(initial_enabled_layer_count)),
    _enabled_layer_names(std::move(initial_enabled_layer_names)),
    _enabled_extension_count(std::move(initial_enabled_extension_count)),
    _enabled_extension_names(std::move(initial_enabled_extension_names))
  {
  }

  /// Copy constructor.
  constexpr instance_create_info(const instance_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _application_info(other._application_info),
    _enabled_layer_count(other._enabled_layer_count),
    _enabled_layer_names(other._enabled_layer_names),
    _enabled_extension_count(other._enabled_extension_count),
    _enabled_extension_names(other._enabled_extension_names)
  {
  }

  /// Move constructor.
  constexpr instance_create_info(instance_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _application_info(std::move(other._application_info)),
    _enabled_layer_count(std::move(other._enabled_layer_count)),
    _enabled_layer_names(std::move(other._enabled_layer_names)),
    _enabled_extension_count(std::move(other._enabled_extension_count)),
    _enabled_extension_names(std::move(other._enabled_extension_names))
  {
  }

  /// Copy assignment operator.
  constexpr instance_create_info& operator=(
    const instance_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _application_info = other._application_info;
    _enabled_layer_count = other._enabled_layer_count;
    _enabled_layer_names = other._enabled_layer_names;
    _enabled_extension_count = other._enabled_extension_count;
    _enabled_extension_names = other._enabled_extension_names;
    return *this;
  }

  /// Move assignment operator.
  constexpr instance_create_info& operator=(
    instance_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _application_info = std::move(other._application_info);
    _enabled_layer_count = std::move(other._enabled_layer_count);
    _enabled_layer_names = std::move(other._enabled_layer_names);
    _enabled_extension_count = std::move(other._enabled_extension_count);
    _enabled_extension_names = std::move(other._enabled_extension_names);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkInstanceCreateInfo&() const
  {
    return *reinterpret_cast<const VkInstanceCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::instance_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::instance_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::instance_create_flags new_flags)
  {
    _flags = new_flags;
  }

  const vk::application_info* application_info()
  {
    return _application_info;
  }

  constexpr const vk::application_info* application_info() const
  {
    return _application_info;
  }

  void application_info(const vk::application_info* new_application_info)
  {
    _application_info = new_application_info;
  }

  uint32_t& enabled_layer_count()
  {
    return _enabled_layer_count;
  }

  constexpr const uint32_t& enabled_layer_count() const
  {
    return _enabled_layer_count;
  }

  void enabled_layer_count(uint32_t new_enabled_layer_count)
  {
    _enabled_layer_count = new_enabled_layer_count;
  }

  const char* const* enabled_layer_names()
  {
    return _enabled_layer_names;
  }

  constexpr const char* const* enabled_layer_names() const
  {
    return _enabled_layer_names;
  }

  void enabled_layer_names(const char* const* new_enabled_layer_names)
  {
    _enabled_layer_names = new_enabled_layer_names;
  }

  template <std::size_t Count>
  void enabled_layer_names(
    const std::array<char*, Count>& new_enabled_layer_names)
  {
    _enabled_layer_count =
      static_cast<uint32_t>(new_enabled_layer_names.size());
    _enabled_layer_names = new_enabled_layer_names.data();
  }

  void enabled_layer_names(const std::vector<char*>& new_enabled_layer_names)
  {
    _enabled_layer_count =
      static_cast<uint32_t>(new_enabled_layer_names.size());
    _enabled_layer_names = new_enabled_layer_names.data();
  }

  uint32_t& enabled_extension_count()
  {
    return _enabled_extension_count;
  }

  constexpr const uint32_t& enabled_extension_count() const
  {
    return _enabled_extension_count;
  }

  void enabled_extension_count(uint32_t new_enabled_extension_count)
  {
    _enabled_extension_count = new_enabled_extension_count;
  }

  const char* const* enabled_extension_names()
  {
    return _enabled_extension_names;
  }

  constexpr const char* const* enabled_extension_names() const
  {
    return _enabled_extension_names;
  }

  void enabled_extension_names(const char* const* new_enabled_extension_names)
  {
    _enabled_extension_names = new_enabled_extension_names;
  }

  template <std::size_t Count>
  void enabled_extension_names(
    const std::array<char*, Count>& new_enabled_extension_names)
  {
    _enabled_extension_count =
      static_cast<uint32_t>(new_enabled_extension_names.size());
    _enabled_extension_names = new_enabled_extension_names.data();
  }

  void enabled_extension_names(
    const std::vector<char*>& new_enabled_extension_names)
  {
    _enabled_extension_count =
      static_cast<uint32_t>(new_enabled_extension_names.size());
    _enabled_extension_names = new_enabled_extension_names.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::instance_create_info;
  const void* _next = nullptr;
  vk::instance_create_flags _flags = vk::instance_create_flag::none;
  const vk::application_info* _application_info = nullptr;
  uint32_t _enabled_layer_count = 0;
  /// Ordered list of layer names to be enabled
  const char* const* _enabled_layer_names = nullptr;
  uint32_t _enabled_extension_count = 0;
  /// Extension names to be enabled
  const char* const* _enabled_extension_names = nullptr;
};
static_assert(sizeof(instance_create_info) == sizeof(::VkInstanceCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkAllocationCallbacks.
class allocation_callbacks
{
public:
  /// Default constructor.
  constexpr allocation_callbacks() = default;

  /// Constructor.
  constexpr allocation_callbacks(
    void* initial_user_data, PFN_vkAllocationFunction initial_pfn_allocation,
    PFN_vkReallocationFunction initial_pfn_reallocation,
    PFN_vkFreeFunction initial_pfn_free,
    PFN_vkInternalAllocationNotification initial_pfn_internal_allocation,
    PFN_vkInternalFreeNotification initial_pfn_internal_free) noexcept
  : _user_data(std::move(initial_user_data)),
    _pfn_allocation(std::move(initial_pfn_allocation)),
    _pfn_reallocation(std::move(initial_pfn_reallocation)),
    _pfn_free(std::move(initial_pfn_free)),
    _pfn_internal_allocation(std::move(initial_pfn_internal_allocation)),
    _pfn_internal_free(std::move(initial_pfn_internal_free))
  {
  }

  /// Copy constructor.
  constexpr allocation_callbacks(const allocation_callbacks& other) = default;

  /// Move constructor.
  constexpr allocation_callbacks(allocation_callbacks&& other) = default;

  /// Copy assignment operator.
  constexpr allocation_callbacks& operator=(const allocation_callbacks& other) =
    default;

  /// Move assignment operator.
  constexpr allocation_callbacks& operator=(allocation_callbacks&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkAllocationCallbacks&() const
  {
    return *reinterpret_cast<const VkAllocationCallbacks*>(this);
  }

  void* user_data()
  {
    return _user_data;
  }

  constexpr void* user_data() const
  {
    return _user_data;
  }

  void user_data(void* new_user_data)
  {
    _user_data = new_user_data;
  }

  PFN_vkAllocationFunction& pfn_allocation()
  {
    return _pfn_allocation;
  }

  constexpr const PFN_vkAllocationFunction& pfn_allocation() const
  {
    return _pfn_allocation;
  }

  void pfn_allocation(PFN_vkAllocationFunction new_pfn_allocation)
  {
    _pfn_allocation = new_pfn_allocation;
  }

  PFN_vkReallocationFunction& pfn_reallocation()
  {
    return _pfn_reallocation;
  }

  constexpr const PFN_vkReallocationFunction& pfn_reallocation() const
  {
    return _pfn_reallocation;
  }

  void pfn_reallocation(PFN_vkReallocationFunction new_pfn_reallocation)
  {
    _pfn_reallocation = new_pfn_reallocation;
  }

  PFN_vkFreeFunction& pfn_free()
  {
    return _pfn_free;
  }

  constexpr const PFN_vkFreeFunction& pfn_free() const
  {
    return _pfn_free;
  }

  void pfn_free(PFN_vkFreeFunction new_pfn_free)
  {
    _pfn_free = new_pfn_free;
  }

  PFN_vkInternalAllocationNotification& pfn_internal_allocation()
  {
    return _pfn_internal_allocation;
  }

  constexpr const PFN_vkInternalAllocationNotification&
  pfn_internal_allocation() const
  {
    return _pfn_internal_allocation;
  }

  void pfn_internal_allocation(
    PFN_vkInternalAllocationNotification new_pfn_internal_allocation)
  {
    _pfn_internal_allocation = new_pfn_internal_allocation;
  }

  PFN_vkInternalFreeNotification& pfn_internal_free()
  {
    return _pfn_internal_free;
  }

  constexpr const PFN_vkInternalFreeNotification& pfn_internal_free() const
  {
    return _pfn_internal_free;
  }

  void pfn_internal_free(PFN_vkInternalFreeNotification new_pfn_internal_free)
  {
    _pfn_internal_free = new_pfn_internal_free;
  }

private:
  void* _user_data = nullptr;
  PFN_vkAllocationFunction _pfn_allocation = nullptr;
  PFN_vkReallocationFunction _pfn_reallocation = nullptr;
  PFN_vkFreeFunction _pfn_free = nullptr;
  PFN_vkInternalAllocationNotification _pfn_internal_allocation = nullptr;
  PFN_vkInternalFreeNotification _pfn_internal_free = nullptr;
};
static_assert(sizeof(allocation_callbacks) == sizeof(::VkAllocationCallbacks),
              "struct and wrapper have different size!");

inline vk::result create_instance(const vk::instance_create_info* create_info,
                                  const vk::allocation_callbacks* allocator,
                                  VkInstance* instance)
{
  return static_cast<vk::result>(
    vkCreateInstance(reinterpret_cast<const VkInstanceCreateInfo*>(create_info),
                     reinterpret_cast<const VkAllocationCallbacks*>(allocator),
                     reinterpret_cast<VkInstance*>(instance)));
}
inline void destroy_instance(VkInstance instance,
                             const vk::allocation_callbacks* allocator)
{
  vkDestroyInstance(static_cast<VkInstance>(instance),
                    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result enumerate_physical_devices(VkInstance instance,
                                             uint32_t* physical_device_count,
                                             VkPhysicalDevice* physical_devices)
{
  return static_cast<vk::result>(vkEnumeratePhysicalDevices(
    static_cast<VkInstance>(instance),
    reinterpret_cast<uint32_t*>(physical_device_count),
    reinterpret_cast<VkPhysicalDevice*>(physical_devices)));
}

/// Enhanced replacement type for VkPhysicalDeviceFeatures.
class physical_device_features
{
public:
  /// Default constructor.
  constexpr physical_device_features() = default;

  /// Constructor.
  constexpr physical_device_features(
    VkBool32 initial_robust_buffer_access,
    VkBool32 initial_full_draw_index_uint32, VkBool32 initial_image_cube_array,
    VkBool32 initial_independent_blend, VkBool32 initial_geometry_shader,
    VkBool32 initial_tessellation_shader, VkBool32 initial_sample_rate_shading,
    VkBool32 initial_dual_src_blend, VkBool32 initial_logic_op,
    VkBool32 initial_multi_draw_indirect,
    VkBool32 initial_draw_indirect_first_instance, VkBool32 initial_depth_clamp,
    VkBool32 initial_depth_bias_clamp, VkBool32 initial_fill_mode_non_solid,
    VkBool32 initial_depth_bounds, VkBool32 initial_wide_lines,
    VkBool32 initial_large_points, VkBool32 initial_alpha_to_one,
    VkBool32 initial_multi_viewport, VkBool32 initial_sampler_anisotropy,
    VkBool32 initial_texture_compression_etc2,
    VkBool32 initial_texture_compression_astc_ldr,
    VkBool32 initial_texture_compression_bc,
    VkBool32 initial_occlusion_query_precise,
    VkBool32 initial_pipeline_statistics_query,
    VkBool32 initial_vertex_pipeline_stores_and_atomics,
    VkBool32 initial_fragment_stores_and_atomics,
    VkBool32 initial_shader_tessellation_and_geometry_point_size,
    VkBool32 initial_shader_image_gather_extended,
    VkBool32 initial_shader_storage_image_extended_formats,
    VkBool32 initial_shader_storage_image_multisample,
    VkBool32 initial_shader_storage_image_read_without_format,
    VkBool32 initial_shader_storage_image_write_without_format,
    VkBool32 initial_shader_uniform_buffer_array_dynamic_indexing,
    VkBool32 initial_shader_sampled_image_array_dynamic_indexing,
    VkBool32 initial_shader_storage_buffer_array_dynamic_indexing,
    VkBool32 initial_shader_storage_image_array_dynamic_indexing,
    VkBool32 initial_shader_clip_distance,
    VkBool32 initial_shader_cull_distance, VkBool32 initial_shader_float64,
    VkBool32 initial_shader_int64, VkBool32 initial_shader_int16,
    VkBool32 initial_shader_resource_residency,
    VkBool32 initial_shader_resource_min_lod, VkBool32 initial_sparse_binding,
    VkBool32 initial_sparse_residency_buffer,
    VkBool32 initial_sparse_residency_image_2d,
    VkBool32 initial_sparse_residency_image_3d,
    VkBool32 initial_sparse_residency_2_samples,
    VkBool32 initial_sparse_residency_4_samples,
    VkBool32 initial_sparse_residency_8_samples,
    VkBool32 initial_sparse_residency_16_samples,
    VkBool32 initial_sparse_residency_aliased,
    VkBool32 initial_variable_multisample_rate,
    VkBool32 initial_inherited_queries) noexcept
  : _robust_buffer_access(std::move(initial_robust_buffer_access)),
    _full_draw_index_uint32(std::move(initial_full_draw_index_uint32)),
    _image_cube_array(std::move(initial_image_cube_array)),
    _independent_blend(std::move(initial_independent_blend)),
    _geometry_shader(std::move(initial_geometry_shader)),
    _tessellation_shader(std::move(initial_tessellation_shader)),
    _sample_rate_shading(std::move(initial_sample_rate_shading)),
    _dual_src_blend(std::move(initial_dual_src_blend)),
    _logic_op(std::move(initial_logic_op)),
    _multi_draw_indirect(std::move(initial_multi_draw_indirect)),
    _draw_indirect_first_instance(
      std::move(initial_draw_indirect_first_instance)),
    _depth_clamp(std::move(initial_depth_clamp)),
    _depth_bias_clamp(std::move(initial_depth_bias_clamp)),
    _fill_mode_non_solid(std::move(initial_fill_mode_non_solid)),
    _depth_bounds(std::move(initial_depth_bounds)),
    _wide_lines(std::move(initial_wide_lines)),
    _large_points(std::move(initial_large_points)),
    _alpha_to_one(std::move(initial_alpha_to_one)),
    _multi_viewport(std::move(initial_multi_viewport)),
    _sampler_anisotropy(std::move(initial_sampler_anisotropy)),
    _texture_compression_etc2(std::move(initial_texture_compression_etc2)),
    _texture_compression_astc_ldr(
      std::move(initial_texture_compression_astc_ldr)),
    _texture_compression_bc(std::move(initial_texture_compression_bc)),
    _occlusion_query_precise(std::move(initial_occlusion_query_precise)),
    _pipeline_statistics_query(std::move(initial_pipeline_statistics_query)),
    _vertex_pipeline_stores_and_atomics(
      std::move(initial_vertex_pipeline_stores_and_atomics)),
    _fragment_stores_and_atomics(
      std::move(initial_fragment_stores_and_atomics)),
    _shader_tessellation_and_geometry_point_size(
      std::move(initial_shader_tessellation_and_geometry_point_size)),
    _shader_image_gather_extended(
      std::move(initial_shader_image_gather_extended)),
    _shader_storage_image_extended_formats(
      std::move(initial_shader_storage_image_extended_formats)),
    _shader_storage_image_multisample(
      std::move(initial_shader_storage_image_multisample)),
    _shader_storage_image_read_without_format(
      std::move(initial_shader_storage_image_read_without_format)),
    _shader_storage_image_write_without_format(
      std::move(initial_shader_storage_image_write_without_format)),
    _shader_uniform_buffer_array_dynamic_indexing(
      std::move(initial_shader_uniform_buffer_array_dynamic_indexing)),
    _shader_sampled_image_array_dynamic_indexing(
      std::move(initial_shader_sampled_image_array_dynamic_indexing)),
    _shader_storage_buffer_array_dynamic_indexing(
      std::move(initial_shader_storage_buffer_array_dynamic_indexing)),
    _shader_storage_image_array_dynamic_indexing(
      std::move(initial_shader_storage_image_array_dynamic_indexing)),
    _shader_clip_distance(std::move(initial_shader_clip_distance)),
    _shader_cull_distance(std::move(initial_shader_cull_distance)),
    _shader_float64(std::move(initial_shader_float64)),
    _shader_int64(std::move(initial_shader_int64)),
    _shader_int16(std::move(initial_shader_int16)),
    _shader_resource_residency(std::move(initial_shader_resource_residency)),
    _shader_resource_min_lod(std::move(initial_shader_resource_min_lod)),
    _sparse_binding(std::move(initial_sparse_binding)),
    _sparse_residency_buffer(std::move(initial_sparse_residency_buffer)),
    _sparse_residency_image_2d(std::move(initial_sparse_residency_image_2d)),
    _sparse_residency_image_3d(std::move(initial_sparse_residency_image_3d)),
    _sparse_residency_2_samples(std::move(initial_sparse_residency_2_samples)),
    _sparse_residency_4_samples(std::move(initial_sparse_residency_4_samples)),
    _sparse_residency_8_samples(std::move(initial_sparse_residency_8_samples)),
    _sparse_residency_16_samples(
      std::move(initial_sparse_residency_16_samples)),
    _sparse_residency_aliased(std::move(initial_sparse_residency_aliased)),
    _variable_multisample_rate(std::move(initial_variable_multisample_rate)),
    _inherited_queries(std::move(initial_inherited_queries))
  {
  }

  /// Copy constructor.
  constexpr physical_device_features(const physical_device_features& other) =
    default;

  /// Move constructor.
  constexpr physical_device_features(physical_device_features&& other) =
    default;

  /// Copy assignment operator.
  constexpr physical_device_features& operator=(
    const physical_device_features& other) = default;

  /// Move assignment operator.
  constexpr physical_device_features& operator=(
    physical_device_features&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceFeatures&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceFeatures*>(this);
  }

  VkBool32& robust_buffer_access()
  {
    return _robust_buffer_access;
  }

  constexpr const VkBool32& robust_buffer_access() const
  {
    return _robust_buffer_access;
  }

  void robust_buffer_access(VkBool32 new_robust_buffer_access)
  {
    _robust_buffer_access = new_robust_buffer_access;
  }

  VkBool32& full_draw_index_uint32()
  {
    return _full_draw_index_uint32;
  }

  constexpr const VkBool32& full_draw_index_uint32() const
  {
    return _full_draw_index_uint32;
  }

  void full_draw_index_uint32(VkBool32 new_full_draw_index_uint32)
  {
    _full_draw_index_uint32 = new_full_draw_index_uint32;
  }

  VkBool32& image_cube_array()
  {
    return _image_cube_array;
  }

  constexpr const VkBool32& image_cube_array() const
  {
    return _image_cube_array;
  }

  void image_cube_array(VkBool32 new_image_cube_array)
  {
    _image_cube_array = new_image_cube_array;
  }

  VkBool32& independent_blend()
  {
    return _independent_blend;
  }

  constexpr const VkBool32& independent_blend() const
  {
    return _independent_blend;
  }

  void independent_blend(VkBool32 new_independent_blend)
  {
    _independent_blend = new_independent_blend;
  }

  VkBool32& geometry_shader()
  {
    return _geometry_shader;
  }

  constexpr const VkBool32& geometry_shader() const
  {
    return _geometry_shader;
  }

  void geometry_shader(VkBool32 new_geometry_shader)
  {
    _geometry_shader = new_geometry_shader;
  }

  VkBool32& tessellation_shader()
  {
    return _tessellation_shader;
  }

  constexpr const VkBool32& tessellation_shader() const
  {
    return _tessellation_shader;
  }

  void tessellation_shader(VkBool32 new_tessellation_shader)
  {
    _tessellation_shader = new_tessellation_shader;
  }

  VkBool32& sample_rate_shading()
  {
    return _sample_rate_shading;
  }

  constexpr const VkBool32& sample_rate_shading() const
  {
    return _sample_rate_shading;
  }

  void sample_rate_shading(VkBool32 new_sample_rate_shading)
  {
    _sample_rate_shading = new_sample_rate_shading;
  }

  VkBool32& dual_src_blend()
  {
    return _dual_src_blend;
  }

  constexpr const VkBool32& dual_src_blend() const
  {
    return _dual_src_blend;
  }

  void dual_src_blend(VkBool32 new_dual_src_blend)
  {
    _dual_src_blend = new_dual_src_blend;
  }

  VkBool32& logic_op()
  {
    return _logic_op;
  }

  constexpr const VkBool32& logic_op() const
  {
    return _logic_op;
  }

  void logic_op(VkBool32 new_logic_op)
  {
    _logic_op = new_logic_op;
  }

  VkBool32& multi_draw_indirect()
  {
    return _multi_draw_indirect;
  }

  constexpr const VkBool32& multi_draw_indirect() const
  {
    return _multi_draw_indirect;
  }

  void multi_draw_indirect(VkBool32 new_multi_draw_indirect)
  {
    _multi_draw_indirect = new_multi_draw_indirect;
  }

  VkBool32& draw_indirect_first_instance()
  {
    return _draw_indirect_first_instance;
  }

  constexpr const VkBool32& draw_indirect_first_instance() const
  {
    return _draw_indirect_first_instance;
  }

  void draw_indirect_first_instance(VkBool32 new_draw_indirect_first_instance)
  {
    _draw_indirect_first_instance = new_draw_indirect_first_instance;
  }

  VkBool32& depth_clamp()
  {
    return _depth_clamp;
  }

  constexpr const VkBool32& depth_clamp() const
  {
    return _depth_clamp;
  }

  void depth_clamp(VkBool32 new_depth_clamp)
  {
    _depth_clamp = new_depth_clamp;
  }

  VkBool32& depth_bias_clamp()
  {
    return _depth_bias_clamp;
  }

  constexpr const VkBool32& depth_bias_clamp() const
  {
    return _depth_bias_clamp;
  }

  void depth_bias_clamp(VkBool32 new_depth_bias_clamp)
  {
    _depth_bias_clamp = new_depth_bias_clamp;
  }

  VkBool32& fill_mode_non_solid()
  {
    return _fill_mode_non_solid;
  }

  constexpr const VkBool32& fill_mode_non_solid() const
  {
    return _fill_mode_non_solid;
  }

  void fill_mode_non_solid(VkBool32 new_fill_mode_non_solid)
  {
    _fill_mode_non_solid = new_fill_mode_non_solid;
  }

  VkBool32& depth_bounds()
  {
    return _depth_bounds;
  }

  constexpr const VkBool32& depth_bounds() const
  {
    return _depth_bounds;
  }

  void depth_bounds(VkBool32 new_depth_bounds)
  {
    _depth_bounds = new_depth_bounds;
  }

  VkBool32& wide_lines()
  {
    return _wide_lines;
  }

  constexpr const VkBool32& wide_lines() const
  {
    return _wide_lines;
  }

  void wide_lines(VkBool32 new_wide_lines)
  {
    _wide_lines = new_wide_lines;
  }

  VkBool32& large_points()
  {
    return _large_points;
  }

  constexpr const VkBool32& large_points() const
  {
    return _large_points;
  }

  void large_points(VkBool32 new_large_points)
  {
    _large_points = new_large_points;
  }

  VkBool32& alpha_to_one()
  {
    return _alpha_to_one;
  }

  constexpr const VkBool32& alpha_to_one() const
  {
    return _alpha_to_one;
  }

  void alpha_to_one(VkBool32 new_alpha_to_one)
  {
    _alpha_to_one = new_alpha_to_one;
  }

  VkBool32& multi_viewport()
  {
    return _multi_viewport;
  }

  constexpr const VkBool32& multi_viewport() const
  {
    return _multi_viewport;
  }

  void multi_viewport(VkBool32 new_multi_viewport)
  {
    _multi_viewport = new_multi_viewport;
  }

  VkBool32& sampler_anisotropy()
  {
    return _sampler_anisotropy;
  }

  constexpr const VkBool32& sampler_anisotropy() const
  {
    return _sampler_anisotropy;
  }

  void sampler_anisotropy(VkBool32 new_sampler_anisotropy)
  {
    _sampler_anisotropy = new_sampler_anisotropy;
  }

  VkBool32& texture_compression_etc2()
  {
    return _texture_compression_etc2;
  }

  constexpr const VkBool32& texture_compression_etc2() const
  {
    return _texture_compression_etc2;
  }

  void texture_compression_etc2(VkBool32 new_texture_compression_etc2)
  {
    _texture_compression_etc2 = new_texture_compression_etc2;
  }

  VkBool32& texture_compression_astc_ldr()
  {
    return _texture_compression_astc_ldr;
  }

  constexpr const VkBool32& texture_compression_astc_ldr() const
  {
    return _texture_compression_astc_ldr;
  }

  void texture_compression_astc_ldr(VkBool32 new_texture_compression_astc_ldr)
  {
    _texture_compression_astc_ldr = new_texture_compression_astc_ldr;
  }

  VkBool32& texture_compression_bc()
  {
    return _texture_compression_bc;
  }

  constexpr const VkBool32& texture_compression_bc() const
  {
    return _texture_compression_bc;
  }

  void texture_compression_bc(VkBool32 new_texture_compression_bc)
  {
    _texture_compression_bc = new_texture_compression_bc;
  }

  VkBool32& occlusion_query_precise()
  {
    return _occlusion_query_precise;
  }

  constexpr const VkBool32& occlusion_query_precise() const
  {
    return _occlusion_query_precise;
  }

  void occlusion_query_precise(VkBool32 new_occlusion_query_precise)
  {
    _occlusion_query_precise = new_occlusion_query_precise;
  }

  VkBool32& pipeline_statistics_query()
  {
    return _pipeline_statistics_query;
  }

  constexpr const VkBool32& pipeline_statistics_query() const
  {
    return _pipeline_statistics_query;
  }

  void pipeline_statistics_query(VkBool32 new_pipeline_statistics_query)
  {
    _pipeline_statistics_query = new_pipeline_statistics_query;
  }

  VkBool32& vertex_pipeline_stores_and_atomics()
  {
    return _vertex_pipeline_stores_and_atomics;
  }

  constexpr const VkBool32& vertex_pipeline_stores_and_atomics() const
  {
    return _vertex_pipeline_stores_and_atomics;
  }

  void vertex_pipeline_stores_and_atomics(
    VkBool32 new_vertex_pipeline_stores_and_atomics)
  {
    _vertex_pipeline_stores_and_atomics =
      new_vertex_pipeline_stores_and_atomics;
  }

  VkBool32& fragment_stores_and_atomics()
  {
    return _fragment_stores_and_atomics;
  }

  constexpr const VkBool32& fragment_stores_and_atomics() const
  {
    return _fragment_stores_and_atomics;
  }

  void fragment_stores_and_atomics(VkBool32 new_fragment_stores_and_atomics)
  {
    _fragment_stores_and_atomics = new_fragment_stores_and_atomics;
  }

  VkBool32& shader_tessellation_and_geometry_point_size()
  {
    return _shader_tessellation_and_geometry_point_size;
  }

  constexpr const VkBool32& shader_tessellation_and_geometry_point_size() const
  {
    return _shader_tessellation_and_geometry_point_size;
  }

  void shader_tessellation_and_geometry_point_size(
    VkBool32 new_shader_tessellation_and_geometry_point_size)
  {
    _shader_tessellation_and_geometry_point_size =
      new_shader_tessellation_and_geometry_point_size;
  }

  VkBool32& shader_image_gather_extended()
  {
    return _shader_image_gather_extended;
  }

  constexpr const VkBool32& shader_image_gather_extended() const
  {
    return _shader_image_gather_extended;
  }

  void shader_image_gather_extended(VkBool32 new_shader_image_gather_extended)
  {
    _shader_image_gather_extended = new_shader_image_gather_extended;
  }

  VkBool32& shader_storage_image_extended_formats()
  {
    return _shader_storage_image_extended_formats;
  }

  constexpr const VkBool32& shader_storage_image_extended_formats() const
  {
    return _shader_storage_image_extended_formats;
  }

  void shader_storage_image_extended_formats(
    VkBool32 new_shader_storage_image_extended_formats)
  {
    _shader_storage_image_extended_formats =
      new_shader_storage_image_extended_formats;
  }

  VkBool32& shader_storage_image_multisample()
  {
    return _shader_storage_image_multisample;
  }

  constexpr const VkBool32& shader_storage_image_multisample() const
  {
    return _shader_storage_image_multisample;
  }

  void shader_storage_image_multisample(
    VkBool32 new_shader_storage_image_multisample)
  {
    _shader_storage_image_multisample = new_shader_storage_image_multisample;
  }

  VkBool32& shader_storage_image_read_without_format()
  {
    return _shader_storage_image_read_without_format;
  }

  constexpr const VkBool32& shader_storage_image_read_without_format() const
  {
    return _shader_storage_image_read_without_format;
  }

  void shader_storage_image_read_without_format(
    VkBool32 new_shader_storage_image_read_without_format)
  {
    _shader_storage_image_read_without_format =
      new_shader_storage_image_read_without_format;
  }

  VkBool32& shader_storage_image_write_without_format()
  {
    return _shader_storage_image_write_without_format;
  }

  constexpr const VkBool32& shader_storage_image_write_without_format() const
  {
    return _shader_storage_image_write_without_format;
  }

  void shader_storage_image_write_without_format(
    VkBool32 new_shader_storage_image_write_without_format)
  {
    _shader_storage_image_write_without_format =
      new_shader_storage_image_write_without_format;
  }

  VkBool32& shader_uniform_buffer_array_dynamic_indexing()
  {
    return _shader_uniform_buffer_array_dynamic_indexing;
  }

  constexpr const VkBool32& shader_uniform_buffer_array_dynamic_indexing() const
  {
    return _shader_uniform_buffer_array_dynamic_indexing;
  }

  void shader_uniform_buffer_array_dynamic_indexing(
    VkBool32 new_shader_uniform_buffer_array_dynamic_indexing)
  {
    _shader_uniform_buffer_array_dynamic_indexing =
      new_shader_uniform_buffer_array_dynamic_indexing;
  }

  VkBool32& shader_sampled_image_array_dynamic_indexing()
  {
    return _shader_sampled_image_array_dynamic_indexing;
  }

  constexpr const VkBool32& shader_sampled_image_array_dynamic_indexing() const
  {
    return _shader_sampled_image_array_dynamic_indexing;
  }

  void shader_sampled_image_array_dynamic_indexing(
    VkBool32 new_shader_sampled_image_array_dynamic_indexing)
  {
    _shader_sampled_image_array_dynamic_indexing =
      new_shader_sampled_image_array_dynamic_indexing;
  }

  VkBool32& shader_storage_buffer_array_dynamic_indexing()
  {
    return _shader_storage_buffer_array_dynamic_indexing;
  }

  constexpr const VkBool32& shader_storage_buffer_array_dynamic_indexing() const
  {
    return _shader_storage_buffer_array_dynamic_indexing;
  }

  void shader_storage_buffer_array_dynamic_indexing(
    VkBool32 new_shader_storage_buffer_array_dynamic_indexing)
  {
    _shader_storage_buffer_array_dynamic_indexing =
      new_shader_storage_buffer_array_dynamic_indexing;
  }

  VkBool32& shader_storage_image_array_dynamic_indexing()
  {
    return _shader_storage_image_array_dynamic_indexing;
  }

  constexpr const VkBool32& shader_storage_image_array_dynamic_indexing() const
  {
    return _shader_storage_image_array_dynamic_indexing;
  }

  void shader_storage_image_array_dynamic_indexing(
    VkBool32 new_shader_storage_image_array_dynamic_indexing)
  {
    _shader_storage_image_array_dynamic_indexing =
      new_shader_storage_image_array_dynamic_indexing;
  }

  VkBool32& shader_clip_distance()
  {
    return _shader_clip_distance;
  }

  constexpr const VkBool32& shader_clip_distance() const
  {
    return _shader_clip_distance;
  }

  void shader_clip_distance(VkBool32 new_shader_clip_distance)
  {
    _shader_clip_distance = new_shader_clip_distance;
  }

  VkBool32& shader_cull_distance()
  {
    return _shader_cull_distance;
  }

  constexpr const VkBool32& shader_cull_distance() const
  {
    return _shader_cull_distance;
  }

  void shader_cull_distance(VkBool32 new_shader_cull_distance)
  {
    _shader_cull_distance = new_shader_cull_distance;
  }

  VkBool32& shader_float64()
  {
    return _shader_float64;
  }

  constexpr const VkBool32& shader_float64() const
  {
    return _shader_float64;
  }

  void shader_float64(VkBool32 new_shader_float64)
  {
    _shader_float64 = new_shader_float64;
  }

  VkBool32& shader_int64()
  {
    return _shader_int64;
  }

  constexpr const VkBool32& shader_int64() const
  {
    return _shader_int64;
  }

  void shader_int64(VkBool32 new_shader_int64)
  {
    _shader_int64 = new_shader_int64;
  }

  VkBool32& shader_int16()
  {
    return _shader_int16;
  }

  constexpr const VkBool32& shader_int16() const
  {
    return _shader_int16;
  }

  void shader_int16(VkBool32 new_shader_int16)
  {
    _shader_int16 = new_shader_int16;
  }

  VkBool32& shader_resource_residency()
  {
    return _shader_resource_residency;
  }

  constexpr const VkBool32& shader_resource_residency() const
  {
    return _shader_resource_residency;
  }

  void shader_resource_residency(VkBool32 new_shader_resource_residency)
  {
    _shader_resource_residency = new_shader_resource_residency;
  }

  VkBool32& shader_resource_min_lod()
  {
    return _shader_resource_min_lod;
  }

  constexpr const VkBool32& shader_resource_min_lod() const
  {
    return _shader_resource_min_lod;
  }

  void shader_resource_min_lod(VkBool32 new_shader_resource_min_lod)
  {
    _shader_resource_min_lod = new_shader_resource_min_lod;
  }

  VkBool32& sparse_binding()
  {
    return _sparse_binding;
  }

  constexpr const VkBool32& sparse_binding() const
  {
    return _sparse_binding;
  }

  void sparse_binding(VkBool32 new_sparse_binding)
  {
    _sparse_binding = new_sparse_binding;
  }

  VkBool32& sparse_residency_buffer()
  {
    return _sparse_residency_buffer;
  }

  constexpr const VkBool32& sparse_residency_buffer() const
  {
    return _sparse_residency_buffer;
  }

  void sparse_residency_buffer(VkBool32 new_sparse_residency_buffer)
  {
    _sparse_residency_buffer = new_sparse_residency_buffer;
  }

  VkBool32& sparse_residency_image_2d()
  {
    return _sparse_residency_image_2d;
  }

  constexpr const VkBool32& sparse_residency_image_2d() const
  {
    return _sparse_residency_image_2d;
  }

  void sparse_residency_image_2d(VkBool32 new_sparse_residency_image_2d)
  {
    _sparse_residency_image_2d = new_sparse_residency_image_2d;
  }

  VkBool32& sparse_residency_image_3d()
  {
    return _sparse_residency_image_3d;
  }

  constexpr const VkBool32& sparse_residency_image_3d() const
  {
    return _sparse_residency_image_3d;
  }

  void sparse_residency_image_3d(VkBool32 new_sparse_residency_image_3d)
  {
    _sparse_residency_image_3d = new_sparse_residency_image_3d;
  }

  VkBool32& sparse_residency_2_samples()
  {
    return _sparse_residency_2_samples;
  }

  constexpr const VkBool32& sparse_residency_2_samples() const
  {
    return _sparse_residency_2_samples;
  }

  void sparse_residency_2_samples(VkBool32 new_sparse_residency_2_samples)
  {
    _sparse_residency_2_samples = new_sparse_residency_2_samples;
  }

  VkBool32& sparse_residency_4_samples()
  {
    return _sparse_residency_4_samples;
  }

  constexpr const VkBool32& sparse_residency_4_samples() const
  {
    return _sparse_residency_4_samples;
  }

  void sparse_residency_4_samples(VkBool32 new_sparse_residency_4_samples)
  {
    _sparse_residency_4_samples = new_sparse_residency_4_samples;
  }

  VkBool32& sparse_residency_8_samples()
  {
    return _sparse_residency_8_samples;
  }

  constexpr const VkBool32& sparse_residency_8_samples() const
  {
    return _sparse_residency_8_samples;
  }

  void sparse_residency_8_samples(VkBool32 new_sparse_residency_8_samples)
  {
    _sparse_residency_8_samples = new_sparse_residency_8_samples;
  }

  VkBool32& sparse_residency_16_samples()
  {
    return _sparse_residency_16_samples;
  }

  constexpr const VkBool32& sparse_residency_16_samples() const
  {
    return _sparse_residency_16_samples;
  }

  void sparse_residency_16_samples(VkBool32 new_sparse_residency_16_samples)
  {
    _sparse_residency_16_samples = new_sparse_residency_16_samples;
  }

  VkBool32& sparse_residency_aliased()
  {
    return _sparse_residency_aliased;
  }

  constexpr const VkBool32& sparse_residency_aliased() const
  {
    return _sparse_residency_aliased;
  }

  void sparse_residency_aliased(VkBool32 new_sparse_residency_aliased)
  {
    _sparse_residency_aliased = new_sparse_residency_aliased;
  }

  VkBool32& variable_multisample_rate()
  {
    return _variable_multisample_rate;
  }

  constexpr const VkBool32& variable_multisample_rate() const
  {
    return _variable_multisample_rate;
  }

  void variable_multisample_rate(VkBool32 new_variable_multisample_rate)
  {
    _variable_multisample_rate = new_variable_multisample_rate;
  }

  VkBool32& inherited_queries()
  {
    return _inherited_queries;
  }

  constexpr const VkBool32& inherited_queries() const
  {
    return _inherited_queries;
  }

  void inherited_queries(VkBool32 new_inherited_queries)
  {
    _inherited_queries = new_inherited_queries;
  }

private:
  /// out of bounds buffer accesses are well defined
  VkBool32 _robust_buffer_access = VK_FALSE;
  /// full 32-bit range of indices for indexed draw calls
  VkBool32 _full_draw_index_uint32 = VK_FALSE;
  /// image views which are arrays of cube maps
  VkBool32 _image_cube_array = VK_FALSE;
  /// blending operations are controlled per-attachment
  VkBool32 _independent_blend = VK_FALSE;
  /// geometry stage
  VkBool32 _geometry_shader = VK_FALSE;
  /// tessellation control and evaluation stage
  VkBool32 _tessellation_shader = VK_FALSE;
  /// per-sample shading and interpolation
  VkBool32 _sample_rate_shading = VK_FALSE;
  /// blend operations which take two sources
  VkBool32 _dual_src_blend = VK_FALSE;
  /// logic operations
  VkBool32 _logic_op = VK_FALSE;
  /// multi draw indirect
  VkBool32 _multi_draw_indirect = VK_FALSE;
  /// indirect draws can use non-zero firstInstance
  VkBool32 _draw_indirect_first_instance = VK_FALSE;
  /// depth clamping
  VkBool32 _depth_clamp = VK_FALSE;
  /// depth bias clamping
  VkBool32 _depth_bias_clamp = VK_FALSE;
  /// point and wireframe fill modes
  VkBool32 _fill_mode_non_solid = VK_FALSE;
  /// depth bounds test
  VkBool32 _depth_bounds = VK_FALSE;
  /// lines with width greater than 1
  VkBool32 _wide_lines = VK_FALSE;
  /// points with size greater than 1
  VkBool32 _large_points = VK_FALSE;
  /// the fragment alpha component can be forced to maximum representable alpha
  /// value
  VkBool32 _alpha_to_one = VK_FALSE;
  /// viewport arrays
  VkBool32 _multi_viewport = VK_FALSE;
  /// anisotropic sampler filtering
  VkBool32 _sampler_anisotropy = VK_FALSE;
  /// ETC texture compression formats
  VkBool32 _texture_compression_etc2 = VK_FALSE;
  /// ASTC LDR texture compression formats
  VkBool32 _texture_compression_astc_ldr = VK_FALSE;
  /// BC1-7 texture compressed formats
  VkBool32 _texture_compression_bc = VK_FALSE;
  /// precise occlusion queries returning actual sample counts
  VkBool32 _occlusion_query_precise = VK_FALSE;
  /// pipeline statistics query
  VkBool32 _pipeline_statistics_query = VK_FALSE;
  /// stores and atomic ops on storage buffers and images are supported in
  /// vertex, tessellation, and geometry stages
  VkBool32 _vertex_pipeline_stores_and_atomics = VK_FALSE;
  /// stores and atomic ops on storage buffers and images are supported in the
  /// fragment stage
  VkBool32 _fragment_stores_and_atomics = VK_FALSE;
  /// tessellation and geometry stages can export point size
  VkBool32 _shader_tessellation_and_geometry_point_size = VK_FALSE;
  /// image gather with run-time values and independent offsets
  VkBool32 _shader_image_gather_extended = VK_FALSE;
  /// the extended set of formats can be used for storage images
  VkBool32 _shader_storage_image_extended_formats = VK_FALSE;
  /// multisample images can be used for storage images
  VkBool32 _shader_storage_image_multisample = VK_FALSE;
  /// read from storage image does not require format qualifier
  VkBool32 _shader_storage_image_read_without_format = VK_FALSE;
  /// write to storage image does not require format qualifier
  VkBool32 _shader_storage_image_write_without_format = VK_FALSE;
  /// arrays of uniform buffers can be accessed with dynamically uniform indices
  VkBool32 _shader_uniform_buffer_array_dynamic_indexing = VK_FALSE;
  /// arrays of sampled images can be accessed with dynamically uniform indices
  VkBool32 _shader_sampled_image_array_dynamic_indexing = VK_FALSE;
  /// arrays of storage buffers can be accessed with dynamically uniform indices
  VkBool32 _shader_storage_buffer_array_dynamic_indexing = VK_FALSE;
  /// arrays of storage images can be accessed with dynamically uniform indices
  VkBool32 _shader_storage_image_array_dynamic_indexing = VK_FALSE;
  /// clip distance in shaders
  VkBool32 _shader_clip_distance = VK_FALSE;
  /// cull distance in shaders
  VkBool32 _shader_cull_distance = VK_FALSE;
  /// 64-bit floats (doubles) in shaders
  VkBool32 _shader_float64 = VK_FALSE;
  /// 64-bit integers in shaders
  VkBool32 _shader_int64 = VK_FALSE;
  /// 16-bit integers in shaders
  VkBool32 _shader_int16 = VK_FALSE;
  /// shader can use texture operations that return resource residency
  /// information (requires sparseNonResident support)
  VkBool32 _shader_resource_residency = VK_FALSE;
  /// shader can use texture operations that specify minimum resource LOD
  VkBool32 _shader_resource_min_lod = VK_FALSE;
  /// Sparse resources support: Resource memory can be managed at opaque page
  /// level rather than object level
  VkBool32 _sparse_binding = VK_FALSE;
  /// Sparse resources support: GPU can access partially resident buffers
  VkBool32 _sparse_residency_buffer = VK_FALSE;
  /// Sparse resources support: GPU can access partially resident 2D (non-MSAA
  /// non-depth/stencil) images
  VkBool32 _sparse_residency_image_2d = VK_FALSE;
  /// Sparse resources support: GPU can access partially resident 3D images
  VkBool32 _sparse_residency_image_3d = VK_FALSE;
  /// Sparse resources support: GPU can access partially resident MSAA 2D images
  /// with 2 samples
  VkBool32 _sparse_residency_2_samples = VK_FALSE;
  /// Sparse resources support: GPU can access partially resident MSAA 2D images
  /// with 4 samples
  VkBool32 _sparse_residency_4_samples = VK_FALSE;
  /// Sparse resources support: GPU can access partially resident MSAA 2D images
  /// with 8 samples
  VkBool32 _sparse_residency_8_samples = VK_FALSE;
  /// Sparse resources support: GPU can access partially resident MSAA 2D images
  /// with 16 samples
  VkBool32 _sparse_residency_16_samples = VK_FALSE;
  /// Sparse resources support: GPU can correctly access data aliased into
  /// multiple locations (opt-in)
  VkBool32 _sparse_residency_aliased = VK_FALSE;
  /// multisample rate must be the same for all pipelines in a subpass
  VkBool32 _variable_multisample_rate = VK_FALSE;
  /// Queries may be inherited from primary to secondary command buffers
  VkBool32 _inherited_queries = VK_FALSE;
};
static_assert(sizeof(physical_device_features) ==
                sizeof(::VkPhysicalDeviceFeatures),
              "struct and wrapper have different size!");

inline void get_physical_device_features(VkPhysicalDevice physical_device,
                                         vk::physical_device_features* features)
{
  vkGetPhysicalDeviceFeatures(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<VkPhysicalDeviceFeatures*>(features));
}
enum class format
{
  /// @see VK_FORMAT_UNDEFINED
  undefined = 0,
  /// @see VK_FORMAT_R4G4_UNORM_PACK8
  r4_g4_unorm_pack8 = 1,
  /// @see VK_FORMAT_R4G4B4A4_UNORM_PACK16
  r4_g4_b4_a4_unorm_pack16 = 2,
  /// @see VK_FORMAT_B4G4R4A4_UNORM_PACK16
  b4_g4_r4_a4_unorm_pack16 = 3,
  /// @see VK_FORMAT_R5G6B5_UNORM_PACK16
  r5_g6_b5_unorm_pack16 = 4,
  /// @see VK_FORMAT_B5G6R5_UNORM_PACK16
  b5_g6_r5_unorm_pack16 = 5,
  /// @see VK_FORMAT_R5G5B5A1_UNORM_PACK16
  r5_g5_b5_a1_unorm_pack16 = 6,
  /// @see VK_FORMAT_B5G5R5A1_UNORM_PACK16
  b5_g5_r5_a1_unorm_pack16 = 7,
  /// @see VK_FORMAT_A1R5G5B5_UNORM_PACK16
  a1_r5_g5_b5_unorm_pack16 = 8,
  /// @see VK_FORMAT_R8_UNORM
  r8_unorm = 9,
  /// @see VK_FORMAT_R8_SNORM
  r8_snorm = 10,
  /// @see VK_FORMAT_R8_USCALED
  r8_uscaled = 11,
  /// @see VK_FORMAT_R8_SSCALED
  r8_sscaled = 12,
  /// @see VK_FORMAT_R8_UINT
  r8_uint = 13,
  /// @see VK_FORMAT_R8_SINT
  r8_sint = 14,
  /// @see VK_FORMAT_R8_SRGB
  r8_srgb = 15,
  /// @see VK_FORMAT_R8G8_UNORM
  r8_g8_unorm = 16,
  /// @see VK_FORMAT_R8G8_SNORM
  r8_g8_snorm = 17,
  /// @see VK_FORMAT_R8G8_USCALED
  r8_g8_uscaled = 18,
  /// @see VK_FORMAT_R8G8_SSCALED
  r8_g8_sscaled = 19,
  /// @see VK_FORMAT_R8G8_UINT
  r8_g8_uint = 20,
  /// @see VK_FORMAT_R8G8_SINT
  r8_g8_sint = 21,
  /// @see VK_FORMAT_R8G8_SRGB
  r8_g8_srgb = 22,
  /// @see VK_FORMAT_R8G8B8_UNORM
  r8_g8_b8_unorm = 23,
  /// @see VK_FORMAT_R8G8B8_SNORM
  r8_g8_b8_snorm = 24,
  /// @see VK_FORMAT_R8G8B8_USCALED
  r8_g8_b8_uscaled = 25,
  /// @see VK_FORMAT_R8G8B8_SSCALED
  r8_g8_b8_sscaled = 26,
  /// @see VK_FORMAT_R8G8B8_UINT
  r8_g8_b8_uint = 27,
  /// @see VK_FORMAT_R8G8B8_SINT
  r8_g8_b8_sint = 28,
  /// @see VK_FORMAT_R8G8B8_SRGB
  r8_g8_b8_srgb = 29,
  /// @see VK_FORMAT_B8G8R8_UNORM
  b8_g8_r8_unorm = 30,
  /// @see VK_FORMAT_B8G8R8_SNORM
  b8_g8_r8_snorm = 31,
  /// @see VK_FORMAT_B8G8R8_USCALED
  b8_g8_r8_uscaled = 32,
  /// @see VK_FORMAT_B8G8R8_SSCALED
  b8_g8_r8_sscaled = 33,
  /// @see VK_FORMAT_B8G8R8_UINT
  b8_g8_r8_uint = 34,
  /// @see VK_FORMAT_B8G8R8_SINT
  b8_g8_r8_sint = 35,
  /// @see VK_FORMAT_B8G8R8_SRGB
  b8_g8_r8_srgb = 36,
  /// @see VK_FORMAT_R8G8B8A8_UNORM
  r8_g8_b8_a8_unorm = 37,
  /// @see VK_FORMAT_R8G8B8A8_SNORM
  r8_g8_b8_a8_snorm = 38,
  /// @see VK_FORMAT_R8G8B8A8_USCALED
  r8_g8_b8_a8_uscaled = 39,
  /// @see VK_FORMAT_R8G8B8A8_SSCALED
  r8_g8_b8_a8_sscaled = 40,
  /// @see VK_FORMAT_R8G8B8A8_UINT
  r8_g8_b8_a8_uint = 41,
  /// @see VK_FORMAT_R8G8B8A8_SINT
  r8_g8_b8_a8_sint = 42,
  /// @see VK_FORMAT_R8G8B8A8_SRGB
  r8_g8_b8_a8_srgb = 43,
  /// @see VK_FORMAT_B8G8R8A8_UNORM
  b8_g8_r8_a8_unorm = 44,
  /// @see VK_FORMAT_B8G8R8A8_SNORM
  b8_g8_r8_a8_snorm = 45,
  /// @see VK_FORMAT_B8G8R8A8_USCALED
  b8_g8_r8_a8_uscaled = 46,
  /// @see VK_FORMAT_B8G8R8A8_SSCALED
  b8_g8_r8_a8_sscaled = 47,
  /// @see VK_FORMAT_B8G8R8A8_UINT
  b8_g8_r8_a8_uint = 48,
  /// @see VK_FORMAT_B8G8R8A8_SINT
  b8_g8_r8_a8_sint = 49,
  /// @see VK_FORMAT_B8G8R8A8_SRGB
  b8_g8_r8_a8_srgb = 50,
  /// @see VK_FORMAT_A8B8G8R8_UNORM_PACK32
  a8_b8_g8_r8_unorm_pack32 = 51,
  /// @see VK_FORMAT_A8B8G8R8_SNORM_PACK32
  a8_b8_g8_r8_snorm_pack32 = 52,
  /// @see VK_FORMAT_A8B8G8R8_USCALED_PACK32
  a8_b8_g8_r8_uscaled_pack32 = 53,
  /// @see VK_FORMAT_A8B8G8R8_SSCALED_PACK32
  a8_b8_g8_r8_sscaled_pack32 = 54,
  /// @see VK_FORMAT_A8B8G8R8_UINT_PACK32
  a8_b8_g8_r8_uint_pack32 = 55,
  /// @see VK_FORMAT_A8B8G8R8_SINT_PACK32
  a8_b8_g8_r8_sint_pack32 = 56,
  /// @see VK_FORMAT_A8B8G8R8_SRGB_PACK32
  a8_b8_g8_r8_srgb_pack32 = 57,
  /// @see VK_FORMAT_A2R10G10B10_UNORM_PACK32
  a2_r10_g10_b10_unorm_pack32 = 58,
  /// @see VK_FORMAT_A2R10G10B10_SNORM_PACK32
  a2_r10_g10_b10_snorm_pack32 = 59,
  /// @see VK_FORMAT_A2R10G10B10_USCALED_PACK32
  a2_r10_g10_b10_uscaled_pack32 = 60,
  /// @see VK_FORMAT_A2R10G10B10_SSCALED_PACK32
  a2_r10_g10_b10_sscaled_pack32 = 61,
  /// @see VK_FORMAT_A2R10G10B10_UINT_PACK32
  a2_r10_g10_b10_uint_pack32 = 62,
  /// @see VK_FORMAT_A2R10G10B10_SINT_PACK32
  a2_r10_g10_b10_sint_pack32 = 63,
  /// @see VK_FORMAT_A2B10G10R10_UNORM_PACK32
  a2_b10_g10_r10_unorm_pack32 = 64,
  /// @see VK_FORMAT_A2B10G10R10_SNORM_PACK32
  a2_b10_g10_r10_snorm_pack32 = 65,
  /// @see VK_FORMAT_A2B10G10R10_USCALED_PACK32
  a2_b10_g10_r10_uscaled_pack32 = 66,
  /// @see VK_FORMAT_A2B10G10R10_SSCALED_PACK32
  a2_b10_g10_r10_sscaled_pack32 = 67,
  /// @see VK_FORMAT_A2B10G10R10_UINT_PACK32
  a2_b10_g10_r10_uint_pack32 = 68,
  /// @see VK_FORMAT_A2B10G10R10_SINT_PACK32
  a2_b10_g10_r10_sint_pack32 = 69,
  /// @see VK_FORMAT_R16_UNORM
  r16_unorm = 70,
  /// @see VK_FORMAT_R16_SNORM
  r16_snorm = 71,
  /// @see VK_FORMAT_R16_USCALED
  r16_uscaled = 72,
  /// @see VK_FORMAT_R16_SSCALED
  r16_sscaled = 73,
  /// @see VK_FORMAT_R16_UINT
  r16_uint = 74,
  /// @see VK_FORMAT_R16_SINT
  r16_sint = 75,
  /// @see VK_FORMAT_R16_SFLOAT
  r16_sfloat = 76,
  /// @see VK_FORMAT_R16G16_UNORM
  r16_g16_unorm = 77,
  /// @see VK_FORMAT_R16G16_SNORM
  r16_g16_snorm = 78,
  /// @see VK_FORMAT_R16G16_USCALED
  r16_g16_uscaled = 79,
  /// @see VK_FORMAT_R16G16_SSCALED
  r16_g16_sscaled = 80,
  /// @see VK_FORMAT_R16G16_UINT
  r16_g16_uint = 81,
  /// @see VK_FORMAT_R16G16_SINT
  r16_g16_sint = 82,
  /// @see VK_FORMAT_R16G16_SFLOAT
  r16_g16_sfloat = 83,
  /// @see VK_FORMAT_R16G16B16_UNORM
  r16_g16_b16_unorm = 84,
  /// @see VK_FORMAT_R16G16B16_SNORM
  r16_g16_b16_snorm = 85,
  /// @see VK_FORMAT_R16G16B16_USCALED
  r16_g16_b16_uscaled = 86,
  /// @see VK_FORMAT_R16G16B16_SSCALED
  r16_g16_b16_sscaled = 87,
  /// @see VK_FORMAT_R16G16B16_UINT
  r16_g16_b16_uint = 88,
  /// @see VK_FORMAT_R16G16B16_SINT
  r16_g16_b16_sint = 89,
  /// @see VK_FORMAT_R16G16B16_SFLOAT
  r16_g16_b16_sfloat = 90,
  /// @see VK_FORMAT_R16G16B16A16_UNORM
  r16_g16_b16_a16_unorm = 91,
  /// @see VK_FORMAT_R16G16B16A16_SNORM
  r16_g16_b16_a16_snorm = 92,
  /// @see VK_FORMAT_R16G16B16A16_USCALED
  r16_g16_b16_a16_uscaled = 93,
  /// @see VK_FORMAT_R16G16B16A16_SSCALED
  r16_g16_b16_a16_sscaled = 94,
  /// @see VK_FORMAT_R16G16B16A16_UINT
  r16_g16_b16_a16_uint = 95,
  /// @see VK_FORMAT_R16G16B16A16_SINT
  r16_g16_b16_a16_sint = 96,
  /// @see VK_FORMAT_R16G16B16A16_SFLOAT
  r16_g16_b16_a16_sfloat = 97,
  /// @see VK_FORMAT_R32_UINT
  r32_uint = 98,
  /// @see VK_FORMAT_R32_SINT
  r32_sint = 99,
  /// @see VK_FORMAT_R32_SFLOAT
  r32_sfloat = 100,
  /// @see VK_FORMAT_R32G32_UINT
  r32_g32_uint = 101,
  /// @see VK_FORMAT_R32G32_SINT
  r32_g32_sint = 102,
  /// @see VK_FORMAT_R32G32_SFLOAT
  r32_g32_sfloat = 103,
  /// @see VK_FORMAT_R32G32B32_UINT
  r32_g32_b32_uint = 104,
  /// @see VK_FORMAT_R32G32B32_SINT
  r32_g32_b32_sint = 105,
  /// @see VK_FORMAT_R32G32B32_SFLOAT
  r32_g32_b32_sfloat = 106,
  /// @see VK_FORMAT_R32G32B32A32_UINT
  r32_g32_b32_a32_uint = 107,
  /// @see VK_FORMAT_R32G32B32A32_SINT
  r32_g32_b32_a32_sint = 108,
  /// @see VK_FORMAT_R32G32B32A32_SFLOAT
  r32_g32_b32_a32_sfloat = 109,
  /// @see VK_FORMAT_R64_UINT
  r64_uint = 110,
  /// @see VK_FORMAT_R64_SINT
  r64_sint = 111,
  /// @see VK_FORMAT_R64_SFLOAT
  r64_sfloat = 112,
  /// @see VK_FORMAT_R64G64_UINT
  r64_g64_uint = 113,
  /// @see VK_FORMAT_R64G64_SINT
  r64_g64_sint = 114,
  /// @see VK_FORMAT_R64G64_SFLOAT
  r64_g64_sfloat = 115,
  /// @see VK_FORMAT_R64G64B64_UINT
  r64_g64_b64_uint = 116,
  /// @see VK_FORMAT_R64G64B64_SINT
  r64_g64_b64_sint = 117,
  /// @see VK_FORMAT_R64G64B64_SFLOAT
  r64_g64_b64_sfloat = 118,
  /// @see VK_FORMAT_R64G64B64A64_UINT
  r64_g64_b64_a64_uint = 119,
  /// @see VK_FORMAT_R64G64B64A64_SINT
  r64_g64_b64_a64_sint = 120,
  /// @see VK_FORMAT_R64G64B64A64_SFLOAT
  r64_g64_b64_a64_sfloat = 121,
  /// @see VK_FORMAT_B10G11R11_UFLOAT_PACK32
  b10_g11_r11_ufloat_pack32 = 122,
  /// @see VK_FORMAT_E5B9G9R9_UFLOAT_PACK32
  e5_b9_g9_r9_ufloat_pack32 = 123,
  /// @see VK_FORMAT_D16_UNORM
  d16_unorm = 124,
  /// @see VK_FORMAT_X8_D24_UNORM_PACK32
  x8_d24_unorm_pack32 = 125,
  /// @see VK_FORMAT_D32_SFLOAT
  d32_sfloat = 126,
  /// @see VK_FORMAT_S8_UINT
  s8_uint = 127,
  /// @see VK_FORMAT_D16_UNORM_S8_UINT
  d16_unorm_s8_uint = 128,
  /// @see VK_FORMAT_D24_UNORM_S8_UINT
  d24_unorm_s8_uint = 129,
  /// @see VK_FORMAT_D32_SFLOAT_S8_UINT
  d32_sfloat_s8_uint = 130,
  /// @see VK_FORMAT_BC1_RGB_UNORM_BLOCK
  bc1_rgb_unorm_block = 131,
  /// @see VK_FORMAT_BC1_RGB_SRGB_BLOCK
  bc1_rgb_srgb_block = 132,
  /// @see VK_FORMAT_BC1_RGBA_UNORM_BLOCK
  bc1_rgba_unorm_block = 133,
  /// @see VK_FORMAT_BC1_RGBA_SRGB_BLOCK
  bc1_rgba_srgb_block = 134,
  /// @see VK_FORMAT_BC2_UNORM_BLOCK
  bc2_unorm_block = 135,
  /// @see VK_FORMAT_BC2_SRGB_BLOCK
  bc2_srgb_block = 136,
  /// @see VK_FORMAT_BC3_UNORM_BLOCK
  bc3_unorm_block = 137,
  /// @see VK_FORMAT_BC3_SRGB_BLOCK
  bc3_srgb_block = 138,
  /// @see VK_FORMAT_BC4_UNORM_BLOCK
  bc4_unorm_block = 139,
  /// @see VK_FORMAT_BC4_SNORM_BLOCK
  bc4_snorm_block = 140,
  /// @see VK_FORMAT_BC5_UNORM_BLOCK
  bc5_unorm_block = 141,
  /// @see VK_FORMAT_BC5_SNORM_BLOCK
  bc5_snorm_block = 142,
  /// @see VK_FORMAT_BC6H_UFLOAT_BLOCK
  bc6h_ufloat_block = 143,
  /// @see VK_FORMAT_BC6H_SFLOAT_BLOCK
  bc6h_sfloat_block = 144,
  /// @see VK_FORMAT_BC7_UNORM_BLOCK
  bc7_unorm_block = 145,
  /// @see VK_FORMAT_BC7_SRGB_BLOCK
  bc7_srgb_block = 146,
  /// @see VK_FORMAT_ETC2_R8G8B8_UNORM_BLOCK
  etc2_r8_g8_b8_unorm_block = 147,
  /// @see VK_FORMAT_ETC2_R8G8B8_SRGB_BLOCK
  etc2_r8_g8_b8_srgb_block = 148,
  /// @see VK_FORMAT_ETC2_R8G8B8A1_UNORM_BLOCK
  etc2_r8_g8_b8_a1_unorm_block = 149,
  /// @see VK_FORMAT_ETC2_R8G8B8A1_SRGB_BLOCK
  etc2_r8_g8_b8_a1_srgb_block = 150,
  /// @see VK_FORMAT_ETC2_R8G8B8A8_UNORM_BLOCK
  etc2_r8_g8_b8_a8_unorm_block = 151,
  /// @see VK_FORMAT_ETC2_R8G8B8A8_SRGB_BLOCK
  etc2_r8_g8_b8_a8_srgb_block = 152,
  /// @see VK_FORMAT_EAC_R11_UNORM_BLOCK
  eac_r11_unorm_block = 153,
  /// @see VK_FORMAT_EAC_R11_SNORM_BLOCK
  eac_r11_snorm_block = 154,
  /// @see VK_FORMAT_EAC_R11G11_UNORM_BLOCK
  eac_r11_g11_unorm_block = 155,
  /// @see VK_FORMAT_EAC_R11G11_SNORM_BLOCK
  eac_r11_g11_snorm_block = 156,
  /// @see VK_FORMAT_ASTC_4x4_UNORM_BLOCK
  astc_4x4_unorm_block = 157,
  /// @see VK_FORMAT_ASTC_4x4_SRGB_BLOCK
  astc_4x4_srgb_block = 158,
  /// @see VK_FORMAT_ASTC_5x4_UNORM_BLOCK
  astc_5x4_unorm_block = 159,
  /// @see VK_FORMAT_ASTC_5x4_SRGB_BLOCK
  astc_5x4_srgb_block = 160,
  /// @see VK_FORMAT_ASTC_5x5_UNORM_BLOCK
  astc_5x5_unorm_block = 161,
  /// @see VK_FORMAT_ASTC_5x5_SRGB_BLOCK
  astc_5x5_srgb_block = 162,
  /// @see VK_FORMAT_ASTC_6x5_UNORM_BLOCK
  astc_6x5_unorm_block = 163,
  /// @see VK_FORMAT_ASTC_6x5_SRGB_BLOCK
  astc_6x5_srgb_block = 164,
  /// @see VK_FORMAT_ASTC_6x6_UNORM_BLOCK
  astc_6x6_unorm_block = 165,
  /// @see VK_FORMAT_ASTC_6x6_SRGB_BLOCK
  astc_6x6_srgb_block = 166,
  /// @see VK_FORMAT_ASTC_8x5_UNORM_BLOCK
  astc_8x5_unorm_block = 167,
  /// @see VK_FORMAT_ASTC_8x5_SRGB_BLOCK
  astc_8x5_srgb_block = 168,
  /// @see VK_FORMAT_ASTC_8x6_UNORM_BLOCK
  astc_8x6_unorm_block = 169,
  /// @see VK_FORMAT_ASTC_8x6_SRGB_BLOCK
  astc_8x6_srgb_block = 170,
  /// @see VK_FORMAT_ASTC_8x8_UNORM_BLOCK
  astc_8x8_unorm_block = 171,
  /// @see VK_FORMAT_ASTC_8x8_SRGB_BLOCK
  astc_8x8_srgb_block = 172,
  /// @see VK_FORMAT_ASTC_10x5_UNORM_BLOCK
  astc_10x5_unorm_block = 173,
  /// @see VK_FORMAT_ASTC_10x5_SRGB_BLOCK
  astc_10x5_srgb_block = 174,
  /// @see VK_FORMAT_ASTC_10x6_UNORM_BLOCK
  astc_10x6_unorm_block = 175,
  /// @see VK_FORMAT_ASTC_10x6_SRGB_BLOCK
  astc_10x6_srgb_block = 176,
  /// @see VK_FORMAT_ASTC_10x8_UNORM_BLOCK
  astc_10x8_unorm_block = 177,
  /// @see VK_FORMAT_ASTC_10x8_SRGB_BLOCK
  astc_10x8_srgb_block = 178,
  /// @see VK_FORMAT_ASTC_10x10_UNORM_BLOCK
  astc_10x10_unorm_block = 179,
  /// @see VK_FORMAT_ASTC_10x10_SRGB_BLOCK
  astc_10x10_srgb_block = 180,
  /// @see VK_FORMAT_ASTC_12x10_UNORM_BLOCK
  astc_12x10_unorm_block = 181,
  /// @see VK_FORMAT_ASTC_12x10_SRGB_BLOCK
  astc_12x10_srgb_block = 182,
  /// @see VK_FORMAT_ASTC_12x12_UNORM_BLOCK
  astc_12x12_unorm_block = 183,
  /// @see VK_FORMAT_ASTC_12x12_SRGB_BLOCK
  astc_12x12_srgb_block = 184,
  /// @see VK_FORMAT_G8B8G8R8_422_UNORM
  g8_b8_g8_r8_422_unorm = 1000156000,
  /// @see VK_FORMAT_B8G8R8G8_422_UNORM
  b8_g8_r8_g8_422_unorm = 1000156001,
  /// @see VK_FORMAT_G8_B8_R8_3PLANE_420_UNORM
  g8_b8_r8_3_plane_420_unorm = 1000156002,
  /// @see VK_FORMAT_G8_B8R8_2PLANE_420_UNORM
  g8_b8_r8_2_plane_420_unorm = 1000156003,
  /// @see VK_FORMAT_G8_B8_R8_3PLANE_422_UNORM
  g8_b8_r8_3_plane_422_unorm = 1000156004,
  /// @see VK_FORMAT_G8_B8R8_2PLANE_422_UNORM
  g8_b8_r8_2_plane_422_unorm = 1000156005,
  /// @see VK_FORMAT_G8_B8_R8_3PLANE_444_UNORM
  g8_b8_r8_3_plane_444_unorm = 1000156006,
  /// @see VK_FORMAT_R10X6_UNORM_PACK16
  r10_x6_unorm_pack16 = 1000156007,
  /// @see VK_FORMAT_R10X6G10X6_UNORM_2PACK16
  r10_x6_g10_x6_unorm_2_pack16 = 1000156008,
  /// @see VK_FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16
  r10_x6_g10_x6_b10_x6_a10_x6_unorm_4_pack16 = 1000156009,
  /// @see VK_FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16
  g10_x6_b10_x6_g10_x6_r10_x6_422_unorm_4_pack16 = 1000156010,
  /// @see VK_FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16
  b10_x6_g10_x6_r10_x6_g10_x6_422_unorm_4_pack16 = 1000156011,
  /// @see VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16
  g10_x6_b10_x6_r10_x6_3_plane_420_unorm_3_pack16 = 1000156012,
  /// @see VK_FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16
  g10_x6_b10_x6_r10_x6_2_plane_420_unorm_3_pack16 = 1000156013,
  /// @see VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16
  g10_x6_b10_x6_r10_x6_3_plane_422_unorm_3_pack16 = 1000156014,
  /// @see VK_FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16
  g10_x6_b10_x6_r10_x6_2_plane_422_unorm_3_pack16 = 1000156015,
  /// @see VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16
  g10_x6_b10_x6_r10_x6_3_plane_444_unorm_3_pack16 = 1000156016,
  /// @see VK_FORMAT_R12X4_UNORM_PACK16
  r12_x4_unorm_pack16 = 1000156017,
  /// @see VK_FORMAT_R12X4G12X4_UNORM_2PACK16
  r12_x4_g12_x4_unorm_2_pack16 = 1000156018,
  /// @see VK_FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16
  r12_x4_g12_x4_b12_x4_a12_x4_unorm_4_pack16 = 1000156019,
  /// @see VK_FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16
  g12_x4_b12_x4_g12_x4_r12_x4_422_unorm_4_pack16 = 1000156020,
  /// @see VK_FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16
  b12_x4_g12_x4_r12_x4_g12_x4_422_unorm_4_pack16 = 1000156021,
  /// @see VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16
  g12_x4_b12_x4_r12_x4_3_plane_420_unorm_3_pack16 = 1000156022,
  /// @see VK_FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16
  g12_x4_b12_x4_r12_x4_2_plane_420_unorm_3_pack16 = 1000156023,
  /// @see VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16
  g12_x4_b12_x4_r12_x4_3_plane_422_unorm_3_pack16 = 1000156024,
  /// @see VK_FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16
  g12_x4_b12_x4_r12_x4_2_plane_422_unorm_3_pack16 = 1000156025,
  /// @see VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16
  g12_x4_b12_x4_r12_x4_3_plane_444_unorm_3_pack16 = 1000156026,
  /// @see VK_FORMAT_G16B16G16R16_422_UNORM
  g16_b16_g16_r16_422_unorm = 1000156027,
  /// @see VK_FORMAT_B16G16R16G16_422_UNORM
  b16_g16_r16_g16_422_unorm = 1000156028,
  /// @see VK_FORMAT_G16_B16_R16_3PLANE_420_UNORM
  g16_b16_r16_3_plane_420_unorm = 1000156029,
  /// @see VK_FORMAT_G16_B16R16_2PLANE_420_UNORM
  g16_b16_r16_2_plane_420_unorm = 1000156030,
  /// @see VK_FORMAT_G16_B16_R16_3PLANE_422_UNORM
  g16_b16_r16_3_plane_422_unorm = 1000156031,
  /// @see VK_FORMAT_G16_B16R16_2PLANE_422_UNORM
  g16_b16_r16_2_plane_422_unorm = 1000156032,
  /// @see VK_FORMAT_G16_B16_R16_3PLANE_444_UNORM
  g16_b16_r16_3_plane_444_unorm = 1000156033,
  /// @see VK_FORMAT_PVRTC1_2BPP_UNORM_BLOCK_IMG
  pvrtc1_2bpp_unorm_block_img = 1000054000,
  /// @see VK_FORMAT_PVRTC1_4BPP_UNORM_BLOCK_IMG
  pvrtc1_4bpp_unorm_block_img = 1000054001,
  /// @see VK_FORMAT_PVRTC2_2BPP_UNORM_BLOCK_IMG
  pvrtc2_2bpp_unorm_block_img = 1000054002,
  /// @see VK_FORMAT_PVRTC2_4BPP_UNORM_BLOCK_IMG
  pvrtc2_4bpp_unorm_block_img = 1000054003,
  /// @see VK_FORMAT_PVRTC1_2BPP_SRGB_BLOCK_IMG
  pvrtc1_2bpp_srgb_block_img = 1000054004,
  /// @see VK_FORMAT_PVRTC1_4BPP_SRGB_BLOCK_IMG
  pvrtc1_4bpp_srgb_block_img = 1000054005,
  /// @see VK_FORMAT_PVRTC2_2BPP_SRGB_BLOCK_IMG
  pvrtc2_2bpp_srgb_block_img = 1000054006,
  /// @see VK_FORMAT_PVRTC2_4BPP_SRGB_BLOCK_IMG
  pvrtc2_4bpp_srgb_block_img = 1000054007,
};
enum class format_feature_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Format can be used for sampled images (SAMPLED_IMAGE and
  /// COMBINED_IMAGE_SAMPLER descriptor types)
  /// @see VK_FORMAT_FEATURE_SAMPLED_IMAGE_BIT
  sampled_image_bit = 1 << 0,
  /// Format can be used for storage images (STORAGE_IMAGE descriptor type)
  /// @see VK_FORMAT_FEATURE_STORAGE_IMAGE_BIT
  storage_image_bit = 1 << 1,
  /// Format supports atomic operations in case it is used for storage images
  /// @see VK_FORMAT_FEATURE_STORAGE_IMAGE_ATOMIC_BIT
  storage_image_atomic_bit = 1 << 2,
  /// Format can be used for uniform texel buffers (TBOs)
  /// @see VK_FORMAT_FEATURE_UNIFORM_TEXEL_BUFFER_BIT
  uniform_texel_buffer_bit = 1 << 3,
  /// Format can be used for storage texel buffers (IBOs)
  /// @see VK_FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_BIT
  storage_texel_buffer_bit = 1 << 4,
  /// Format supports atomic operations in case it is used for storage texel
  /// buffers
  /// @see VK_FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_ATOMIC_BIT
  storage_texel_buffer_atomic_bit = 1 << 5,
  /// Format can be used for vertex buffers (VBOs)
  /// @see VK_FORMAT_FEATURE_VERTEX_BUFFER_BIT
  vertex_buffer_bit = 1 << 6,
  /// Format can be used for color attachment images
  /// @see VK_FORMAT_FEATURE_COLOR_ATTACHMENT_BIT
  color_attachment_bit = 1 << 7,
  /// Format supports blending in case it is used for color attachment images
  /// @see VK_FORMAT_FEATURE_COLOR_ATTACHMENT_BLEND_BIT
  color_attachment_blend_bit = 1 << 8,
  /// Format can be used for depth/stencil attachment images
  /// @see VK_FORMAT_FEATURE_DEPTH_STENCIL_ATTACHMENT_BIT
  depth_stencil_attachment_bit = 1 << 9,
  /// Format can be used as the source image of blits with vkCmdBlitImage
  /// @see VK_FORMAT_FEATURE_BLIT_SRC_BIT
  blit_src_bit = 1 << 10,
  /// Format can be used as the destination image of blits with vkCmdBlitImage
  /// @see VK_FORMAT_FEATURE_BLIT_DST_BIT
  blit_dst_bit = 1 << 11,
  /// Format can be filtered with VK_FILTER_LINEAR when being sampled
  /// @see VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT
  sampled_image_filter_linear_bit = 1 << 12,
  /// Format can be used as the source image of image transfer commands
  /// @see VK_FORMAT_FEATURE_TRANSFER_SRC_BIT
  transfer_src_bit = 1 << 14,
  /// Format can be used as the destination image of image transfer commands
  /// @see VK_FORMAT_FEATURE_TRANSFER_DST_BIT
  transfer_dst_bit = 1 << 15,
  /// Format can have midpoint rather than cosited chroma samples
  /// @see VK_FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT
  midpoint_chroma_samples_bit = 1 << 17,
  /// Format can be used with linear filtering whilst color conversion is
  /// enabled
  /// @see VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT
  sampled_image_ycbcr_conversion_linear_filter_bit = 1 << 18,
  /// Format can have different chroma, min and mag filters
  /// @see
  /// VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT
  sampled_image_ycbcr_conversion_separate_reconstruction_filter_bit = 1 << 19,
  /// @see
  /// VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT
  sampled_image_ycbcr_conversion_chroma_reconstruction_explicit_bit = 1 << 20,
  /// @see
  /// VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT
  sampled_image_ycbcr_conversion_chroma_reconstruction_explicit_forceable_bit =
    1 << 21,
  /// Format supports disjoint planes
  /// @see VK_FORMAT_FEATURE_DISJOINT_BIT
  disjoint_bit = 1 << 22,
  /// Format can have cosited rather than midpoint chroma samples
  /// @see VK_FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT
  cosited_chroma_samples_bit = 1 << 23,
  /// Format can be filtered with VK_FILTER_CUBIC_IMG when being sampled
  /// @see VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_CUBIC_BIT_IMG
  sampled_image_filter_cubic_bit_img = 1 << 13,
  /// Format can be used with min/max reduction filtering
  /// @see VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_MINMAX_BIT_EXT
  sampled_image_filter_minmax_bit_ext = 1 << 16,
};
using format_feature_flags =
  shift::core::bit_field<format_feature_flag, VkFormatFeatureFlags>;
inline constexpr format_feature_flags operator|(format_feature_flag lhs,
                                                format_feature_flag rhs)
{
  return format_feature_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkFormatProperties.
class format_properties
{
public:
  /// Default constructor.
  constexpr format_properties() = default;

  /// Constructor.
  constexpr format_properties(
    vk::format_feature_flags initial_linear_tiling_features,
    vk::format_feature_flags initial_optimal_tiling_features,
    vk::format_feature_flags initial_buffer_features) noexcept
  : _linear_tiling_features(std::move(initial_linear_tiling_features)),
    _optimal_tiling_features(std::move(initial_optimal_tiling_features)),
    _buffer_features(std::move(initial_buffer_features))
  {
  }

  /// Copy constructor.
  constexpr format_properties(const format_properties& other) = default;

  /// Move constructor.
  constexpr format_properties(format_properties&& other) = default;

  /// Copy assignment operator.
  constexpr format_properties& operator=(const format_properties& other) =
    default;

  /// Move assignment operator.
  constexpr format_properties& operator=(format_properties&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkFormatProperties&() const
  {
    return *reinterpret_cast<const VkFormatProperties*>(this);
  }

  vk::format_feature_flags& linear_tiling_features()
  {
    return _linear_tiling_features;
  }

  constexpr const vk::format_feature_flags& linear_tiling_features() const
  {
    return _linear_tiling_features;
  }

  void linear_tiling_features(
    vk::format_feature_flags new_linear_tiling_features)
  {
    _linear_tiling_features = new_linear_tiling_features;
  }

  vk::format_feature_flags& optimal_tiling_features()
  {
    return _optimal_tiling_features;
  }

  constexpr const vk::format_feature_flags& optimal_tiling_features() const
  {
    return _optimal_tiling_features;
  }

  void optimal_tiling_features(
    vk::format_feature_flags new_optimal_tiling_features)
  {
    _optimal_tiling_features = new_optimal_tiling_features;
  }

  vk::format_feature_flags& buffer_features()
  {
    return _buffer_features;
  }

  constexpr const vk::format_feature_flags& buffer_features() const
  {
    return _buffer_features;
  }

  void buffer_features(vk::format_feature_flags new_buffer_features)
  {
    _buffer_features = new_buffer_features;
  }

private:
  /// Format features in case of linear tiling
  vk::format_feature_flags _linear_tiling_features =
    vk::format_feature_flag::none;
  /// Format features in case of optimal tiling
  vk::format_feature_flags _optimal_tiling_features =
    vk::format_feature_flag::none;
  /// Format features supported by buffers
  vk::format_feature_flags _buffer_features = vk::format_feature_flag::none;
};
static_assert(sizeof(format_properties) == sizeof(::VkFormatProperties),
              "struct and wrapper have different size!");

inline void get_physical_device_format_properties(
  VkPhysicalDevice physical_device, vk::format format,
  vk::format_properties* format_properties)
{
  vkGetPhysicalDeviceFormatProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkFormat>(format),
    reinterpret_cast<VkFormatProperties*>(format_properties));
}
enum class image_type
{
  /// @see VK_IMAGE_TYPE_1D
  _1d = 0,
  /// @see VK_IMAGE_TYPE_2D
  _2d = 1,
  /// @see VK_IMAGE_TYPE_3D
  _3d = 2,
};
enum class image_tiling
{
  /// @see VK_IMAGE_TILING_OPTIMAL
  optimal = 0,
  /// @see VK_IMAGE_TILING_LINEAR
  linear = 1,
};
enum class image_usage_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Can be used as a source of transfer operations
  /// @see VK_IMAGE_USAGE_TRANSFER_SRC_BIT
  transfer_src_bit = 1 << 0,
  /// Can be used as a destination of transfer operations
  /// @see VK_IMAGE_USAGE_TRANSFER_DST_BIT
  transfer_dst_bit = 1 << 1,
  /// Can be sampled from (SAMPLED_IMAGE and COMBINED_IMAGE_SAMPLER descriptor
  /// types)
  /// @see VK_IMAGE_USAGE_SAMPLED_BIT
  sampled_bit = 1 << 2,
  /// Can be used as storage image (STORAGE_IMAGE descriptor type)
  /// @see VK_IMAGE_USAGE_STORAGE_BIT
  storage_bit = 1 << 3,
  /// Can be used as framebuffer color attachment
  /// @see VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT
  color_attachment_bit = 1 << 4,
  /// Can be used as framebuffer depth/stencil attachment
  /// @see VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT
  depth_stencil_attachment_bit = 1 << 5,
  /// Image data not needed outside of rendering
  /// @see VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT
  transient_attachment_bit = 1 << 6,
  /// Can be used as framebuffer input attachment
  /// @see VK_IMAGE_USAGE_INPUT_ATTACHMENT_BIT
  input_attachment_bit = 1 << 7,
  /// @see VK_IMAGE_USAGE_SHADING_RATE_IMAGE_BIT_NV
  shading_rate_image_bit_nv = 1 << 8,
};
using image_usage_flags =
  shift::core::bit_field<image_usage_flag, VkImageUsageFlags>;
inline constexpr image_usage_flags operator|(image_usage_flag lhs,
                                             image_usage_flag rhs)
{
  return image_usage_flags{lhs} | rhs;
}
enum class image_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Image should support sparse backing
  /// @see VK_IMAGE_CREATE_SPARSE_BINDING_BIT
  sparse_binding_bit = 1 << 0,
  /// Image should support sparse backing with partial residency
  /// @see VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT
  sparse_residency_bit = 1 << 1,
  /// Image should support constent data access to physical memory ranges mapped
  /// into multiple locations of sparse images
  /// @see VK_IMAGE_CREATE_SPARSE_ALIASED_BIT
  sparse_aliased_bit = 1 << 2,
  /// Allows image views to have different format than the base image
  /// @see VK_IMAGE_CREATE_MUTABLE_FORMAT_BIT
  mutable_format_bit = 1 << 3,
  /// Allows creating image views with cube type from the created image
  /// @see VK_IMAGE_CREATE_CUBE_COMPATIBLE_BIT
  cube_compatible_bit = 1 << 4,
  /// @see VK_IMAGE_CREATE_ALIAS_BIT
  alias_bit = 1 << 10,
  /// Allows using VkBindImageMemoryDeviceGroupInfo::pSplitInstanceBindRegions
  /// when binding memory to the image
  /// @see VK_IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT
  split_instance_bind_regions_bit = 1 << 6,
  /// The 3D image can be viewed as a 2D or 2D array image
  /// @see VK_IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT
  _2d_array_compatible_bit = 1 << 5,
  /// @see VK_IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT
  block_texel_view_compatible_bit = 1 << 7,
  /// @see VK_IMAGE_CREATE_EXTENDED_USAGE_BIT
  extended_usage_bit = 1 << 8,
  /// Image requires protected memory
  /// @see VK_IMAGE_CREATE_PROTECTED_BIT
  protected_bit = 1 << 11,
  /// @see VK_IMAGE_CREATE_DISJOINT_BIT
  disjoint_bit = 1 << 9,
  /// @see VK_IMAGE_CREATE_CORNER_SAMPLED_BIT_NV
  corner_sampled_bit_nv = 1 << 13,
  /// @see VK_IMAGE_CREATE_SAMPLE_LOCATIONS_COMPATIBLE_DEPTH_BIT_EXT
  sample_locations_compatible_depth_bit_ext = 1 << 12,
};
using image_create_flags =
  shift::core::bit_field<image_create_flag, VkImageCreateFlags>;
inline constexpr image_create_flags operator|(image_create_flag lhs,
                                              image_create_flag rhs)
{
  return image_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkExtent3D.
class extent_3d
{
public:
  /// Default constructor.
  constexpr extent_3d() = default;

  /// Constructor.
  constexpr extent_3d(uint32_t initial_width, uint32_t initial_height,
                      uint32_t initial_depth) noexcept
  : _width(std::move(initial_width)),
    _height(std::move(initial_height)),
    _depth(std::move(initial_depth))
  {
  }

  /// Copy constructor.
  constexpr extent_3d(const extent_3d& other) = default;

  /// Move constructor.
  constexpr extent_3d(extent_3d&& other) = default;

  /// Copy assignment operator.
  constexpr extent_3d& operator=(const extent_3d& other) = default;

  /// Move assignment operator.
  constexpr extent_3d& operator=(extent_3d&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkExtent3D&() const
  {
    return *reinterpret_cast<const VkExtent3D*>(this);
  }

  uint32_t& width()
  {
    return _width;
  }

  constexpr const uint32_t& width() const
  {
    return _width;
  }

  void width(uint32_t new_width)
  {
    _width = new_width;
  }

  uint32_t& height()
  {
    return _height;
  }

  constexpr const uint32_t& height() const
  {
    return _height;
  }

  void height(uint32_t new_height)
  {
    _height = new_height;
  }

  uint32_t& depth()
  {
    return _depth;
  }

  constexpr const uint32_t& depth() const
  {
    return _depth;
  }

  void depth(uint32_t new_depth)
  {
    _depth = new_depth;
  }

private:
  uint32_t _width = 0;
  uint32_t _height = 0;
  uint32_t _depth = 0;
};
static_assert(sizeof(extent_3d) == sizeof(::VkExtent3D),
              "struct and wrapper have different size!");

enum class sample_count_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Sample count 1 supported
  /// @see VK_SAMPLE_COUNT_1_BIT
  _1_bit = 1 << 0,
  /// Sample count 2 supported
  /// @see VK_SAMPLE_COUNT_2_BIT
  _2_bit = 1 << 1,
  /// Sample count 4 supported
  /// @see VK_SAMPLE_COUNT_4_BIT
  _4_bit = 1 << 2,
  /// Sample count 8 supported
  /// @see VK_SAMPLE_COUNT_8_BIT
  _8_bit = 1 << 3,
  /// Sample count 16 supported
  /// @see VK_SAMPLE_COUNT_16_BIT
  _16_bit = 1 << 4,
  /// Sample count 32 supported
  /// @see VK_SAMPLE_COUNT_32_BIT
  _32_bit = 1 << 5,
  /// Sample count 64 supported
  /// @see VK_SAMPLE_COUNT_64_BIT
  _64_bit = 1 << 6,
};
using sample_count_flags =
  shift::core::bit_field<sample_count_flag, VkSampleCountFlags>;
inline constexpr sample_count_flags operator|(sample_count_flag lhs,
                                              sample_count_flag rhs)
{
  return sample_count_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkImageFormatProperties.
class image_format_properties
{
public:
  /// Default constructor.
  constexpr image_format_properties() = default;

  /// Constructor.
  constexpr image_format_properties(
    vk::extent_3d initial_max_extent, uint32_t initial_max_mip_levels,
    uint32_t initial_max_array_layers,
    vk::sample_count_flags initial_sample_counts,
    VkDeviceSize initial_max_resource_size) noexcept
  : _max_extent(std::move(initial_max_extent)),
    _max_mip_levels(std::move(initial_max_mip_levels)),
    _max_array_layers(std::move(initial_max_array_layers)),
    _sample_counts(std::move(initial_sample_counts)),
    _max_resource_size(std::move(initial_max_resource_size))
  {
  }

  /// Copy constructor.
  constexpr image_format_properties(const image_format_properties& other) =
    default;

  /// Move constructor.
  constexpr image_format_properties(image_format_properties&& other) = default;

  /// Copy assignment operator.
  constexpr image_format_properties& operator=(
    const image_format_properties& other) = default;

  /// Move assignment operator.
  constexpr image_format_properties& operator=(
    image_format_properties&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkImageFormatProperties&() const
  {
    return *reinterpret_cast<const VkImageFormatProperties*>(this);
  }

  vk::extent_3d& max_extent()
  {
    return _max_extent;
  }

  constexpr const vk::extent_3d& max_extent() const
  {
    return _max_extent;
  }

  void max_extent(vk::extent_3d new_max_extent)
  {
    _max_extent = new_max_extent;
  }

  uint32_t& max_mip_levels()
  {
    return _max_mip_levels;
  }

  constexpr const uint32_t& max_mip_levels() const
  {
    return _max_mip_levels;
  }

  void max_mip_levels(uint32_t new_max_mip_levels)
  {
    _max_mip_levels = new_max_mip_levels;
  }

  uint32_t& max_array_layers()
  {
    return _max_array_layers;
  }

  constexpr const uint32_t& max_array_layers() const
  {
    return _max_array_layers;
  }

  void max_array_layers(uint32_t new_max_array_layers)
  {
    _max_array_layers = new_max_array_layers;
  }

  vk::sample_count_flags& sample_counts()
  {
    return _sample_counts;
  }

  constexpr const vk::sample_count_flags& sample_counts() const
  {
    return _sample_counts;
  }

  void sample_counts(vk::sample_count_flags new_sample_counts)
  {
    _sample_counts = new_sample_counts;
  }

  VkDeviceSize& max_resource_size()
  {
    return _max_resource_size;
  }

  constexpr const VkDeviceSize& max_resource_size() const
  {
    return _max_resource_size;
  }

  void max_resource_size(VkDeviceSize new_max_resource_size)
  {
    _max_resource_size = new_max_resource_size;
  }

private:
  /// max image dimensions for this resource type
  vk::extent_3d _max_extent = vk::extent_3d{};
  /// max number of mipmap levels for this resource type
  uint32_t _max_mip_levels = 0;
  /// max array size for this resource type
  uint32_t _max_array_layers = 0;
  /// supported sample counts for this resource type
  vk::sample_count_flags _sample_counts = vk::sample_count_flag::none;
  /// max size (in bytes) of this resource type
  VkDeviceSize _max_resource_size = 0;
};
static_assert(sizeof(image_format_properties) ==
                sizeof(::VkImageFormatProperties),
              "struct and wrapper have different size!");

inline vk::result get_physical_device_image_format_properties(
  VkPhysicalDevice physical_device, vk::format format, vk::image_type type,
  vk::image_tiling tiling, vk::image_usage_flags usage,
  vk::image_create_flags flags,
  vk::image_format_properties* image_format_properties)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceImageFormatProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkFormat>(format), static_cast<VkImageType>(type),
    static_cast<VkImageTiling>(tiling), static_cast<VkImageUsageFlags>(usage),
    static_cast<VkImageCreateFlags>(flags),
    reinterpret_cast<VkImageFormatProperties*>(image_format_properties)));
}
enum class physical_device_type
{
  /// @see VK_PHYSICAL_DEVICE_TYPE_OTHER
  other = 0,
  /// @see VK_PHYSICAL_DEVICE_TYPE_INTEGRATED_GPU
  integrated_gpu = 1,
  /// @see VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU
  discrete_gpu = 2,
  /// @see VK_PHYSICAL_DEVICE_TYPE_VIRTUAL_GPU
  virtual_gpu = 3,
  /// @see VK_PHYSICAL_DEVICE_TYPE_CPU
  cpu = 4,
};

/// Enhanced replacement type for VkPhysicalDeviceLimits.
class physical_device_limits
{
public:
  /// Default constructor.
  constexpr physical_device_limits() = default;

  /// Constructor.
  constexpr physical_device_limits(
    uint32_t initial_max_image_dimension_1d,
    uint32_t initial_max_image_dimension_2d,
    uint32_t initial_max_image_dimension_3d,
    uint32_t initial_max_image_dimension_cube,
    uint32_t initial_max_image_array_layers,
    uint32_t initial_max_texel_buffer_elements,
    uint32_t initial_max_uniform_buffer_range,
    uint32_t initial_max_storage_buffer_range,
    uint32_t initial_max_push_constants_size,
    uint32_t initial_max_memory_allocation_count,
    uint32_t initial_max_sampler_allocation_count,
    VkDeviceSize initial_buffer_image_granularity,
    VkDeviceSize initial_sparse_address_space_size,
    uint32_t initial_max_bound_descriptor_sets,
    uint32_t initial_max_per_stage_descriptor_samplers,
    uint32_t initial_max_per_stage_descriptor_uniform_buffers,
    uint32_t initial_max_per_stage_descriptor_storage_buffers,
    uint32_t initial_max_per_stage_descriptor_sampled_images,
    uint32_t initial_max_per_stage_descriptor_storage_images,
    uint32_t initial_max_per_stage_descriptor_input_attachments,
    uint32_t initial_max_per_stage_resources,
    uint32_t initial_max_descriptor_set_samplers,
    uint32_t initial_max_descriptor_set_uniform_buffers,
    uint32_t initial_max_descriptor_set_uniform_buffers_dynamic,
    uint32_t initial_max_descriptor_set_storage_buffers,
    uint32_t initial_max_descriptor_set_storage_buffers_dynamic,
    uint32_t initial_max_descriptor_set_sampled_images,
    uint32_t initial_max_descriptor_set_storage_images,
    uint32_t initial_max_descriptor_set_input_attachments,
    uint32_t initial_max_vertex_input_attributes,
    uint32_t initial_max_vertex_input_bindings,
    uint32_t initial_max_vertex_input_attribute_offset,
    uint32_t initial_max_vertex_input_binding_stride,
    uint32_t initial_max_vertex_output_components,
    uint32_t initial_max_tessellation_generation_level,
    uint32_t initial_max_tessellation_patch_size,
    uint32_t initial_max_tessellation_control_per_vertex_input_components,
    uint32_t initial_max_tessellation_control_per_vertex_output_components,
    uint32_t initial_max_tessellation_control_per_patch_output_components,
    uint32_t initial_max_tessellation_control_total_output_components,
    uint32_t initial_max_tessellation_evaluation_input_components,
    uint32_t initial_max_tessellation_evaluation_output_components,
    uint32_t initial_max_geometry_shader_invocations,
    uint32_t initial_max_geometry_input_components,
    uint32_t initial_max_geometry_output_components,
    uint32_t initial_max_geometry_output_vertices,
    uint32_t initial_max_geometry_total_output_components,
    uint32_t initial_max_fragment_input_components,
    uint32_t initial_max_fragment_output_attachments,
    uint32_t initial_max_fragment_dual_src_attachments,
    uint32_t initial_max_fragment_combined_output_resources,
    uint32_t initial_max_compute_shared_memory_size,
    std::array<uint32_t, 3> initial_max_compute_work_group_count,
    uint32_t initial_max_compute_work_group_invocations,
    std::array<uint32_t, 3> initial_max_compute_work_group_size,
    uint32_t initial_sub_pixel_precision_bits,
    uint32_t initial_sub_texel_precision_bits,
    uint32_t initial_mipmap_precision_bits,
    uint32_t initial_max_draw_indexed_index_value,
    uint32_t initial_max_draw_indirect_count,
    float initial_max_sampler_lod_bias, float initial_max_sampler_anisotropy,
    uint32_t initial_max_viewports,
    std::array<uint32_t, 2> initial_max_viewport_dimensions,
    std::array<float, 2> initial_viewport_bounds_range,
    uint32_t initial_viewport_sub_pixel_bits,
    size_t initial_min_memory_map_alignment,
    VkDeviceSize initial_min_texel_buffer_offset_alignment,
    VkDeviceSize initial_min_uniform_buffer_offset_alignment,
    VkDeviceSize initial_min_storage_buffer_offset_alignment,
    int32_t initial_min_texel_offset, uint32_t initial_max_texel_offset,
    int32_t initial_min_texel_gather_offset,
    uint32_t initial_max_texel_gather_offset,
    float initial_min_interpolation_offset,
    float initial_max_interpolation_offset,
    uint32_t initial_sub_pixel_interpolation_offset_bits,
    uint32_t initial_max_framebuffer_width,
    uint32_t initial_max_framebuffer_height,
    uint32_t initial_max_framebuffer_layers,
    vk::sample_count_flags initial_framebuffer_color_sample_counts,
    vk::sample_count_flags initial_framebuffer_depth_sample_counts,
    vk::sample_count_flags initial_framebuffer_stencil_sample_counts,
    vk::sample_count_flags initial_framebuffer_no_attachments_sample_counts,
    uint32_t initial_max_color_attachments,
    vk::sample_count_flags initial_sampled_image_color_sample_counts,
    vk::sample_count_flags initial_sampled_image_integer_sample_counts,
    vk::sample_count_flags initial_sampled_image_depth_sample_counts,
    vk::sample_count_flags initial_sampled_image_stencil_sample_counts,
    vk::sample_count_flags initial_storage_image_sample_counts,
    uint32_t initial_max_sample_mask_words,
    VkBool32 initial_timestamp_compute_and_graphics,
    float initial_timestamp_period, uint32_t initial_max_clip_distances,
    uint32_t initial_max_cull_distances,
    uint32_t initial_max_combined_clip_and_cull_distances,
    uint32_t initial_discrete_queue_priorities,
    std::array<float, 2> initial_point_size_range,
    std::array<float, 2> initial_line_width_range,
    float initial_point_size_granularity, float initial_line_width_granularity,
    VkBool32 initial_strict_lines, VkBool32 initial_standard_sample_locations,
    VkDeviceSize initial_optimal_buffer_copy_offset_alignment,
    VkDeviceSize initial_optimal_buffer_copy_row_pitch_alignment,
    VkDeviceSize initial_non_coherent_atom_size) noexcept
  : _max_image_dimension_1d(std::move(initial_max_image_dimension_1d)),
    _max_image_dimension_2d(std::move(initial_max_image_dimension_2d)),
    _max_image_dimension_3d(std::move(initial_max_image_dimension_3d)),
    _max_image_dimension_cube(std::move(initial_max_image_dimension_cube)),
    _max_image_array_layers(std::move(initial_max_image_array_layers)),
    _max_texel_buffer_elements(std::move(initial_max_texel_buffer_elements)),
    _max_uniform_buffer_range(std::move(initial_max_uniform_buffer_range)),
    _max_storage_buffer_range(std::move(initial_max_storage_buffer_range)),
    _max_push_constants_size(std::move(initial_max_push_constants_size)),
    _max_memory_allocation_count(
      std::move(initial_max_memory_allocation_count)),
    _max_sampler_allocation_count(
      std::move(initial_max_sampler_allocation_count)),
    _buffer_image_granularity(std::move(initial_buffer_image_granularity)),
    _sparse_address_space_size(std::move(initial_sparse_address_space_size)),
    _max_bound_descriptor_sets(std::move(initial_max_bound_descriptor_sets)),
    _max_per_stage_descriptor_samplers(
      std::move(initial_max_per_stage_descriptor_samplers)),
    _max_per_stage_descriptor_uniform_buffers(
      std::move(initial_max_per_stage_descriptor_uniform_buffers)),
    _max_per_stage_descriptor_storage_buffers(
      std::move(initial_max_per_stage_descriptor_storage_buffers)),
    _max_per_stage_descriptor_sampled_images(
      std::move(initial_max_per_stage_descriptor_sampled_images)),
    _max_per_stage_descriptor_storage_images(
      std::move(initial_max_per_stage_descriptor_storage_images)),
    _max_per_stage_descriptor_input_attachments(
      std::move(initial_max_per_stage_descriptor_input_attachments)),
    _max_per_stage_resources(std::move(initial_max_per_stage_resources)),
    _max_descriptor_set_samplers(
      std::move(initial_max_descriptor_set_samplers)),
    _max_descriptor_set_uniform_buffers(
      std::move(initial_max_descriptor_set_uniform_buffers)),
    _max_descriptor_set_uniform_buffers_dynamic(
      std::move(initial_max_descriptor_set_uniform_buffers_dynamic)),
    _max_descriptor_set_storage_buffers(
      std::move(initial_max_descriptor_set_storage_buffers)),
    _max_descriptor_set_storage_buffers_dynamic(
      std::move(initial_max_descriptor_set_storage_buffers_dynamic)),
    _max_descriptor_set_sampled_images(
      std::move(initial_max_descriptor_set_sampled_images)),
    _max_descriptor_set_storage_images(
      std::move(initial_max_descriptor_set_storage_images)),
    _max_descriptor_set_input_attachments(
      std::move(initial_max_descriptor_set_input_attachments)),
    _max_vertex_input_attributes(
      std::move(initial_max_vertex_input_attributes)),
    _max_vertex_input_bindings(std::move(initial_max_vertex_input_bindings)),
    _max_vertex_input_attribute_offset(
      std::move(initial_max_vertex_input_attribute_offset)),
    _max_vertex_input_binding_stride(
      std::move(initial_max_vertex_input_binding_stride)),
    _max_vertex_output_components(
      std::move(initial_max_vertex_output_components)),
    _max_tessellation_generation_level(
      std::move(initial_max_tessellation_generation_level)),
    _max_tessellation_patch_size(
      std::move(initial_max_tessellation_patch_size)),
    _max_tessellation_control_per_vertex_input_components(
      std::move(initial_max_tessellation_control_per_vertex_input_components)),
    _max_tessellation_control_per_vertex_output_components(
      std::move(initial_max_tessellation_control_per_vertex_output_components)),
    _max_tessellation_control_per_patch_output_components(
      std::move(initial_max_tessellation_control_per_patch_output_components)),
    _max_tessellation_control_total_output_components(
      std::move(initial_max_tessellation_control_total_output_components)),
    _max_tessellation_evaluation_input_components(
      std::move(initial_max_tessellation_evaluation_input_components)),
    _max_tessellation_evaluation_output_components(
      std::move(initial_max_tessellation_evaluation_output_components)),
    _max_geometry_shader_invocations(
      std::move(initial_max_geometry_shader_invocations)),
    _max_geometry_input_components(
      std::move(initial_max_geometry_input_components)),
    _max_geometry_output_components(
      std::move(initial_max_geometry_output_components)),
    _max_geometry_output_vertices(
      std::move(initial_max_geometry_output_vertices)),
    _max_geometry_total_output_components(
      std::move(initial_max_geometry_total_output_components)),
    _max_fragment_input_components(
      std::move(initial_max_fragment_input_components)),
    _max_fragment_output_attachments(
      std::move(initial_max_fragment_output_attachments)),
    _max_fragment_dual_src_attachments(
      std::move(initial_max_fragment_dual_src_attachments)),
    _max_fragment_combined_output_resources(
      std::move(initial_max_fragment_combined_output_resources)),
    _max_compute_shared_memory_size(
      std::move(initial_max_compute_shared_memory_size)),
    _max_compute_work_group_count(
      std::move(initial_max_compute_work_group_count)),
    _max_compute_work_group_invocations(
      std::move(initial_max_compute_work_group_invocations)),
    _max_compute_work_group_size(
      std::move(initial_max_compute_work_group_size)),
    _sub_pixel_precision_bits(std::move(initial_sub_pixel_precision_bits)),
    _sub_texel_precision_bits(std::move(initial_sub_texel_precision_bits)),
    _mipmap_precision_bits(std::move(initial_mipmap_precision_bits)),
    _max_draw_indexed_index_value(
      std::move(initial_max_draw_indexed_index_value)),
    _max_draw_indirect_count(std::move(initial_max_draw_indirect_count)),
    _max_sampler_lod_bias(std::move(initial_max_sampler_lod_bias)),
    _max_sampler_anisotropy(std::move(initial_max_sampler_anisotropy)),
    _max_viewports(std::move(initial_max_viewports)),
    _max_viewport_dimensions(std::move(initial_max_viewport_dimensions)),
    _viewport_bounds_range(std::move(initial_viewport_bounds_range)),
    _viewport_sub_pixel_bits(std::move(initial_viewport_sub_pixel_bits)),
    _min_memory_map_alignment(std::move(initial_min_memory_map_alignment)),
    _min_texel_buffer_offset_alignment(
      std::move(initial_min_texel_buffer_offset_alignment)),
    _min_uniform_buffer_offset_alignment(
      std::move(initial_min_uniform_buffer_offset_alignment)),
    _min_storage_buffer_offset_alignment(
      std::move(initial_min_storage_buffer_offset_alignment)),
    _min_texel_offset(std::move(initial_min_texel_offset)),
    _max_texel_offset(std::move(initial_max_texel_offset)),
    _min_texel_gather_offset(std::move(initial_min_texel_gather_offset)),
    _max_texel_gather_offset(std::move(initial_max_texel_gather_offset)),
    _min_interpolation_offset(std::move(initial_min_interpolation_offset)),
    _max_interpolation_offset(std::move(initial_max_interpolation_offset)),
    _sub_pixel_interpolation_offset_bits(
      std::move(initial_sub_pixel_interpolation_offset_bits)),
    _max_framebuffer_width(std::move(initial_max_framebuffer_width)),
    _max_framebuffer_height(std::move(initial_max_framebuffer_height)),
    _max_framebuffer_layers(std::move(initial_max_framebuffer_layers)),
    _framebuffer_color_sample_counts(
      std::move(initial_framebuffer_color_sample_counts)),
    _framebuffer_depth_sample_counts(
      std::move(initial_framebuffer_depth_sample_counts)),
    _framebuffer_stencil_sample_counts(
      std::move(initial_framebuffer_stencil_sample_counts)),
    _framebuffer_no_attachments_sample_counts(
      std::move(initial_framebuffer_no_attachments_sample_counts)),
    _max_color_attachments(std::move(initial_max_color_attachments)),
    _sampled_image_color_sample_counts(
      std::move(initial_sampled_image_color_sample_counts)),
    _sampled_image_integer_sample_counts(
      std::move(initial_sampled_image_integer_sample_counts)),
    _sampled_image_depth_sample_counts(
      std::move(initial_sampled_image_depth_sample_counts)),
    _sampled_image_stencil_sample_counts(
      std::move(initial_sampled_image_stencil_sample_counts)),
    _storage_image_sample_counts(
      std::move(initial_storage_image_sample_counts)),
    _max_sample_mask_words(std::move(initial_max_sample_mask_words)),
    _timestamp_compute_and_graphics(
      std::move(initial_timestamp_compute_and_graphics)),
    _timestamp_period(std::move(initial_timestamp_period)),
    _max_clip_distances(std::move(initial_max_clip_distances)),
    _max_cull_distances(std::move(initial_max_cull_distances)),
    _max_combined_clip_and_cull_distances(
      std::move(initial_max_combined_clip_and_cull_distances)),
    _discrete_queue_priorities(std::move(initial_discrete_queue_priorities)),
    _point_size_range(std::move(initial_point_size_range)),
    _line_width_range(std::move(initial_line_width_range)),
    _point_size_granularity(std::move(initial_point_size_granularity)),
    _line_width_granularity(std::move(initial_line_width_granularity)),
    _strict_lines(std::move(initial_strict_lines)),
    _standard_sample_locations(std::move(initial_standard_sample_locations)),
    _optimal_buffer_copy_offset_alignment(
      std::move(initial_optimal_buffer_copy_offset_alignment)),
    _optimal_buffer_copy_row_pitch_alignment(
      std::move(initial_optimal_buffer_copy_row_pitch_alignment)),
    _non_coherent_atom_size(std::move(initial_non_coherent_atom_size))
  {
  }

  /// Copy constructor.
  constexpr physical_device_limits(const physical_device_limits& other) =
    default;

  /// Move constructor.
  constexpr physical_device_limits(physical_device_limits&& other) = default;

  /// Copy assignment operator.
  constexpr physical_device_limits& operator=(
    const physical_device_limits& other) = default;

  /// Move assignment operator.
  constexpr physical_device_limits& operator=(physical_device_limits&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceLimits&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceLimits*>(this);
  }

  uint32_t& max_image_dimension_1d()
  {
    return _max_image_dimension_1d;
  }

  constexpr const uint32_t& max_image_dimension_1d() const
  {
    return _max_image_dimension_1d;
  }

  void max_image_dimension_1d(uint32_t new_max_image_dimension_1d)
  {
    _max_image_dimension_1d = new_max_image_dimension_1d;
  }

  uint32_t& max_image_dimension_2d()
  {
    return _max_image_dimension_2d;
  }

  constexpr const uint32_t& max_image_dimension_2d() const
  {
    return _max_image_dimension_2d;
  }

  void max_image_dimension_2d(uint32_t new_max_image_dimension_2d)
  {
    _max_image_dimension_2d = new_max_image_dimension_2d;
  }

  uint32_t& max_image_dimension_3d()
  {
    return _max_image_dimension_3d;
  }

  constexpr const uint32_t& max_image_dimension_3d() const
  {
    return _max_image_dimension_3d;
  }

  void max_image_dimension_3d(uint32_t new_max_image_dimension_3d)
  {
    _max_image_dimension_3d = new_max_image_dimension_3d;
  }

  uint32_t& max_image_dimension_cube()
  {
    return _max_image_dimension_cube;
  }

  constexpr const uint32_t& max_image_dimension_cube() const
  {
    return _max_image_dimension_cube;
  }

  void max_image_dimension_cube(uint32_t new_max_image_dimension_cube)
  {
    _max_image_dimension_cube = new_max_image_dimension_cube;
  }

  uint32_t& max_image_array_layers()
  {
    return _max_image_array_layers;
  }

  constexpr const uint32_t& max_image_array_layers() const
  {
    return _max_image_array_layers;
  }

  void max_image_array_layers(uint32_t new_max_image_array_layers)
  {
    _max_image_array_layers = new_max_image_array_layers;
  }

  uint32_t& max_texel_buffer_elements()
  {
    return _max_texel_buffer_elements;
  }

  constexpr const uint32_t& max_texel_buffer_elements() const
  {
    return _max_texel_buffer_elements;
  }

  void max_texel_buffer_elements(uint32_t new_max_texel_buffer_elements)
  {
    _max_texel_buffer_elements = new_max_texel_buffer_elements;
  }

  uint32_t& max_uniform_buffer_range()
  {
    return _max_uniform_buffer_range;
  }

  constexpr const uint32_t& max_uniform_buffer_range() const
  {
    return _max_uniform_buffer_range;
  }

  void max_uniform_buffer_range(uint32_t new_max_uniform_buffer_range)
  {
    _max_uniform_buffer_range = new_max_uniform_buffer_range;
  }

  uint32_t& max_storage_buffer_range()
  {
    return _max_storage_buffer_range;
  }

  constexpr const uint32_t& max_storage_buffer_range() const
  {
    return _max_storage_buffer_range;
  }

  void max_storage_buffer_range(uint32_t new_max_storage_buffer_range)
  {
    _max_storage_buffer_range = new_max_storage_buffer_range;
  }

  uint32_t& max_push_constants_size()
  {
    return _max_push_constants_size;
  }

  constexpr const uint32_t& max_push_constants_size() const
  {
    return _max_push_constants_size;
  }

  void max_push_constants_size(uint32_t new_max_push_constants_size)
  {
    _max_push_constants_size = new_max_push_constants_size;
  }

  uint32_t& max_memory_allocation_count()
  {
    return _max_memory_allocation_count;
  }

  constexpr const uint32_t& max_memory_allocation_count() const
  {
    return _max_memory_allocation_count;
  }

  void max_memory_allocation_count(uint32_t new_max_memory_allocation_count)
  {
    _max_memory_allocation_count = new_max_memory_allocation_count;
  }

  uint32_t& max_sampler_allocation_count()
  {
    return _max_sampler_allocation_count;
  }

  constexpr const uint32_t& max_sampler_allocation_count() const
  {
    return _max_sampler_allocation_count;
  }

  void max_sampler_allocation_count(uint32_t new_max_sampler_allocation_count)
  {
    _max_sampler_allocation_count = new_max_sampler_allocation_count;
  }

  VkDeviceSize& buffer_image_granularity()
  {
    return _buffer_image_granularity;
  }

  constexpr const VkDeviceSize& buffer_image_granularity() const
  {
    return _buffer_image_granularity;
  }

  void buffer_image_granularity(VkDeviceSize new_buffer_image_granularity)
  {
    _buffer_image_granularity = new_buffer_image_granularity;
  }

  VkDeviceSize& sparse_address_space_size()
  {
    return _sparse_address_space_size;
  }

  constexpr const VkDeviceSize& sparse_address_space_size() const
  {
    return _sparse_address_space_size;
  }

  void sparse_address_space_size(VkDeviceSize new_sparse_address_space_size)
  {
    _sparse_address_space_size = new_sparse_address_space_size;
  }

  uint32_t& max_bound_descriptor_sets()
  {
    return _max_bound_descriptor_sets;
  }

  constexpr const uint32_t& max_bound_descriptor_sets() const
  {
    return _max_bound_descriptor_sets;
  }

  void max_bound_descriptor_sets(uint32_t new_max_bound_descriptor_sets)
  {
    _max_bound_descriptor_sets = new_max_bound_descriptor_sets;
  }

  uint32_t& max_per_stage_descriptor_samplers()
  {
    return _max_per_stage_descriptor_samplers;
  }

  constexpr const uint32_t& max_per_stage_descriptor_samplers() const
  {
    return _max_per_stage_descriptor_samplers;
  }

  void max_per_stage_descriptor_samplers(
    uint32_t new_max_per_stage_descriptor_samplers)
  {
    _max_per_stage_descriptor_samplers = new_max_per_stage_descriptor_samplers;
  }

  uint32_t& max_per_stage_descriptor_uniform_buffers()
  {
    return _max_per_stage_descriptor_uniform_buffers;
  }

  constexpr const uint32_t& max_per_stage_descriptor_uniform_buffers() const
  {
    return _max_per_stage_descriptor_uniform_buffers;
  }

  void max_per_stage_descriptor_uniform_buffers(
    uint32_t new_max_per_stage_descriptor_uniform_buffers)
  {
    _max_per_stage_descriptor_uniform_buffers =
      new_max_per_stage_descriptor_uniform_buffers;
  }

  uint32_t& max_per_stage_descriptor_storage_buffers()
  {
    return _max_per_stage_descriptor_storage_buffers;
  }

  constexpr const uint32_t& max_per_stage_descriptor_storage_buffers() const
  {
    return _max_per_stage_descriptor_storage_buffers;
  }

  void max_per_stage_descriptor_storage_buffers(
    uint32_t new_max_per_stage_descriptor_storage_buffers)
  {
    _max_per_stage_descriptor_storage_buffers =
      new_max_per_stage_descriptor_storage_buffers;
  }

  uint32_t& max_per_stage_descriptor_sampled_images()
  {
    return _max_per_stage_descriptor_sampled_images;
  }

  constexpr const uint32_t& max_per_stage_descriptor_sampled_images() const
  {
    return _max_per_stage_descriptor_sampled_images;
  }

  void max_per_stage_descriptor_sampled_images(
    uint32_t new_max_per_stage_descriptor_sampled_images)
  {
    _max_per_stage_descriptor_sampled_images =
      new_max_per_stage_descriptor_sampled_images;
  }

  uint32_t& max_per_stage_descriptor_storage_images()
  {
    return _max_per_stage_descriptor_storage_images;
  }

  constexpr const uint32_t& max_per_stage_descriptor_storage_images() const
  {
    return _max_per_stage_descriptor_storage_images;
  }

  void max_per_stage_descriptor_storage_images(
    uint32_t new_max_per_stage_descriptor_storage_images)
  {
    _max_per_stage_descriptor_storage_images =
      new_max_per_stage_descriptor_storage_images;
  }

  uint32_t& max_per_stage_descriptor_input_attachments()
  {
    return _max_per_stage_descriptor_input_attachments;
  }

  constexpr const uint32_t& max_per_stage_descriptor_input_attachments() const
  {
    return _max_per_stage_descriptor_input_attachments;
  }

  void max_per_stage_descriptor_input_attachments(
    uint32_t new_max_per_stage_descriptor_input_attachments)
  {
    _max_per_stage_descriptor_input_attachments =
      new_max_per_stage_descriptor_input_attachments;
  }

  uint32_t& max_per_stage_resources()
  {
    return _max_per_stage_resources;
  }

  constexpr const uint32_t& max_per_stage_resources() const
  {
    return _max_per_stage_resources;
  }

  void max_per_stage_resources(uint32_t new_max_per_stage_resources)
  {
    _max_per_stage_resources = new_max_per_stage_resources;
  }

  uint32_t& max_descriptor_set_samplers()
  {
    return _max_descriptor_set_samplers;
  }

  constexpr const uint32_t& max_descriptor_set_samplers() const
  {
    return _max_descriptor_set_samplers;
  }

  void max_descriptor_set_samplers(uint32_t new_max_descriptor_set_samplers)
  {
    _max_descriptor_set_samplers = new_max_descriptor_set_samplers;
  }

  uint32_t& max_descriptor_set_uniform_buffers()
  {
    return _max_descriptor_set_uniform_buffers;
  }

  constexpr const uint32_t& max_descriptor_set_uniform_buffers() const
  {
    return _max_descriptor_set_uniform_buffers;
  }

  void max_descriptor_set_uniform_buffers(
    uint32_t new_max_descriptor_set_uniform_buffers)
  {
    _max_descriptor_set_uniform_buffers =
      new_max_descriptor_set_uniform_buffers;
  }

  uint32_t& max_descriptor_set_uniform_buffers_dynamic()
  {
    return _max_descriptor_set_uniform_buffers_dynamic;
  }

  constexpr const uint32_t& max_descriptor_set_uniform_buffers_dynamic() const
  {
    return _max_descriptor_set_uniform_buffers_dynamic;
  }

  void max_descriptor_set_uniform_buffers_dynamic(
    uint32_t new_max_descriptor_set_uniform_buffers_dynamic)
  {
    _max_descriptor_set_uniform_buffers_dynamic =
      new_max_descriptor_set_uniform_buffers_dynamic;
  }

  uint32_t& max_descriptor_set_storage_buffers()
  {
    return _max_descriptor_set_storage_buffers;
  }

  constexpr const uint32_t& max_descriptor_set_storage_buffers() const
  {
    return _max_descriptor_set_storage_buffers;
  }

  void max_descriptor_set_storage_buffers(
    uint32_t new_max_descriptor_set_storage_buffers)
  {
    _max_descriptor_set_storage_buffers =
      new_max_descriptor_set_storage_buffers;
  }

  uint32_t& max_descriptor_set_storage_buffers_dynamic()
  {
    return _max_descriptor_set_storage_buffers_dynamic;
  }

  constexpr const uint32_t& max_descriptor_set_storage_buffers_dynamic() const
  {
    return _max_descriptor_set_storage_buffers_dynamic;
  }

  void max_descriptor_set_storage_buffers_dynamic(
    uint32_t new_max_descriptor_set_storage_buffers_dynamic)
  {
    _max_descriptor_set_storage_buffers_dynamic =
      new_max_descriptor_set_storage_buffers_dynamic;
  }

  uint32_t& max_descriptor_set_sampled_images()
  {
    return _max_descriptor_set_sampled_images;
  }

  constexpr const uint32_t& max_descriptor_set_sampled_images() const
  {
    return _max_descriptor_set_sampled_images;
  }

  void max_descriptor_set_sampled_images(
    uint32_t new_max_descriptor_set_sampled_images)
  {
    _max_descriptor_set_sampled_images = new_max_descriptor_set_sampled_images;
  }

  uint32_t& max_descriptor_set_storage_images()
  {
    return _max_descriptor_set_storage_images;
  }

  constexpr const uint32_t& max_descriptor_set_storage_images() const
  {
    return _max_descriptor_set_storage_images;
  }

  void max_descriptor_set_storage_images(
    uint32_t new_max_descriptor_set_storage_images)
  {
    _max_descriptor_set_storage_images = new_max_descriptor_set_storage_images;
  }

  uint32_t& max_descriptor_set_input_attachments()
  {
    return _max_descriptor_set_input_attachments;
  }

  constexpr const uint32_t& max_descriptor_set_input_attachments() const
  {
    return _max_descriptor_set_input_attachments;
  }

  void max_descriptor_set_input_attachments(
    uint32_t new_max_descriptor_set_input_attachments)
  {
    _max_descriptor_set_input_attachments =
      new_max_descriptor_set_input_attachments;
  }

  uint32_t& max_vertex_input_attributes()
  {
    return _max_vertex_input_attributes;
  }

  constexpr const uint32_t& max_vertex_input_attributes() const
  {
    return _max_vertex_input_attributes;
  }

  void max_vertex_input_attributes(uint32_t new_max_vertex_input_attributes)
  {
    _max_vertex_input_attributes = new_max_vertex_input_attributes;
  }

  uint32_t& max_vertex_input_bindings()
  {
    return _max_vertex_input_bindings;
  }

  constexpr const uint32_t& max_vertex_input_bindings() const
  {
    return _max_vertex_input_bindings;
  }

  void max_vertex_input_bindings(uint32_t new_max_vertex_input_bindings)
  {
    _max_vertex_input_bindings = new_max_vertex_input_bindings;
  }

  uint32_t& max_vertex_input_attribute_offset()
  {
    return _max_vertex_input_attribute_offset;
  }

  constexpr const uint32_t& max_vertex_input_attribute_offset() const
  {
    return _max_vertex_input_attribute_offset;
  }

  void max_vertex_input_attribute_offset(
    uint32_t new_max_vertex_input_attribute_offset)
  {
    _max_vertex_input_attribute_offset = new_max_vertex_input_attribute_offset;
  }

  uint32_t& max_vertex_input_binding_stride()
  {
    return _max_vertex_input_binding_stride;
  }

  constexpr const uint32_t& max_vertex_input_binding_stride() const
  {
    return _max_vertex_input_binding_stride;
  }

  void max_vertex_input_binding_stride(
    uint32_t new_max_vertex_input_binding_stride)
  {
    _max_vertex_input_binding_stride = new_max_vertex_input_binding_stride;
  }

  uint32_t& max_vertex_output_components()
  {
    return _max_vertex_output_components;
  }

  constexpr const uint32_t& max_vertex_output_components() const
  {
    return _max_vertex_output_components;
  }

  void max_vertex_output_components(uint32_t new_max_vertex_output_components)
  {
    _max_vertex_output_components = new_max_vertex_output_components;
  }

  uint32_t& max_tessellation_generation_level()
  {
    return _max_tessellation_generation_level;
  }

  constexpr const uint32_t& max_tessellation_generation_level() const
  {
    return _max_tessellation_generation_level;
  }

  void max_tessellation_generation_level(
    uint32_t new_max_tessellation_generation_level)
  {
    _max_tessellation_generation_level = new_max_tessellation_generation_level;
  }

  uint32_t& max_tessellation_patch_size()
  {
    return _max_tessellation_patch_size;
  }

  constexpr const uint32_t& max_tessellation_patch_size() const
  {
    return _max_tessellation_patch_size;
  }

  void max_tessellation_patch_size(uint32_t new_max_tessellation_patch_size)
  {
    _max_tessellation_patch_size = new_max_tessellation_patch_size;
  }

  uint32_t& max_tessellation_control_per_vertex_input_components()
  {
    return _max_tessellation_control_per_vertex_input_components;
  }

  constexpr const uint32_t&
  max_tessellation_control_per_vertex_input_components() const
  {
    return _max_tessellation_control_per_vertex_input_components;
  }

  void max_tessellation_control_per_vertex_input_components(
    uint32_t new_max_tessellation_control_per_vertex_input_components)
  {
    _max_tessellation_control_per_vertex_input_components =
      new_max_tessellation_control_per_vertex_input_components;
  }

  uint32_t& max_tessellation_control_per_vertex_output_components()
  {
    return _max_tessellation_control_per_vertex_output_components;
  }

  constexpr const uint32_t&
  max_tessellation_control_per_vertex_output_components() const
  {
    return _max_tessellation_control_per_vertex_output_components;
  }

  void max_tessellation_control_per_vertex_output_components(
    uint32_t new_max_tessellation_control_per_vertex_output_components)
  {
    _max_tessellation_control_per_vertex_output_components =
      new_max_tessellation_control_per_vertex_output_components;
  }

  uint32_t& max_tessellation_control_per_patch_output_components()
  {
    return _max_tessellation_control_per_patch_output_components;
  }

  constexpr const uint32_t&
  max_tessellation_control_per_patch_output_components() const
  {
    return _max_tessellation_control_per_patch_output_components;
  }

  void max_tessellation_control_per_patch_output_components(
    uint32_t new_max_tessellation_control_per_patch_output_components)
  {
    _max_tessellation_control_per_patch_output_components =
      new_max_tessellation_control_per_patch_output_components;
  }

  uint32_t& max_tessellation_control_total_output_components()
  {
    return _max_tessellation_control_total_output_components;
  }

  constexpr const uint32_t& max_tessellation_control_total_output_components()
    const
  {
    return _max_tessellation_control_total_output_components;
  }

  void max_tessellation_control_total_output_components(
    uint32_t new_max_tessellation_control_total_output_components)
  {
    _max_tessellation_control_total_output_components =
      new_max_tessellation_control_total_output_components;
  }

  uint32_t& max_tessellation_evaluation_input_components()
  {
    return _max_tessellation_evaluation_input_components;
  }

  constexpr const uint32_t& max_tessellation_evaluation_input_components() const
  {
    return _max_tessellation_evaluation_input_components;
  }

  void max_tessellation_evaluation_input_components(
    uint32_t new_max_tessellation_evaluation_input_components)
  {
    _max_tessellation_evaluation_input_components =
      new_max_tessellation_evaluation_input_components;
  }

  uint32_t& max_tessellation_evaluation_output_components()
  {
    return _max_tessellation_evaluation_output_components;
  }

  constexpr const uint32_t& max_tessellation_evaluation_output_components()
    const
  {
    return _max_tessellation_evaluation_output_components;
  }

  void max_tessellation_evaluation_output_components(
    uint32_t new_max_tessellation_evaluation_output_components)
  {
    _max_tessellation_evaluation_output_components =
      new_max_tessellation_evaluation_output_components;
  }

  uint32_t& max_geometry_shader_invocations()
  {
    return _max_geometry_shader_invocations;
  }

  constexpr const uint32_t& max_geometry_shader_invocations() const
  {
    return _max_geometry_shader_invocations;
  }

  void max_geometry_shader_invocations(
    uint32_t new_max_geometry_shader_invocations)
  {
    _max_geometry_shader_invocations = new_max_geometry_shader_invocations;
  }

  uint32_t& max_geometry_input_components()
  {
    return _max_geometry_input_components;
  }

  constexpr const uint32_t& max_geometry_input_components() const
  {
    return _max_geometry_input_components;
  }

  void max_geometry_input_components(uint32_t new_max_geometry_input_components)
  {
    _max_geometry_input_components = new_max_geometry_input_components;
  }

  uint32_t& max_geometry_output_components()
  {
    return _max_geometry_output_components;
  }

  constexpr const uint32_t& max_geometry_output_components() const
  {
    return _max_geometry_output_components;
  }

  void max_geometry_output_components(
    uint32_t new_max_geometry_output_components)
  {
    _max_geometry_output_components = new_max_geometry_output_components;
  }

  uint32_t& max_geometry_output_vertices()
  {
    return _max_geometry_output_vertices;
  }

  constexpr const uint32_t& max_geometry_output_vertices() const
  {
    return _max_geometry_output_vertices;
  }

  void max_geometry_output_vertices(uint32_t new_max_geometry_output_vertices)
  {
    _max_geometry_output_vertices = new_max_geometry_output_vertices;
  }

  uint32_t& max_geometry_total_output_components()
  {
    return _max_geometry_total_output_components;
  }

  constexpr const uint32_t& max_geometry_total_output_components() const
  {
    return _max_geometry_total_output_components;
  }

  void max_geometry_total_output_components(
    uint32_t new_max_geometry_total_output_components)
  {
    _max_geometry_total_output_components =
      new_max_geometry_total_output_components;
  }

  uint32_t& max_fragment_input_components()
  {
    return _max_fragment_input_components;
  }

  constexpr const uint32_t& max_fragment_input_components() const
  {
    return _max_fragment_input_components;
  }

  void max_fragment_input_components(uint32_t new_max_fragment_input_components)
  {
    _max_fragment_input_components = new_max_fragment_input_components;
  }

  uint32_t& max_fragment_output_attachments()
  {
    return _max_fragment_output_attachments;
  }

  constexpr const uint32_t& max_fragment_output_attachments() const
  {
    return _max_fragment_output_attachments;
  }

  void max_fragment_output_attachments(
    uint32_t new_max_fragment_output_attachments)
  {
    _max_fragment_output_attachments = new_max_fragment_output_attachments;
  }

  uint32_t& max_fragment_dual_src_attachments()
  {
    return _max_fragment_dual_src_attachments;
  }

  constexpr const uint32_t& max_fragment_dual_src_attachments() const
  {
    return _max_fragment_dual_src_attachments;
  }

  void max_fragment_dual_src_attachments(
    uint32_t new_max_fragment_dual_src_attachments)
  {
    _max_fragment_dual_src_attachments = new_max_fragment_dual_src_attachments;
  }

  uint32_t& max_fragment_combined_output_resources()
  {
    return _max_fragment_combined_output_resources;
  }

  constexpr const uint32_t& max_fragment_combined_output_resources() const
  {
    return _max_fragment_combined_output_resources;
  }

  void max_fragment_combined_output_resources(
    uint32_t new_max_fragment_combined_output_resources)
  {
    _max_fragment_combined_output_resources =
      new_max_fragment_combined_output_resources;
  }

  uint32_t& max_compute_shared_memory_size()
  {
    return _max_compute_shared_memory_size;
  }

  constexpr const uint32_t& max_compute_shared_memory_size() const
  {
    return _max_compute_shared_memory_size;
  }

  void max_compute_shared_memory_size(
    uint32_t new_max_compute_shared_memory_size)
  {
    _max_compute_shared_memory_size = new_max_compute_shared_memory_size;
  }

  std::array<uint32_t, 3>& max_compute_work_group_count()
  {
    return _max_compute_work_group_count;
  }

  constexpr const std::array<uint32_t, 3>& max_compute_work_group_count() const
  {
    return _max_compute_work_group_count;
  }

  void max_compute_work_group_count(
    std::array<uint32_t, 3> new_max_compute_work_group_count)
  {
    _max_compute_work_group_count = new_max_compute_work_group_count;
  }

  uint32_t& max_compute_work_group_invocations()
  {
    return _max_compute_work_group_invocations;
  }

  constexpr const uint32_t& max_compute_work_group_invocations() const
  {
    return _max_compute_work_group_invocations;
  }

  void max_compute_work_group_invocations(
    uint32_t new_max_compute_work_group_invocations)
  {
    _max_compute_work_group_invocations =
      new_max_compute_work_group_invocations;
  }

  std::array<uint32_t, 3>& max_compute_work_group_size()
  {
    return _max_compute_work_group_size;
  }

  constexpr const std::array<uint32_t, 3>& max_compute_work_group_size() const
  {
    return _max_compute_work_group_size;
  }

  void max_compute_work_group_size(
    std::array<uint32_t, 3> new_max_compute_work_group_size)
  {
    _max_compute_work_group_size = new_max_compute_work_group_size;
  }

  uint32_t& sub_pixel_precision_bits()
  {
    return _sub_pixel_precision_bits;
  }

  constexpr const uint32_t& sub_pixel_precision_bits() const
  {
    return _sub_pixel_precision_bits;
  }

  void sub_pixel_precision_bits(uint32_t new_sub_pixel_precision_bits)
  {
    _sub_pixel_precision_bits = new_sub_pixel_precision_bits;
  }

  uint32_t& sub_texel_precision_bits()
  {
    return _sub_texel_precision_bits;
  }

  constexpr const uint32_t& sub_texel_precision_bits() const
  {
    return _sub_texel_precision_bits;
  }

  void sub_texel_precision_bits(uint32_t new_sub_texel_precision_bits)
  {
    _sub_texel_precision_bits = new_sub_texel_precision_bits;
  }

  uint32_t& mipmap_precision_bits()
  {
    return _mipmap_precision_bits;
  }

  constexpr const uint32_t& mipmap_precision_bits() const
  {
    return _mipmap_precision_bits;
  }

  void mipmap_precision_bits(uint32_t new_mipmap_precision_bits)
  {
    _mipmap_precision_bits = new_mipmap_precision_bits;
  }

  uint32_t& max_draw_indexed_index_value()
  {
    return _max_draw_indexed_index_value;
  }

  constexpr const uint32_t& max_draw_indexed_index_value() const
  {
    return _max_draw_indexed_index_value;
  }

  void max_draw_indexed_index_value(uint32_t new_max_draw_indexed_index_value)
  {
    _max_draw_indexed_index_value = new_max_draw_indexed_index_value;
  }

  uint32_t& max_draw_indirect_count()
  {
    return _max_draw_indirect_count;
  }

  constexpr const uint32_t& max_draw_indirect_count() const
  {
    return _max_draw_indirect_count;
  }

  void max_draw_indirect_count(uint32_t new_max_draw_indirect_count)
  {
    _max_draw_indirect_count = new_max_draw_indirect_count;
  }

  float& max_sampler_lod_bias()
  {
    return _max_sampler_lod_bias;
  }

  constexpr const float& max_sampler_lod_bias() const
  {
    return _max_sampler_lod_bias;
  }

  void max_sampler_lod_bias(float new_max_sampler_lod_bias)
  {
    _max_sampler_lod_bias = new_max_sampler_lod_bias;
  }

  float& max_sampler_anisotropy()
  {
    return _max_sampler_anisotropy;
  }

  constexpr const float& max_sampler_anisotropy() const
  {
    return _max_sampler_anisotropy;
  }

  void max_sampler_anisotropy(float new_max_sampler_anisotropy)
  {
    _max_sampler_anisotropy = new_max_sampler_anisotropy;
  }

  uint32_t& max_viewports()
  {
    return _max_viewports;
  }

  constexpr const uint32_t& max_viewports() const
  {
    return _max_viewports;
  }

  void max_viewports(uint32_t new_max_viewports)
  {
    _max_viewports = new_max_viewports;
  }

  std::array<uint32_t, 2>& max_viewport_dimensions()
  {
    return _max_viewport_dimensions;
  }

  constexpr const std::array<uint32_t, 2>& max_viewport_dimensions() const
  {
    return _max_viewport_dimensions;
  }

  void max_viewport_dimensions(
    std::array<uint32_t, 2> new_max_viewport_dimensions)
  {
    _max_viewport_dimensions = new_max_viewport_dimensions;
  }

  std::array<float, 2>& viewport_bounds_range()
  {
    return _viewport_bounds_range;
  }

  constexpr const std::array<float, 2>& viewport_bounds_range() const
  {
    return _viewport_bounds_range;
  }

  void viewport_bounds_range(std::array<float, 2> new_viewport_bounds_range)
  {
    _viewport_bounds_range = new_viewport_bounds_range;
  }

  uint32_t& viewport_sub_pixel_bits()
  {
    return _viewport_sub_pixel_bits;
  }

  constexpr const uint32_t& viewport_sub_pixel_bits() const
  {
    return _viewport_sub_pixel_bits;
  }

  void viewport_sub_pixel_bits(uint32_t new_viewport_sub_pixel_bits)
  {
    _viewport_sub_pixel_bits = new_viewport_sub_pixel_bits;
  }

  size_t& min_memory_map_alignment()
  {
    return _min_memory_map_alignment;
  }

  constexpr const size_t& min_memory_map_alignment() const
  {
    return _min_memory_map_alignment;
  }

  void min_memory_map_alignment(size_t new_min_memory_map_alignment)
  {
    _min_memory_map_alignment = new_min_memory_map_alignment;
  }

  VkDeviceSize& min_texel_buffer_offset_alignment()
  {
    return _min_texel_buffer_offset_alignment;
  }

  constexpr const VkDeviceSize& min_texel_buffer_offset_alignment() const
  {
    return _min_texel_buffer_offset_alignment;
  }

  void min_texel_buffer_offset_alignment(
    VkDeviceSize new_min_texel_buffer_offset_alignment)
  {
    _min_texel_buffer_offset_alignment = new_min_texel_buffer_offset_alignment;
  }

  VkDeviceSize& min_uniform_buffer_offset_alignment()
  {
    return _min_uniform_buffer_offset_alignment;
  }

  constexpr const VkDeviceSize& min_uniform_buffer_offset_alignment() const
  {
    return _min_uniform_buffer_offset_alignment;
  }

  void min_uniform_buffer_offset_alignment(
    VkDeviceSize new_min_uniform_buffer_offset_alignment)
  {
    _min_uniform_buffer_offset_alignment =
      new_min_uniform_buffer_offset_alignment;
  }

  VkDeviceSize& min_storage_buffer_offset_alignment()
  {
    return _min_storage_buffer_offset_alignment;
  }

  constexpr const VkDeviceSize& min_storage_buffer_offset_alignment() const
  {
    return _min_storage_buffer_offset_alignment;
  }

  void min_storage_buffer_offset_alignment(
    VkDeviceSize new_min_storage_buffer_offset_alignment)
  {
    _min_storage_buffer_offset_alignment =
      new_min_storage_buffer_offset_alignment;
  }

  int32_t& min_texel_offset()
  {
    return _min_texel_offset;
  }

  constexpr const int32_t& min_texel_offset() const
  {
    return _min_texel_offset;
  }

  void min_texel_offset(int32_t new_min_texel_offset)
  {
    _min_texel_offset = new_min_texel_offset;
  }

  uint32_t& max_texel_offset()
  {
    return _max_texel_offset;
  }

  constexpr const uint32_t& max_texel_offset() const
  {
    return _max_texel_offset;
  }

  void max_texel_offset(uint32_t new_max_texel_offset)
  {
    _max_texel_offset = new_max_texel_offset;
  }

  int32_t& min_texel_gather_offset()
  {
    return _min_texel_gather_offset;
  }

  constexpr const int32_t& min_texel_gather_offset() const
  {
    return _min_texel_gather_offset;
  }

  void min_texel_gather_offset(int32_t new_min_texel_gather_offset)
  {
    _min_texel_gather_offset = new_min_texel_gather_offset;
  }

  uint32_t& max_texel_gather_offset()
  {
    return _max_texel_gather_offset;
  }

  constexpr const uint32_t& max_texel_gather_offset() const
  {
    return _max_texel_gather_offset;
  }

  void max_texel_gather_offset(uint32_t new_max_texel_gather_offset)
  {
    _max_texel_gather_offset = new_max_texel_gather_offset;
  }

  float& min_interpolation_offset()
  {
    return _min_interpolation_offset;
  }

  constexpr const float& min_interpolation_offset() const
  {
    return _min_interpolation_offset;
  }

  void min_interpolation_offset(float new_min_interpolation_offset)
  {
    _min_interpolation_offset = new_min_interpolation_offset;
  }

  float& max_interpolation_offset()
  {
    return _max_interpolation_offset;
  }

  constexpr const float& max_interpolation_offset() const
  {
    return _max_interpolation_offset;
  }

  void max_interpolation_offset(float new_max_interpolation_offset)
  {
    _max_interpolation_offset = new_max_interpolation_offset;
  }

  uint32_t& sub_pixel_interpolation_offset_bits()
  {
    return _sub_pixel_interpolation_offset_bits;
  }

  constexpr const uint32_t& sub_pixel_interpolation_offset_bits() const
  {
    return _sub_pixel_interpolation_offset_bits;
  }

  void sub_pixel_interpolation_offset_bits(
    uint32_t new_sub_pixel_interpolation_offset_bits)
  {
    _sub_pixel_interpolation_offset_bits =
      new_sub_pixel_interpolation_offset_bits;
  }

  uint32_t& max_framebuffer_width()
  {
    return _max_framebuffer_width;
  }

  constexpr const uint32_t& max_framebuffer_width() const
  {
    return _max_framebuffer_width;
  }

  void max_framebuffer_width(uint32_t new_max_framebuffer_width)
  {
    _max_framebuffer_width = new_max_framebuffer_width;
  }

  uint32_t& max_framebuffer_height()
  {
    return _max_framebuffer_height;
  }

  constexpr const uint32_t& max_framebuffer_height() const
  {
    return _max_framebuffer_height;
  }

  void max_framebuffer_height(uint32_t new_max_framebuffer_height)
  {
    _max_framebuffer_height = new_max_framebuffer_height;
  }

  uint32_t& max_framebuffer_layers()
  {
    return _max_framebuffer_layers;
  }

  constexpr const uint32_t& max_framebuffer_layers() const
  {
    return _max_framebuffer_layers;
  }

  void max_framebuffer_layers(uint32_t new_max_framebuffer_layers)
  {
    _max_framebuffer_layers = new_max_framebuffer_layers;
  }

  vk::sample_count_flags& framebuffer_color_sample_counts()
  {
    return _framebuffer_color_sample_counts;
  }

  constexpr const vk::sample_count_flags& framebuffer_color_sample_counts()
    const
  {
    return _framebuffer_color_sample_counts;
  }

  void framebuffer_color_sample_counts(
    vk::sample_count_flags new_framebuffer_color_sample_counts)
  {
    _framebuffer_color_sample_counts = new_framebuffer_color_sample_counts;
  }

  vk::sample_count_flags& framebuffer_depth_sample_counts()
  {
    return _framebuffer_depth_sample_counts;
  }

  constexpr const vk::sample_count_flags& framebuffer_depth_sample_counts()
    const
  {
    return _framebuffer_depth_sample_counts;
  }

  void framebuffer_depth_sample_counts(
    vk::sample_count_flags new_framebuffer_depth_sample_counts)
  {
    _framebuffer_depth_sample_counts = new_framebuffer_depth_sample_counts;
  }

  vk::sample_count_flags& framebuffer_stencil_sample_counts()
  {
    return _framebuffer_stencil_sample_counts;
  }

  constexpr const vk::sample_count_flags& framebuffer_stencil_sample_counts()
    const
  {
    return _framebuffer_stencil_sample_counts;
  }

  void framebuffer_stencil_sample_counts(
    vk::sample_count_flags new_framebuffer_stencil_sample_counts)
  {
    _framebuffer_stencil_sample_counts = new_framebuffer_stencil_sample_counts;
  }

  vk::sample_count_flags& framebuffer_no_attachments_sample_counts()
  {
    return _framebuffer_no_attachments_sample_counts;
  }

  constexpr const vk::sample_count_flags&
  framebuffer_no_attachments_sample_counts() const
  {
    return _framebuffer_no_attachments_sample_counts;
  }

  void framebuffer_no_attachments_sample_counts(
    vk::sample_count_flags new_framebuffer_no_attachments_sample_counts)
  {
    _framebuffer_no_attachments_sample_counts =
      new_framebuffer_no_attachments_sample_counts;
  }

  uint32_t& max_color_attachments()
  {
    return _max_color_attachments;
  }

  constexpr const uint32_t& max_color_attachments() const
  {
    return _max_color_attachments;
  }

  void max_color_attachments(uint32_t new_max_color_attachments)
  {
    _max_color_attachments = new_max_color_attachments;
  }

  vk::sample_count_flags& sampled_image_color_sample_counts()
  {
    return _sampled_image_color_sample_counts;
  }

  constexpr const vk::sample_count_flags& sampled_image_color_sample_counts()
    const
  {
    return _sampled_image_color_sample_counts;
  }

  void sampled_image_color_sample_counts(
    vk::sample_count_flags new_sampled_image_color_sample_counts)
  {
    _sampled_image_color_sample_counts = new_sampled_image_color_sample_counts;
  }

  vk::sample_count_flags& sampled_image_integer_sample_counts()
  {
    return _sampled_image_integer_sample_counts;
  }

  constexpr const vk::sample_count_flags& sampled_image_integer_sample_counts()
    const
  {
    return _sampled_image_integer_sample_counts;
  }

  void sampled_image_integer_sample_counts(
    vk::sample_count_flags new_sampled_image_integer_sample_counts)
  {
    _sampled_image_integer_sample_counts =
      new_sampled_image_integer_sample_counts;
  }

  vk::sample_count_flags& sampled_image_depth_sample_counts()
  {
    return _sampled_image_depth_sample_counts;
  }

  constexpr const vk::sample_count_flags& sampled_image_depth_sample_counts()
    const
  {
    return _sampled_image_depth_sample_counts;
  }

  void sampled_image_depth_sample_counts(
    vk::sample_count_flags new_sampled_image_depth_sample_counts)
  {
    _sampled_image_depth_sample_counts = new_sampled_image_depth_sample_counts;
  }

  vk::sample_count_flags& sampled_image_stencil_sample_counts()
  {
    return _sampled_image_stencil_sample_counts;
  }

  constexpr const vk::sample_count_flags& sampled_image_stencil_sample_counts()
    const
  {
    return _sampled_image_stencil_sample_counts;
  }

  void sampled_image_stencil_sample_counts(
    vk::sample_count_flags new_sampled_image_stencil_sample_counts)
  {
    _sampled_image_stencil_sample_counts =
      new_sampled_image_stencil_sample_counts;
  }

  vk::sample_count_flags& storage_image_sample_counts()
  {
    return _storage_image_sample_counts;
  }

  constexpr const vk::sample_count_flags& storage_image_sample_counts() const
  {
    return _storage_image_sample_counts;
  }

  void storage_image_sample_counts(
    vk::sample_count_flags new_storage_image_sample_counts)
  {
    _storage_image_sample_counts = new_storage_image_sample_counts;
  }

  uint32_t& max_sample_mask_words()
  {
    return _max_sample_mask_words;
  }

  constexpr const uint32_t& max_sample_mask_words() const
  {
    return _max_sample_mask_words;
  }

  void max_sample_mask_words(uint32_t new_max_sample_mask_words)
  {
    _max_sample_mask_words = new_max_sample_mask_words;
  }

  VkBool32& timestamp_compute_and_graphics()
  {
    return _timestamp_compute_and_graphics;
  }

  constexpr const VkBool32& timestamp_compute_and_graphics() const
  {
    return _timestamp_compute_and_graphics;
  }

  void timestamp_compute_and_graphics(
    VkBool32 new_timestamp_compute_and_graphics)
  {
    _timestamp_compute_and_graphics = new_timestamp_compute_and_graphics;
  }

  float& timestamp_period()
  {
    return _timestamp_period;
  }

  constexpr const float& timestamp_period() const
  {
    return _timestamp_period;
  }

  void timestamp_period(float new_timestamp_period)
  {
    _timestamp_period = new_timestamp_period;
  }

  uint32_t& max_clip_distances()
  {
    return _max_clip_distances;
  }

  constexpr const uint32_t& max_clip_distances() const
  {
    return _max_clip_distances;
  }

  void max_clip_distances(uint32_t new_max_clip_distances)
  {
    _max_clip_distances = new_max_clip_distances;
  }

  uint32_t& max_cull_distances()
  {
    return _max_cull_distances;
  }

  constexpr const uint32_t& max_cull_distances() const
  {
    return _max_cull_distances;
  }

  void max_cull_distances(uint32_t new_max_cull_distances)
  {
    _max_cull_distances = new_max_cull_distances;
  }

  uint32_t& max_combined_clip_and_cull_distances()
  {
    return _max_combined_clip_and_cull_distances;
  }

  constexpr const uint32_t& max_combined_clip_and_cull_distances() const
  {
    return _max_combined_clip_and_cull_distances;
  }

  void max_combined_clip_and_cull_distances(
    uint32_t new_max_combined_clip_and_cull_distances)
  {
    _max_combined_clip_and_cull_distances =
      new_max_combined_clip_and_cull_distances;
  }

  uint32_t& discrete_queue_priorities()
  {
    return _discrete_queue_priorities;
  }

  constexpr const uint32_t& discrete_queue_priorities() const
  {
    return _discrete_queue_priorities;
  }

  void discrete_queue_priorities(uint32_t new_discrete_queue_priorities)
  {
    _discrete_queue_priorities = new_discrete_queue_priorities;
  }

  std::array<float, 2>& point_size_range()
  {
    return _point_size_range;
  }

  constexpr const std::array<float, 2>& point_size_range() const
  {
    return _point_size_range;
  }

  void point_size_range(std::array<float, 2> new_point_size_range)
  {
    _point_size_range = new_point_size_range;
  }

  std::array<float, 2>& line_width_range()
  {
    return _line_width_range;
  }

  constexpr const std::array<float, 2>& line_width_range() const
  {
    return _line_width_range;
  }

  void line_width_range(std::array<float, 2> new_line_width_range)
  {
    _line_width_range = new_line_width_range;
  }

  float& point_size_granularity()
  {
    return _point_size_granularity;
  }

  constexpr const float& point_size_granularity() const
  {
    return _point_size_granularity;
  }

  void point_size_granularity(float new_point_size_granularity)
  {
    _point_size_granularity = new_point_size_granularity;
  }

  float& line_width_granularity()
  {
    return _line_width_granularity;
  }

  constexpr const float& line_width_granularity() const
  {
    return _line_width_granularity;
  }

  void line_width_granularity(float new_line_width_granularity)
  {
    _line_width_granularity = new_line_width_granularity;
  }

  VkBool32& strict_lines()
  {
    return _strict_lines;
  }

  constexpr const VkBool32& strict_lines() const
  {
    return _strict_lines;
  }

  void strict_lines(VkBool32 new_strict_lines)
  {
    _strict_lines = new_strict_lines;
  }

  VkBool32& standard_sample_locations()
  {
    return _standard_sample_locations;
  }

  constexpr const VkBool32& standard_sample_locations() const
  {
    return _standard_sample_locations;
  }

  void standard_sample_locations(VkBool32 new_standard_sample_locations)
  {
    _standard_sample_locations = new_standard_sample_locations;
  }

  VkDeviceSize& optimal_buffer_copy_offset_alignment()
  {
    return _optimal_buffer_copy_offset_alignment;
  }

  constexpr const VkDeviceSize& optimal_buffer_copy_offset_alignment() const
  {
    return _optimal_buffer_copy_offset_alignment;
  }

  void optimal_buffer_copy_offset_alignment(
    VkDeviceSize new_optimal_buffer_copy_offset_alignment)
  {
    _optimal_buffer_copy_offset_alignment =
      new_optimal_buffer_copy_offset_alignment;
  }

  VkDeviceSize& optimal_buffer_copy_row_pitch_alignment()
  {
    return _optimal_buffer_copy_row_pitch_alignment;
  }

  constexpr const VkDeviceSize& optimal_buffer_copy_row_pitch_alignment() const
  {
    return _optimal_buffer_copy_row_pitch_alignment;
  }

  void optimal_buffer_copy_row_pitch_alignment(
    VkDeviceSize new_optimal_buffer_copy_row_pitch_alignment)
  {
    _optimal_buffer_copy_row_pitch_alignment =
      new_optimal_buffer_copy_row_pitch_alignment;
  }

  VkDeviceSize& non_coherent_atom_size()
  {
    return _non_coherent_atom_size;
  }

  constexpr const VkDeviceSize& non_coherent_atom_size() const
  {
    return _non_coherent_atom_size;
  }

  void non_coherent_atom_size(VkDeviceSize new_non_coherent_atom_size)
  {
    _non_coherent_atom_size = new_non_coherent_atom_size;
  }

private:
  /// max 1D image dimension
  uint32_t _max_image_dimension_1d = 0;
  /// max 2D image dimension
  uint32_t _max_image_dimension_2d = 0;
  /// max 3D image dimension
  uint32_t _max_image_dimension_3d = 0;
  /// max cubemap image dimension
  uint32_t _max_image_dimension_cube = 0;
  /// max layers for image arrays
  uint32_t _max_image_array_layers = 0;
  /// max texel buffer size (fstexels)
  uint32_t _max_texel_buffer_elements = 0;
  /// max uniform buffer range (bytes)
  uint32_t _max_uniform_buffer_range = 0;
  /// max storage buffer range (bytes)
  uint32_t _max_storage_buffer_range = 0;
  /// max size of the push constants pool (bytes)
  uint32_t _max_push_constants_size = 0;
  /// max number of device memory allocations supported
  uint32_t _max_memory_allocation_count = 0;
  /// max number of samplers that can be allocated on a device
  uint32_t _max_sampler_allocation_count = 0;
  /// Granularity (in bytes) at which buffers and images can be bound to
  /// adjacent memory for simultaneous usage
  VkDeviceSize _buffer_image_granularity = 0;
  /// Total address space available for sparse allocations (bytes)
  VkDeviceSize _sparse_address_space_size = 0;
  /// max number of descriptors sets that can be bound to a pipeline
  uint32_t _max_bound_descriptor_sets = 0;
  /// max number of samplers allowed per-stage in a descriptor set
  uint32_t _max_per_stage_descriptor_samplers = 0;
  /// max number of uniform buffers allowed per-stage in a descriptor set
  uint32_t _max_per_stage_descriptor_uniform_buffers = 0;
  /// max number of storage buffers allowed per-stage in a descriptor set
  uint32_t _max_per_stage_descriptor_storage_buffers = 0;
  /// max number of sampled images allowed per-stage in a descriptor set
  uint32_t _max_per_stage_descriptor_sampled_images = 0;
  /// max number of storage images allowed per-stage in a descriptor set
  uint32_t _max_per_stage_descriptor_storage_images = 0;
  /// max number of input attachments allowed per-stage in a descriptor set
  uint32_t _max_per_stage_descriptor_input_attachments = 0;
  /// max number of resources allowed by a single stage
  uint32_t _max_per_stage_resources = 0;
  /// max number of samplers allowed in all stages in a descriptor set
  uint32_t _max_descriptor_set_samplers = 0;
  /// max number of uniform buffers allowed in all stages in a descriptor set
  uint32_t _max_descriptor_set_uniform_buffers = 0;
  /// max number of dynamic uniform buffers allowed in all stages in a
  /// descriptor set
  uint32_t _max_descriptor_set_uniform_buffers_dynamic = 0;
  /// max number of storage buffers allowed in all stages in a descriptor set
  uint32_t _max_descriptor_set_storage_buffers = 0;
  /// max number of dynamic storage buffers allowed in all stages in a
  /// descriptor set
  uint32_t _max_descriptor_set_storage_buffers_dynamic = 0;
  /// max number of sampled images allowed in all stages in a descriptor set
  uint32_t _max_descriptor_set_sampled_images = 0;
  /// max number of storage images allowed in all stages in a descriptor set
  uint32_t _max_descriptor_set_storage_images = 0;
  /// max number of input attachments allowed in all stages in a descriptor set
  uint32_t _max_descriptor_set_input_attachments = 0;
  /// max number of vertex input attribute slots
  uint32_t _max_vertex_input_attributes = 0;
  /// max number of vertex input binding slots
  uint32_t _max_vertex_input_bindings = 0;
  /// max vertex input attribute offset added to vertex buffer offset
  uint32_t _max_vertex_input_attribute_offset = 0;
  /// max vertex input binding stride
  uint32_t _max_vertex_input_binding_stride = 0;
  /// max number of output components written by vertex shader
  uint32_t _max_vertex_output_components = 0;
  /// max level supported by tessellation primitive generator
  uint32_t _max_tessellation_generation_level = 0;
  /// max patch size (vertices)
  uint32_t _max_tessellation_patch_size = 0;
  /// max number of input components per-vertex in TCS
  uint32_t _max_tessellation_control_per_vertex_input_components = 0;
  /// max number of output components per-vertex in TCS
  uint32_t _max_tessellation_control_per_vertex_output_components = 0;
  /// max number of output components per-patch in TCS
  uint32_t _max_tessellation_control_per_patch_output_components = 0;
  /// max total number of per-vertex and per-patch output components in TCS
  uint32_t _max_tessellation_control_total_output_components = 0;
  /// max number of input components per vertex in TES
  uint32_t _max_tessellation_evaluation_input_components = 0;
  /// max number of output components per vertex in TES
  uint32_t _max_tessellation_evaluation_output_components = 0;
  /// max invocation count supported in geometry shader
  uint32_t _max_geometry_shader_invocations = 0;
  /// max number of input components read in geometry stage
  uint32_t _max_geometry_input_components = 0;
  /// max number of output components written in geometry stage
  uint32_t _max_geometry_output_components = 0;
  /// max number of vertices that can be emitted in geometry stage
  uint32_t _max_geometry_output_vertices = 0;
  /// max total number of components (all vertices) written in geometry stage
  uint32_t _max_geometry_total_output_components = 0;
  /// max number of input components read in fragment stage
  uint32_t _max_fragment_input_components = 0;
  /// max number of output attachments written in fragment stage
  uint32_t _max_fragment_output_attachments = 0;
  /// max number of output attachments written when using dual source blending
  uint32_t _max_fragment_dual_src_attachments = 0;
  /// max total number of storage buffers, storage images and output buffers
  uint32_t _max_fragment_combined_output_resources = 0;
  /// max total storage size of work group local storage (bytes)
  uint32_t _max_compute_shared_memory_size = 0;
  /// max num of compute work groups that may be dispatched by a single command
  /// (x,y,z)
  std::array<uint32_t, 3> _max_compute_work_group_count = {};
  /// max total compute invocations in a single local work group
  uint32_t _max_compute_work_group_invocations = 0;
  /// max local size of a compute work group (x,y,z)
  std::array<uint32_t, 3> _max_compute_work_group_size = {};
  /// number bits of subpixel precision in screen x and y
  uint32_t _sub_pixel_precision_bits = 0;
  /// number bits of precision for selecting texel weights
  uint32_t _sub_texel_precision_bits = 0;
  /// number bits of precision for selecting mipmap weights
  uint32_t _mipmap_precision_bits = 0;
  /// max index value for indexed draw calls (for 32-bit indices)
  uint32_t _max_draw_indexed_index_value = 0;
  /// max draw count for indirect draw calls
  uint32_t _max_draw_indirect_count = 0;
  /// max absolute sampler LOD bias
  float _max_sampler_lod_bias = 0.0f;
  /// max degree of sampler anisotropy
  float _max_sampler_anisotropy = 0.0f;
  /// max number of active viewports
  uint32_t _max_viewports = 0;
  /// max viewport dimensions (x,y)
  std::array<uint32_t, 2> _max_viewport_dimensions = {};
  /// viewport bounds range (min,max)
  std::array<float, 2> _viewport_bounds_range = {};
  /// number bits of subpixel precision for viewport
  uint32_t _viewport_sub_pixel_bits = 0;
  /// min required alignment of pointers returned by MapMemory (bytes)
  size_t _min_memory_map_alignment = 0;
  /// min required alignment for texel buffer offsets (bytes)
  VkDeviceSize _min_texel_buffer_offset_alignment = 0;
  /// min required alignment for uniform buffer sizes and offsets (bytes)
  VkDeviceSize _min_uniform_buffer_offset_alignment = 0;
  /// min required alignment for storage buffer offsets (bytes)
  VkDeviceSize _min_storage_buffer_offset_alignment = 0;
  /// min texel offset for OpTextureSampleOffset
  int32_t _min_texel_offset = 0;
  /// max texel offset for OpTextureSampleOffset
  uint32_t _max_texel_offset = 0;
  /// min texel offset for OpTextureGatherOffset
  int32_t _min_texel_gather_offset = 0;
  /// max texel offset for OpTextureGatherOffset
  uint32_t _max_texel_gather_offset = 0;
  /// furthest negative offset for interpolateAtOffset
  float _min_interpolation_offset = 0.0f;
  /// furthest positive offset for interpolateAtOffset
  float _max_interpolation_offset = 0.0f;
  /// number of subpixel bits for interpolateAtOffset
  uint32_t _sub_pixel_interpolation_offset_bits = 0;
  /// max width for a framebuffer
  uint32_t _max_framebuffer_width = 0;
  /// max height for a framebuffer
  uint32_t _max_framebuffer_height = 0;
  /// max layer count for a layered framebuffer
  uint32_t _max_framebuffer_layers = 0;
  /// supported color sample counts for a framebuffer
  vk::sample_count_flags _framebuffer_color_sample_counts =
    vk::sample_count_flag::none;
  /// supported depth sample counts for a framebuffer
  vk::sample_count_flags _framebuffer_depth_sample_counts =
    vk::sample_count_flag::none;
  /// supported stencil sample counts for a framebuffer
  vk::sample_count_flags _framebuffer_stencil_sample_counts =
    vk::sample_count_flag::none;
  /// supported sample counts for a framebuffer with no attachments
  vk::sample_count_flags _framebuffer_no_attachments_sample_counts =
    vk::sample_count_flag::none;
  /// max number of color attachments per subpass
  uint32_t _max_color_attachments = 0;
  /// supported color sample counts for a non-integer sampled image
  vk::sample_count_flags _sampled_image_color_sample_counts =
    vk::sample_count_flag::none;
  /// supported sample counts for an integer image
  vk::sample_count_flags _sampled_image_integer_sample_counts =
    vk::sample_count_flag::none;
  /// supported depth sample counts for a sampled image
  vk::sample_count_flags _sampled_image_depth_sample_counts =
    vk::sample_count_flag::none;
  /// supported stencil sample counts for a sampled image
  vk::sample_count_flags _sampled_image_stencil_sample_counts =
    vk::sample_count_flag::none;
  /// supported sample counts for a storage image
  vk::sample_count_flags _storage_image_sample_counts =
    vk::sample_count_flag::none;
  /// max number of sample mask words
  uint32_t _max_sample_mask_words = 0;
  /// timestamps on graphics and compute queues
  VkBool32 _timestamp_compute_and_graphics = VK_FALSE;
  /// number of nanoseconds it takes for timestamp query value to increment by 1
  float _timestamp_period = 0.0f;
  /// max number of clip distances
  uint32_t _max_clip_distances = 0;
  /// max number of cull distances
  uint32_t _max_cull_distances = 0;
  /// max combined number of user clipping
  uint32_t _max_combined_clip_and_cull_distances = 0;
  /// distinct queue priorities available
  uint32_t _discrete_queue_priorities = 0;
  /// range (min,max) of supported point sizes
  std::array<float, 2> _point_size_range = {};
  /// range (min,max) of supported line widths
  std::array<float, 2> _line_width_range = {};
  /// granularity of supported point sizes
  float _point_size_granularity = 0.0f;
  /// granularity of supported line widths
  float _line_width_granularity = 0.0f;
  /// line rasterization follows preferred rules
  VkBool32 _strict_lines = VK_FALSE;
  /// supports standard sample locations for all supported sample counts
  VkBool32 _standard_sample_locations = VK_FALSE;
  /// optimal offset of buffer copies
  VkDeviceSize _optimal_buffer_copy_offset_alignment = 0;
  /// optimal pitch of buffer copies
  VkDeviceSize _optimal_buffer_copy_row_pitch_alignment = 0;
  /// minimum size and alignment for non-coherent host-mapped device memory
  /// access
  VkDeviceSize _non_coherent_atom_size = 0;
};
static_assert(sizeof(physical_device_limits) ==
                sizeof(::VkPhysicalDeviceLimits),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceSparseProperties.
class physical_device_sparse_properties
{
public:
  /// Default constructor.
  constexpr physical_device_sparse_properties() = default;

  /// Constructor.
  constexpr physical_device_sparse_properties(
    VkBool32 initial_residency_standard_2d_block_shape,
    VkBool32 initial_residency_standard_2d_multisample_block_shape,
    VkBool32 initial_residency_standard_3d_block_shape,
    VkBool32 initial_residency_aligned_mip_size,
    VkBool32 initial_residency_non_resident_strict) noexcept
  : _residency_standard_2d_block_shape(
      std::move(initial_residency_standard_2d_block_shape)),
    _residency_standard_2d_multisample_block_shape(
      std::move(initial_residency_standard_2d_multisample_block_shape)),
    _residency_standard_3d_block_shape(
      std::move(initial_residency_standard_3d_block_shape)),
    _residency_aligned_mip_size(std::move(initial_residency_aligned_mip_size)),
    _residency_non_resident_strict(
      std::move(initial_residency_non_resident_strict))
  {
  }

  /// Copy constructor.
  constexpr physical_device_sparse_properties(
    const physical_device_sparse_properties& other) = default;

  /// Move constructor.
  constexpr physical_device_sparse_properties(
    physical_device_sparse_properties&& other) = default;

  /// Copy assignment operator.
  constexpr physical_device_sparse_properties& operator=(
    const physical_device_sparse_properties& other) = default;

  /// Move assignment operator.
  constexpr physical_device_sparse_properties& operator=(
    physical_device_sparse_properties&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceSparseProperties&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceSparseProperties*>(this);
  }

  VkBool32& residency_standard_2d_block_shape()
  {
    return _residency_standard_2d_block_shape;
  }

  constexpr const VkBool32& residency_standard_2d_block_shape() const
  {
    return _residency_standard_2d_block_shape;
  }

  void residency_standard_2d_block_shape(
    VkBool32 new_residency_standard_2d_block_shape)
  {
    _residency_standard_2d_block_shape = new_residency_standard_2d_block_shape;
  }

  VkBool32& residency_standard_2d_multisample_block_shape()
  {
    return _residency_standard_2d_multisample_block_shape;
  }

  constexpr const VkBool32& residency_standard_2d_multisample_block_shape()
    const
  {
    return _residency_standard_2d_multisample_block_shape;
  }

  void residency_standard_2d_multisample_block_shape(
    VkBool32 new_residency_standard_2d_multisample_block_shape)
  {
    _residency_standard_2d_multisample_block_shape =
      new_residency_standard_2d_multisample_block_shape;
  }

  VkBool32& residency_standard_3d_block_shape()
  {
    return _residency_standard_3d_block_shape;
  }

  constexpr const VkBool32& residency_standard_3d_block_shape() const
  {
    return _residency_standard_3d_block_shape;
  }

  void residency_standard_3d_block_shape(
    VkBool32 new_residency_standard_3d_block_shape)
  {
    _residency_standard_3d_block_shape = new_residency_standard_3d_block_shape;
  }

  VkBool32& residency_aligned_mip_size()
  {
    return _residency_aligned_mip_size;
  }

  constexpr const VkBool32& residency_aligned_mip_size() const
  {
    return _residency_aligned_mip_size;
  }

  void residency_aligned_mip_size(VkBool32 new_residency_aligned_mip_size)
  {
    _residency_aligned_mip_size = new_residency_aligned_mip_size;
  }

  VkBool32& residency_non_resident_strict()
  {
    return _residency_non_resident_strict;
  }

  constexpr const VkBool32& residency_non_resident_strict() const
  {
    return _residency_non_resident_strict;
  }

  void residency_non_resident_strict(VkBool32 new_residency_non_resident_strict)
  {
    _residency_non_resident_strict = new_residency_non_resident_strict;
  }

private:
  /// Sparse resources support: GPU will access all 2D (single sample) sparse
  /// resources using the standard sparse image block shapes (based on pixel
  /// format)
  VkBool32 _residency_standard_2d_block_shape = VK_FALSE;
  /// Sparse resources support: GPU will access all 2D (multisample) sparse
  /// resources using the standard sparse image block shapes (based on pixel
  /// format)
  VkBool32 _residency_standard_2d_multisample_block_shape = VK_FALSE;
  /// Sparse resources support: GPU will access all 3D sparse resources using
  /// the standard sparse image block shapes (based on pixel format)
  VkBool32 _residency_standard_3d_block_shape = VK_FALSE;
  /// Sparse resources support: Images with mip level dimensions that are NOT a
  /// multiple of the sparse image block dimensions will be placed in the mip
  /// tail
  VkBool32 _residency_aligned_mip_size = VK_FALSE;
  /// Sparse resources support: GPU can consistently access non-resident regions
  /// of a resource, all reads return as if data is 0, writes are discarded
  VkBool32 _residency_non_resident_strict = VK_FALSE;
};
static_assert(sizeof(physical_device_sparse_properties) ==
                sizeof(::VkPhysicalDeviceSparseProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceProperties.
class physical_device_properties
{
public:
  /// Default constructor.
  constexpr physical_device_properties() = default;

  /// Constructor.
  constexpr physical_device_properties(
    uint32_t initial_api_version, uint32_t initial_driver_version,
    uint32_t initial_vendor_id, uint32_t initial_device_id,
    vk::physical_device_type initial_device_type,
    std::array<char, VK_MAX_PHYSICAL_DEVICE_NAME_SIZE> initial_device_name,
    std::array<uint8_t, VK_UUID_SIZE> initial_pipeline_cache_uuid,
    vk::physical_device_limits initial_limits,
    vk::physical_device_sparse_properties initial_sparse_properties) noexcept
  : _api_version(std::move(initial_api_version)),
    _driver_version(std::move(initial_driver_version)),
    _vendor_id(std::move(initial_vendor_id)),
    _device_id(std::move(initial_device_id)),
    _device_type(std::move(initial_device_type)),
    _device_name(std::move(initial_device_name)),
    _pipeline_cache_uuid(std::move(initial_pipeline_cache_uuid)),
    _limits(std::move(initial_limits)),
    _sparse_properties(std::move(initial_sparse_properties))
  {
  }

  /// Copy constructor.
  constexpr physical_device_properties(
    const physical_device_properties& other) = default;

  /// Move constructor.
  constexpr physical_device_properties(physical_device_properties&& other) =
    default;

  /// Copy assignment operator.
  constexpr physical_device_properties& operator=(
    const physical_device_properties& other) = default;

  /// Move assignment operator.
  constexpr physical_device_properties& operator=(
    physical_device_properties&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceProperties&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceProperties*>(this);
  }

  uint32_t& api_version()
  {
    return _api_version;
  }

  constexpr const uint32_t& api_version() const
  {
    return _api_version;
  }

  void api_version(uint32_t new_api_version)
  {
    _api_version = new_api_version;
  }

  uint32_t& driver_version()
  {
    return _driver_version;
  }

  constexpr const uint32_t& driver_version() const
  {
    return _driver_version;
  }

  void driver_version(uint32_t new_driver_version)
  {
    _driver_version = new_driver_version;
  }

  uint32_t& vendor_id()
  {
    return _vendor_id;
  }

  constexpr const uint32_t& vendor_id() const
  {
    return _vendor_id;
  }

  void vendor_id(uint32_t new_vendor_id)
  {
    _vendor_id = new_vendor_id;
  }

  uint32_t& device_id()
  {
    return _device_id;
  }

  constexpr const uint32_t& device_id() const
  {
    return _device_id;
  }

  void device_id(uint32_t new_device_id)
  {
    _device_id = new_device_id;
  }

  vk::physical_device_type& device_type()
  {
    return _device_type;
  }

  constexpr const vk::physical_device_type& device_type() const
  {
    return _device_type;
  }

  void device_type(vk::physical_device_type new_device_type)
  {
    _device_type = new_device_type;
  }

  std::array<char, VK_MAX_PHYSICAL_DEVICE_NAME_SIZE>& device_name()
  {
    return _device_name;
  }

  constexpr const std::array<char, VK_MAX_PHYSICAL_DEVICE_NAME_SIZE>&
  device_name() const
  {
    return _device_name;
  }

  void device_name(
    std::array<char, VK_MAX_PHYSICAL_DEVICE_NAME_SIZE> new_device_name)
  {
    _device_name = new_device_name;
  }

  std::array<uint8_t, VK_UUID_SIZE>& pipeline_cache_uuid()
  {
    return _pipeline_cache_uuid;
  }

  constexpr const std::array<uint8_t, VK_UUID_SIZE>& pipeline_cache_uuid() const
  {
    return _pipeline_cache_uuid;
  }

  void pipeline_cache_uuid(
    std::array<uint8_t, VK_UUID_SIZE> new_pipeline_cache_uuid)
  {
    _pipeline_cache_uuid = new_pipeline_cache_uuid;
  }

  vk::physical_device_limits& limits()
  {
    return _limits;
  }

  constexpr const vk::physical_device_limits& limits() const
  {
    return _limits;
  }

  void limits(vk::physical_device_limits new_limits)
  {
    _limits = new_limits;
  }

  vk::physical_device_sparse_properties& sparse_properties()
  {
    return _sparse_properties;
  }

  constexpr const vk::physical_device_sparse_properties& sparse_properties()
    const
  {
    return _sparse_properties;
  }

  void sparse_properties(
    vk::physical_device_sparse_properties new_sparse_properties)
  {
    _sparse_properties = new_sparse_properties;
  }

private:
  uint32_t _api_version = 0;
  uint32_t _driver_version = 0;
  uint32_t _vendor_id = 0;
  uint32_t _device_id = 0;
  vk::physical_device_type _device_type = vk::physical_device_type::other;
  std::array<char, VK_MAX_PHYSICAL_DEVICE_NAME_SIZE> _device_name = {};
  std::array<uint8_t, VK_UUID_SIZE> _pipeline_cache_uuid = {};
  vk::physical_device_limits _limits = vk::physical_device_limits{};
  vk::physical_device_sparse_properties _sparse_properties =
    vk::physical_device_sparse_properties{};
};
static_assert(sizeof(physical_device_properties) ==
                sizeof(::VkPhysicalDeviceProperties),
              "struct and wrapper have different size!");

inline void get_physical_device_properties(
  VkPhysicalDevice physical_device, vk::physical_device_properties* properties)
{
  vkGetPhysicalDeviceProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<VkPhysicalDeviceProperties*>(properties));
}
enum class queue_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Queue supports graphics operations
  /// @see VK_QUEUE_GRAPHICS_BIT
  graphics_bit = 1 << 0,
  /// Queue supports compute operations
  /// @see VK_QUEUE_COMPUTE_BIT
  compute_bit = 1 << 1,
  /// Queue supports transfer operations
  /// @see VK_QUEUE_TRANSFER_BIT
  transfer_bit = 1 << 2,
  /// Queue supports sparse resource memory management operations
  /// @see VK_QUEUE_SPARSE_BINDING_BIT
  sparse_binding_bit = 1 << 3,
  /// Queues may support protected operations
  /// @see VK_QUEUE_PROTECTED_BIT
  protected_bit = 1 << 4,
};
using queue_flags = shift::core::bit_field<queue_flag, VkQueueFlags>;
inline constexpr queue_flags operator|(queue_flag lhs, queue_flag rhs)
{
  return queue_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkQueueFamilyProperties.
class queue_family_properties
{
public:
  /// Default constructor.
  constexpr queue_family_properties() = default;

  /// Constructor.
  constexpr queue_family_properties(
    vk::queue_flags initial_queue_flags, uint32_t initial_queue_count,
    uint32_t initial_timestamp_valid_bits,
    vk::extent_3d initial_min_image_transfer_granularity) noexcept
  : _queue_flags(std::move(initial_queue_flags)),
    _queue_count(std::move(initial_queue_count)),
    _timestamp_valid_bits(std::move(initial_timestamp_valid_bits)),
    _min_image_transfer_granularity(
      std::move(initial_min_image_transfer_granularity))
  {
  }

  /// Copy constructor.
  constexpr queue_family_properties(const queue_family_properties& other) =
    default;

  /// Move constructor.
  constexpr queue_family_properties(queue_family_properties&& other) = default;

  /// Copy assignment operator.
  constexpr queue_family_properties& operator=(
    const queue_family_properties& other) = default;

  /// Move assignment operator.
  constexpr queue_family_properties& operator=(
    queue_family_properties&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkQueueFamilyProperties&() const
  {
    return *reinterpret_cast<const VkQueueFamilyProperties*>(this);
  }

  vk::queue_flags& queue_flags()
  {
    return _queue_flags;
  }

  constexpr const vk::queue_flags& queue_flags() const
  {
    return _queue_flags;
  }

  void queue_flags(vk::queue_flags new_queue_flags)
  {
    _queue_flags = new_queue_flags;
  }

  uint32_t& queue_count()
  {
    return _queue_count;
  }

  constexpr const uint32_t& queue_count() const
  {
    return _queue_count;
  }

  void queue_count(uint32_t new_queue_count)
  {
    _queue_count = new_queue_count;
  }

  uint32_t& timestamp_valid_bits()
  {
    return _timestamp_valid_bits;
  }

  constexpr const uint32_t& timestamp_valid_bits() const
  {
    return _timestamp_valid_bits;
  }

  void timestamp_valid_bits(uint32_t new_timestamp_valid_bits)
  {
    _timestamp_valid_bits = new_timestamp_valid_bits;
  }

  vk::extent_3d& min_image_transfer_granularity()
  {
    return _min_image_transfer_granularity;
  }

  constexpr const vk::extent_3d& min_image_transfer_granularity() const
  {
    return _min_image_transfer_granularity;
  }

  void min_image_transfer_granularity(
    vk::extent_3d new_min_image_transfer_granularity)
  {
    _min_image_transfer_granularity = new_min_image_transfer_granularity;
  }

private:
  /// Queue flags
  vk::queue_flags _queue_flags = vk::queue_flag::none;
  uint32_t _queue_count = 0;
  uint32_t _timestamp_valid_bits = 0;
  /// Minimum alignment requirement for image transfers
  vk::extent_3d _min_image_transfer_granularity = vk::extent_3d{};
};
static_assert(sizeof(queue_family_properties) ==
                sizeof(::VkQueueFamilyProperties),
              "struct and wrapper have different size!");

inline void get_physical_device_queue_family_properties(
  VkPhysicalDevice physical_device, uint32_t* queue_family_property_count,
  vk::queue_family_properties* queue_family_properties)
{
  vkGetPhysicalDeviceQueueFamilyProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<uint32_t*>(queue_family_property_count),
    reinterpret_cast<VkQueueFamilyProperties*>(queue_family_properties));
}
enum class memory_property_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// If otherwise stated, then allocate memory on device
  /// @see VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT
  device_local_bit = 1 << 0,
  /// Memory is mappable by host
  /// @see VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT
  host_visible_bit = 1 << 1,
  /// Memory will have i/o coherency. If not set, application may need to use
  /// vkFlushMappedMemoryRanges and vkInvalidateMappedMemoryRanges to
  /// flush/invalidate host cache
  /// @see VK_MEMORY_PROPERTY_HOST_COHERENT_BIT
  host_coherent_bit = 1 << 2,
  /// Memory will be cached by the host
  /// @see VK_MEMORY_PROPERTY_HOST_CACHED_BIT
  host_cached_bit = 1 << 3,
  /// Memory may be allocated by the driver when it is required
  /// @see VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT
  lazily_allocated_bit = 1 << 4,
  /// Memory is protected
  /// @see VK_MEMORY_PROPERTY_PROTECTED_BIT
  protected_bit = 1 << 5,
};
using memory_property_flags =
  shift::core::bit_field<memory_property_flag, VkMemoryPropertyFlags>;
inline constexpr memory_property_flags operator|(memory_property_flag lhs,
                                                 memory_property_flag rhs)
{
  return memory_property_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkMemoryType.
class memory_type
{
public:
  /// Default constructor.
  constexpr memory_type() = default;

  /// Constructor.
  constexpr memory_type(vk::memory_property_flags initial_property_flags,
                        uint32_t initial_heap_index) noexcept
  : _property_flags(std::move(initial_property_flags)),
    _heap_index(std::move(initial_heap_index))
  {
  }

  /// Copy constructor.
  constexpr memory_type(const memory_type& other) = default;

  /// Move constructor.
  constexpr memory_type(memory_type&& other) = default;

  /// Copy assignment operator.
  constexpr memory_type& operator=(const memory_type& other) = default;

  /// Move assignment operator.
  constexpr memory_type& operator=(memory_type&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryType&() const
  {
    return *reinterpret_cast<const VkMemoryType*>(this);
  }

  vk::memory_property_flags& property_flags()
  {
    return _property_flags;
  }

  constexpr const vk::memory_property_flags& property_flags() const
  {
    return _property_flags;
  }

  void property_flags(vk::memory_property_flags new_property_flags)
  {
    _property_flags = new_property_flags;
  }

  uint32_t& heap_index()
  {
    return _heap_index;
  }

  constexpr const uint32_t& heap_index() const
  {
    return _heap_index;
  }

  void heap_index(uint32_t new_heap_index)
  {
    _heap_index = new_heap_index;
  }

private:
  /// Memory properties of this memory type
  vk::memory_property_flags _property_flags = vk::memory_property_flag::none;
  /// Index of the memory heap allocations of this memory type are taken from
  uint32_t _heap_index = 0;
};
static_assert(sizeof(memory_type) == sizeof(::VkMemoryType),
              "struct and wrapper have different size!");

enum class memory_heap_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// If set, heap represents device memory
  /// @see VK_MEMORY_HEAP_DEVICE_LOCAL_BIT
  device_local_bit = 1 << 0,
  /// If set, heap allocations allocate multiple instances by default
  /// @see VK_MEMORY_HEAP_MULTI_INSTANCE_BIT
  multi_instance_bit = 1 << 1,
};
using memory_heap_flags =
  shift::core::bit_field<memory_heap_flag, VkMemoryHeapFlags>;
inline constexpr memory_heap_flags operator|(memory_heap_flag lhs,
                                             memory_heap_flag rhs)
{
  return memory_heap_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkMemoryHeap.
class memory_heap
{
public:
  /// Default constructor.
  constexpr memory_heap() = default;

  /// Constructor.
  constexpr memory_heap(VkDeviceSize initial_size,
                        vk::memory_heap_flags initial_flags) noexcept
  : _size(std::move(initial_size)), _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr memory_heap(const memory_heap& other) = default;

  /// Move constructor.
  constexpr memory_heap(memory_heap&& other) = default;

  /// Copy assignment operator.
  constexpr memory_heap& operator=(const memory_heap& other) = default;

  /// Move assignment operator.
  constexpr memory_heap& operator=(memory_heap&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryHeap&() const
  {
    return *reinterpret_cast<const VkMemoryHeap*>(this);
  }

  VkDeviceSize& size()
  {
    return _size;
  }

  constexpr const VkDeviceSize& size() const
  {
    return _size;
  }

  void size(VkDeviceSize new_size)
  {
    _size = new_size;
  }

  vk::memory_heap_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::memory_heap_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::memory_heap_flags new_flags)
  {
    _flags = new_flags;
  }

private:
  /// Available memory in the heap
  VkDeviceSize _size = 0;
  /// Flags for the heap
  vk::memory_heap_flags _flags = vk::memory_heap_flag::none;
};
static_assert(sizeof(memory_heap) == sizeof(::VkMemoryHeap),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceMemoryProperties.
class physical_device_memory_properties
{
public:
  /// Default constructor.
  constexpr physical_device_memory_properties() = default;

  /// Constructor.
  constexpr physical_device_memory_properties(
    uint32_t initial_memory_type_count,
    std::array<vk::memory_type, VK_MAX_MEMORY_TYPES> initial_memory_types,
    uint32_t initial_memory_heap_count,
    std::array<vk::memory_heap, VK_MAX_MEMORY_HEAPS>
      initial_memory_heaps) noexcept
  : _memory_type_count(std::move(initial_memory_type_count)),
    _memory_types(std::move(initial_memory_types)),
    _memory_heap_count(std::move(initial_memory_heap_count)),
    _memory_heaps(std::move(initial_memory_heaps))
  {
  }

  /// Copy constructor.
  constexpr physical_device_memory_properties(
    const physical_device_memory_properties& other) = default;

  /// Move constructor.
  constexpr physical_device_memory_properties(
    physical_device_memory_properties&& other) = default;

  /// Copy assignment operator.
  constexpr physical_device_memory_properties& operator=(
    const physical_device_memory_properties& other) = default;

  /// Move assignment operator.
  constexpr physical_device_memory_properties& operator=(
    physical_device_memory_properties&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceMemoryProperties&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceMemoryProperties*>(this);
  }

  uint32_t& memory_type_count()
  {
    return _memory_type_count;
  }

  constexpr const uint32_t& memory_type_count() const
  {
    return _memory_type_count;
  }

  void memory_type_count(uint32_t new_memory_type_count)
  {
    _memory_type_count = new_memory_type_count;
  }

  std::array<vk::memory_type, VK_MAX_MEMORY_TYPES>& memory_types()
  {
    return _memory_types;
  }

  constexpr const std::array<vk::memory_type, VK_MAX_MEMORY_TYPES>&
  memory_types() const
  {
    return _memory_types;
  }

  void memory_types(
    std::array<vk::memory_type, VK_MAX_MEMORY_TYPES> new_memory_types)
  {
    _memory_types = new_memory_types;
  }

  uint32_t& memory_heap_count()
  {
    return _memory_heap_count;
  }

  constexpr const uint32_t& memory_heap_count() const
  {
    return _memory_heap_count;
  }

  void memory_heap_count(uint32_t new_memory_heap_count)
  {
    _memory_heap_count = new_memory_heap_count;
  }

  std::array<vk::memory_heap, VK_MAX_MEMORY_HEAPS>& memory_heaps()
  {
    return _memory_heaps;
  }

  constexpr const std::array<vk::memory_heap, VK_MAX_MEMORY_HEAPS>&
  memory_heaps() const
  {
    return _memory_heaps;
  }

  void memory_heaps(
    std::array<vk::memory_heap, VK_MAX_MEMORY_HEAPS> new_memory_heaps)
  {
    _memory_heaps = new_memory_heaps;
  }

private:
  uint32_t _memory_type_count = 0;
  std::array<vk::memory_type, VK_MAX_MEMORY_TYPES> _memory_types = {};
  uint32_t _memory_heap_count = 0;
  std::array<vk::memory_heap, VK_MAX_MEMORY_HEAPS> _memory_heaps = {};
};
static_assert(sizeof(physical_device_memory_properties) ==
                sizeof(::VkPhysicalDeviceMemoryProperties),
              "struct and wrapper have different size!");

inline void get_physical_device_memory_properties(
  VkPhysicalDevice physical_device,
  vk::physical_device_memory_properties* memory_properties)
{
  vkGetPhysicalDeviceMemoryProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<VkPhysicalDeviceMemoryProperties*>(memory_properties));
}
inline PFN_vkVoidFunction get_instance_proc_addr(VkInstance instance,
                                                 const char* name)
{
  return static_cast<PFN_vkVoidFunction>(vkGetInstanceProcAddr(
    static_cast<VkInstance>(instance), reinterpret_cast<const char*>(name)));
}
inline PFN_vkVoidFunction get_device_proc_addr(VkDevice device,
                                               const char* name)
{
  return static_cast<PFN_vkVoidFunction>(vkGetDeviceProcAddr(
    static_cast<VkDevice>(device), reinterpret_cast<const char*>(name)));
}
enum class device_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using device_create_flags =
  shift::core::bit_field<device_create_flag, VkDeviceCreateFlags>;
inline constexpr device_create_flags operator|(device_create_flag lhs,
                                               device_create_flag rhs)
{
  return device_create_flags{lhs} | rhs;
}
enum class device_queue_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Queue is a protected-capable device queue
  /// @see VK_DEVICE_QUEUE_CREATE_PROTECTED_BIT
  protected_bit = 1 << 0,
};
using device_queue_create_flags =
  shift::core::bit_field<device_queue_create_flag, VkDeviceQueueCreateFlags>;
inline constexpr device_queue_create_flags operator|(
  device_queue_create_flag lhs, device_queue_create_flag rhs)
{
  return device_queue_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkDeviceQueueCreateInfo.
class device_queue_create_info
{
public:
  /// Default constructor.
  constexpr device_queue_create_info() = default;

  /// Constructor.
  constexpr device_queue_create_info(
    const void* initial_next, vk::device_queue_create_flags initial_flags,
    uint32_t initial_queue_family_index, uint32_t initial_queue_count,
    const float* initial_queue_priorities) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _queue_family_index(std::move(initial_queue_family_index)),
    _queue_count(std::move(initial_queue_count)),
    _queue_priorities(std::move(initial_queue_priorities))
  {
  }

  /// Copy constructor.
  constexpr device_queue_create_info(
    const device_queue_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _queue_family_index(other._queue_family_index),
    _queue_count(other._queue_count),
    _queue_priorities(other._queue_priorities)
  {
  }

  /// Move constructor.
  constexpr device_queue_create_info(device_queue_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _queue_family_index(std::move(other._queue_family_index)),
    _queue_count(std::move(other._queue_count)),
    _queue_priorities(std::move(other._queue_priorities))
  {
  }

  /// Copy assignment operator.
  constexpr device_queue_create_info& operator=(
    const device_queue_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _queue_family_index = other._queue_family_index;
    _queue_count = other._queue_count;
    _queue_priorities = other._queue_priorities;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_queue_create_info& operator=(
    device_queue_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _queue_family_index = std::move(other._queue_family_index);
    _queue_count = std::move(other._queue_count);
    _queue_priorities = std::move(other._queue_priorities);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceQueueCreateInfo&() const
  {
    return *reinterpret_cast<const VkDeviceQueueCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::device_queue_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::device_queue_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::device_queue_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& queue_family_index()
  {
    return _queue_family_index;
  }

  constexpr const uint32_t& queue_family_index() const
  {
    return _queue_family_index;
  }

  void queue_family_index(uint32_t new_queue_family_index)
  {
    _queue_family_index = new_queue_family_index;
  }

  uint32_t& queue_count()
  {
    return _queue_count;
  }

  constexpr const uint32_t& queue_count() const
  {
    return _queue_count;
  }

  void queue_count(uint32_t new_queue_count)
  {
    _queue_count = new_queue_count;
  }

  const float* queue_priorities()
  {
    return _queue_priorities;
  }

  constexpr const float* queue_priorities() const
  {
    return _queue_priorities;
  }

  void queue_priorities(const float* new_queue_priorities)
  {
    _queue_priorities = new_queue_priorities;
  }

  template <std::size_t Count>
  void queue_priorities(const std::array<float, Count>& new_queue_priorities)
  {
    _queue_count = static_cast<uint32_t>(new_queue_priorities.size());
    _queue_priorities = new_queue_priorities.data();
  }

  void queue_priorities(const std::vector<float>& new_queue_priorities)
  {
    _queue_count = static_cast<uint32_t>(new_queue_priorities.size());
    _queue_priorities = new_queue_priorities.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_queue_create_info;
  const void* _next = nullptr;
  vk::device_queue_create_flags _flags = vk::device_queue_create_flag::none;
  uint32_t _queue_family_index = 0;
  uint32_t _queue_count = 0;
  const float* _queue_priorities = nullptr;
};
static_assert(sizeof(device_queue_create_info) ==
                sizeof(::VkDeviceQueueCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceCreateInfo.
class device_create_info
{
public:
  /// Default constructor.
  constexpr device_create_info() = default;

  /// Constructor.
  constexpr device_create_info(
    const void* initial_next, vk::device_create_flags initial_flags,
    uint32_t initial_queue_create_info_count,
    const vk::device_queue_create_info* initial_queue_create_infos,
    uint32_t initial_enabled_layer_count,
    const char* const* initial_enabled_layer_names,
    uint32_t initial_enabled_extension_count,
    const char* const* initial_enabled_extension_names,
    const vk::physical_device_features* initial_enabled_features) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _queue_create_info_count(std::move(initial_queue_create_info_count)),
    _queue_create_infos(std::move(initial_queue_create_infos)),
    _enabled_layer_count(std::move(initial_enabled_layer_count)),
    _enabled_layer_names(std::move(initial_enabled_layer_names)),
    _enabled_extension_count(std::move(initial_enabled_extension_count)),
    _enabled_extension_names(std::move(initial_enabled_extension_names)),
    _enabled_features(std::move(initial_enabled_features))
  {
  }

  /// Copy constructor.
  constexpr device_create_info(const device_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _queue_create_info_count(other._queue_create_info_count),
    _queue_create_infos(other._queue_create_infos),
    _enabled_layer_count(other._enabled_layer_count),
    _enabled_layer_names(other._enabled_layer_names),
    _enabled_extension_count(other._enabled_extension_count),
    _enabled_extension_names(other._enabled_extension_names),
    _enabled_features(other._enabled_features)
  {
  }

  /// Move constructor.
  constexpr device_create_info(device_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _queue_create_info_count(std::move(other._queue_create_info_count)),
    _queue_create_infos(std::move(other._queue_create_infos)),
    _enabled_layer_count(std::move(other._enabled_layer_count)),
    _enabled_layer_names(std::move(other._enabled_layer_names)),
    _enabled_extension_count(std::move(other._enabled_extension_count)),
    _enabled_extension_names(std::move(other._enabled_extension_names)),
    _enabled_features(std::move(other._enabled_features))
  {
  }

  /// Copy assignment operator.
  constexpr device_create_info& operator=(
    const device_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _queue_create_info_count = other._queue_create_info_count;
    _queue_create_infos = other._queue_create_infos;
    _enabled_layer_count = other._enabled_layer_count;
    _enabled_layer_names = other._enabled_layer_names;
    _enabled_extension_count = other._enabled_extension_count;
    _enabled_extension_names = other._enabled_extension_names;
    _enabled_features = other._enabled_features;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_create_info& operator=(device_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _queue_create_info_count = std::move(other._queue_create_info_count);
    _queue_create_infos = std::move(other._queue_create_infos);
    _enabled_layer_count = std::move(other._enabled_layer_count);
    _enabled_layer_names = std::move(other._enabled_layer_names);
    _enabled_extension_count = std::move(other._enabled_extension_count);
    _enabled_extension_names = std::move(other._enabled_extension_names);
    _enabled_features = std::move(other._enabled_features);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceCreateInfo&() const
  {
    return *reinterpret_cast<const VkDeviceCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::device_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::device_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::device_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& queue_create_info_count()
  {
    return _queue_create_info_count;
  }

  constexpr const uint32_t& queue_create_info_count() const
  {
    return _queue_create_info_count;
  }

  void queue_create_info_count(uint32_t new_queue_create_info_count)
  {
    _queue_create_info_count = new_queue_create_info_count;
  }

  const vk::device_queue_create_info* queue_create_infos()
  {
    return _queue_create_infos;
  }

  constexpr const vk::device_queue_create_info* queue_create_infos() const
  {
    return _queue_create_infos;
  }

  void queue_create_infos(
    const vk::device_queue_create_info* new_queue_create_infos)
  {
    _queue_create_infos = new_queue_create_infos;
  }

  template <std::size_t Count>
  void queue_create_infos(const std::array<vk::device_queue_create_info, Count>&
                            new_queue_create_infos)
  {
    _queue_create_info_count =
      static_cast<uint32_t>(new_queue_create_infos.size());
    _queue_create_infos = new_queue_create_infos.data();
  }

  void queue_create_infos(
    const std::vector<vk::device_queue_create_info>& new_queue_create_infos)
  {
    _queue_create_info_count =
      static_cast<uint32_t>(new_queue_create_infos.size());
    _queue_create_infos = new_queue_create_infos.data();
  }

  uint32_t& enabled_layer_count()
  {
    return _enabled_layer_count;
  }

  constexpr const uint32_t& enabled_layer_count() const
  {
    return _enabled_layer_count;
  }

  void enabled_layer_count(uint32_t new_enabled_layer_count)
  {
    _enabled_layer_count = new_enabled_layer_count;
  }

  const char* const* enabled_layer_names()
  {
    return _enabled_layer_names;
  }

  constexpr const char* const* enabled_layer_names() const
  {
    return _enabled_layer_names;
  }

  void enabled_layer_names(const char* const* new_enabled_layer_names)
  {
    _enabled_layer_names = new_enabled_layer_names;
  }

  template <std::size_t Count>
  void enabled_layer_names(
    const std::array<char*, Count>& new_enabled_layer_names)
  {
    _enabled_layer_count =
      static_cast<uint32_t>(new_enabled_layer_names.size());
    _enabled_layer_names = new_enabled_layer_names.data();
  }

  void enabled_layer_names(const std::vector<char*>& new_enabled_layer_names)
  {
    _enabled_layer_count =
      static_cast<uint32_t>(new_enabled_layer_names.size());
    _enabled_layer_names = new_enabled_layer_names.data();
  }

  uint32_t& enabled_extension_count()
  {
    return _enabled_extension_count;
  }

  constexpr const uint32_t& enabled_extension_count() const
  {
    return _enabled_extension_count;
  }

  void enabled_extension_count(uint32_t new_enabled_extension_count)
  {
    _enabled_extension_count = new_enabled_extension_count;
  }

  const char* const* enabled_extension_names()
  {
    return _enabled_extension_names;
  }

  constexpr const char* const* enabled_extension_names() const
  {
    return _enabled_extension_names;
  }

  void enabled_extension_names(const char* const* new_enabled_extension_names)
  {
    _enabled_extension_names = new_enabled_extension_names;
  }

  template <std::size_t Count>
  void enabled_extension_names(
    const std::array<char*, Count>& new_enabled_extension_names)
  {
    _enabled_extension_count =
      static_cast<uint32_t>(new_enabled_extension_names.size());
    _enabled_extension_names = new_enabled_extension_names.data();
  }

  void enabled_extension_names(
    const std::vector<char*>& new_enabled_extension_names)
  {
    _enabled_extension_count =
      static_cast<uint32_t>(new_enabled_extension_names.size());
    _enabled_extension_names = new_enabled_extension_names.data();
  }

  const vk::physical_device_features* enabled_features()
  {
    return _enabled_features;
  }

  constexpr const vk::physical_device_features* enabled_features() const
  {
    return _enabled_features;
  }

  void enabled_features(
    const vk::physical_device_features* new_enabled_features)
  {
    _enabled_features = new_enabled_features;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_create_info;
  const void* _next = nullptr;
  vk::device_create_flags _flags = vk::device_create_flag::none;
  uint32_t _queue_create_info_count = 0;
  const vk::device_queue_create_info* _queue_create_infos = nullptr;
  uint32_t _enabled_layer_count = 0;
  /// Ordered list of layer names to be enabled
  const char* const* _enabled_layer_names = nullptr;
  uint32_t _enabled_extension_count = 0;
  const char* const* _enabled_extension_names = nullptr;
  const vk::physical_device_features* _enabled_features = nullptr;
};
static_assert(sizeof(device_create_info) == sizeof(::VkDeviceCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_device(VkPhysicalDevice physical_device,
                                const vk::device_create_info* create_info,
                                const vk::allocation_callbacks* allocator,
                                VkDevice* device)
{
  return static_cast<vk::result>(
    vkCreateDevice(static_cast<VkPhysicalDevice>(physical_device),
                   reinterpret_cast<const VkDeviceCreateInfo*>(create_info),
                   reinterpret_cast<const VkAllocationCallbacks*>(allocator),
                   reinterpret_cast<VkDevice*>(device)));
}
inline void destroy_device(VkDevice device,
                           const vk::allocation_callbacks* allocator)
{
  vkDestroyDevice(static_cast<VkDevice>(device),
                  reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}

/// Enhanced replacement type for VkExtensionProperties.
class extension_properties
{
public:
  /// Default constructor.
  constexpr extension_properties() = default;

  /// Constructor.
  constexpr extension_properties(
    std::array<char, VK_MAX_EXTENSION_NAME_SIZE> initial_extension_name,
    uint32_t initial_spec_version) noexcept
  : _extension_name(std::move(initial_extension_name)),
    _spec_version(std::move(initial_spec_version))
  {
  }

  /// Copy constructor.
  constexpr extension_properties(const extension_properties& other) = default;

  /// Move constructor.
  constexpr extension_properties(extension_properties&& other) = default;

  /// Copy assignment operator.
  constexpr extension_properties& operator=(const extension_properties& other) =
    default;

  /// Move assignment operator.
  constexpr extension_properties& operator=(extension_properties&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkExtensionProperties&() const
  {
    return *reinterpret_cast<const VkExtensionProperties*>(this);
  }

  std::array<char, VK_MAX_EXTENSION_NAME_SIZE>& extension_name()
  {
    return _extension_name;
  }

  constexpr const std::array<char, VK_MAX_EXTENSION_NAME_SIZE>& extension_name()
    const
  {
    return _extension_name;
  }

  void extension_name(
    std::array<char, VK_MAX_EXTENSION_NAME_SIZE> new_extension_name)
  {
    _extension_name = new_extension_name;
  }

  uint32_t& spec_version()
  {
    return _spec_version;
  }

  constexpr const uint32_t& spec_version() const
  {
    return _spec_version;
  }

  void spec_version(uint32_t new_spec_version)
  {
    _spec_version = new_spec_version;
  }

private:
  /// extension name
  std::array<char, VK_MAX_EXTENSION_NAME_SIZE> _extension_name = {};
  /// version of the extension specification implemented
  uint32_t _spec_version = 0;
};
static_assert(sizeof(extension_properties) == sizeof(::VkExtensionProperties),
              "struct and wrapper have different size!");

inline vk::result enumerate_instance_extension_properties(
  const char* layer_name, uint32_t* property_count,
  vk::extension_properties* properties)
{
  return static_cast<vk::result>(vkEnumerateInstanceExtensionProperties(
    reinterpret_cast<const char*>(layer_name),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkExtensionProperties*>(properties)));
}
inline vk::result enumerate_device_extension_properties(
  VkPhysicalDevice physical_device, const char* layer_name,
  uint32_t* property_count, vk::extension_properties* properties)
{
  return static_cast<vk::result>(vkEnumerateDeviceExtensionProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<const char*>(layer_name),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkExtensionProperties*>(properties)));
}

/// Enhanced replacement type for VkLayerProperties.
class layer_properties
{
public:
  /// Default constructor.
  constexpr layer_properties() = default;

  /// Constructor.
  constexpr layer_properties(
    std::array<char, VK_MAX_EXTENSION_NAME_SIZE> initial_layer_name,
    uint32_t initial_spec_version, uint32_t initial_implementation_version,
    std::array<char, VK_MAX_DESCRIPTION_SIZE> initial_description) noexcept
  : _layer_name(std::move(initial_layer_name)),
    _spec_version(std::move(initial_spec_version)),
    _implementation_version(std::move(initial_implementation_version)),
    _description(std::move(initial_description))
  {
  }

  /// Copy constructor.
  constexpr layer_properties(const layer_properties& other) = default;

  /// Move constructor.
  constexpr layer_properties(layer_properties&& other) = default;

  /// Copy assignment operator.
  constexpr layer_properties& operator=(const layer_properties& other) =
    default;

  /// Move assignment operator.
  constexpr layer_properties& operator=(layer_properties&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkLayerProperties&() const
  {
    return *reinterpret_cast<const VkLayerProperties*>(this);
  }

  std::array<char, VK_MAX_EXTENSION_NAME_SIZE>& layer_name()
  {
    return _layer_name;
  }

  constexpr const std::array<char, VK_MAX_EXTENSION_NAME_SIZE>& layer_name()
    const
  {
    return _layer_name;
  }

  void layer_name(std::array<char, VK_MAX_EXTENSION_NAME_SIZE> new_layer_name)
  {
    _layer_name = new_layer_name;
  }

  uint32_t& spec_version()
  {
    return _spec_version;
  }

  constexpr const uint32_t& spec_version() const
  {
    return _spec_version;
  }

  void spec_version(uint32_t new_spec_version)
  {
    _spec_version = new_spec_version;
  }

  uint32_t& implementation_version()
  {
    return _implementation_version;
  }

  constexpr const uint32_t& implementation_version() const
  {
    return _implementation_version;
  }

  void implementation_version(uint32_t new_implementation_version)
  {
    _implementation_version = new_implementation_version;
  }

  std::array<char, VK_MAX_DESCRIPTION_SIZE>& description()
  {
    return _description;
  }

  constexpr const std::array<char, VK_MAX_DESCRIPTION_SIZE>& description() const
  {
    return _description;
  }

  void description(std::array<char, VK_MAX_DESCRIPTION_SIZE> new_description)
  {
    _description = new_description;
  }

private:
  /// layer name
  std::array<char, VK_MAX_EXTENSION_NAME_SIZE> _layer_name = {};
  /// version of the layer specification implemented
  uint32_t _spec_version = 0;
  /// build or release version of the layer's library
  uint32_t _implementation_version = 0;
  /// Free-form description of the layer
  std::array<char, VK_MAX_DESCRIPTION_SIZE> _description = {};
};
static_assert(sizeof(layer_properties) == sizeof(::VkLayerProperties),
              "struct and wrapper have different size!");

inline vk::result enumerate_instance_layer_properties(
  uint32_t* property_count, vk::layer_properties* properties)
{
  return static_cast<vk::result>(vkEnumerateInstanceLayerProperties(
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkLayerProperties*>(properties)));
}
inline vk::result enumerate_device_layer_properties(
  VkPhysicalDevice physical_device, uint32_t* property_count,
  vk::layer_properties* properties)
{
  return static_cast<vk::result>(vkEnumerateDeviceLayerProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkLayerProperties*>(properties)));
}
inline void get_device_queue(VkDevice device, uint32_t queue_family_index,
                             uint32_t queue_index, VkQueue* queue)
{
  vkGetDeviceQueue(
    static_cast<VkDevice>(device), static_cast<uint32_t>(queue_family_index),
    static_cast<uint32_t>(queue_index), reinterpret_cast<VkQueue*>(queue));
}
enum class pipeline_stage_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Before subsequent commands are processed
  /// @see VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT
  top_of_pipe_bit = 1 << 0,
  /// Draw/DispatchIndirect command fetch
  /// @see VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT
  draw_indirect_bit = 1 << 1,
  /// Vertex/index fetch
  /// @see VK_PIPELINE_STAGE_VERTEX_INPUT_BIT
  vertex_input_bit = 1 << 2,
  /// Vertex shading
  /// @see VK_PIPELINE_STAGE_VERTEX_SHADER_BIT
  vertex_shader_bit = 1 << 3,
  /// Tessellation control shading
  /// @see VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT
  tessellation_control_shader_bit = 1 << 4,
  /// Tessellation evaluation shading
  /// @see VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT
  tessellation_evaluation_shader_bit = 1 << 5,
  /// Geometry shading
  /// @see VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT
  geometry_shader_bit = 1 << 6,
  /// Fragment shading
  /// @see VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT
  fragment_shader_bit = 1 << 7,
  /// Early fragment (depth and stencil) tests
  /// @see VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT
  early_fragment_tests_bit = 1 << 8,
  /// Late fragment (depth and stencil) tests
  /// @see VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT
  late_fragment_tests_bit = 1 << 9,
  /// Color attachment writes
  /// @see VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT
  color_attachment_output_bit = 1 << 10,
  /// Compute shading
  /// @see VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT
  compute_shader_bit = 1 << 11,
  /// Transfer/copy operations
  /// @see VK_PIPELINE_STAGE_TRANSFER_BIT
  transfer_bit = 1 << 12,
  /// After previous commands have completed
  /// @see VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT
  bottom_of_pipe_bit = 1 << 13,
  /// Indicates host (CPU) is a source/sink of the dependency
  /// @see VK_PIPELINE_STAGE_HOST_BIT
  host_bit = 1 << 14,
  /// All stages of the graphics pipeline
  /// @see VK_PIPELINE_STAGE_ALL_GRAPHICS_BIT
  all_graphics_bit = 1 << 15,
  /// All stages supported on the queue
  /// @see VK_PIPELINE_STAGE_ALL_COMMANDS_BIT
  all_commands_bit = 1 << 16,
  /// A pipeline stage for conditional rendering predicate fetch
  /// @see VK_PIPELINE_STAGE_CONDITIONAL_RENDERING_BIT_EXT
  conditional_rendering_bit_ext = 1 << 18,
  /// @see VK_PIPELINE_STAGE_COMMAND_PROCESS_BIT_NVX
  command_process_bit_nvx = 1 << 17,
  /// @see VK_PIPELINE_STAGE_SHADING_RATE_IMAGE_BIT_NV
  shading_rate_image_bit_nv = 1 << 22,
  /// @see VK_PIPELINE_STAGE_RAYTRACING_BIT_NVX
  raytracing_bit_nvx = 1 << 21,
  /// @see VK_PIPELINE_STAGE_TASK_SHADER_BIT_NV
  task_shader_bit_nv = 1 << 19,
  /// @see VK_PIPELINE_STAGE_MESH_SHADER_BIT_NV
  mesh_shader_bit_nv = 1 << 20,
};
using pipeline_stage_flags =
  shift::core::bit_field<pipeline_stage_flag, VkPipelineStageFlags>;
inline constexpr pipeline_stage_flags operator|(pipeline_stage_flag lhs,
                                                pipeline_stage_flag rhs)
{
  return pipeline_stage_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkSubmitInfo.
class submit_info
{
public:
  /// Default constructor.
  constexpr submit_info() = default;

  /// Constructor.
  constexpr submit_info(
    const void* initial_next, uint32_t initial_wait_semaphore_count,
    const VkSemaphore* initial_wait_semaphores,
    const vk::pipeline_stage_flags* initial_wait_dst_stage_mask,
    uint32_t initial_command_buffer_count,
    const VkCommandBuffer* initial_command_buffers,
    uint32_t initial_signal_semaphore_count,
    const VkSemaphore* initial_signal_semaphores) noexcept
  : _next(std::move(initial_next)),
    _wait_semaphore_count(std::move(initial_wait_semaphore_count)),
    _wait_semaphores(std::move(initial_wait_semaphores)),
    _wait_dst_stage_mask(std::move(initial_wait_dst_stage_mask)),
    _command_buffer_count(std::move(initial_command_buffer_count)),
    _command_buffers(std::move(initial_command_buffers)),
    _signal_semaphore_count(std::move(initial_signal_semaphore_count)),
    _signal_semaphores(std::move(initial_signal_semaphores))
  {
  }

  /// Copy constructor.
  constexpr submit_info(const submit_info& other) noexcept
  : _next(other._next),
    _wait_semaphore_count(other._wait_semaphore_count),
    _wait_semaphores(other._wait_semaphores),
    _wait_dst_stage_mask(other._wait_dst_stage_mask),
    _command_buffer_count(other._command_buffer_count),
    _command_buffers(other._command_buffers),
    _signal_semaphore_count(other._signal_semaphore_count),
    _signal_semaphores(other._signal_semaphores)
  {
  }

  /// Move constructor.
  constexpr submit_info(submit_info&& other) noexcept
  : _next(std::move(other._next)),
    _wait_semaphore_count(std::move(other._wait_semaphore_count)),
    _wait_semaphores(std::move(other._wait_semaphores)),
    _wait_dst_stage_mask(std::move(other._wait_dst_stage_mask)),
    _command_buffer_count(std::move(other._command_buffer_count)),
    _command_buffers(std::move(other._command_buffers)),
    _signal_semaphore_count(std::move(other._signal_semaphore_count)),
    _signal_semaphores(std::move(other._signal_semaphores))
  {
  }

  /// Copy assignment operator.
  constexpr submit_info& operator=(const submit_info& other) noexcept
  {
    _next = other._next;
    _wait_semaphore_count = other._wait_semaphore_count;
    _wait_semaphores = other._wait_semaphores;
    _wait_dst_stage_mask = other._wait_dst_stage_mask;
    _command_buffer_count = other._command_buffer_count;
    _command_buffers = other._command_buffers;
    _signal_semaphore_count = other._signal_semaphore_count;
    _signal_semaphores = other._signal_semaphores;
    return *this;
  }

  /// Move assignment operator.
  constexpr submit_info& operator=(submit_info&& other) noexcept
  {
    _next = std::move(other._next);
    _wait_semaphore_count = std::move(other._wait_semaphore_count);
    _wait_semaphores = std::move(other._wait_semaphores);
    _wait_dst_stage_mask = std::move(other._wait_dst_stage_mask);
    _command_buffer_count = std::move(other._command_buffer_count);
    _command_buffers = std::move(other._command_buffers);
    _signal_semaphore_count = std::move(other._signal_semaphore_count);
    _signal_semaphores = std::move(other._signal_semaphores);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSubmitInfo&() const
  {
    return *reinterpret_cast<const VkSubmitInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& wait_semaphore_count()
  {
    return _wait_semaphore_count;
  }

  constexpr const uint32_t& wait_semaphore_count() const
  {
    return _wait_semaphore_count;
  }

  void wait_semaphore_count(uint32_t new_wait_semaphore_count)
  {
    _wait_semaphore_count = new_wait_semaphore_count;
  }

  const VkSemaphore* wait_semaphores()
  {
    return _wait_semaphores;
  }

  constexpr const VkSemaphore* wait_semaphores() const
  {
    return _wait_semaphores;
  }

  void wait_semaphores(const VkSemaphore* new_wait_semaphores)
  {
    _wait_semaphores = new_wait_semaphores;
  }

  template <std::size_t Count>
  void wait_semaphores(
    const std::array<VkSemaphore, Count>& new_wait_semaphores)
  {
    _wait_semaphore_count = static_cast<uint32_t>(new_wait_semaphores.size());
    _wait_semaphores = new_wait_semaphores.data();
  }

  void wait_semaphores(const std::vector<VkSemaphore>& new_wait_semaphores)
  {
    _wait_semaphore_count = static_cast<uint32_t>(new_wait_semaphores.size());
    _wait_semaphores = new_wait_semaphores.data();
  }

  const vk::pipeline_stage_flags* wait_dst_stage_mask()
  {
    return _wait_dst_stage_mask;
  }

  constexpr const vk::pipeline_stage_flags* wait_dst_stage_mask() const
  {
    return _wait_dst_stage_mask;
  }

  void wait_dst_stage_mask(
    const vk::pipeline_stage_flags* new_wait_dst_stage_mask)
  {
    _wait_dst_stage_mask = new_wait_dst_stage_mask;
  }

  template <std::size_t Count>
  void wait_dst_stage_mask(
    const std::array<vk::pipeline_stage_flags, Count>& new_wait_dst_stage_mask)
  {
    _wait_semaphore_count =
      static_cast<uint32_t>(new_wait_dst_stage_mask.size());
    _wait_dst_stage_mask = new_wait_dst_stage_mask.data();
  }

  void wait_dst_stage_mask(
    const std::vector<vk::pipeline_stage_flags>& new_wait_dst_stage_mask)
  {
    _wait_semaphore_count =
      static_cast<uint32_t>(new_wait_dst_stage_mask.size());
    _wait_dst_stage_mask = new_wait_dst_stage_mask.data();
  }

  uint32_t& command_buffer_count()
  {
    return _command_buffer_count;
  }

  constexpr const uint32_t& command_buffer_count() const
  {
    return _command_buffer_count;
  }

  void command_buffer_count(uint32_t new_command_buffer_count)
  {
    _command_buffer_count = new_command_buffer_count;
  }

  const VkCommandBuffer* command_buffers()
  {
    return _command_buffers;
  }

  constexpr const VkCommandBuffer* command_buffers() const
  {
    return _command_buffers;
  }

  void command_buffers(const VkCommandBuffer* new_command_buffers)
  {
    _command_buffers = new_command_buffers;
  }

  template <std::size_t Count>
  void command_buffers(
    const std::array<VkCommandBuffer, Count>& new_command_buffers)
  {
    _command_buffer_count = static_cast<uint32_t>(new_command_buffers.size());
    _command_buffers = new_command_buffers.data();
  }

  void command_buffers(const std::vector<VkCommandBuffer>& new_command_buffers)
  {
    _command_buffer_count = static_cast<uint32_t>(new_command_buffers.size());
    _command_buffers = new_command_buffers.data();
  }

  uint32_t& signal_semaphore_count()
  {
    return _signal_semaphore_count;
  }

  constexpr const uint32_t& signal_semaphore_count() const
  {
    return _signal_semaphore_count;
  }

  void signal_semaphore_count(uint32_t new_signal_semaphore_count)
  {
    _signal_semaphore_count = new_signal_semaphore_count;
  }

  const VkSemaphore* signal_semaphores()
  {
    return _signal_semaphores;
  }

  constexpr const VkSemaphore* signal_semaphores() const
  {
    return _signal_semaphores;
  }

  void signal_semaphores(const VkSemaphore* new_signal_semaphores)
  {
    _signal_semaphores = new_signal_semaphores;
  }

  template <std::size_t Count>
  void signal_semaphores(
    const std::array<VkSemaphore, Count>& new_signal_semaphores)
  {
    _signal_semaphore_count =
      static_cast<uint32_t>(new_signal_semaphores.size());
    _signal_semaphores = new_signal_semaphores.data();
  }

  void signal_semaphores(const std::vector<VkSemaphore>& new_signal_semaphores)
  {
    _signal_semaphore_count =
      static_cast<uint32_t>(new_signal_semaphores.size());
    _signal_semaphores = new_signal_semaphores.data();
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::submit_info;
  const void* _next = nullptr;
  uint32_t _wait_semaphore_count = 0;
  const VkSemaphore* _wait_semaphores = nullptr;
  const vk::pipeline_stage_flags* _wait_dst_stage_mask = nullptr;
  uint32_t _command_buffer_count = 0;
  const VkCommandBuffer* _command_buffers = nullptr;
  uint32_t _signal_semaphore_count = 0;
  const VkSemaphore* _signal_semaphores = nullptr;
};
static_assert(sizeof(submit_info) == sizeof(::VkSubmitInfo),
              "struct and wrapper have different size!");

inline vk::result queue_submit(VkQueue queue, uint32_t submit_count,
                               const vk::submit_info* submits, VkFence fence)
{
  return static_cast<vk::result>(vkQueueSubmit(
    static_cast<VkQueue>(queue), static_cast<uint32_t>(submit_count),
    reinterpret_cast<const VkSubmitInfo*>(submits),
    static_cast<VkFence>(fence)));
}
inline vk::result queue_wait_idle(VkQueue queue)
{
  return static_cast<vk::result>(vkQueueWaitIdle(static_cast<VkQueue>(queue)));
}
inline vk::result device_wait_idle(VkDevice device)
{
  return static_cast<vk::result>(
    vkDeviceWaitIdle(static_cast<VkDevice>(device)));
}

/// Enhanced replacement type for VkMemoryAllocateInfo.
class memory_allocate_info
{
public:
  /// Default constructor.
  constexpr memory_allocate_info() = default;

  /// Constructor.
  constexpr memory_allocate_info(const void* initial_next,
                                 VkDeviceSize initial_allocation_size,
                                 uint32_t initial_memory_type_index) noexcept
  : _next(std::move(initial_next)),
    _allocation_size(std::move(initial_allocation_size)),
    _memory_type_index(std::move(initial_memory_type_index))
  {
  }

  /// Copy constructor.
  constexpr memory_allocate_info(const memory_allocate_info& other) noexcept
  : _next(other._next),
    _allocation_size(other._allocation_size),
    _memory_type_index(other._memory_type_index)
  {
  }

  /// Move constructor.
  constexpr memory_allocate_info(memory_allocate_info&& other) noexcept
  : _next(std::move(other._next)),
    _allocation_size(std::move(other._allocation_size)),
    _memory_type_index(std::move(other._memory_type_index))
  {
  }

  /// Copy assignment operator.
  constexpr memory_allocate_info& operator=(
    const memory_allocate_info& other) noexcept
  {
    _next = other._next;
    _allocation_size = other._allocation_size;
    _memory_type_index = other._memory_type_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_allocate_info& operator=(
    memory_allocate_info&& other) noexcept
  {
    _next = std::move(other._next);
    _allocation_size = std::move(other._allocation_size);
    _memory_type_index = std::move(other._memory_type_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryAllocateInfo&() const
  {
    return *reinterpret_cast<const VkMemoryAllocateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkDeviceSize& allocation_size()
  {
    return _allocation_size;
  }

  constexpr const VkDeviceSize& allocation_size() const
  {
    return _allocation_size;
  }

  void allocation_size(VkDeviceSize new_allocation_size)
  {
    _allocation_size = new_allocation_size;
  }

  uint32_t& memory_type_index()
  {
    return _memory_type_index;
  }

  constexpr const uint32_t& memory_type_index() const
  {
    return _memory_type_index;
  }

  void memory_type_index(uint32_t new_memory_type_index)
  {
    _memory_type_index = new_memory_type_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_allocate_info;
  const void* _next = nullptr;
  /// Size of memory allocation
  VkDeviceSize _allocation_size = 0;
  /// Index of the of the memory type to allocate from
  uint32_t _memory_type_index = 0;
};
static_assert(sizeof(memory_allocate_info) == sizeof(::VkMemoryAllocateInfo),
              "struct and wrapper have different size!");

inline vk::result allocate_memory(VkDevice device,
                                  const vk::memory_allocate_info* allocate_info,
                                  const vk::allocation_callbacks* allocator,
                                  VkDeviceMemory* memory)
{
  return static_cast<vk::result>(vkAllocateMemory(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkMemoryAllocateInfo*>(allocate_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkDeviceMemory*>(memory)));
}
inline void free_memory(VkDevice device, VkDeviceMemory memory,
                        const vk::allocation_callbacks* allocator)
{
  vkFreeMemory(static_cast<VkDevice>(device),
               static_cast<VkDeviceMemory>(memory),
               reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
using memory_map_flags = VkFlags;
inline vk::result map_memory(VkDevice device, VkDeviceMemory memory,
                             VkDeviceSize offset, VkDeviceSize size,
                             vk::memory_map_flags flags, void** data)
{
  return static_cast<vk::result>(vkMapMemory(
    static_cast<VkDevice>(device), static_cast<VkDeviceMemory>(memory),
    static_cast<VkDeviceSize>(offset), static_cast<VkDeviceSize>(size),
    static_cast<VkMemoryMapFlags>(flags), reinterpret_cast<void**>(data)));
}
inline void unmap_memory(VkDevice device, VkDeviceMemory memory)
{
  vkUnmapMemory(static_cast<VkDevice>(device),
                static_cast<VkDeviceMemory>(memory));
}

/// Enhanced replacement type for VkMappedMemoryRange.
class mapped_memory_range
{
public:
  /// Default constructor.
  constexpr mapped_memory_range() = default;

  /// Constructor.
  constexpr mapped_memory_range(const void* initial_next,
                                VkDeviceMemory initial_memory,
                                VkDeviceSize initial_offset,
                                VkDeviceSize initial_size) noexcept
  : _next(std::move(initial_next)),
    _memory(std::move(initial_memory)),
    _offset(std::move(initial_offset)),
    _size(std::move(initial_size))
  {
  }

  /// Copy constructor.
  constexpr mapped_memory_range(const mapped_memory_range& other) noexcept
  : _next(other._next),
    _memory(other._memory),
    _offset(other._offset),
    _size(other._size)
  {
  }

  /// Move constructor.
  constexpr mapped_memory_range(mapped_memory_range&& other) noexcept
  : _next(std::move(other._next)),
    _memory(std::move(other._memory)),
    _offset(std::move(other._offset)),
    _size(std::move(other._size))
  {
  }

  /// Copy assignment operator.
  constexpr mapped_memory_range& operator=(
    const mapped_memory_range& other) noexcept
  {
    _next = other._next;
    _memory = other._memory;
    _offset = other._offset;
    _size = other._size;
    return *this;
  }

  /// Move assignment operator.
  constexpr mapped_memory_range& operator=(mapped_memory_range&& other) noexcept
  {
    _next = std::move(other._next);
    _memory = std::move(other._memory);
    _offset = std::move(other._offset);
    _size = std::move(other._size);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMappedMemoryRange&() const
  {
    return *reinterpret_cast<const VkMappedMemoryRange*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkDeviceMemory& memory()
  {
    return _memory;
  }

  constexpr const VkDeviceMemory& memory() const
  {
    return _memory;
  }

  void memory(VkDeviceMemory new_memory)
  {
    _memory = new_memory;
  }

  VkDeviceSize& offset()
  {
    return _offset;
  }

  constexpr const VkDeviceSize& offset() const
  {
    return _offset;
  }

  void offset(VkDeviceSize new_offset)
  {
    _offset = new_offset;
  }

  VkDeviceSize& size()
  {
    return _size;
  }

  constexpr const VkDeviceSize& size() const
  {
    return _size;
  }

  void size(VkDeviceSize new_size)
  {
    _size = new_size;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::mapped_memory_range;
  const void* _next = nullptr;
  /// Mapped memory object
  VkDeviceMemory _memory = nullptr;
  /// Offset within the memory object where the range starts
  VkDeviceSize _offset = 0;
  /// Size of the range within the memory object
  VkDeviceSize _size = 0;
};
static_assert(sizeof(mapped_memory_range) == sizeof(::VkMappedMemoryRange),
              "struct and wrapper have different size!");

inline vk::result flush_mapped_memory_ranges(
  VkDevice device, uint32_t memory_range_count,
  const vk::mapped_memory_range* memory_ranges)
{
  return static_cast<vk::result>(vkFlushMappedMemoryRanges(
    static_cast<VkDevice>(device), static_cast<uint32_t>(memory_range_count),
    reinterpret_cast<const VkMappedMemoryRange*>(memory_ranges)));
}
inline vk::result invalidate_mapped_memory_ranges(
  VkDevice device, uint32_t memory_range_count,
  const vk::mapped_memory_range* memory_ranges)
{
  return static_cast<vk::result>(vkInvalidateMappedMemoryRanges(
    static_cast<VkDevice>(device), static_cast<uint32_t>(memory_range_count),
    reinterpret_cast<const VkMappedMemoryRange*>(memory_ranges)));
}
inline void get_device_memory_commitment(
  VkDevice device, VkDeviceMemory memory,
  VkDeviceSize* committed_memory_in_bytes)
{
  vkGetDeviceMemoryCommitment(
    static_cast<VkDevice>(device), static_cast<VkDeviceMemory>(memory),
    reinterpret_cast<VkDeviceSize*>(committed_memory_in_bytes));
}
inline vk::result bind_buffer_memory(VkDevice device, VkBuffer buffer,
                                     VkDeviceMemory memory,
                                     VkDeviceSize memory_offset)
{
  return static_cast<vk::result>(vkBindBufferMemory(
    static_cast<VkDevice>(device), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceMemory>(memory),
    static_cast<VkDeviceSize>(memory_offset)));
}
inline vk::result bind_image_memory(VkDevice device, VkImage image,
                                    VkDeviceMemory memory,
                                    VkDeviceSize memory_offset)
{
  return static_cast<vk::result>(vkBindImageMemory(
    static_cast<VkDevice>(device), static_cast<VkImage>(image),
    static_cast<VkDeviceMemory>(memory),
    static_cast<VkDeviceSize>(memory_offset)));
}

/// Enhanced replacement type for VkMemoryRequirements.
class memory_requirements
{
public:
  /// Default constructor.
  constexpr memory_requirements() = default;

  /// Constructor.
  constexpr memory_requirements(VkDeviceSize initial_size,
                                VkDeviceSize initial_alignment,
                                uint32_t initial_memory_type_bits) noexcept
  : _size(std::move(initial_size)),
    _alignment(std::move(initial_alignment)),
    _memory_type_bits(std::move(initial_memory_type_bits))
  {
  }

  /// Copy constructor.
  constexpr memory_requirements(const memory_requirements& other) = default;

  /// Move constructor.
  constexpr memory_requirements(memory_requirements&& other) = default;

  /// Copy assignment operator.
  constexpr memory_requirements& operator=(const memory_requirements& other) =
    default;

  /// Move assignment operator.
  constexpr memory_requirements& operator=(memory_requirements&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryRequirements&() const
  {
    return *reinterpret_cast<const VkMemoryRequirements*>(this);
  }

  VkDeviceSize& size()
  {
    return _size;
  }

  constexpr const VkDeviceSize& size() const
  {
    return _size;
  }

  void size(VkDeviceSize new_size)
  {
    _size = new_size;
  }

  VkDeviceSize& alignment()
  {
    return _alignment;
  }

  constexpr const VkDeviceSize& alignment() const
  {
    return _alignment;
  }

  void alignment(VkDeviceSize new_alignment)
  {
    _alignment = new_alignment;
  }

  uint32_t& memory_type_bits()
  {
    return _memory_type_bits;
  }

  constexpr const uint32_t& memory_type_bits() const
  {
    return _memory_type_bits;
  }

  void memory_type_bits(uint32_t new_memory_type_bits)
  {
    _memory_type_bits = new_memory_type_bits;
  }

private:
  /// Specified in bytes
  VkDeviceSize _size = 0;
  /// Specified in bytes
  VkDeviceSize _alignment = 0;
  /// Bitmask of the allowed memory type indices into memoryTypes[] for this
  /// object
  uint32_t _memory_type_bits = 0;
};
static_assert(sizeof(memory_requirements) == sizeof(::VkMemoryRequirements),
              "struct and wrapper have different size!");

inline void get_buffer_memory_requirements(
  VkDevice device, VkBuffer buffer,
  vk::memory_requirements* memory_requirements)
{
  vkGetBufferMemoryRequirements(
    static_cast<VkDevice>(device), static_cast<VkBuffer>(buffer),
    reinterpret_cast<VkMemoryRequirements*>(memory_requirements));
}
inline void get_image_memory_requirements(
  VkDevice device, VkImage image, vk::memory_requirements* memory_requirements)
{
  vkGetImageMemoryRequirements(
    static_cast<VkDevice>(device), static_cast<VkImage>(image),
    reinterpret_cast<VkMemoryRequirements*>(memory_requirements));
}
enum class sparse_image_format_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Image uses a single mip tail region for all array layers
  /// @see VK_SPARSE_IMAGE_FORMAT_SINGLE_MIPTAIL_BIT
  single_miptail_bit = 1 << 0,
  /// Image requires mip level dimensions to be an integer multiple of the
  /// sparse image block dimensions for non-tail mip levels.
  /// @see VK_SPARSE_IMAGE_FORMAT_ALIGNED_MIP_SIZE_BIT
  aligned_mip_size_bit = 1 << 1,
  /// Image uses a non-standard sparse image block dimensions
  /// @see VK_SPARSE_IMAGE_FORMAT_NONSTANDARD_BLOCK_SIZE_BIT
  nonstandard_block_size_bit = 1 << 2,
};
using sparse_image_format_flags =
  shift::core::bit_field<sparse_image_format_flag, VkSparseImageFormatFlags>;
inline constexpr sparse_image_format_flags operator|(
  sparse_image_format_flag lhs, sparse_image_format_flag rhs)
{
  return sparse_image_format_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkSparseImageFormatProperties.
class sparse_image_format_properties
{
public:
  /// Default constructor.
  constexpr sparse_image_format_properties() = default;

  /// Constructor.
  constexpr sparse_image_format_properties(
    vk::image_aspect_flags initial_aspect_mask,
    vk::extent_3d initial_image_granularity,
    vk::sparse_image_format_flags initial_flags) noexcept
  : _aspect_mask(std::move(initial_aspect_mask)),
    _image_granularity(std::move(initial_image_granularity)),
    _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr sparse_image_format_properties(
    const sparse_image_format_properties& other) = default;

  /// Move constructor.
  constexpr sparse_image_format_properties(
    sparse_image_format_properties&& other) = default;

  /// Copy assignment operator.
  constexpr sparse_image_format_properties& operator=(
    const sparse_image_format_properties& other) = default;

  /// Move assignment operator.
  constexpr sparse_image_format_properties& operator=(
    sparse_image_format_properties&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSparseImageFormatProperties&() const
  {
    return *reinterpret_cast<const VkSparseImageFormatProperties*>(this);
  }

  vk::image_aspect_flags& aspect_mask()
  {
    return _aspect_mask;
  }

  constexpr const vk::image_aspect_flags& aspect_mask() const
  {
    return _aspect_mask;
  }

  void aspect_mask(vk::image_aspect_flags new_aspect_mask)
  {
    _aspect_mask = new_aspect_mask;
  }

  vk::extent_3d& image_granularity()
  {
    return _image_granularity;
  }

  constexpr const vk::extent_3d& image_granularity() const
  {
    return _image_granularity;
  }

  void image_granularity(vk::extent_3d new_image_granularity)
  {
    _image_granularity = new_image_granularity;
  }

  vk::sparse_image_format_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::sparse_image_format_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::sparse_image_format_flags new_flags)
  {
    _flags = new_flags;
  }

private:
  vk::image_aspect_flags _aspect_mask = vk::image_aspect_flag::none;
  vk::extent_3d _image_granularity = vk::extent_3d{};
  vk::sparse_image_format_flags _flags = vk::sparse_image_format_flag::none;
};
static_assert(sizeof(sparse_image_format_properties) ==
                sizeof(::VkSparseImageFormatProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSparseImageMemoryRequirements.
class sparse_image_memory_requirements
{
public:
  /// Default constructor.
  constexpr sparse_image_memory_requirements() = default;

  /// Constructor.
  constexpr sparse_image_memory_requirements(
    vk::sparse_image_format_properties initial_format_properties,
    uint32_t initial_image_mip_tail_first_lod,
    VkDeviceSize initial_image_mip_tail_size,
    VkDeviceSize initial_image_mip_tail_offset,
    VkDeviceSize initial_image_mip_tail_stride) noexcept
  : _format_properties(std::move(initial_format_properties)),
    _image_mip_tail_first_lod(std::move(initial_image_mip_tail_first_lod)),
    _image_mip_tail_size(std::move(initial_image_mip_tail_size)),
    _image_mip_tail_offset(std::move(initial_image_mip_tail_offset)),
    _image_mip_tail_stride(std::move(initial_image_mip_tail_stride))
  {
  }

  /// Copy constructor.
  constexpr sparse_image_memory_requirements(
    const sparse_image_memory_requirements& other) = default;

  /// Move constructor.
  constexpr sparse_image_memory_requirements(
    sparse_image_memory_requirements&& other) = default;

  /// Copy assignment operator.
  constexpr sparse_image_memory_requirements& operator=(
    const sparse_image_memory_requirements& other) = default;

  /// Move assignment operator.
  constexpr sparse_image_memory_requirements& operator=(
    sparse_image_memory_requirements&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSparseImageMemoryRequirements&() const
  {
    return *reinterpret_cast<const VkSparseImageMemoryRequirements*>(this);
  }

  vk::sparse_image_format_properties& format_properties()
  {
    return _format_properties;
  }

  constexpr const vk::sparse_image_format_properties& format_properties() const
  {
    return _format_properties;
  }

  void format_properties(
    vk::sparse_image_format_properties new_format_properties)
  {
    _format_properties = new_format_properties;
  }

  uint32_t& image_mip_tail_first_lod()
  {
    return _image_mip_tail_first_lod;
  }

  constexpr const uint32_t& image_mip_tail_first_lod() const
  {
    return _image_mip_tail_first_lod;
  }

  void image_mip_tail_first_lod(uint32_t new_image_mip_tail_first_lod)
  {
    _image_mip_tail_first_lod = new_image_mip_tail_first_lod;
  }

  VkDeviceSize& image_mip_tail_size()
  {
    return _image_mip_tail_size;
  }

  constexpr const VkDeviceSize& image_mip_tail_size() const
  {
    return _image_mip_tail_size;
  }

  void image_mip_tail_size(VkDeviceSize new_image_mip_tail_size)
  {
    _image_mip_tail_size = new_image_mip_tail_size;
  }

  VkDeviceSize& image_mip_tail_offset()
  {
    return _image_mip_tail_offset;
  }

  constexpr const VkDeviceSize& image_mip_tail_offset() const
  {
    return _image_mip_tail_offset;
  }

  void image_mip_tail_offset(VkDeviceSize new_image_mip_tail_offset)
  {
    _image_mip_tail_offset = new_image_mip_tail_offset;
  }

  VkDeviceSize& image_mip_tail_stride()
  {
    return _image_mip_tail_stride;
  }

  constexpr const VkDeviceSize& image_mip_tail_stride() const
  {
    return _image_mip_tail_stride;
  }

  void image_mip_tail_stride(VkDeviceSize new_image_mip_tail_stride)
  {
    _image_mip_tail_stride = new_image_mip_tail_stride;
  }

private:
  vk::sparse_image_format_properties _format_properties =
    vk::sparse_image_format_properties{};
  uint32_t _image_mip_tail_first_lod = 0;
  /// Specified in bytes, must be a multiple of sparse block size in bytes /
  /// alignment
  VkDeviceSize _image_mip_tail_size = 0;
  /// Specified in bytes, must be a multiple of sparse block size in bytes /
  /// alignment
  VkDeviceSize _image_mip_tail_offset = 0;
  /// Specified in bytes, must be a multiple of sparse block size in bytes /
  /// alignment
  VkDeviceSize _image_mip_tail_stride = 0;
};
static_assert(sizeof(sparse_image_memory_requirements) ==
                sizeof(::VkSparseImageMemoryRequirements),
              "struct and wrapper have different size!");

inline void get_image_sparse_memory_requirements(
  VkDevice device, VkImage image, uint32_t* sparse_memory_requirement_count,
  vk::sparse_image_memory_requirements* sparse_memory_requirements)
{
  vkGetImageSparseMemoryRequirements(
    static_cast<VkDevice>(device), static_cast<VkImage>(image),
    reinterpret_cast<uint32_t*>(sparse_memory_requirement_count),
    reinterpret_cast<VkSparseImageMemoryRequirements*>(
      sparse_memory_requirements));
}
inline void get_physical_device_sparse_image_format_properties(
  VkPhysicalDevice physical_device, vk::format format, vk::image_type type,
  vk::sample_count_flag samples, vk::image_usage_flags usage,
  vk::image_tiling tiling, uint32_t* property_count,
  vk::sparse_image_format_properties* properties)
{
  vkGetPhysicalDeviceSparseImageFormatProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkFormat>(format), static_cast<VkImageType>(type),
    static_cast<VkSampleCountFlagBits>(samples),
    static_cast<VkImageUsageFlags>(usage), static_cast<VkImageTiling>(tiling),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkSparseImageFormatProperties*>(properties));
}
enum class sparse_memory_bind_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Operation binds resource metadata to memory
  /// @see VK_SPARSE_MEMORY_BIND_METADATA_BIT
  metadata_bit = 1 << 0,
};
using sparse_memory_bind_flags =
  shift::core::bit_field<sparse_memory_bind_flag, VkSparseMemoryBindFlags>;
inline constexpr sparse_memory_bind_flags operator|(sparse_memory_bind_flag lhs,
                                                    sparse_memory_bind_flag rhs)
{
  return sparse_memory_bind_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkSparseMemoryBind.
class sparse_memory_bind
{
public:
  /// Default constructor.
  constexpr sparse_memory_bind() = default;

  /// Constructor.
  constexpr sparse_memory_bind(
    VkDeviceSize initial_resource_offset, VkDeviceSize initial_size,
    VkDeviceMemory initial_memory, VkDeviceSize initial_memory_offset,
    vk::sparse_memory_bind_flags initial_flags) noexcept
  : _resource_offset(std::move(initial_resource_offset)),
    _size(std::move(initial_size)),
    _memory(std::move(initial_memory)),
    _memory_offset(std::move(initial_memory_offset)),
    _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr sparse_memory_bind(const sparse_memory_bind& other) = default;

  /// Move constructor.
  constexpr sparse_memory_bind(sparse_memory_bind&& other) = default;

  /// Copy assignment operator.
  constexpr sparse_memory_bind& operator=(const sparse_memory_bind& other) =
    default;

  /// Move assignment operator.
  constexpr sparse_memory_bind& operator=(sparse_memory_bind&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSparseMemoryBind&() const
  {
    return *reinterpret_cast<const VkSparseMemoryBind*>(this);
  }

  VkDeviceSize& resource_offset()
  {
    return _resource_offset;
  }

  constexpr const VkDeviceSize& resource_offset() const
  {
    return _resource_offset;
  }

  void resource_offset(VkDeviceSize new_resource_offset)
  {
    _resource_offset = new_resource_offset;
  }

  VkDeviceSize& size()
  {
    return _size;
  }

  constexpr const VkDeviceSize& size() const
  {
    return _size;
  }

  void size(VkDeviceSize new_size)
  {
    _size = new_size;
  }

  VkDeviceMemory& memory()
  {
    return _memory;
  }

  constexpr const VkDeviceMemory& memory() const
  {
    return _memory;
  }

  void memory(VkDeviceMemory new_memory)
  {
    _memory = new_memory;
  }

  VkDeviceSize& memory_offset()
  {
    return _memory_offset;
  }

  constexpr const VkDeviceSize& memory_offset() const
  {
    return _memory_offset;
  }

  void memory_offset(VkDeviceSize new_memory_offset)
  {
    _memory_offset = new_memory_offset;
  }

  vk::sparse_memory_bind_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::sparse_memory_bind_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::sparse_memory_bind_flags new_flags)
  {
    _flags = new_flags;
  }

private:
  /// Specified in bytes
  VkDeviceSize _resource_offset = 0;
  /// Specified in bytes
  VkDeviceSize _size = 0;
  VkDeviceMemory _memory = nullptr;
  /// Specified in bytes
  VkDeviceSize _memory_offset = 0;
  vk::sparse_memory_bind_flags _flags = vk::sparse_memory_bind_flag::none;
};
static_assert(sizeof(sparse_memory_bind) == sizeof(::VkSparseMemoryBind),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSparseBufferMemoryBindInfo.
class sparse_buffer_memory_bind_info
{
public:
  /// Default constructor.
  constexpr sparse_buffer_memory_bind_info() = default;

  /// Constructor.
  constexpr sparse_buffer_memory_bind_info(
    VkBuffer initial_buffer, uint32_t initial_bind_count,
    const vk::sparse_memory_bind* initial_binds) noexcept
  : _buffer(std::move(initial_buffer)),
    _bind_count(std::move(initial_bind_count)),
    _binds(std::move(initial_binds))
  {
  }

  /// Copy constructor.
  constexpr sparse_buffer_memory_bind_info(
    const sparse_buffer_memory_bind_info& other) = default;

  /// Move constructor.
  constexpr sparse_buffer_memory_bind_info(
    sparse_buffer_memory_bind_info&& other) = default;

  /// Copy assignment operator.
  constexpr sparse_buffer_memory_bind_info& operator=(
    const sparse_buffer_memory_bind_info& other) = default;

  /// Move assignment operator.
  constexpr sparse_buffer_memory_bind_info& operator=(
    sparse_buffer_memory_bind_info&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSparseBufferMemoryBindInfo&() const
  {
    return *reinterpret_cast<const VkSparseBufferMemoryBindInfo*>(this);
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

  uint32_t& bind_count()
  {
    return _bind_count;
  }

  constexpr const uint32_t& bind_count() const
  {
    return _bind_count;
  }

  void bind_count(uint32_t new_bind_count)
  {
    _bind_count = new_bind_count;
  }

  const vk::sparse_memory_bind* binds()
  {
    return _binds;
  }

  constexpr const vk::sparse_memory_bind* binds() const
  {
    return _binds;
  }

  void binds(const vk::sparse_memory_bind* new_binds)
  {
    _binds = new_binds;
  }

  template <std::size_t Count>
  void binds(const std::array<vk::sparse_memory_bind, Count>& new_binds)
  {
    _bind_count = static_cast<uint32_t>(new_binds.size());
    _binds = new_binds.data();
  }

  void binds(const std::vector<vk::sparse_memory_bind>& new_binds)
  {
    _bind_count = static_cast<uint32_t>(new_binds.size());
    _binds = new_binds.data();
  }

private:
  VkBuffer _buffer = nullptr;
  uint32_t _bind_count = 0;
  const vk::sparse_memory_bind* _binds = nullptr;
};
static_assert(sizeof(sparse_buffer_memory_bind_info) ==
                sizeof(::VkSparseBufferMemoryBindInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSparseImageOpaqueMemoryBindInfo.
class sparse_image_opaque_memory_bind_info
{
public:
  /// Default constructor.
  constexpr sparse_image_opaque_memory_bind_info() = default;

  /// Constructor.
  constexpr sparse_image_opaque_memory_bind_info(
    VkImage initial_image, uint32_t initial_bind_count,
    const vk::sparse_memory_bind* initial_binds) noexcept
  : _image(std::move(initial_image)),
    _bind_count(std::move(initial_bind_count)),
    _binds(std::move(initial_binds))
  {
  }

  /// Copy constructor.
  constexpr sparse_image_opaque_memory_bind_info(
    const sparse_image_opaque_memory_bind_info& other) = default;

  /// Move constructor.
  constexpr sparse_image_opaque_memory_bind_info(
    sparse_image_opaque_memory_bind_info&& other) = default;

  /// Copy assignment operator.
  constexpr sparse_image_opaque_memory_bind_info& operator=(
    const sparse_image_opaque_memory_bind_info& other) = default;

  /// Move assignment operator.
  constexpr sparse_image_opaque_memory_bind_info& operator=(
    sparse_image_opaque_memory_bind_info&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSparseImageOpaqueMemoryBindInfo&() const
  {
    return *reinterpret_cast<const VkSparseImageOpaqueMemoryBindInfo*>(this);
  }

  VkImage& image()
  {
    return _image;
  }

  constexpr const VkImage& image() const
  {
    return _image;
  }

  void image(VkImage new_image)
  {
    _image = new_image;
  }

  uint32_t& bind_count()
  {
    return _bind_count;
  }

  constexpr const uint32_t& bind_count() const
  {
    return _bind_count;
  }

  void bind_count(uint32_t new_bind_count)
  {
    _bind_count = new_bind_count;
  }

  const vk::sparse_memory_bind* binds()
  {
    return _binds;
  }

  constexpr const vk::sparse_memory_bind* binds() const
  {
    return _binds;
  }

  void binds(const vk::sparse_memory_bind* new_binds)
  {
    _binds = new_binds;
  }

  template <std::size_t Count>
  void binds(const std::array<vk::sparse_memory_bind, Count>& new_binds)
  {
    _bind_count = static_cast<uint32_t>(new_binds.size());
    _binds = new_binds.data();
  }

  void binds(const std::vector<vk::sparse_memory_bind>& new_binds)
  {
    _bind_count = static_cast<uint32_t>(new_binds.size());
    _binds = new_binds.data();
  }

private:
  VkImage _image = nullptr;
  uint32_t _bind_count = 0;
  const vk::sparse_memory_bind* _binds = nullptr;
};
static_assert(sizeof(sparse_image_opaque_memory_bind_info) ==
                sizeof(::VkSparseImageOpaqueMemoryBindInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImageSubresource.
class image_subresource
{
public:
  /// Default constructor.
  constexpr image_subresource() = default;

  /// Constructor.
  constexpr image_subresource(vk::image_aspect_flags initial_aspect_mask,
                              uint32_t initial_mip_level,
                              uint32_t initial_array_layer) noexcept
  : _aspect_mask(std::move(initial_aspect_mask)),
    _mip_level(std::move(initial_mip_level)),
    _array_layer(std::move(initial_array_layer))
  {
  }

  /// Copy constructor.
  constexpr image_subresource(const image_subresource& other) = default;

  /// Move constructor.
  constexpr image_subresource(image_subresource&& other) = default;

  /// Copy assignment operator.
  constexpr image_subresource& operator=(const image_subresource& other) =
    default;

  /// Move assignment operator.
  constexpr image_subresource& operator=(image_subresource&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkImageSubresource&() const
  {
    return *reinterpret_cast<const VkImageSubresource*>(this);
  }

  vk::image_aspect_flags& aspect_mask()
  {
    return _aspect_mask;
  }

  constexpr const vk::image_aspect_flags& aspect_mask() const
  {
    return _aspect_mask;
  }

  void aspect_mask(vk::image_aspect_flags new_aspect_mask)
  {
    _aspect_mask = new_aspect_mask;
  }

  uint32_t& mip_level()
  {
    return _mip_level;
  }

  constexpr const uint32_t& mip_level() const
  {
    return _mip_level;
  }

  void mip_level(uint32_t new_mip_level)
  {
    _mip_level = new_mip_level;
  }

  uint32_t& array_layer()
  {
    return _array_layer;
  }

  constexpr const uint32_t& array_layer() const
  {
    return _array_layer;
  }

  void array_layer(uint32_t new_array_layer)
  {
    _array_layer = new_array_layer;
  }

private:
  vk::image_aspect_flags _aspect_mask = vk::image_aspect_flag::none;
  uint32_t _mip_level = 0;
  uint32_t _array_layer = 0;
};
static_assert(sizeof(image_subresource) == sizeof(::VkImageSubresource),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkOffset3D.
class offset_3d
{
public:
  /// Default constructor.
  constexpr offset_3d() = default;

  /// Constructor.
  constexpr offset_3d(int32_t initial_x, int32_t initial_y,
                      int32_t initial_z) noexcept
  : _x(std::move(initial_x)), _y(std::move(initial_y)), _z(std::move(initial_z))
  {
  }

  /// Copy constructor.
  constexpr offset_3d(const offset_3d& other) = default;

  /// Move constructor.
  constexpr offset_3d(offset_3d&& other) = default;

  /// Copy assignment operator.
  constexpr offset_3d& operator=(const offset_3d& other) = default;

  /// Move assignment operator.
  constexpr offset_3d& operator=(offset_3d&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkOffset3D&() const
  {
    return *reinterpret_cast<const VkOffset3D*>(this);
  }

  int32_t& x()
  {
    return _x;
  }

  constexpr const int32_t& x() const
  {
    return _x;
  }

  void x(int32_t new_x)
  {
    _x = new_x;
  }

  int32_t& y()
  {
    return _y;
  }

  constexpr const int32_t& y() const
  {
    return _y;
  }

  void y(int32_t new_y)
  {
    _y = new_y;
  }

  int32_t& z()
  {
    return _z;
  }

  constexpr const int32_t& z() const
  {
    return _z;
  }

  void z(int32_t new_z)
  {
    _z = new_z;
  }

private:
  int32_t _x = 0;
  int32_t _y = 0;
  int32_t _z = 0;
};
static_assert(sizeof(offset_3d) == sizeof(::VkOffset3D),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSparseImageMemoryBind.
class sparse_image_memory_bind
{
public:
  /// Default constructor.
  constexpr sparse_image_memory_bind() = default;

  /// Constructor.
  constexpr sparse_image_memory_bind(
    vk::image_subresource initial_subresource, vk::offset_3d initial_offset,
    vk::extent_3d initial_extent, VkDeviceMemory initial_memory,
    VkDeviceSize initial_memory_offset,
    vk::sparse_memory_bind_flags initial_flags) noexcept
  : _subresource(std::move(initial_subresource)),
    _offset(std::move(initial_offset)),
    _extent(std::move(initial_extent)),
    _memory(std::move(initial_memory)),
    _memory_offset(std::move(initial_memory_offset)),
    _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr sparse_image_memory_bind(const sparse_image_memory_bind& other) =
    default;

  /// Move constructor.
  constexpr sparse_image_memory_bind(sparse_image_memory_bind&& other) =
    default;

  /// Copy assignment operator.
  constexpr sparse_image_memory_bind& operator=(
    const sparse_image_memory_bind& other) = default;

  /// Move assignment operator.
  constexpr sparse_image_memory_bind& operator=(
    sparse_image_memory_bind&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSparseImageMemoryBind&() const
  {
    return *reinterpret_cast<const VkSparseImageMemoryBind*>(this);
  }

  vk::image_subresource& subresource()
  {
    return _subresource;
  }

  constexpr const vk::image_subresource& subresource() const
  {
    return _subresource;
  }

  void subresource(vk::image_subresource new_subresource)
  {
    _subresource = new_subresource;
  }

  vk::offset_3d& offset()
  {
    return _offset;
  }

  constexpr const vk::offset_3d& offset() const
  {
    return _offset;
  }

  void offset(vk::offset_3d new_offset)
  {
    _offset = new_offset;
  }

  vk::extent_3d& extent()
  {
    return _extent;
  }

  constexpr const vk::extent_3d& extent() const
  {
    return _extent;
  }

  void extent(vk::extent_3d new_extent)
  {
    _extent = new_extent;
  }

  VkDeviceMemory& memory()
  {
    return _memory;
  }

  constexpr const VkDeviceMemory& memory() const
  {
    return _memory;
  }

  void memory(VkDeviceMemory new_memory)
  {
    _memory = new_memory;
  }

  VkDeviceSize& memory_offset()
  {
    return _memory_offset;
  }

  constexpr const VkDeviceSize& memory_offset() const
  {
    return _memory_offset;
  }

  void memory_offset(VkDeviceSize new_memory_offset)
  {
    _memory_offset = new_memory_offset;
  }

  vk::sparse_memory_bind_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::sparse_memory_bind_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::sparse_memory_bind_flags new_flags)
  {
    _flags = new_flags;
  }

private:
  vk::image_subresource _subresource = vk::image_subresource{};
  vk::offset_3d _offset = vk::offset_3d{};
  vk::extent_3d _extent = vk::extent_3d{};
  VkDeviceMemory _memory = nullptr;
  /// Specified in bytes
  VkDeviceSize _memory_offset = 0;
  vk::sparse_memory_bind_flags _flags = vk::sparse_memory_bind_flag::none;
};
static_assert(sizeof(sparse_image_memory_bind) ==
                sizeof(::VkSparseImageMemoryBind),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSparseImageMemoryBindInfo.
class sparse_image_memory_bind_info
{
public:
  /// Default constructor.
  constexpr sparse_image_memory_bind_info() = default;

  /// Constructor.
  constexpr sparse_image_memory_bind_info(
    VkImage initial_image, uint32_t initial_bind_count,
    const vk::sparse_image_memory_bind* initial_binds) noexcept
  : _image(std::move(initial_image)),
    _bind_count(std::move(initial_bind_count)),
    _binds(std::move(initial_binds))
  {
  }

  /// Copy constructor.
  constexpr sparse_image_memory_bind_info(
    const sparse_image_memory_bind_info& other) = default;

  /// Move constructor.
  constexpr sparse_image_memory_bind_info(
    sparse_image_memory_bind_info&& other) = default;

  /// Copy assignment operator.
  constexpr sparse_image_memory_bind_info& operator=(
    const sparse_image_memory_bind_info& other) = default;

  /// Move assignment operator.
  constexpr sparse_image_memory_bind_info& operator=(
    sparse_image_memory_bind_info&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSparseImageMemoryBindInfo&() const
  {
    return *reinterpret_cast<const VkSparseImageMemoryBindInfo*>(this);
  }

  VkImage& image()
  {
    return _image;
  }

  constexpr const VkImage& image() const
  {
    return _image;
  }

  void image(VkImage new_image)
  {
    _image = new_image;
  }

  uint32_t& bind_count()
  {
    return _bind_count;
  }

  constexpr const uint32_t& bind_count() const
  {
    return _bind_count;
  }

  void bind_count(uint32_t new_bind_count)
  {
    _bind_count = new_bind_count;
  }

  const vk::sparse_image_memory_bind* binds()
  {
    return _binds;
  }

  constexpr const vk::sparse_image_memory_bind* binds() const
  {
    return _binds;
  }

  void binds(const vk::sparse_image_memory_bind* new_binds)
  {
    _binds = new_binds;
  }

  template <std::size_t Count>
  void binds(const std::array<vk::sparse_image_memory_bind, Count>& new_binds)
  {
    _bind_count = static_cast<uint32_t>(new_binds.size());
    _binds = new_binds.data();
  }

  void binds(const std::vector<vk::sparse_image_memory_bind>& new_binds)
  {
    _bind_count = static_cast<uint32_t>(new_binds.size());
    _binds = new_binds.data();
  }

private:
  VkImage _image = nullptr;
  uint32_t _bind_count = 0;
  const vk::sparse_image_memory_bind* _binds = nullptr;
};
static_assert(sizeof(sparse_image_memory_bind_info) ==
                sizeof(::VkSparseImageMemoryBindInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkBindSparseInfo.
class bind_sparse_info
{
public:
  /// Default constructor.
  constexpr bind_sparse_info() = default;

  /// Constructor.
  constexpr bind_sparse_info(
    const void* initial_next, uint32_t initial_wait_semaphore_count,
    const VkSemaphore* initial_wait_semaphores,
    uint32_t initial_buffer_bind_count,
    const vk::sparse_buffer_memory_bind_info* initial_buffer_binds,
    uint32_t initial_image_opaque_bind_count,
    const vk::sparse_image_opaque_memory_bind_info* initial_image_opaque_binds,
    uint32_t initial_image_bind_count,
    const vk::sparse_image_memory_bind_info* initial_image_binds,
    uint32_t initial_signal_semaphore_count,
    const VkSemaphore* initial_signal_semaphores) noexcept
  : _next(std::move(initial_next)),
    _wait_semaphore_count(std::move(initial_wait_semaphore_count)),
    _wait_semaphores(std::move(initial_wait_semaphores)),
    _buffer_bind_count(std::move(initial_buffer_bind_count)),
    _buffer_binds(std::move(initial_buffer_binds)),
    _image_opaque_bind_count(std::move(initial_image_opaque_bind_count)),
    _image_opaque_binds(std::move(initial_image_opaque_binds)),
    _image_bind_count(std::move(initial_image_bind_count)),
    _image_binds(std::move(initial_image_binds)),
    _signal_semaphore_count(std::move(initial_signal_semaphore_count)),
    _signal_semaphores(std::move(initial_signal_semaphores))
  {
  }

  /// Copy constructor.
  constexpr bind_sparse_info(const bind_sparse_info& other) noexcept
  : _next(other._next),
    _wait_semaphore_count(other._wait_semaphore_count),
    _wait_semaphores(other._wait_semaphores),
    _buffer_bind_count(other._buffer_bind_count),
    _buffer_binds(other._buffer_binds),
    _image_opaque_bind_count(other._image_opaque_bind_count),
    _image_opaque_binds(other._image_opaque_binds),
    _image_bind_count(other._image_bind_count),
    _image_binds(other._image_binds),
    _signal_semaphore_count(other._signal_semaphore_count),
    _signal_semaphores(other._signal_semaphores)
  {
  }

  /// Move constructor.
  constexpr bind_sparse_info(bind_sparse_info&& other) noexcept
  : _next(std::move(other._next)),
    _wait_semaphore_count(std::move(other._wait_semaphore_count)),
    _wait_semaphores(std::move(other._wait_semaphores)),
    _buffer_bind_count(std::move(other._buffer_bind_count)),
    _buffer_binds(std::move(other._buffer_binds)),
    _image_opaque_bind_count(std::move(other._image_opaque_bind_count)),
    _image_opaque_binds(std::move(other._image_opaque_binds)),
    _image_bind_count(std::move(other._image_bind_count)),
    _image_binds(std::move(other._image_binds)),
    _signal_semaphore_count(std::move(other._signal_semaphore_count)),
    _signal_semaphores(std::move(other._signal_semaphores))
  {
  }

  /// Copy assignment operator.
  constexpr bind_sparse_info& operator=(const bind_sparse_info& other) noexcept
  {
    _next = other._next;
    _wait_semaphore_count = other._wait_semaphore_count;
    _wait_semaphores = other._wait_semaphores;
    _buffer_bind_count = other._buffer_bind_count;
    _buffer_binds = other._buffer_binds;
    _image_opaque_bind_count = other._image_opaque_bind_count;
    _image_opaque_binds = other._image_opaque_binds;
    _image_bind_count = other._image_bind_count;
    _image_binds = other._image_binds;
    _signal_semaphore_count = other._signal_semaphore_count;
    _signal_semaphores = other._signal_semaphores;
    return *this;
  }

  /// Move assignment operator.
  constexpr bind_sparse_info& operator=(bind_sparse_info&& other) noexcept
  {
    _next = std::move(other._next);
    _wait_semaphore_count = std::move(other._wait_semaphore_count);
    _wait_semaphores = std::move(other._wait_semaphores);
    _buffer_bind_count = std::move(other._buffer_bind_count);
    _buffer_binds = std::move(other._buffer_binds);
    _image_opaque_bind_count = std::move(other._image_opaque_bind_count);
    _image_opaque_binds = std::move(other._image_opaque_binds);
    _image_bind_count = std::move(other._image_bind_count);
    _image_binds = std::move(other._image_binds);
    _signal_semaphore_count = std::move(other._signal_semaphore_count);
    _signal_semaphores = std::move(other._signal_semaphores);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBindSparseInfo&() const
  {
    return *reinterpret_cast<const VkBindSparseInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& wait_semaphore_count()
  {
    return _wait_semaphore_count;
  }

  constexpr const uint32_t& wait_semaphore_count() const
  {
    return _wait_semaphore_count;
  }

  void wait_semaphore_count(uint32_t new_wait_semaphore_count)
  {
    _wait_semaphore_count = new_wait_semaphore_count;
  }

  const VkSemaphore* wait_semaphores()
  {
    return _wait_semaphores;
  }

  constexpr const VkSemaphore* wait_semaphores() const
  {
    return _wait_semaphores;
  }

  void wait_semaphores(const VkSemaphore* new_wait_semaphores)
  {
    _wait_semaphores = new_wait_semaphores;
  }

  template <std::size_t Count>
  void wait_semaphores(
    const std::array<VkSemaphore, Count>& new_wait_semaphores)
  {
    _wait_semaphore_count = static_cast<uint32_t>(new_wait_semaphores.size());
    _wait_semaphores = new_wait_semaphores.data();
  }

  void wait_semaphores(const std::vector<VkSemaphore>& new_wait_semaphores)
  {
    _wait_semaphore_count = static_cast<uint32_t>(new_wait_semaphores.size());
    _wait_semaphores = new_wait_semaphores.data();
  }

  uint32_t& buffer_bind_count()
  {
    return _buffer_bind_count;
  }

  constexpr const uint32_t& buffer_bind_count() const
  {
    return _buffer_bind_count;
  }

  void buffer_bind_count(uint32_t new_buffer_bind_count)
  {
    _buffer_bind_count = new_buffer_bind_count;
  }

  const vk::sparse_buffer_memory_bind_info* buffer_binds()
  {
    return _buffer_binds;
  }

  constexpr const vk::sparse_buffer_memory_bind_info* buffer_binds() const
  {
    return _buffer_binds;
  }

  void buffer_binds(const vk::sparse_buffer_memory_bind_info* new_buffer_binds)
  {
    _buffer_binds = new_buffer_binds;
  }

  template <std::size_t Count>
  void buffer_binds(const std::array<vk::sparse_buffer_memory_bind_info, Count>&
                      new_buffer_binds)
  {
    _buffer_bind_count = static_cast<uint32_t>(new_buffer_binds.size());
    _buffer_binds = new_buffer_binds.data();
  }

  void buffer_binds(
    const std::vector<vk::sparse_buffer_memory_bind_info>& new_buffer_binds)
  {
    _buffer_bind_count = static_cast<uint32_t>(new_buffer_binds.size());
    _buffer_binds = new_buffer_binds.data();
  }

  uint32_t& image_opaque_bind_count()
  {
    return _image_opaque_bind_count;
  }

  constexpr const uint32_t& image_opaque_bind_count() const
  {
    return _image_opaque_bind_count;
  }

  void image_opaque_bind_count(uint32_t new_image_opaque_bind_count)
  {
    _image_opaque_bind_count = new_image_opaque_bind_count;
  }

  const vk::sparse_image_opaque_memory_bind_info* image_opaque_binds()
  {
    return _image_opaque_binds;
  }

  constexpr const vk::sparse_image_opaque_memory_bind_info* image_opaque_binds()
    const
  {
    return _image_opaque_binds;
  }

  void image_opaque_binds(
    const vk::sparse_image_opaque_memory_bind_info* new_image_opaque_binds)
  {
    _image_opaque_binds = new_image_opaque_binds;
  }

  template <std::size_t Count>
  void image_opaque_binds(
    const std::array<vk::sparse_image_opaque_memory_bind_info, Count>&
      new_image_opaque_binds)
  {
    _image_opaque_bind_count =
      static_cast<uint32_t>(new_image_opaque_binds.size());
    _image_opaque_binds = new_image_opaque_binds.data();
  }

  void image_opaque_binds(
    const std::vector<vk::sparse_image_opaque_memory_bind_info>&
      new_image_opaque_binds)
  {
    _image_opaque_bind_count =
      static_cast<uint32_t>(new_image_opaque_binds.size());
    _image_opaque_binds = new_image_opaque_binds.data();
  }

  uint32_t& image_bind_count()
  {
    return _image_bind_count;
  }

  constexpr const uint32_t& image_bind_count() const
  {
    return _image_bind_count;
  }

  void image_bind_count(uint32_t new_image_bind_count)
  {
    _image_bind_count = new_image_bind_count;
  }

  const vk::sparse_image_memory_bind_info* image_binds()
  {
    return _image_binds;
  }

  constexpr const vk::sparse_image_memory_bind_info* image_binds() const
  {
    return _image_binds;
  }

  void image_binds(const vk::sparse_image_memory_bind_info* new_image_binds)
  {
    _image_binds = new_image_binds;
  }

  template <std::size_t Count>
  void image_binds(
    const std::array<vk::sparse_image_memory_bind_info, Count>& new_image_binds)
  {
    _image_bind_count = static_cast<uint32_t>(new_image_binds.size());
    _image_binds = new_image_binds.data();
  }

  void image_binds(
    const std::vector<vk::sparse_image_memory_bind_info>& new_image_binds)
  {
    _image_bind_count = static_cast<uint32_t>(new_image_binds.size());
    _image_binds = new_image_binds.data();
  }

  uint32_t& signal_semaphore_count()
  {
    return _signal_semaphore_count;
  }

  constexpr const uint32_t& signal_semaphore_count() const
  {
    return _signal_semaphore_count;
  }

  void signal_semaphore_count(uint32_t new_signal_semaphore_count)
  {
    _signal_semaphore_count = new_signal_semaphore_count;
  }

  const VkSemaphore* signal_semaphores()
  {
    return _signal_semaphores;
  }

  constexpr const VkSemaphore* signal_semaphores() const
  {
    return _signal_semaphores;
  }

  void signal_semaphores(const VkSemaphore* new_signal_semaphores)
  {
    _signal_semaphores = new_signal_semaphores;
  }

  template <std::size_t Count>
  void signal_semaphores(
    const std::array<VkSemaphore, Count>& new_signal_semaphores)
  {
    _signal_semaphore_count =
      static_cast<uint32_t>(new_signal_semaphores.size());
    _signal_semaphores = new_signal_semaphores.data();
  }

  void signal_semaphores(const std::vector<VkSemaphore>& new_signal_semaphores)
  {
    _signal_semaphore_count =
      static_cast<uint32_t>(new_signal_semaphores.size());
    _signal_semaphores = new_signal_semaphores.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::bind_sparse_info;
  const void* _next = nullptr;
  uint32_t _wait_semaphore_count = 0;
  const VkSemaphore* _wait_semaphores = nullptr;
  uint32_t _buffer_bind_count = 0;
  const vk::sparse_buffer_memory_bind_info* _buffer_binds = nullptr;
  uint32_t _image_opaque_bind_count = 0;
  const vk::sparse_image_opaque_memory_bind_info* _image_opaque_binds = nullptr;
  uint32_t _image_bind_count = 0;
  const vk::sparse_image_memory_bind_info* _image_binds = nullptr;
  uint32_t _signal_semaphore_count = 0;
  const VkSemaphore* _signal_semaphores = nullptr;
};
static_assert(sizeof(bind_sparse_info) == sizeof(::VkBindSparseInfo),
              "struct and wrapper have different size!");

inline vk::result queue_bind_sparse(VkQueue queue, uint32_t bind_info_count,
                                    const vk::bind_sparse_info* bind_info,
                                    VkFence fence)
{
  return static_cast<vk::result>(vkQueueBindSparse(
    static_cast<VkQueue>(queue), static_cast<uint32_t>(bind_info_count),
    reinterpret_cast<const VkBindSparseInfo*>(bind_info),
    static_cast<VkFence>(fence)));
}
enum class fence_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_FENCE_CREATE_SIGNALED_BIT
  signaled_bit = 1 << 0,
};
using fence_create_flags =
  shift::core::bit_field<fence_create_flag, VkFenceCreateFlags>;
inline constexpr fence_create_flags operator|(fence_create_flag lhs,
                                              fence_create_flag rhs)
{
  return fence_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkFenceCreateInfo.
class fence_create_info
{
public:
  /// Default constructor.
  constexpr fence_create_info() = default;

  /// Constructor.
  constexpr fence_create_info(const void* initial_next,
                              vk::fence_create_flags initial_flags) noexcept
  : _next(std::move(initial_next)), _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr fence_create_info(const fence_create_info& other) noexcept
  : _next(other._next), _flags(other._flags)
  {
  }

  /// Move constructor.
  constexpr fence_create_info(fence_create_info&& other) noexcept
  : _next(std::move(other._next)), _flags(std::move(other._flags))
  {
  }

  /// Copy assignment operator.
  constexpr fence_create_info& operator=(
    const fence_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    return *this;
  }

  /// Move assignment operator.
  constexpr fence_create_info& operator=(fence_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkFenceCreateInfo&() const
  {
    return *reinterpret_cast<const VkFenceCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::fence_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::fence_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::fence_create_flags new_flags)
  {
    _flags = new_flags;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::fence_create_info;
  const void* _next = nullptr;
  /// Fence creation flags
  vk::fence_create_flags _flags = vk::fence_create_flag::none;
};
static_assert(sizeof(fence_create_info) == sizeof(::VkFenceCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_fence(VkDevice device,
                               const vk::fence_create_info* create_info,
                               const vk::allocation_callbacks* allocator,
                               VkFence* fence)
{
  return static_cast<vk::result>(
    vkCreateFence(static_cast<VkDevice>(device),
                  reinterpret_cast<const VkFenceCreateInfo*>(create_info),
                  reinterpret_cast<const VkAllocationCallbacks*>(allocator),
                  reinterpret_cast<VkFence*>(fence)));
}
inline void destroy_fence(VkDevice device, VkFence fence,
                          const vk::allocation_callbacks* allocator)
{
  vkDestroyFence(static_cast<VkDevice>(device), static_cast<VkFence>(fence),
                 reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result reset_fences(VkDevice device, uint32_t fence_count,
                               const VkFence* fences)
{
  return static_cast<vk::result>(vkResetFences(
    static_cast<VkDevice>(device), static_cast<uint32_t>(fence_count),
    reinterpret_cast<const VkFence*>(fences)));
}
inline vk::result get_fence_status(VkDevice device, VkFence fence)
{
  return static_cast<vk::result>(vkGetFenceStatus(static_cast<VkDevice>(device),
                                                  static_cast<VkFence>(fence)));
}
inline vk::result wait_for_fences(VkDevice device, uint32_t fence_count,
                                  const VkFence* fences, VkBool32 wait_all,
                                  uint64_t timeout)
{
  return static_cast<vk::result>(vkWaitForFences(
    static_cast<VkDevice>(device), static_cast<uint32_t>(fence_count),
    reinterpret_cast<const VkFence*>(fences), static_cast<VkBool32>(wait_all),
    static_cast<uint64_t>(timeout)));
}
using semaphore_create_flags = VkFlags;

/// Enhanced replacement type for VkSemaphoreCreateInfo.
class semaphore_create_info
{
public:
  /// Default constructor.
  constexpr semaphore_create_info() = default;

  /// Constructor.
  constexpr semaphore_create_info(
    const void* initial_next, vk::semaphore_create_flags initial_flags) noexcept
  : _next(std::move(initial_next)), _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr semaphore_create_info(const semaphore_create_info& other) noexcept
  : _next(other._next), _flags(other._flags)
  {
  }

  /// Move constructor.
  constexpr semaphore_create_info(semaphore_create_info&& other) noexcept
  : _next(std::move(other._next)), _flags(std::move(other._flags))
  {
  }

  /// Copy assignment operator.
  constexpr semaphore_create_info& operator=(
    const semaphore_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    return *this;
  }

  /// Move assignment operator.
  constexpr semaphore_create_info& operator=(
    semaphore_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSemaphoreCreateInfo&() const
  {
    return *reinterpret_cast<const VkSemaphoreCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::semaphore_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::semaphore_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::semaphore_create_flags new_flags)
  {
    _flags = new_flags;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::semaphore_create_info;
  const void* _next = nullptr;
  /// Semaphore creation flags
  vk::semaphore_create_flags _flags = 0;
};
static_assert(sizeof(semaphore_create_info) == sizeof(::VkSemaphoreCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_semaphore(VkDevice device,
                                   const vk::semaphore_create_info* create_info,
                                   const vk::allocation_callbacks* allocator,
                                   VkSemaphore* semaphore)
{
  return static_cast<vk::result>(vkCreateSemaphore(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkSemaphoreCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSemaphore*>(semaphore)));
}
inline void destroy_semaphore(VkDevice device, VkSemaphore semaphore,
                              const vk::allocation_callbacks* allocator)
{
  vkDestroySemaphore(static_cast<VkDevice>(device),
                     static_cast<VkSemaphore>(semaphore),
                     reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
using event_create_flags = VkFlags;

/// Enhanced replacement type for VkEventCreateInfo.
class event_create_info
{
public:
  /// Default constructor.
  constexpr event_create_info() = default;

  /// Constructor.
  constexpr event_create_info(const void* initial_next,
                              vk::event_create_flags initial_flags) noexcept
  : _next(std::move(initial_next)), _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr event_create_info(const event_create_info& other) noexcept
  : _next(other._next), _flags(other._flags)
  {
  }

  /// Move constructor.
  constexpr event_create_info(event_create_info&& other) noexcept
  : _next(std::move(other._next)), _flags(std::move(other._flags))
  {
  }

  /// Copy assignment operator.
  constexpr event_create_info& operator=(
    const event_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    return *this;
  }

  /// Move assignment operator.
  constexpr event_create_info& operator=(event_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkEventCreateInfo&() const
  {
    return *reinterpret_cast<const VkEventCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::event_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::event_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::event_create_flags new_flags)
  {
    _flags = new_flags;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::event_create_info;
  const void* _next = nullptr;
  /// Event creation flags
  vk::event_create_flags _flags = 0;
};
static_assert(sizeof(event_create_info) == sizeof(::VkEventCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_event(VkDevice device,
                               const vk::event_create_info* create_info,
                               const vk::allocation_callbacks* allocator,
                               VkEvent* event)
{
  return static_cast<vk::result>(
    vkCreateEvent(static_cast<VkDevice>(device),
                  reinterpret_cast<const VkEventCreateInfo*>(create_info),
                  reinterpret_cast<const VkAllocationCallbacks*>(allocator),
                  reinterpret_cast<VkEvent*>(event)));
}
inline void destroy_event(VkDevice device, VkEvent event,
                          const vk::allocation_callbacks* allocator)
{
  vkDestroyEvent(static_cast<VkDevice>(device), static_cast<VkEvent>(event),
                 reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result get_event_status(VkDevice device, VkEvent event)
{
  return static_cast<vk::result>(vkGetEventStatus(static_cast<VkDevice>(device),
                                                  static_cast<VkEvent>(event)));
}
inline vk::result set_event(VkDevice device, VkEvent event)
{
  return static_cast<vk::result>(
    vkSetEvent(static_cast<VkDevice>(device), static_cast<VkEvent>(event)));
}
inline vk::result reset_event(VkDevice device, VkEvent event)
{
  return static_cast<vk::result>(
    vkResetEvent(static_cast<VkDevice>(device), static_cast<VkEvent>(event)));
}
enum class query_pool_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using query_pool_create_flags =
  shift::core::bit_field<query_pool_create_flag, VkQueryPoolCreateFlags>;
inline constexpr query_pool_create_flags operator|(query_pool_create_flag lhs,
                                                   query_pool_create_flag rhs)
{
  return query_pool_create_flags{lhs} | rhs;
}
enum class query_type
{
  /// @see VK_QUERY_TYPE_OCCLUSION
  occlusion = 0,
  /// Optional
  /// @see VK_QUERY_TYPE_PIPELINE_STATISTICS
  pipeline_statistics = 1,
  /// @see VK_QUERY_TYPE_TIMESTAMP
  timestamp = 2,
  /// @see VK_QUERY_TYPE_COMPACTED_SIZE_NVX
  compacted_size_nvx = 1000165000,
};
enum class query_pipeline_statistic_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_VERTICES_BIT
  input_assembly_vertices_bit = 1 << 0,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_PRIMITIVES_BIT
  input_assembly_primitives_bit = 1 << 1,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_VERTEX_SHADER_INVOCATIONS_BIT
  vertex_shader_invocations_bit = 1 << 2,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_INVOCATIONS_BIT
  geometry_shader_invocations_bit = 1 << 3,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_PRIMITIVES_BIT
  geometry_shader_primitives_bit = 1 << 4,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_CLIPPING_INVOCATIONS_BIT
  clipping_invocations_bit = 1 << 5,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_CLIPPING_PRIMITIVES_BIT
  clipping_primitives_bit = 1 << 6,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_FRAGMENT_SHADER_INVOCATIONS_BIT
  fragment_shader_invocations_bit = 1 << 7,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_TESSELLATION_CONTROL_SHADER_PATCHES_BIT
  tessellation_control_shader_patches_bit = 1 << 8,
  /// Optional
  /// @see
  /// VK_QUERY_PIPELINE_STATISTIC_TESSELLATION_EVALUATION_SHADER_INVOCATIONS_BIT
  tessellation_evaluation_shader_invocations_bit = 1 << 9,
  /// Optional
  /// @see VK_QUERY_PIPELINE_STATISTIC_COMPUTE_SHADER_INVOCATIONS_BIT
  compute_shader_invocations_bit = 1 << 10,
};
using query_pipeline_statistic_flags =
  shift::core::bit_field<query_pipeline_statistic_flag,
                         VkQueryPipelineStatisticFlags>;
inline constexpr query_pipeline_statistic_flags operator|(
  query_pipeline_statistic_flag lhs, query_pipeline_statistic_flag rhs)
{
  return query_pipeline_statistic_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkQueryPoolCreateInfo.
class query_pool_create_info
{
public:
  /// Default constructor.
  constexpr query_pool_create_info() = default;

  /// Constructor.
  constexpr query_pool_create_info(
    const void* initial_next, vk::query_pool_create_flags initial_flags,
    vk::query_type initial_query_type, uint32_t initial_query_count,
    vk::query_pipeline_statistic_flags initial_pipeline_statistics) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _query_type(std::move(initial_query_type)),
    _query_count(std::move(initial_query_count)),
    _pipeline_statistics(std::move(initial_pipeline_statistics))
  {
  }

  /// Copy constructor.
  constexpr query_pool_create_info(const query_pool_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _query_type(other._query_type),
    _query_count(other._query_count),
    _pipeline_statistics(other._pipeline_statistics)
  {
  }

  /// Move constructor.
  constexpr query_pool_create_info(query_pool_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _query_type(std::move(other._query_type)),
    _query_count(std::move(other._query_count)),
    _pipeline_statistics(std::move(other._pipeline_statistics))
  {
  }

  /// Copy assignment operator.
  constexpr query_pool_create_info& operator=(
    const query_pool_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _query_type = other._query_type;
    _query_count = other._query_count;
    _pipeline_statistics = other._pipeline_statistics;
    return *this;
  }

  /// Move assignment operator.
  constexpr query_pool_create_info& operator=(
    query_pool_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _query_type = std::move(other._query_type);
    _query_count = std::move(other._query_count);
    _pipeline_statistics = std::move(other._pipeline_statistics);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkQueryPoolCreateInfo&() const
  {
    return *reinterpret_cast<const VkQueryPoolCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::query_pool_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::query_pool_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::query_pool_create_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::query_type& query_type()
  {
    return _query_type;
  }

  constexpr const vk::query_type& query_type() const
  {
    return _query_type;
  }

  void query_type(vk::query_type new_query_type)
  {
    _query_type = new_query_type;
  }

  uint32_t& query_count()
  {
    return _query_count;
  }

  constexpr const uint32_t& query_count() const
  {
    return _query_count;
  }

  void query_count(uint32_t new_query_count)
  {
    _query_count = new_query_count;
  }

  vk::query_pipeline_statistic_flags& pipeline_statistics()
  {
    return _pipeline_statistics;
  }

  constexpr const vk::query_pipeline_statistic_flags& pipeline_statistics()
    const
  {
    return _pipeline_statistics;
  }

  void pipeline_statistics(
    vk::query_pipeline_statistic_flags new_pipeline_statistics)
  {
    _pipeline_statistics = new_pipeline_statistics;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::query_pool_create_info;
  const void* _next = nullptr;
  vk::query_pool_create_flags _flags = vk::query_pool_create_flag::none;
  vk::query_type _query_type = vk::query_type::occlusion;
  uint32_t _query_count = 0;
  /// Optional
  vk::query_pipeline_statistic_flags _pipeline_statistics =
    vk::query_pipeline_statistic_flag::none;
};
static_assert(sizeof(query_pool_create_info) == sizeof(::VkQueryPoolCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_query_pool(
  VkDevice device, const vk::query_pool_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkQueryPool* query_pool)
{
  return static_cast<vk::result>(vkCreateQueryPool(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkQueryPoolCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkQueryPool*>(query_pool)));
}
inline void destroy_query_pool(VkDevice device, VkQueryPool query_pool,
                               const vk::allocation_callbacks* allocator)
{
  vkDestroyQueryPool(static_cast<VkDevice>(device),
                     static_cast<VkQueryPool>(query_pool),
                     reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
enum class query_result_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Results of the queries are written to the destination buffer as 64-bit
  /// values
  /// @see VK_QUERY_RESULT_64_BIT
  _64_bit = 1 << 0,
  /// Results of the queries are waited on before proceeding with the result
  /// copy
  /// @see VK_QUERY_RESULT_WAIT_BIT
  wait_bit = 1 << 1,
  /// Besides the results of the query, the availability of the results is also
  /// written
  /// @see VK_QUERY_RESULT_WITH_AVAILABILITY_BIT
  with_availability_bit = 1 << 2,
  /// Copy the partial results of the query even if the final results are not
  /// available
  /// @see VK_QUERY_RESULT_PARTIAL_BIT
  partial_bit = 1 << 3,
};
using query_result_flags =
  shift::core::bit_field<query_result_flag, VkQueryResultFlags>;
inline constexpr query_result_flags operator|(query_result_flag lhs,
                                              query_result_flag rhs)
{
  return query_result_flags{lhs} | rhs;
}
inline vk::result get_query_pool_results(VkDevice device,
                                         VkQueryPool query_pool,
                                         uint32_t first_query,
                                         uint32_t query_count, size_t data_size,
                                         void* data, VkDeviceSize stride,
                                         vk::query_result_flags flags)
{
  return static_cast<vk::result>(vkGetQueryPoolResults(
    static_cast<VkDevice>(device), static_cast<VkQueryPool>(query_pool),
    static_cast<uint32_t>(first_query), static_cast<uint32_t>(query_count),
    static_cast<size_t>(data_size), reinterpret_cast<void*>(data),
    static_cast<VkDeviceSize>(stride), static_cast<VkQueryResultFlags>(flags)));
}
enum class buffer_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Buffer should support sparse backing
  /// @see VK_BUFFER_CREATE_SPARSE_BINDING_BIT
  sparse_binding_bit = 1 << 0,
  /// Buffer should support sparse backing with partial residency
  /// @see VK_BUFFER_CREATE_SPARSE_RESIDENCY_BIT
  sparse_residency_bit = 1 << 1,
  /// Buffer should support constent data access to physical memory ranges
  /// mapped into multiple locations of sparse buffers
  /// @see VK_BUFFER_CREATE_SPARSE_ALIASED_BIT
  sparse_aliased_bit = 1 << 2,
  /// Buffer requires protected memory
  /// @see VK_BUFFER_CREATE_PROTECTED_BIT
  protected_bit = 1 << 3,
};
using buffer_create_flags =
  shift::core::bit_field<buffer_create_flag, VkBufferCreateFlags>;
inline constexpr buffer_create_flags operator|(buffer_create_flag lhs,
                                               buffer_create_flag rhs)
{
  return buffer_create_flags{lhs} | rhs;
}
enum class buffer_usage_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Can be used as a source of transfer operations
  /// @see VK_BUFFER_USAGE_TRANSFER_SRC_BIT
  transfer_src_bit = 1 << 0,
  /// Can be used as a destination of transfer operations
  /// @see VK_BUFFER_USAGE_TRANSFER_DST_BIT
  transfer_dst_bit = 1 << 1,
  /// Can be used as TBO
  /// @see VK_BUFFER_USAGE_UNIFORM_TEXEL_BUFFER_BIT
  uniform_texel_buffer_bit = 1 << 2,
  /// Can be used as IBO
  /// @see VK_BUFFER_USAGE_STORAGE_TEXEL_BUFFER_BIT
  storage_texel_buffer_bit = 1 << 3,
  /// Can be used as UBO
  /// @see VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT
  uniform_buffer_bit = 1 << 4,
  /// Can be used as SSBO
  /// @see VK_BUFFER_USAGE_STORAGE_BUFFER_BIT
  storage_buffer_bit = 1 << 5,
  /// Can be used as source of fixed-function index fetch (index buffer)
  /// @see VK_BUFFER_USAGE_INDEX_BUFFER_BIT
  index_buffer_bit = 1 << 6,
  /// Can be used as source of fixed-function vertex fetch (VBO)
  /// @see VK_BUFFER_USAGE_VERTEX_BUFFER_BIT
  vertex_buffer_bit = 1 << 7,
  /// Can be the source of indirect parameters (e.g. indirect buffer, parameter
  /// buffer)
  /// @see VK_BUFFER_USAGE_INDIRECT_BUFFER_BIT
  indirect_buffer_bit = 1 << 8,
  /// Specifies the buffer can be used as predicate in conditional rendering
  /// @see VK_BUFFER_USAGE_CONDITIONAL_RENDERING_BIT_EXT
  conditional_rendering_bit_ext = 1 << 9,
  /// @see VK_BUFFER_USAGE_RAYTRACING_BIT_NVX
  raytracing_bit_nvx = 1 << 10,
};
using buffer_usage_flags =
  shift::core::bit_field<buffer_usage_flag, VkBufferUsageFlags>;
inline constexpr buffer_usage_flags operator|(buffer_usage_flag lhs,
                                              buffer_usage_flag rhs)
{
  return buffer_usage_flags{lhs} | rhs;
}
enum class sharing_mode
{
  /// @see VK_SHARING_MODE_EXCLUSIVE
  exclusive = 0,
  /// @see VK_SHARING_MODE_CONCURRENT
  concurrent = 1,
};

/// Enhanced replacement type for VkBufferCreateInfo.
class buffer_create_info
{
public:
  /// Default constructor.
  constexpr buffer_create_info() = default;

  /// Constructor.
  constexpr buffer_create_info(
    const void* initial_next, vk::buffer_create_flags initial_flags,
    VkDeviceSize initial_size, vk::buffer_usage_flags initial_usage,
    vk::sharing_mode initial_sharing_mode,
    uint32_t initial_queue_family_index_count,
    const uint32_t* initial_queue_family_indices) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _size(std::move(initial_size)),
    _usage(std::move(initial_usage)),
    _sharing_mode(std::move(initial_sharing_mode)),
    _queue_family_index_count(std::move(initial_queue_family_index_count)),
    _queue_family_indices(std::move(initial_queue_family_indices))
  {
  }

  /// Copy constructor.
  constexpr buffer_create_info(const buffer_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _size(other._size),
    _usage(other._usage),
    _sharing_mode(other._sharing_mode),
    _queue_family_index_count(other._queue_family_index_count),
    _queue_family_indices(other._queue_family_indices)
  {
  }

  /// Move constructor.
  constexpr buffer_create_info(buffer_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _size(std::move(other._size)),
    _usage(std::move(other._usage)),
    _sharing_mode(std::move(other._sharing_mode)),
    _queue_family_index_count(std::move(other._queue_family_index_count)),
    _queue_family_indices(std::move(other._queue_family_indices))
  {
  }

  /// Copy assignment operator.
  constexpr buffer_create_info& operator=(
    const buffer_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _size = other._size;
    _usage = other._usage;
    _sharing_mode = other._sharing_mode;
    _queue_family_index_count = other._queue_family_index_count;
    _queue_family_indices = other._queue_family_indices;
    return *this;
  }

  /// Move assignment operator.
  constexpr buffer_create_info& operator=(buffer_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _size = std::move(other._size);
    _usage = std::move(other._usage);
    _sharing_mode = std::move(other._sharing_mode);
    _queue_family_index_count = std::move(other._queue_family_index_count);
    _queue_family_indices = std::move(other._queue_family_indices);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBufferCreateInfo&() const
  {
    return *reinterpret_cast<const VkBufferCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::buffer_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::buffer_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::buffer_create_flags new_flags)
  {
    _flags = new_flags;
  }

  VkDeviceSize& size()
  {
    return _size;
  }

  constexpr const VkDeviceSize& size() const
  {
    return _size;
  }

  void size(VkDeviceSize new_size)
  {
    _size = new_size;
  }

  vk::buffer_usage_flags& usage()
  {
    return _usage;
  }

  constexpr const vk::buffer_usage_flags& usage() const
  {
    return _usage;
  }

  void usage(vk::buffer_usage_flags new_usage)
  {
    _usage = new_usage;
  }

  vk::sharing_mode& sharing_mode()
  {
    return _sharing_mode;
  }

  constexpr const vk::sharing_mode& sharing_mode() const
  {
    return _sharing_mode;
  }

  void sharing_mode(vk::sharing_mode new_sharing_mode)
  {
    _sharing_mode = new_sharing_mode;
  }

  uint32_t& queue_family_index_count()
  {
    return _queue_family_index_count;
  }

  constexpr const uint32_t& queue_family_index_count() const
  {
    return _queue_family_index_count;
  }

  void queue_family_index_count(uint32_t new_queue_family_index_count)
  {
    _queue_family_index_count = new_queue_family_index_count;
  }

  const uint32_t* queue_family_indices()
  {
    return _queue_family_indices;
  }

  constexpr const uint32_t* queue_family_indices() const
  {
    return _queue_family_indices;
  }

  void queue_family_indices(const uint32_t* new_queue_family_indices)
  {
    _queue_family_indices = new_queue_family_indices;
  }

  template <std::size_t Count>
  void queue_family_indices(
    const std::array<uint32_t, Count>& new_queue_family_indices)
  {
    _queue_family_index_count =
      static_cast<uint32_t>(new_queue_family_indices.size());
    _queue_family_indices = new_queue_family_indices.data();
  }

  void queue_family_indices(
    const std::vector<uint32_t>& new_queue_family_indices)
  {
    _queue_family_index_count =
      static_cast<uint32_t>(new_queue_family_indices.size());
    _queue_family_indices = new_queue_family_indices.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::buffer_create_info;
  const void* _next = nullptr;
  /// Buffer creation flags
  vk::buffer_create_flags _flags = vk::buffer_create_flag::none;
  /// Specified in bytes
  VkDeviceSize _size = 0;
  /// Buffer usage flags
  vk::buffer_usage_flags _usage = vk::buffer_usage_flag::none;
  vk::sharing_mode _sharing_mode = vk::sharing_mode::exclusive;
  uint32_t _queue_family_index_count = 0;
  const uint32_t* _queue_family_indices = nullptr;
};
static_assert(sizeof(buffer_create_info) == sizeof(::VkBufferCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_buffer(VkDevice device,
                                const vk::buffer_create_info* create_info,
                                const vk::allocation_callbacks* allocator,
                                VkBuffer* buffer)
{
  return static_cast<vk::result>(
    vkCreateBuffer(static_cast<VkDevice>(device),
                   reinterpret_cast<const VkBufferCreateInfo*>(create_info),
                   reinterpret_cast<const VkAllocationCallbacks*>(allocator),
                   reinterpret_cast<VkBuffer*>(buffer)));
}
inline void destroy_buffer(VkDevice device, VkBuffer buffer,
                           const vk::allocation_callbacks* allocator)
{
  vkDestroyBuffer(static_cast<VkDevice>(device), static_cast<VkBuffer>(buffer),
                  reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
enum class buffer_view_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using buffer_view_create_flags =
  shift::core::bit_field<buffer_view_create_flag, VkBufferViewCreateFlags>;
inline constexpr buffer_view_create_flags operator|(buffer_view_create_flag lhs,
                                                    buffer_view_create_flag rhs)
{
  return buffer_view_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkBufferViewCreateInfo.
class buffer_view_create_info
{
public:
  /// Default constructor.
  constexpr buffer_view_create_info() = default;

  /// Constructor.
  constexpr buffer_view_create_info(const void* initial_next,
                                    vk::buffer_view_create_flags initial_flags,
                                    VkBuffer initial_buffer,
                                    vk::format initial_format,
                                    VkDeviceSize initial_offset,
                                    VkDeviceSize initial_range) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _buffer(std::move(initial_buffer)),
    _format(std::move(initial_format)),
    _offset(std::move(initial_offset)),
    _range(std::move(initial_range))
  {
  }

  /// Copy constructor.
  constexpr buffer_view_create_info(
    const buffer_view_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _buffer(other._buffer),
    _format(other._format),
    _offset(other._offset),
    _range(other._range)
  {
  }

  /// Move constructor.
  constexpr buffer_view_create_info(buffer_view_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _buffer(std::move(other._buffer)),
    _format(std::move(other._format)),
    _offset(std::move(other._offset)),
    _range(std::move(other._range))
  {
  }

  /// Copy assignment operator.
  constexpr buffer_view_create_info& operator=(
    const buffer_view_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _buffer = other._buffer;
    _format = other._format;
    _offset = other._offset;
    _range = other._range;
    return *this;
  }

  /// Move assignment operator.
  constexpr buffer_view_create_info& operator=(
    buffer_view_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _buffer = std::move(other._buffer);
    _format = std::move(other._format);
    _offset = std::move(other._offset);
    _range = std::move(other._range);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBufferViewCreateInfo&() const
  {
    return *reinterpret_cast<const VkBufferViewCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::buffer_view_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::buffer_view_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::buffer_view_create_flags new_flags)
  {
    _flags = new_flags;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  VkDeviceSize& offset()
  {
    return _offset;
  }

  constexpr const VkDeviceSize& offset() const
  {
    return _offset;
  }

  void offset(VkDeviceSize new_offset)
  {
    _offset = new_offset;
  }

  VkDeviceSize& range()
  {
    return _range;
  }

  constexpr const VkDeviceSize& range() const
  {
    return _range;
  }

  void range(VkDeviceSize new_range)
  {
    _range = new_range;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::buffer_view_create_info;
  const void* _next = nullptr;
  vk::buffer_view_create_flags _flags = vk::buffer_view_create_flag::none;
  VkBuffer _buffer = nullptr;
  /// Optionally specifies format of elements
  vk::format _format = vk::format::undefined;
  /// Specified in bytes
  VkDeviceSize _offset = 0;
  /// View size specified in bytes
  VkDeviceSize _range = 0;
};
static_assert(sizeof(buffer_view_create_info) ==
                sizeof(::VkBufferViewCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_buffer_view(
  VkDevice device, const vk::buffer_view_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkBufferView* view)
{
  return static_cast<vk::result>(vkCreateBufferView(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkBufferViewCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkBufferView*>(view)));
}
inline void destroy_buffer_view(VkDevice device, VkBufferView buffer_view,
                                const vk::allocation_callbacks* allocator)
{
  vkDestroyBufferView(
    static_cast<VkDevice>(device), static_cast<VkBufferView>(buffer_view),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}

/// Enhanced replacement type for VkImageCreateInfo.
class image_create_info
{
public:
  /// Default constructor.
  constexpr image_create_info() = default;

  /// Constructor.
  constexpr image_create_info(
    const void* initial_next, vk::image_create_flags initial_flags,
    vk::image_type initial_image_type, vk::format initial_format,
    vk::extent_3d initial_extent, uint32_t initial_mip_levels,
    uint32_t initial_array_layers, vk::sample_count_flag initial_samples,
    vk::image_tiling initial_tiling, vk::image_usage_flags initial_usage,
    vk::sharing_mode initial_sharing_mode,
    uint32_t initial_queue_family_index_count,
    const uint32_t* initial_queue_family_indices,
    vk::image_layout initial_initial_layout) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _image_type(std::move(initial_image_type)),
    _format(std::move(initial_format)),
    _extent(std::move(initial_extent)),
    _mip_levels(std::move(initial_mip_levels)),
    _array_layers(std::move(initial_array_layers)),
    _samples(std::move(initial_samples)),
    _tiling(std::move(initial_tiling)),
    _usage(std::move(initial_usage)),
    _sharing_mode(std::move(initial_sharing_mode)),
    _queue_family_index_count(std::move(initial_queue_family_index_count)),
    _queue_family_indices(std::move(initial_queue_family_indices)),
    _initial_layout(std::move(initial_initial_layout))
  {
  }

  /// Copy constructor.
  constexpr image_create_info(const image_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _image_type(other._image_type),
    _format(other._format),
    _extent(other._extent),
    _mip_levels(other._mip_levels),
    _array_layers(other._array_layers),
    _samples(other._samples),
    _tiling(other._tiling),
    _usage(other._usage),
    _sharing_mode(other._sharing_mode),
    _queue_family_index_count(other._queue_family_index_count),
    _queue_family_indices(other._queue_family_indices),
    _initial_layout(other._initial_layout)
  {
  }

  /// Move constructor.
  constexpr image_create_info(image_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _image_type(std::move(other._image_type)),
    _format(std::move(other._format)),
    _extent(std::move(other._extent)),
    _mip_levels(std::move(other._mip_levels)),
    _array_layers(std::move(other._array_layers)),
    _samples(std::move(other._samples)),
    _tiling(std::move(other._tiling)),
    _usage(std::move(other._usage)),
    _sharing_mode(std::move(other._sharing_mode)),
    _queue_family_index_count(std::move(other._queue_family_index_count)),
    _queue_family_indices(std::move(other._queue_family_indices)),
    _initial_layout(std::move(other._initial_layout))
  {
  }

  /// Copy assignment operator.
  constexpr image_create_info& operator=(
    const image_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _image_type = other._image_type;
    _format = other._format;
    _extent = other._extent;
    _mip_levels = other._mip_levels;
    _array_layers = other._array_layers;
    _samples = other._samples;
    _tiling = other._tiling;
    _usage = other._usage;
    _sharing_mode = other._sharing_mode;
    _queue_family_index_count = other._queue_family_index_count;
    _queue_family_indices = other._queue_family_indices;
    _initial_layout = other._initial_layout;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_create_info& operator=(image_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _image_type = std::move(other._image_type);
    _format = std::move(other._format);
    _extent = std::move(other._extent);
    _mip_levels = std::move(other._mip_levels);
    _array_layers = std::move(other._array_layers);
    _samples = std::move(other._samples);
    _tiling = std::move(other._tiling);
    _usage = std::move(other._usage);
    _sharing_mode = std::move(other._sharing_mode);
    _queue_family_index_count = std::move(other._queue_family_index_count);
    _queue_family_indices = std::move(other._queue_family_indices);
    _initial_layout = std::move(other._initial_layout);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageCreateInfo&() const
  {
    return *reinterpret_cast<const VkImageCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::image_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::image_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::image_create_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::image_type& image_type()
  {
    return _image_type;
  }

  constexpr const vk::image_type& image_type() const
  {
    return _image_type;
  }

  void image_type(vk::image_type new_image_type)
  {
    _image_type = new_image_type;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  vk::extent_3d& extent()
  {
    return _extent;
  }

  constexpr const vk::extent_3d& extent() const
  {
    return _extent;
  }

  void extent(vk::extent_3d new_extent)
  {
    _extent = new_extent;
  }

  uint32_t& mip_levels()
  {
    return _mip_levels;
  }

  constexpr const uint32_t& mip_levels() const
  {
    return _mip_levels;
  }

  void mip_levels(uint32_t new_mip_levels)
  {
    _mip_levels = new_mip_levels;
  }

  uint32_t& array_layers()
  {
    return _array_layers;
  }

  constexpr const uint32_t& array_layers() const
  {
    return _array_layers;
  }

  void array_layers(uint32_t new_array_layers)
  {
    _array_layers = new_array_layers;
  }

  vk::sample_count_flag& samples()
  {
    return _samples;
  }

  constexpr const vk::sample_count_flag& samples() const
  {
    return _samples;
  }

  void samples(vk::sample_count_flag new_samples)
  {
    _samples = new_samples;
  }

  vk::image_tiling& tiling()
  {
    return _tiling;
  }

  constexpr const vk::image_tiling& tiling() const
  {
    return _tiling;
  }

  void tiling(vk::image_tiling new_tiling)
  {
    _tiling = new_tiling;
  }

  vk::image_usage_flags& usage()
  {
    return _usage;
  }

  constexpr const vk::image_usage_flags& usage() const
  {
    return _usage;
  }

  void usage(vk::image_usage_flags new_usage)
  {
    _usage = new_usage;
  }

  vk::sharing_mode& sharing_mode()
  {
    return _sharing_mode;
  }

  constexpr const vk::sharing_mode& sharing_mode() const
  {
    return _sharing_mode;
  }

  void sharing_mode(vk::sharing_mode new_sharing_mode)
  {
    _sharing_mode = new_sharing_mode;
  }

  uint32_t& queue_family_index_count()
  {
    return _queue_family_index_count;
  }

  constexpr const uint32_t& queue_family_index_count() const
  {
    return _queue_family_index_count;
  }

  void queue_family_index_count(uint32_t new_queue_family_index_count)
  {
    _queue_family_index_count = new_queue_family_index_count;
  }

  const uint32_t* queue_family_indices()
  {
    return _queue_family_indices;
  }

  constexpr const uint32_t* queue_family_indices() const
  {
    return _queue_family_indices;
  }

  void queue_family_indices(const uint32_t* new_queue_family_indices)
  {
    _queue_family_indices = new_queue_family_indices;
  }

  template <std::size_t Count>
  void queue_family_indices(
    const std::array<uint32_t, Count>& new_queue_family_indices)
  {
    _queue_family_index_count =
      static_cast<uint32_t>(new_queue_family_indices.size());
    _queue_family_indices = new_queue_family_indices.data();
  }

  void queue_family_indices(
    const std::vector<uint32_t>& new_queue_family_indices)
  {
    _queue_family_index_count =
      static_cast<uint32_t>(new_queue_family_indices.size());
    _queue_family_indices = new_queue_family_indices.data();
  }

  vk::image_layout& initial_layout()
  {
    return _initial_layout;
  }

  constexpr const vk::image_layout& initial_layout() const
  {
    return _initial_layout;
  }

  void initial_layout(vk::image_layout new_initial_layout)
  {
    _initial_layout = new_initial_layout;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_create_info;
  const void* _next = nullptr;
  /// Image creation flags
  vk::image_create_flags _flags = vk::image_create_flag::none;
  vk::image_type _image_type = vk::image_type::_1d;
  vk::format _format = vk::format::undefined;
  vk::extent_3d _extent = vk::extent_3d{};
  uint32_t _mip_levels = 0;
  uint32_t _array_layers = 0;
  vk::sample_count_flag _samples = vk::sample_count_flag::none;
  vk::image_tiling _tiling = vk::image_tiling::optimal;
  /// Image usage flags
  vk::image_usage_flags _usage = vk::image_usage_flag::none;
  /// Cross-queue-family sharing mode
  vk::sharing_mode _sharing_mode = vk::sharing_mode::exclusive;
  /// Number of queue families to share across
  uint32_t _queue_family_index_count = 0;
  /// Array of queue family indices to share across
  const uint32_t* _queue_family_indices = nullptr;
  /// Initial image layout for all subresources
  vk::image_layout _initial_layout = vk::image_layout::undefined;
};
static_assert(sizeof(image_create_info) == sizeof(::VkImageCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_image(VkDevice device,
                               const vk::image_create_info* create_info,
                               const vk::allocation_callbacks* allocator,
                               VkImage* image)
{
  return static_cast<vk::result>(
    vkCreateImage(static_cast<VkDevice>(device),
                  reinterpret_cast<const VkImageCreateInfo*>(create_info),
                  reinterpret_cast<const VkAllocationCallbacks*>(allocator),
                  reinterpret_cast<VkImage*>(image)));
}
inline void destroy_image(VkDevice device, VkImage image,
                          const vk::allocation_callbacks* allocator)
{
  vkDestroyImage(static_cast<VkDevice>(device), static_cast<VkImage>(image),
                 reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}

/// Enhanced replacement type for VkSubresourceLayout.
class subresource_layout
{
public:
  /// Default constructor.
  constexpr subresource_layout() = default;

  /// Constructor.
  constexpr subresource_layout(VkDeviceSize initial_offset,
                               VkDeviceSize initial_size,
                               VkDeviceSize initial_row_pitch,
                               VkDeviceSize initial_array_pitch,
                               VkDeviceSize initial_depth_pitch) noexcept
  : _offset(std::move(initial_offset)),
    _size(std::move(initial_size)),
    _row_pitch(std::move(initial_row_pitch)),
    _array_pitch(std::move(initial_array_pitch)),
    _depth_pitch(std::move(initial_depth_pitch))
  {
  }

  /// Copy constructor.
  constexpr subresource_layout(const subresource_layout& other) = default;

  /// Move constructor.
  constexpr subresource_layout(subresource_layout&& other) = default;

  /// Copy assignment operator.
  constexpr subresource_layout& operator=(const subresource_layout& other) =
    default;

  /// Move assignment operator.
  constexpr subresource_layout& operator=(subresource_layout&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSubresourceLayout&() const
  {
    return *reinterpret_cast<const VkSubresourceLayout*>(this);
  }

  VkDeviceSize& offset()
  {
    return _offset;
  }

  constexpr const VkDeviceSize& offset() const
  {
    return _offset;
  }

  void offset(VkDeviceSize new_offset)
  {
    _offset = new_offset;
  }

  VkDeviceSize& size()
  {
    return _size;
  }

  constexpr const VkDeviceSize& size() const
  {
    return _size;
  }

  void size(VkDeviceSize new_size)
  {
    _size = new_size;
  }

  VkDeviceSize& row_pitch()
  {
    return _row_pitch;
  }

  constexpr const VkDeviceSize& row_pitch() const
  {
    return _row_pitch;
  }

  void row_pitch(VkDeviceSize new_row_pitch)
  {
    _row_pitch = new_row_pitch;
  }

  VkDeviceSize& array_pitch()
  {
    return _array_pitch;
  }

  constexpr const VkDeviceSize& array_pitch() const
  {
    return _array_pitch;
  }

  void array_pitch(VkDeviceSize new_array_pitch)
  {
    _array_pitch = new_array_pitch;
  }

  VkDeviceSize& depth_pitch()
  {
    return _depth_pitch;
  }

  constexpr const VkDeviceSize& depth_pitch() const
  {
    return _depth_pitch;
  }

  void depth_pitch(VkDeviceSize new_depth_pitch)
  {
    _depth_pitch = new_depth_pitch;
  }

private:
  /// Specified in bytes
  VkDeviceSize _offset = 0;
  /// Specified in bytes
  VkDeviceSize _size = 0;
  /// Specified in bytes
  VkDeviceSize _row_pitch = 0;
  /// Specified in bytes
  VkDeviceSize _array_pitch = 0;
  /// Specified in bytes
  VkDeviceSize _depth_pitch = 0;
};
static_assert(sizeof(subresource_layout) == sizeof(::VkSubresourceLayout),
              "struct and wrapper have different size!");

inline void get_image_subresource_layout(
  VkDevice device, VkImage image, const vk::image_subresource* subresource,
  vk::subresource_layout* layout)
{
  vkGetImageSubresourceLayout(
    static_cast<VkDevice>(device), static_cast<VkImage>(image),
    reinterpret_cast<const VkImageSubresource*>(subresource),
    reinterpret_cast<VkSubresourceLayout*>(layout));
}
using image_view_create_flags = VkFlags;
enum class image_view_type
{
  /// @see VK_IMAGE_VIEW_TYPE_1D
  _1d = 0,
  /// @see VK_IMAGE_VIEW_TYPE_2D
  _2d = 1,
  /// @see VK_IMAGE_VIEW_TYPE_3D
  _3d = 2,
  /// @see VK_IMAGE_VIEW_TYPE_CUBE
  cube = 3,
  /// @see VK_IMAGE_VIEW_TYPE_1D_ARRAY
  _1d_array = 4,
  /// @see VK_IMAGE_VIEW_TYPE_2D_ARRAY
  _2d_array = 5,
  /// @see VK_IMAGE_VIEW_TYPE_CUBE_ARRAY
  cube_array = 6,
};
enum class component_swizzle
{
  /// @see VK_COMPONENT_SWIZZLE_IDENTITY
  identity = 0,
  /// @see VK_COMPONENT_SWIZZLE_ZERO
  zero = 1,
  /// @see VK_COMPONENT_SWIZZLE_ONE
  one = 2,
  /// @see VK_COMPONENT_SWIZZLE_R
  r = 3,
  /// @see VK_COMPONENT_SWIZZLE_G
  g = 4,
  /// @see VK_COMPONENT_SWIZZLE_B
  b = 5,
  /// @see VK_COMPONENT_SWIZZLE_A
  a = 6,
};

/// Enhanced replacement type for VkComponentMapping.
class component_mapping
{
public:
  /// Default constructor.
  constexpr component_mapping() = default;

  /// Constructor.
  constexpr component_mapping(vk::component_swizzle initial_r,
                              vk::component_swizzle initial_g,
                              vk::component_swizzle initial_b,
                              vk::component_swizzle initial_a) noexcept
  : _r(std::move(initial_r)),
    _g(std::move(initial_g)),
    _b(std::move(initial_b)),
    _a(std::move(initial_a))
  {
  }

  /// Copy constructor.
  constexpr component_mapping(const component_mapping& other) = default;

  /// Move constructor.
  constexpr component_mapping(component_mapping&& other) = default;

  /// Copy assignment operator.
  constexpr component_mapping& operator=(const component_mapping& other) =
    default;

  /// Move assignment operator.
  constexpr component_mapping& operator=(component_mapping&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkComponentMapping&() const
  {
    return *reinterpret_cast<const VkComponentMapping*>(this);
  }

  vk::component_swizzle& r()
  {
    return _r;
  }

  constexpr const vk::component_swizzle& r() const
  {
    return _r;
  }

  void r(vk::component_swizzle new_r)
  {
    _r = new_r;
  }

  vk::component_swizzle& g()
  {
    return _g;
  }

  constexpr const vk::component_swizzle& g() const
  {
    return _g;
  }

  void g(vk::component_swizzle new_g)
  {
    _g = new_g;
  }

  vk::component_swizzle& b()
  {
    return _b;
  }

  constexpr const vk::component_swizzle& b() const
  {
    return _b;
  }

  void b(vk::component_swizzle new_b)
  {
    _b = new_b;
  }

  vk::component_swizzle& a()
  {
    return _a;
  }

  constexpr const vk::component_swizzle& a() const
  {
    return _a;
  }

  void a(vk::component_swizzle new_a)
  {
    _a = new_a;
  }

private:
  vk::component_swizzle _r = vk::component_swizzle::identity;
  vk::component_swizzle _g = vk::component_swizzle::identity;
  vk::component_swizzle _b = vk::component_swizzle::identity;
  vk::component_swizzle _a = vk::component_swizzle::identity;
};
static_assert(sizeof(component_mapping) == sizeof(::VkComponentMapping),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImageViewCreateInfo.
class image_view_create_info
{
public:
  /// Default constructor.
  constexpr image_view_create_info() = default;

  /// Constructor.
  constexpr image_view_create_info(
    const void* initial_next, vk::image_view_create_flags initial_flags,
    VkImage initial_image, vk::image_view_type initial_view_type,
    vk::format initial_format, vk::component_mapping initial_components,
    vk::image_subresource_range initial_subresource_range) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _image(std::move(initial_image)),
    _view_type(std::move(initial_view_type)),
    _format(std::move(initial_format)),
    _components(std::move(initial_components)),
    _subresource_range(std::move(initial_subresource_range))
  {
  }

  /// Copy constructor.
  constexpr image_view_create_info(const image_view_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _image(other._image),
    _view_type(other._view_type),
    _format(other._format),
    _components(other._components),
    _subresource_range(other._subresource_range)
  {
  }

  /// Move constructor.
  constexpr image_view_create_info(image_view_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _image(std::move(other._image)),
    _view_type(std::move(other._view_type)),
    _format(std::move(other._format)),
    _components(std::move(other._components)),
    _subresource_range(std::move(other._subresource_range))
  {
  }

  /// Copy assignment operator.
  constexpr image_view_create_info& operator=(
    const image_view_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _image = other._image;
    _view_type = other._view_type;
    _format = other._format;
    _components = other._components;
    _subresource_range = other._subresource_range;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_view_create_info& operator=(
    image_view_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _image = std::move(other._image);
    _view_type = std::move(other._view_type);
    _format = std::move(other._format);
    _components = std::move(other._components);
    _subresource_range = std::move(other._subresource_range);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageViewCreateInfo&() const
  {
    return *reinterpret_cast<const VkImageViewCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::image_view_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::image_view_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::image_view_create_flags new_flags)
  {
    _flags = new_flags;
  }

  VkImage& image()
  {
    return _image;
  }

  constexpr const VkImage& image() const
  {
    return _image;
  }

  void image(VkImage new_image)
  {
    _image = new_image;
  }

  vk::image_view_type& view_type()
  {
    return _view_type;
  }

  constexpr const vk::image_view_type& view_type() const
  {
    return _view_type;
  }

  void view_type(vk::image_view_type new_view_type)
  {
    _view_type = new_view_type;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  vk::component_mapping& components()
  {
    return _components;
  }

  constexpr const vk::component_mapping& components() const
  {
    return _components;
  }

  void components(vk::component_mapping new_components)
  {
    _components = new_components;
  }

  vk::image_subresource_range& subresource_range()
  {
    return _subresource_range;
  }

  constexpr const vk::image_subresource_range& subresource_range() const
  {
    return _subresource_range;
  }

  void subresource_range(vk::image_subresource_range new_subresource_range)
  {
    _subresource_range = new_subresource_range;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_view_create_info;
  const void* _next = nullptr;
  vk::image_view_create_flags _flags = 0;
  VkImage _image = nullptr;
  vk::image_view_type _view_type = vk::image_view_type::_1d;
  vk::format _format = vk::format::undefined;
  vk::component_mapping _components = vk::component_mapping{};
  vk::image_subresource_range _subresource_range =
    vk::image_subresource_range{};
};
static_assert(sizeof(image_view_create_info) == sizeof(::VkImageViewCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_image_view(
  VkDevice device, const vk::image_view_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkImageView* view)
{
  return static_cast<vk::result>(vkCreateImageView(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkImageViewCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkImageView*>(view)));
}
inline void destroy_image_view(VkDevice device, VkImageView image_view,
                               const vk::allocation_callbacks* allocator)
{
  vkDestroyImageView(static_cast<VkDevice>(device),
                     static_cast<VkImageView>(image_view),
                     reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
using shader_module_create_flags = VkFlags;

/// Enhanced replacement type for VkShaderModuleCreateInfo.
class shader_module_create_info
{
public:
  /// Default constructor.
  constexpr shader_module_create_info() = default;

  /// Constructor.
  constexpr shader_module_create_info(
    const void* initial_next, vk::shader_module_create_flags initial_flags,
    size_t initial_code_size, const uint32_t* initial_code) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _code_size(std::move(initial_code_size)),
    _code(std::move(initial_code))
  {
  }

  /// Copy constructor.
  constexpr shader_module_create_info(
    const shader_module_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _code_size(other._code_size),
    _code(other._code)
  {
  }

  /// Move constructor.
  constexpr shader_module_create_info(
    shader_module_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _code_size(std::move(other._code_size)),
    _code(std::move(other._code))
  {
  }

  /// Copy assignment operator.
  constexpr shader_module_create_info& operator=(
    const shader_module_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _code_size = other._code_size;
    _code = other._code;
    return *this;
  }

  /// Move assignment operator.
  constexpr shader_module_create_info& operator=(
    shader_module_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _code_size = std::move(other._code_size);
    _code = std::move(other._code);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkShaderModuleCreateInfo&() const
  {
    return *reinterpret_cast<const VkShaderModuleCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::shader_module_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::shader_module_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::shader_module_create_flags new_flags)
  {
    _flags = new_flags;
  }

  size_t& code_size()
  {
    return _code_size;
  }

  constexpr const size_t& code_size() const
  {
    return _code_size;
  }

  void code_size(size_t new_code_size)
  {
    _code_size = new_code_size;
  }

  const uint32_t* code()
  {
    return _code;
  }

  constexpr const uint32_t* code() const
  {
    return _code;
  }

  void code(const uint32_t* new_code)
  {
    _code = new_code;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::shader_module_create_info;
  const void* _next = nullptr;
  vk::shader_module_create_flags _flags = 0;
  /// Specified in bytes
  size_t _code_size = 0;
  /// Binary code of size codeSize
  const uint32_t* _code = nullptr;
};
static_assert(sizeof(shader_module_create_info) ==
                sizeof(::VkShaderModuleCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_shader_module(
  VkDevice device, const vk::shader_module_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkShaderModule* shader_module)
{
  return static_cast<vk::result>(vkCreateShaderModule(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkShaderModuleCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkShaderModule*>(shader_module)));
}
inline void destroy_shader_module(VkDevice device, VkShaderModule shader_module,
                                  const vk::allocation_callbacks* allocator)
{
  vkDestroyShaderModule(
    static_cast<VkDevice>(device), static_cast<VkShaderModule>(shader_module),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
enum class pipeline_cache_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_cache_create_flags =
  shift::core::bit_field<pipeline_cache_create_flag,
                         VkPipelineCacheCreateFlags>;
inline constexpr pipeline_cache_create_flags operator|(
  pipeline_cache_create_flag lhs, pipeline_cache_create_flag rhs)
{
  return pipeline_cache_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkPipelineCacheCreateInfo.
class pipeline_cache_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_cache_create_info() = default;

  /// Constructor.
  constexpr pipeline_cache_create_info(
    const void* initial_next, vk::pipeline_cache_create_flags initial_flags,
    size_t initial_initial_data_size, const void* initial_initial_data) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _initial_data_size(std::move(initial_initial_data_size)),
    _initial_data(std::move(initial_initial_data))
  {
  }

  /// Copy constructor.
  constexpr pipeline_cache_create_info(
    const pipeline_cache_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _initial_data_size(other._initial_data_size),
    _initial_data(other._initial_data)
  {
  }

  /// Move constructor.
  constexpr pipeline_cache_create_info(
    pipeline_cache_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _initial_data_size(std::move(other._initial_data_size)),
    _initial_data(std::move(other._initial_data))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_cache_create_info& operator=(
    const pipeline_cache_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _initial_data_size = other._initial_data_size;
    _initial_data = other._initial_data;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_cache_create_info& operator=(
    pipeline_cache_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _initial_data_size = std::move(other._initial_data_size);
    _initial_data = std::move(other._initial_data);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineCacheCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineCacheCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_cache_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_cache_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_cache_create_flags new_flags)
  {
    _flags = new_flags;
  }

  size_t& initial_data_size()
  {
    return _initial_data_size;
  }

  constexpr const size_t& initial_data_size() const
  {
    return _initial_data_size;
  }

  void initial_data_size(size_t new_initial_data_size)
  {
    _initial_data_size = new_initial_data_size;
  }

  const void* initial_data()
  {
    return _initial_data;
  }

  constexpr const void* initial_data() const
  {
    return _initial_data;
  }

  void initial_data(const void* new_initial_data)
  {
    _initial_data = new_initial_data;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_cache_create_info;
  const void* _next = nullptr;
  vk::pipeline_cache_create_flags _flags = vk::pipeline_cache_create_flag::none;
  /// Size of initial data to populate cache, in bytes
  size_t _initial_data_size = 0;
  /// Initial data to populate cache
  const void* _initial_data = nullptr;
};
static_assert(sizeof(pipeline_cache_create_info) ==
                sizeof(::VkPipelineCacheCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_pipeline_cache(
  VkDevice device, const vk::pipeline_cache_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkPipelineCache* pipeline_cache)
{
  return static_cast<vk::result>(vkCreatePipelineCache(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkPipelineCacheCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkPipelineCache*>(pipeline_cache)));
}
inline void destroy_pipeline_cache(VkDevice device,
                                   VkPipelineCache pipeline_cache,
                                   const vk::allocation_callbacks* allocator)
{
  vkDestroyPipelineCache(
    static_cast<VkDevice>(device), static_cast<VkPipelineCache>(pipeline_cache),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result get_pipeline_cache_data(VkDevice device,
                                          VkPipelineCache pipeline_cache,
                                          size_t* data_size, void* data)
{
  return static_cast<vk::result>(vkGetPipelineCacheData(
    static_cast<VkDevice>(device), static_cast<VkPipelineCache>(pipeline_cache),
    reinterpret_cast<size_t*>(data_size), reinterpret_cast<void*>(data)));
}
inline vk::result merge_pipeline_caches(VkDevice device,
                                        VkPipelineCache dst_cache,
                                        uint32_t src_cache_count,
                                        const VkPipelineCache* src_caches)
{
  return static_cast<vk::result>(vkMergePipelineCaches(
    static_cast<VkDevice>(device), static_cast<VkPipelineCache>(dst_cache),
    static_cast<uint32_t>(src_cache_count),
    reinterpret_cast<const VkPipelineCache*>(src_caches)));
}
enum class pipeline_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_PIPELINE_CREATE_DISABLE_OPTIMIZATION_BIT
  disable_optimization_bit = 1 << 0,
  /// @see VK_PIPELINE_CREATE_ALLOW_DERIVATIVES_BIT
  allow_derivatives_bit = 1 << 1,
  /// @see VK_PIPELINE_CREATE_DERIVATIVE_BIT
  derivative_bit = 1 << 2,
  /// @see VK_PIPELINE_CREATE_VIEW_INDEX_FROM_DEVICE_INDEX_BIT
  view_index_from_device_index_bit = 1 << 3,
  /// @see VK_PIPELINE_CREATE_DISPATCH_BASE
  dispatch_base = 1 << 4,
  /// @see VK_PIPELINE_CREATE_DEFER_COMPILE_BIT_NVX
  defer_compile_bit_nvx = 1 << 5,
};
using pipeline_create_flags =
  shift::core::bit_field<pipeline_create_flag, VkPipelineCreateFlags>;
inline constexpr pipeline_create_flags operator|(pipeline_create_flag lhs,
                                                 pipeline_create_flag rhs)
{
  return pipeline_create_flags{lhs} | rhs;
}
enum class pipeline_shader_stage_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_shader_stage_create_flags =
  shift::core::bit_field<pipeline_shader_stage_create_flag,
                         VkPipelineShaderStageCreateFlags>;
inline constexpr pipeline_shader_stage_create_flags operator|(
  pipeline_shader_stage_create_flag lhs, pipeline_shader_stage_create_flag rhs)
{
  return pipeline_shader_stage_create_flags{lhs} | rhs;
}
enum class shader_stage_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_SHADER_STAGE_VERTEX_BIT
  vertex_bit = 1 << 0,
  /// @see VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT
  tessellation_control_bit = 1 << 1,
  /// @see VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT
  tessellation_evaluation_bit = 1 << 2,
  /// @see VK_SHADER_STAGE_GEOMETRY_BIT
  geometry_bit = 1 << 3,
  /// @see VK_SHADER_STAGE_FRAGMENT_BIT
  fragment_bit = 1 << 4,
  /// @see VK_SHADER_STAGE_COMPUTE_BIT
  compute_bit = 1 << 5,
  /// @see VK_SHADER_STAGE_ALL_GRAPHICS
  all_graphics = 0x0000001F,
  /// @see VK_SHADER_STAGE_ALL
  all = 0x7FFFFFFF,
  /// @see VK_SHADER_STAGE_RAYGEN_BIT_NVX
  raygen_bit_nvx = 1 << 8,
  /// @see VK_SHADER_STAGE_ANY_HIT_BIT_NVX
  any_hit_bit_nvx = 1 << 9,
  /// @see VK_SHADER_STAGE_CLOSEST_HIT_BIT_NVX
  closest_hit_bit_nvx = 1 << 10,
  /// @see VK_SHADER_STAGE_MISS_BIT_NVX
  miss_bit_nvx = 1 << 11,
  /// @see VK_SHADER_STAGE_INTERSECTION_BIT_NVX
  intersection_bit_nvx = 1 << 12,
  /// @see VK_SHADER_STAGE_CALLABLE_BIT_NVX
  callable_bit_nvx = 1 << 13,
  /// @see VK_SHADER_STAGE_TASK_BIT_NV
  task_bit_nv = 1 << 6,
  /// @see VK_SHADER_STAGE_MESH_BIT_NV
  mesh_bit_nv = 1 << 7,
};

/// Enhanced replacement type for VkSpecializationMapEntry.
class specialization_map_entry
{
public:
  /// Default constructor.
  constexpr specialization_map_entry() = default;

  /// Constructor.
  constexpr specialization_map_entry(uint32_t initial_constant_id,
                                     uint32_t initial_offset,
                                     size_t initial_size) noexcept
  : _constant_id(std::move(initial_constant_id)),
    _offset(std::move(initial_offset)),
    _size(std::move(initial_size))
  {
  }

  /// Copy constructor.
  constexpr specialization_map_entry(const specialization_map_entry& other) =
    default;

  /// Move constructor.
  constexpr specialization_map_entry(specialization_map_entry&& other) =
    default;

  /// Copy assignment operator.
  constexpr specialization_map_entry& operator=(
    const specialization_map_entry& other) = default;

  /// Move assignment operator.
  constexpr specialization_map_entry& operator=(
    specialization_map_entry&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSpecializationMapEntry&() const
  {
    return *reinterpret_cast<const VkSpecializationMapEntry*>(this);
  }

  uint32_t& constant_id()
  {
    return _constant_id;
  }

  constexpr const uint32_t& constant_id() const
  {
    return _constant_id;
  }

  void constant_id(uint32_t new_constant_id)
  {
    _constant_id = new_constant_id;
  }

  uint32_t& offset()
  {
    return _offset;
  }

  constexpr const uint32_t& offset() const
  {
    return _offset;
  }

  void offset(uint32_t new_offset)
  {
    _offset = new_offset;
  }

  size_t& size()
  {
    return _size;
  }

  constexpr const size_t& size() const
  {
    return _size;
  }

  void size(size_t new_size)
  {
    _size = new_size;
  }

private:
  /// The SpecConstant ID specified in the BIL
  uint32_t _constant_id = 0;
  /// Offset of the value in the data block
  uint32_t _offset = 0;
  /// Size in bytes of the SpecConstant
  size_t _size = 0;
};
static_assert(sizeof(specialization_map_entry) ==
                sizeof(::VkSpecializationMapEntry),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSpecializationInfo.
class specialization_info
{
public:
  /// Default constructor.
  constexpr specialization_info() = default;

  /// Constructor.
  constexpr specialization_info(
    uint32_t initial_map_entry_count,
    const vk::specialization_map_entry* initial_map_entries,
    size_t initial_data_size, const void* initial_data) noexcept
  : _map_entry_count(std::move(initial_map_entry_count)),
    _map_entries(std::move(initial_map_entries)),
    _data_size(std::move(initial_data_size)),
    _data(std::move(initial_data))
  {
  }

  /// Copy constructor.
  constexpr specialization_info(const specialization_info& other) = default;

  /// Move constructor.
  constexpr specialization_info(specialization_info&& other) = default;

  /// Copy assignment operator.
  constexpr specialization_info& operator=(const specialization_info& other) =
    default;

  /// Move assignment operator.
  constexpr specialization_info& operator=(specialization_info&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkSpecializationInfo&() const
  {
    return *reinterpret_cast<const VkSpecializationInfo*>(this);
  }

  uint32_t& map_entry_count()
  {
    return _map_entry_count;
  }

  constexpr const uint32_t& map_entry_count() const
  {
    return _map_entry_count;
  }

  void map_entry_count(uint32_t new_map_entry_count)
  {
    _map_entry_count = new_map_entry_count;
  }

  const vk::specialization_map_entry* map_entries()
  {
    return _map_entries;
  }

  constexpr const vk::specialization_map_entry* map_entries() const
  {
    return _map_entries;
  }

  void map_entries(const vk::specialization_map_entry* new_map_entries)
  {
    _map_entries = new_map_entries;
  }

  template <std::size_t Count>
  void map_entries(
    const std::array<vk::specialization_map_entry, Count>& new_map_entries)
  {
    _map_entry_count = static_cast<uint32_t>(new_map_entries.size());
    _map_entries = new_map_entries.data();
  }

  void map_entries(
    const std::vector<vk::specialization_map_entry>& new_map_entries)
  {
    _map_entry_count = static_cast<uint32_t>(new_map_entries.size());
    _map_entries = new_map_entries.data();
  }

  size_t& data_size()
  {
    return _data_size;
  }

  constexpr const size_t& data_size() const
  {
    return _data_size;
  }

  void data_size(size_t new_data_size)
  {
    _data_size = new_data_size;
  }

  const void* data()
  {
    return _data;
  }

  constexpr const void* data() const
  {
    return _data;
  }

  void data(const void* new_data)
  {
    _data = new_data;
  }

private:
  /// Number of entries in the map
  uint32_t _map_entry_count = 0;
  /// Array of map entries
  const vk::specialization_map_entry* _map_entries = nullptr;
  /// Size in bytes of pData
  size_t _data_size = 0;
  /// Pointer to SpecConstant data
  const void* _data = nullptr;
};
static_assert(sizeof(specialization_info) == sizeof(::VkSpecializationInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPipelineShaderStageCreateInfo.
class pipeline_shader_stage_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_shader_stage_create_info() = default;

  /// Constructor.
  constexpr pipeline_shader_stage_create_info(
    const void* initial_next,
    vk::pipeline_shader_stage_create_flags initial_flags,
    vk::shader_stage_flag initial_stage, VkShaderModule initial_module,
    const char* initial_name,
    const vk::specialization_info* initial_specialization_info) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _stage(std::move(initial_stage)),
    _module(std::move(initial_module)),
    _name(std::move(initial_name)),
    _specialization_info(std::move(initial_specialization_info))
  {
  }

  /// Copy constructor.
  constexpr pipeline_shader_stage_create_info(
    const pipeline_shader_stage_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _stage(other._stage),
    _module(other._module),
    _name(other._name),
    _specialization_info(other._specialization_info)
  {
  }

  /// Move constructor.
  constexpr pipeline_shader_stage_create_info(
    pipeline_shader_stage_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _stage(std::move(other._stage)),
    _module(std::move(other._module)),
    _name(std::move(other._name)),
    _specialization_info(std::move(other._specialization_info))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_shader_stage_create_info& operator=(
    const pipeline_shader_stage_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _stage = other._stage;
    _module = other._module;
    _name = other._name;
    _specialization_info = other._specialization_info;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_shader_stage_create_info& operator=(
    pipeline_shader_stage_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _stage = std::move(other._stage);
    _module = std::move(other._module);
    _name = std::move(other._name);
    _specialization_info = std::move(other._specialization_info);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineShaderStageCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineShaderStageCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_shader_stage_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_shader_stage_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_shader_stage_create_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::shader_stage_flag& stage()
  {
    return _stage;
  }

  constexpr const vk::shader_stage_flag& stage() const
  {
    return _stage;
  }

  void stage(vk::shader_stage_flag new_stage)
  {
    _stage = new_stage;
  }

  VkShaderModule& module()
  {
    return _module;
  }

  constexpr const VkShaderModule& module() const
  {
    return _module;
  }

  void module(VkShaderModule new_module)
  {
    _module = new_module;
  }

  const char* name()
  {
    return _name;
  }

  constexpr const char* name() const
  {
    return _name;
  }

  void name(const char* new_name)
  {
    _name = new_name;
  }

  const vk::specialization_info* specialization_info()
  {
    return _specialization_info;
  }

  constexpr const vk::specialization_info* specialization_info() const
  {
    return _specialization_info;
  }

  void specialization_info(
    const vk::specialization_info* new_specialization_info)
  {
    _specialization_info = new_specialization_info;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_shader_stage_create_info;
  const void* _next = nullptr;
  vk::pipeline_shader_stage_create_flags _flags =
    vk::pipeline_shader_stage_create_flag::none;
  /// Shader stage
  vk::shader_stage_flag _stage = vk::shader_stage_flag::none;
  /// Module containing entry point
  VkShaderModule _module = nullptr;
  /// Null-terminated entry point name
  const char* _name = nullptr;
  const vk::specialization_info* _specialization_info = nullptr;
};
static_assert(sizeof(pipeline_shader_stage_create_info) ==
                sizeof(::VkPipelineShaderStageCreateInfo),
              "struct and wrapper have different size!");

enum class pipeline_vertex_input_state_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_vertex_input_state_create_flags =
  shift::core::bit_field<pipeline_vertex_input_state_create_flag,
                         VkPipelineVertexInputStateCreateFlags>;
inline constexpr pipeline_vertex_input_state_create_flags operator|(
  pipeline_vertex_input_state_create_flag lhs,
  pipeline_vertex_input_state_create_flag rhs)
{
  return pipeline_vertex_input_state_create_flags{lhs} | rhs;
}
enum class vertex_input_rate
{
  /// @see VK_VERTEX_INPUT_RATE_VERTEX
  vertex = 0,
  /// @see VK_VERTEX_INPUT_RATE_INSTANCE
  instance = 1,
};

/// Enhanced replacement type for VkVertexInputBindingDescription.
class vertex_input_binding_description
{
public:
  /// Default constructor.
  constexpr vertex_input_binding_description() = default;

  /// Constructor.
  constexpr vertex_input_binding_description(
    uint32_t initial_binding, uint32_t initial_stride,
    vk::vertex_input_rate initial_input_rate) noexcept
  : _binding(std::move(initial_binding)),
    _stride(std::move(initial_stride)),
    _input_rate(std::move(initial_input_rate))
  {
  }

  /// Copy constructor.
  constexpr vertex_input_binding_description(
    const vertex_input_binding_description& other) = default;

  /// Move constructor.
  constexpr vertex_input_binding_description(
    vertex_input_binding_description&& other) = default;

  /// Copy assignment operator.
  constexpr vertex_input_binding_description& operator=(
    const vertex_input_binding_description& other) = default;

  /// Move assignment operator.
  constexpr vertex_input_binding_description& operator=(
    vertex_input_binding_description&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkVertexInputBindingDescription&() const
  {
    return *reinterpret_cast<const VkVertexInputBindingDescription*>(this);
  }

  uint32_t& binding()
  {
    return _binding;
  }

  constexpr const uint32_t& binding() const
  {
    return _binding;
  }

  void binding(uint32_t new_binding)
  {
    _binding = new_binding;
  }

  uint32_t& stride()
  {
    return _stride;
  }

  constexpr const uint32_t& stride() const
  {
    return _stride;
  }

  void stride(uint32_t new_stride)
  {
    _stride = new_stride;
  }

  vk::vertex_input_rate& input_rate()
  {
    return _input_rate;
  }

  constexpr const vk::vertex_input_rate& input_rate() const
  {
    return _input_rate;
  }

  void input_rate(vk::vertex_input_rate new_input_rate)
  {
    _input_rate = new_input_rate;
  }

private:
  /// Vertex buffer binding id
  uint32_t _binding = 0;
  /// Distance between vertices in bytes (0 = no advancement)
  uint32_t _stride = 0;
  /// The rate at which the vertex data is consumed
  vk::vertex_input_rate _input_rate = vk::vertex_input_rate::vertex;
};
static_assert(sizeof(vertex_input_binding_description) ==
                sizeof(::VkVertexInputBindingDescription),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkVertexInputAttributeDescription.
class vertex_input_attribute_description
{
public:
  /// Default constructor.
  constexpr vertex_input_attribute_description() = default;

  /// Constructor.
  constexpr vertex_input_attribute_description(uint32_t initial_location,
                                               uint32_t initial_binding,
                                               vk::format initial_format,
                                               uint32_t initial_offset) noexcept
  : _location(std::move(initial_location)),
    _binding(std::move(initial_binding)),
    _format(std::move(initial_format)),
    _offset(std::move(initial_offset))
  {
  }

  /// Copy constructor.
  constexpr vertex_input_attribute_description(
    const vertex_input_attribute_description& other) = default;

  /// Move constructor.
  constexpr vertex_input_attribute_description(
    vertex_input_attribute_description&& other) = default;

  /// Copy assignment operator.
  constexpr vertex_input_attribute_description& operator=(
    const vertex_input_attribute_description& other) = default;

  /// Move assignment operator.
  constexpr vertex_input_attribute_description& operator=(
    vertex_input_attribute_description&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkVertexInputAttributeDescription&() const
  {
    return *reinterpret_cast<const VkVertexInputAttributeDescription*>(this);
  }

  uint32_t& location()
  {
    return _location;
  }

  constexpr const uint32_t& location() const
  {
    return _location;
  }

  void location(uint32_t new_location)
  {
    _location = new_location;
  }

  uint32_t& binding()
  {
    return _binding;
  }

  constexpr const uint32_t& binding() const
  {
    return _binding;
  }

  void binding(uint32_t new_binding)
  {
    _binding = new_binding;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  uint32_t& offset()
  {
    return _offset;
  }

  constexpr const uint32_t& offset() const
  {
    return _offset;
  }

  void offset(uint32_t new_offset)
  {
    _offset = new_offset;
  }

private:
  /// location of the shader vertex attrib
  uint32_t _location = 0;
  /// Vertex buffer binding id
  uint32_t _binding = 0;
  /// format of source data
  vk::format _format = vk::format::undefined;
  /// Offset of first element in bytes from base of vertex
  uint32_t _offset = 0;
};
static_assert(sizeof(vertex_input_attribute_description) ==
                sizeof(::VkVertexInputAttributeDescription),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPipelineVertexInputStateCreateInfo.
class pipeline_vertex_input_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_vertex_input_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_vertex_input_state_create_info(
    const void* initial_next,
    vk::pipeline_vertex_input_state_create_flags initial_flags,
    uint32_t initial_vertex_binding_description_count,
    const vk::vertex_input_binding_description*
      initial_vertex_binding_descriptions,
    uint32_t initial_vertex_attribute_description_count,
    const vk::vertex_input_attribute_description*
      initial_vertex_attribute_descriptions) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _vertex_binding_description_count(
      std::move(initial_vertex_binding_description_count)),
    _vertex_binding_descriptions(
      std::move(initial_vertex_binding_descriptions)),
    _vertex_attribute_description_count(
      std::move(initial_vertex_attribute_description_count)),
    _vertex_attribute_descriptions(
      std::move(initial_vertex_attribute_descriptions))
  {
  }

  /// Copy constructor.
  constexpr pipeline_vertex_input_state_create_info(
    const pipeline_vertex_input_state_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _vertex_binding_description_count(other._vertex_binding_description_count),
    _vertex_binding_descriptions(other._vertex_binding_descriptions),
    _vertex_attribute_description_count(
      other._vertex_attribute_description_count),
    _vertex_attribute_descriptions(other._vertex_attribute_descriptions)
  {
  }

  /// Move constructor.
  constexpr pipeline_vertex_input_state_create_info(
    pipeline_vertex_input_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _vertex_binding_description_count(
      std::move(other._vertex_binding_description_count)),
    _vertex_binding_descriptions(std::move(other._vertex_binding_descriptions)),
    _vertex_attribute_description_count(
      std::move(other._vertex_attribute_description_count)),
    _vertex_attribute_descriptions(
      std::move(other._vertex_attribute_descriptions))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_vertex_input_state_create_info& operator=(
    const pipeline_vertex_input_state_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _vertex_binding_description_count = other._vertex_binding_description_count;
    _vertex_binding_descriptions = other._vertex_binding_descriptions;
    _vertex_attribute_description_count =
      other._vertex_attribute_description_count;
    _vertex_attribute_descriptions = other._vertex_attribute_descriptions;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_vertex_input_state_create_info& operator=(
    pipeline_vertex_input_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _vertex_binding_description_count =
      std::move(other._vertex_binding_description_count);
    _vertex_binding_descriptions =
      std::move(other._vertex_binding_descriptions);
    _vertex_attribute_description_count =
      std::move(other._vertex_attribute_description_count);
    _vertex_attribute_descriptions =
      std::move(other._vertex_attribute_descriptions);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineVertexInputStateCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineVertexInputStateCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_vertex_input_state_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_vertex_input_state_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_vertex_input_state_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& vertex_binding_description_count()
  {
    return _vertex_binding_description_count;
  }

  constexpr const uint32_t& vertex_binding_description_count() const
  {
    return _vertex_binding_description_count;
  }

  void vertex_binding_description_count(
    uint32_t new_vertex_binding_description_count)
  {
    _vertex_binding_description_count = new_vertex_binding_description_count;
  }

  const vk::vertex_input_binding_description* vertex_binding_descriptions()
  {
    return _vertex_binding_descriptions;
  }

  constexpr const vk::vertex_input_binding_description*
  vertex_binding_descriptions() const
  {
    return _vertex_binding_descriptions;
  }

  void vertex_binding_descriptions(
    const vk::vertex_input_binding_description* new_vertex_binding_descriptions)
  {
    _vertex_binding_descriptions = new_vertex_binding_descriptions;
  }

  template <std::size_t Count>
  void vertex_binding_descriptions(
    const std::array<vk::vertex_input_binding_description, Count>&
      new_vertex_binding_descriptions)
  {
    _vertex_binding_description_count =
      static_cast<uint32_t>(new_vertex_binding_descriptions.size());
    _vertex_binding_descriptions = new_vertex_binding_descriptions.data();
  }

  void vertex_binding_descriptions(
    const std::vector<vk::vertex_input_binding_description>&
      new_vertex_binding_descriptions)
  {
    _vertex_binding_description_count =
      static_cast<uint32_t>(new_vertex_binding_descriptions.size());
    _vertex_binding_descriptions = new_vertex_binding_descriptions.data();
  }

  uint32_t& vertex_attribute_description_count()
  {
    return _vertex_attribute_description_count;
  }

  constexpr const uint32_t& vertex_attribute_description_count() const
  {
    return _vertex_attribute_description_count;
  }

  void vertex_attribute_description_count(
    uint32_t new_vertex_attribute_description_count)
  {
    _vertex_attribute_description_count =
      new_vertex_attribute_description_count;
  }

  const vk::vertex_input_attribute_description* vertex_attribute_descriptions()
  {
    return _vertex_attribute_descriptions;
  }

  constexpr const vk::vertex_input_attribute_description*
  vertex_attribute_descriptions() const
  {
    return _vertex_attribute_descriptions;
  }

  void vertex_attribute_descriptions(
    const vk::vertex_input_attribute_description*
      new_vertex_attribute_descriptions)
  {
    _vertex_attribute_descriptions = new_vertex_attribute_descriptions;
  }

  template <std::size_t Count>
  void vertex_attribute_descriptions(
    const std::array<vk::vertex_input_attribute_description, Count>&
      new_vertex_attribute_descriptions)
  {
    _vertex_attribute_description_count =
      static_cast<uint32_t>(new_vertex_attribute_descriptions.size());
    _vertex_attribute_descriptions = new_vertex_attribute_descriptions.data();
  }

  void vertex_attribute_descriptions(
    const std::vector<vk::vertex_input_attribute_description>&
      new_vertex_attribute_descriptions)
  {
    _vertex_attribute_description_count =
      static_cast<uint32_t>(new_vertex_attribute_descriptions.size());
    _vertex_attribute_descriptions = new_vertex_attribute_descriptions.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_vertex_input_state_create_info;
  const void* _next = nullptr;
  vk::pipeline_vertex_input_state_create_flags _flags =
    vk::pipeline_vertex_input_state_create_flag::none;
  /// number of bindings
  uint32_t _vertex_binding_description_count = 0;
  const vk::vertex_input_binding_description* _vertex_binding_descriptions =
    nullptr;
  /// number of attributes
  uint32_t _vertex_attribute_description_count = 0;
  const vk::vertex_input_attribute_description* _vertex_attribute_descriptions =
    nullptr;
};
static_assert(sizeof(pipeline_vertex_input_state_create_info) ==
                sizeof(::VkPipelineVertexInputStateCreateInfo),
              "struct and wrapper have different size!");

enum class pipeline_input_assembly_state_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_input_assembly_state_create_flags =
  shift::core::bit_field<pipeline_input_assembly_state_create_flag,
                         VkPipelineInputAssemblyStateCreateFlags>;
inline constexpr pipeline_input_assembly_state_create_flags operator|(
  pipeline_input_assembly_state_create_flag lhs,
  pipeline_input_assembly_state_create_flag rhs)
{
  return pipeline_input_assembly_state_create_flags{lhs} | rhs;
}
enum class primitive_topology
{
  /// @see VK_PRIMITIVE_TOPOLOGY_POINT_LIST
  point_list = 0,
  /// @see VK_PRIMITIVE_TOPOLOGY_LINE_LIST
  line_list = 1,
  /// @see VK_PRIMITIVE_TOPOLOGY_LINE_STRIP
  line_strip = 2,
  /// @see VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST
  triangle_list = 3,
  /// @see VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP
  triangle_strip = 4,
  /// @see VK_PRIMITIVE_TOPOLOGY_TRIANGLE_FAN
  triangle_fan = 5,
  /// @see VK_PRIMITIVE_TOPOLOGY_LINE_LIST_WITH_ADJACENCY
  line_list_with_adjacency = 6,
  /// @see VK_PRIMITIVE_TOPOLOGY_LINE_STRIP_WITH_ADJACENCY
  line_strip_with_adjacency = 7,
  /// @see VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST_WITH_ADJACENCY
  triangle_list_with_adjacency = 8,
  /// @see VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP_WITH_ADJACENCY
  triangle_strip_with_adjacency = 9,
  /// @see VK_PRIMITIVE_TOPOLOGY_PATCH_LIST
  patch_list = 10,
};

/// Enhanced replacement type for VkPipelineInputAssemblyStateCreateInfo.
class pipeline_input_assembly_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_input_assembly_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_input_assembly_state_create_info(
    const void* initial_next,
    vk::pipeline_input_assembly_state_create_flags initial_flags,
    vk::primitive_topology initial_topology,
    VkBool32 initial_primitive_restart_enable) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _topology(std::move(initial_topology)),
    _primitive_restart_enable(std::move(initial_primitive_restart_enable))
  {
  }

  /// Copy constructor.
  constexpr pipeline_input_assembly_state_create_info(
    const pipeline_input_assembly_state_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _topology(other._topology),
    _primitive_restart_enable(other._primitive_restart_enable)
  {
  }

  /// Move constructor.
  constexpr pipeline_input_assembly_state_create_info(
    pipeline_input_assembly_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _topology(std::move(other._topology)),
    _primitive_restart_enable(std::move(other._primitive_restart_enable))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_input_assembly_state_create_info& operator=(
    const pipeline_input_assembly_state_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _topology = other._topology;
    _primitive_restart_enable = other._primitive_restart_enable;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_input_assembly_state_create_info& operator=(
    pipeline_input_assembly_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _topology = std::move(other._topology);
    _primitive_restart_enable = std::move(other._primitive_restart_enable);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineInputAssemblyStateCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineInputAssemblyStateCreateInfo*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_input_assembly_state_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_input_assembly_state_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_input_assembly_state_create_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::primitive_topology& topology()
  {
    return _topology;
  }

  constexpr const vk::primitive_topology& topology() const
  {
    return _topology;
  }

  void topology(vk::primitive_topology new_topology)
  {
    _topology = new_topology;
  }

  VkBool32& primitive_restart_enable()
  {
    return _primitive_restart_enable;
  }

  constexpr const VkBool32& primitive_restart_enable() const
  {
    return _primitive_restart_enable;
  }

  void primitive_restart_enable(VkBool32 new_primitive_restart_enable)
  {
    _primitive_restart_enable = new_primitive_restart_enable;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_input_assembly_state_create_info;
  const void* _next = nullptr;
  vk::pipeline_input_assembly_state_create_flags _flags =
    vk::pipeline_input_assembly_state_create_flag::none;
  vk::primitive_topology _topology = vk::primitive_topology::point_list;
  VkBool32 _primitive_restart_enable = VK_FALSE;
};
static_assert(sizeof(pipeline_input_assembly_state_create_info) ==
                sizeof(::VkPipelineInputAssemblyStateCreateInfo),
              "struct and wrapper have different size!");

enum class pipeline_tessellation_state_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_tessellation_state_create_flags =
  shift::core::bit_field<pipeline_tessellation_state_create_flag,
                         VkPipelineTessellationStateCreateFlags>;
inline constexpr pipeline_tessellation_state_create_flags operator|(
  pipeline_tessellation_state_create_flag lhs,
  pipeline_tessellation_state_create_flag rhs)
{
  return pipeline_tessellation_state_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkPipelineTessellationStateCreateInfo.
class pipeline_tessellation_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_tessellation_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_tessellation_state_create_info(
    const void* initial_next,
    vk::pipeline_tessellation_state_create_flags initial_flags,
    uint32_t initial_patch_control_points) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _patch_control_points(std::move(initial_patch_control_points))
  {
  }

  /// Copy constructor.
  constexpr pipeline_tessellation_state_create_info(
    const pipeline_tessellation_state_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _patch_control_points(other._patch_control_points)
  {
  }

  /// Move constructor.
  constexpr pipeline_tessellation_state_create_info(
    pipeline_tessellation_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _patch_control_points(std::move(other._patch_control_points))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_tessellation_state_create_info& operator=(
    const pipeline_tessellation_state_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _patch_control_points = other._patch_control_points;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_tessellation_state_create_info& operator=(
    pipeline_tessellation_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _patch_control_points = std::move(other._patch_control_points);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineTessellationStateCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineTessellationStateCreateInfo*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_tessellation_state_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_tessellation_state_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_tessellation_state_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& patch_control_points()
  {
    return _patch_control_points;
  }

  constexpr const uint32_t& patch_control_points() const
  {
    return _patch_control_points;
  }

  void patch_control_points(uint32_t new_patch_control_points)
  {
    _patch_control_points = new_patch_control_points;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_tessellation_state_create_info;
  const void* _next = nullptr;
  vk::pipeline_tessellation_state_create_flags _flags =
    vk::pipeline_tessellation_state_create_flag::none;
  uint32_t _patch_control_points = 0;
};
static_assert(sizeof(pipeline_tessellation_state_create_info) ==
                sizeof(::VkPipelineTessellationStateCreateInfo),
              "struct and wrapper have different size!");

enum class pipeline_viewport_state_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_viewport_state_create_flags =
  shift::core::bit_field<pipeline_viewport_state_create_flag,
                         VkPipelineViewportStateCreateFlags>;
inline constexpr pipeline_viewport_state_create_flags operator|(
  pipeline_viewport_state_create_flag lhs,
  pipeline_viewport_state_create_flag rhs)
{
  return pipeline_viewport_state_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkViewport.
class viewport
{
public:
  /// Default constructor.
  constexpr viewport() = default;

  /// Constructor.
  constexpr viewport(float initial_x, float initial_y, float initial_width,
                     float initial_height, float initial_min_depth,
                     float initial_max_depth) noexcept
  : _x(std::move(initial_x)),
    _y(std::move(initial_y)),
    _width(std::move(initial_width)),
    _height(std::move(initial_height)),
    _min_depth(std::move(initial_min_depth)),
    _max_depth(std::move(initial_max_depth))
  {
  }

  /// Copy constructor.
  constexpr viewport(const viewport& other) = default;

  /// Move constructor.
  constexpr viewport(viewport&& other) = default;

  /// Copy assignment operator.
  constexpr viewport& operator=(const viewport& other) = default;

  /// Move assignment operator.
  constexpr viewport& operator=(viewport&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkViewport&() const
  {
    return *reinterpret_cast<const VkViewport*>(this);
  }

  float& x()
  {
    return _x;
  }

  constexpr const float& x() const
  {
    return _x;
  }

  void x(float new_x)
  {
    _x = new_x;
  }

  float& y()
  {
    return _y;
  }

  constexpr const float& y() const
  {
    return _y;
  }

  void y(float new_y)
  {
    _y = new_y;
  }

  float& width()
  {
    return _width;
  }

  constexpr const float& width() const
  {
    return _width;
  }

  void width(float new_width)
  {
    _width = new_width;
  }

  float& height()
  {
    return _height;
  }

  constexpr const float& height() const
  {
    return _height;
  }

  void height(float new_height)
  {
    _height = new_height;
  }

  float& min_depth()
  {
    return _min_depth;
  }

  constexpr const float& min_depth() const
  {
    return _min_depth;
  }

  void min_depth(float new_min_depth)
  {
    _min_depth = new_min_depth;
  }

  float& max_depth()
  {
    return _max_depth;
  }

  constexpr const float& max_depth() const
  {
    return _max_depth;
  }

  void max_depth(float new_max_depth)
  {
    _max_depth = new_max_depth;
  }

private:
  float _x = 0.0f;
  float _y = 0.0f;
  float _width = 0.0f;
  float _height = 0.0f;
  float _min_depth = 0.0f;
  float _max_depth = 0.0f;
};
static_assert(sizeof(viewport) == sizeof(::VkViewport),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkOffset2D.
class offset_2d
{
public:
  /// Default constructor.
  constexpr offset_2d() = default;

  /// Constructor.
  constexpr offset_2d(int32_t initial_x, int32_t initial_y) noexcept
  : _x(std::move(initial_x)), _y(std::move(initial_y))
  {
  }

  /// Copy constructor.
  constexpr offset_2d(const offset_2d& other) = default;

  /// Move constructor.
  constexpr offset_2d(offset_2d&& other) = default;

  /// Copy assignment operator.
  constexpr offset_2d& operator=(const offset_2d& other) = default;

  /// Move assignment operator.
  constexpr offset_2d& operator=(offset_2d&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkOffset2D&() const
  {
    return *reinterpret_cast<const VkOffset2D*>(this);
  }

  int32_t& x()
  {
    return _x;
  }

  constexpr const int32_t& x() const
  {
    return _x;
  }

  void x(int32_t new_x)
  {
    _x = new_x;
  }

  int32_t& y()
  {
    return _y;
  }

  constexpr const int32_t& y() const
  {
    return _y;
  }

  void y(int32_t new_y)
  {
    _y = new_y;
  }

private:
  int32_t _x = 0;
  int32_t _y = 0;
};
static_assert(sizeof(offset_2d) == sizeof(::VkOffset2D),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkExtent2D.
class extent_2d
{
public:
  /// Default constructor.
  constexpr extent_2d() = default;

  /// Constructor.
  constexpr extent_2d(uint32_t initial_width, uint32_t initial_height) noexcept
  : _width(std::move(initial_width)), _height(std::move(initial_height))
  {
  }

  /// Copy constructor.
  constexpr extent_2d(const extent_2d& other) = default;

  /// Move constructor.
  constexpr extent_2d(extent_2d&& other) = default;

  /// Copy assignment operator.
  constexpr extent_2d& operator=(const extent_2d& other) = default;

  /// Move assignment operator.
  constexpr extent_2d& operator=(extent_2d&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkExtent2D&() const
  {
    return *reinterpret_cast<const VkExtent2D*>(this);
  }

  uint32_t& width()
  {
    return _width;
  }

  constexpr const uint32_t& width() const
  {
    return _width;
  }

  void width(uint32_t new_width)
  {
    _width = new_width;
  }

  uint32_t& height()
  {
    return _height;
  }

  constexpr const uint32_t& height() const
  {
    return _height;
  }

  void height(uint32_t new_height)
  {
    _height = new_height;
  }

private:
  uint32_t _width = 0;
  uint32_t _height = 0;
};
static_assert(sizeof(extent_2d) == sizeof(::VkExtent2D),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkRect2D.
class rect_2d
{
public:
  /// Default constructor.
  constexpr rect_2d() = default;

  /// Constructor.
  constexpr rect_2d(vk::offset_2d initial_offset,
                    vk::extent_2d initial_extent) noexcept
  : _offset(std::move(initial_offset)), _extent(std::move(initial_extent))
  {
  }

  /// Copy constructor.
  constexpr rect_2d(const rect_2d& other) = default;

  /// Move constructor.
  constexpr rect_2d(rect_2d&& other) = default;

  /// Copy assignment operator.
  constexpr rect_2d& operator=(const rect_2d& other) = default;

  /// Move assignment operator.
  constexpr rect_2d& operator=(rect_2d&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkRect2D&() const
  {
    return *reinterpret_cast<const VkRect2D*>(this);
  }

  vk::offset_2d& offset()
  {
    return _offset;
  }

  constexpr const vk::offset_2d& offset() const
  {
    return _offset;
  }

  void offset(vk::offset_2d new_offset)
  {
    _offset = new_offset;
  }

  vk::extent_2d& extent()
  {
    return _extent;
  }

  constexpr const vk::extent_2d& extent() const
  {
    return _extent;
  }

  void extent(vk::extent_2d new_extent)
  {
    _extent = new_extent;
  }

private:
  vk::offset_2d _offset = vk::offset_2d{};
  vk::extent_2d _extent = vk::extent_2d{};
};
static_assert(sizeof(rect_2d) == sizeof(::VkRect2D),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPipelineViewportStateCreateInfo.
class pipeline_viewport_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_viewport_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_viewport_state_create_info(
    const void* initial_next,
    vk::pipeline_viewport_state_create_flags initial_flags,
    uint32_t initial_viewport_count, const vk::viewport* initial_viewports,
    uint32_t initial_scissor_count,
    const vk::rect_2d* initial_scissors) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _viewport_count(std::move(initial_viewport_count)),
    _viewports(std::move(initial_viewports)),
    _scissor_count(std::move(initial_scissor_count)),
    _scissors(std::move(initial_scissors))
  {
  }

  /// Copy constructor.
  constexpr pipeline_viewport_state_create_info(
    const pipeline_viewport_state_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _viewport_count(other._viewport_count),
    _viewports(other._viewports),
    _scissor_count(other._scissor_count),
    _scissors(other._scissors)
  {
  }

  /// Move constructor.
  constexpr pipeline_viewport_state_create_info(
    pipeline_viewport_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _viewport_count(std::move(other._viewport_count)),
    _viewports(std::move(other._viewports)),
    _scissor_count(std::move(other._scissor_count)),
    _scissors(std::move(other._scissors))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_viewport_state_create_info& operator=(
    const pipeline_viewport_state_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _viewport_count = other._viewport_count;
    _viewports = other._viewports;
    _scissor_count = other._scissor_count;
    _scissors = other._scissors;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_viewport_state_create_info& operator=(
    pipeline_viewport_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _viewport_count = std::move(other._viewport_count);
    _viewports = std::move(other._viewports);
    _scissor_count = std::move(other._scissor_count);
    _scissors = std::move(other._scissors);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineViewportStateCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineViewportStateCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_viewport_state_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_viewport_state_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_viewport_state_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& viewport_count()
  {
    return _viewport_count;
  }

  constexpr const uint32_t& viewport_count() const
  {
    return _viewport_count;
  }

  void viewport_count(uint32_t new_viewport_count)
  {
    _viewport_count = new_viewport_count;
  }

  const vk::viewport* viewports()
  {
    return _viewports;
  }

  constexpr const vk::viewport* viewports() const
  {
    return _viewports;
  }

  void viewports(const vk::viewport* new_viewports)
  {
    _viewports = new_viewports;
  }

  template <std::size_t Count>
  void viewports(const std::array<vk::viewport, Count>& new_viewports)
  {
    _viewport_count = static_cast<uint32_t>(new_viewports.size());
    _viewports = new_viewports.data();
  }

  void viewports(const std::vector<vk::viewport>& new_viewports)
  {
    _viewport_count = static_cast<uint32_t>(new_viewports.size());
    _viewports = new_viewports.data();
  }

  uint32_t& scissor_count()
  {
    return _scissor_count;
  }

  constexpr const uint32_t& scissor_count() const
  {
    return _scissor_count;
  }

  void scissor_count(uint32_t new_scissor_count)
  {
    _scissor_count = new_scissor_count;
  }

  const vk::rect_2d* scissors()
  {
    return _scissors;
  }

  constexpr const vk::rect_2d* scissors() const
  {
    return _scissors;
  }

  void scissors(const vk::rect_2d* new_scissors)
  {
    _scissors = new_scissors;
  }

  template <std::size_t Count>
  void scissors(const std::array<vk::rect_2d, Count>& new_scissors)
  {
    _scissor_count = static_cast<uint32_t>(new_scissors.size());
    _scissors = new_scissors.data();
  }

  void scissors(const std::vector<vk::rect_2d>& new_scissors)
  {
    _scissor_count = static_cast<uint32_t>(new_scissors.size());
    _scissors = new_scissors.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_viewport_state_create_info;
  const void* _next = nullptr;
  vk::pipeline_viewport_state_create_flags _flags =
    vk::pipeline_viewport_state_create_flag::none;
  uint32_t _viewport_count = 0;
  const vk::viewport* _viewports = nullptr;
  uint32_t _scissor_count = 0;
  const vk::rect_2d* _scissors = nullptr;
};
static_assert(sizeof(pipeline_viewport_state_create_info) ==
                sizeof(::VkPipelineViewportStateCreateInfo),
              "struct and wrapper have different size!");

enum class pipeline_rasterization_state_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_rasterization_state_create_flags =
  shift::core::bit_field<pipeline_rasterization_state_create_flag,
                         VkPipelineRasterizationStateCreateFlags>;
inline constexpr pipeline_rasterization_state_create_flags operator|(
  pipeline_rasterization_state_create_flag lhs,
  pipeline_rasterization_state_create_flag rhs)
{
  return pipeline_rasterization_state_create_flags{lhs} | rhs;
}
enum class polygon_mode
{
  /// @see VK_POLYGON_MODE_FILL
  fill = 0,
  /// @see VK_POLYGON_MODE_LINE
  line = 1,
  /// @see VK_POLYGON_MODE_POINT
  point = 2,
  /// @see VK_POLYGON_MODE_FILL_RECTANGLE_NV
  fill_rectangle_nv = 1000153000,
};
enum class cull_mode_flag
{
  /// @see VK_CULL_MODE_NONE
  none = 0,
  /// @see VK_CULL_MODE_FRONT_BIT
  front_bit = 1 << 0,
  /// @see VK_CULL_MODE_BACK_BIT
  back_bit = 1 << 1,
  /// @see VK_CULL_MODE_FRONT_AND_BACK
  front_and_back = 0x00000003,
};
using cull_mode_flags = shift::core::bit_field<cull_mode_flag, VkCullModeFlags>;
inline constexpr cull_mode_flags operator|(cull_mode_flag lhs,
                                           cull_mode_flag rhs)
{
  return cull_mode_flags{lhs} | rhs;
}
enum class front_face
{
  /// @see VK_FRONT_FACE_COUNTER_CLOCKWISE
  counter_clockwise = 0,
  /// @see VK_FRONT_FACE_CLOCKWISE
  clockwise = 1,
};

/// Enhanced replacement type for VkPipelineRasterizationStateCreateInfo.
class pipeline_rasterization_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_rasterization_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_rasterization_state_create_info(
    const void* initial_next,
    vk::pipeline_rasterization_state_create_flags initial_flags,
    VkBool32 initial_depth_clamp_enable,
    VkBool32 initial_rasterizer_discard_enable,
    vk::polygon_mode initial_polygon_mode,
    vk::cull_mode_flags initial_cull_mode, vk::front_face initial_front_face,
    VkBool32 initial_depth_bias_enable,
    float initial_depth_bias_constant_factor, float initial_depth_bias_clamp,
    float initial_depth_bias_slope_factor, float initial_line_width) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _depth_clamp_enable(std::move(initial_depth_clamp_enable)),
    _rasterizer_discard_enable(std::move(initial_rasterizer_discard_enable)),
    _polygon_mode(std::move(initial_polygon_mode)),
    _cull_mode(std::move(initial_cull_mode)),
    _front_face(std::move(initial_front_face)),
    _depth_bias_enable(std::move(initial_depth_bias_enable)),
    _depth_bias_constant_factor(std::move(initial_depth_bias_constant_factor)),
    _depth_bias_clamp(std::move(initial_depth_bias_clamp)),
    _depth_bias_slope_factor(std::move(initial_depth_bias_slope_factor)),
    _line_width(std::move(initial_line_width))
  {
  }

  /// Copy constructor.
  constexpr pipeline_rasterization_state_create_info(
    const pipeline_rasterization_state_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _depth_clamp_enable(other._depth_clamp_enable),
    _rasterizer_discard_enable(other._rasterizer_discard_enable),
    _polygon_mode(other._polygon_mode),
    _cull_mode(other._cull_mode),
    _front_face(other._front_face),
    _depth_bias_enable(other._depth_bias_enable),
    _depth_bias_constant_factor(other._depth_bias_constant_factor),
    _depth_bias_clamp(other._depth_bias_clamp),
    _depth_bias_slope_factor(other._depth_bias_slope_factor),
    _line_width(other._line_width)
  {
  }

  /// Move constructor.
  constexpr pipeline_rasterization_state_create_info(
    pipeline_rasterization_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _depth_clamp_enable(std::move(other._depth_clamp_enable)),
    _rasterizer_discard_enable(std::move(other._rasterizer_discard_enable)),
    _polygon_mode(std::move(other._polygon_mode)),
    _cull_mode(std::move(other._cull_mode)),
    _front_face(std::move(other._front_face)),
    _depth_bias_enable(std::move(other._depth_bias_enable)),
    _depth_bias_constant_factor(std::move(other._depth_bias_constant_factor)),
    _depth_bias_clamp(std::move(other._depth_bias_clamp)),
    _depth_bias_slope_factor(std::move(other._depth_bias_slope_factor)),
    _line_width(std::move(other._line_width))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_rasterization_state_create_info& operator=(
    const pipeline_rasterization_state_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _depth_clamp_enable = other._depth_clamp_enable;
    _rasterizer_discard_enable = other._rasterizer_discard_enable;
    _polygon_mode = other._polygon_mode;
    _cull_mode = other._cull_mode;
    _front_face = other._front_face;
    _depth_bias_enable = other._depth_bias_enable;
    _depth_bias_constant_factor = other._depth_bias_constant_factor;
    _depth_bias_clamp = other._depth_bias_clamp;
    _depth_bias_slope_factor = other._depth_bias_slope_factor;
    _line_width = other._line_width;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_rasterization_state_create_info& operator=(
    pipeline_rasterization_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _depth_clamp_enable = std::move(other._depth_clamp_enable);
    _rasterizer_discard_enable = std::move(other._rasterizer_discard_enable);
    _polygon_mode = std::move(other._polygon_mode);
    _cull_mode = std::move(other._cull_mode);
    _front_face = std::move(other._front_face);
    _depth_bias_enable = std::move(other._depth_bias_enable);
    _depth_bias_constant_factor = std::move(other._depth_bias_constant_factor);
    _depth_bias_clamp = std::move(other._depth_bias_clamp);
    _depth_bias_slope_factor = std::move(other._depth_bias_slope_factor);
    _line_width = std::move(other._line_width);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineRasterizationStateCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineRasterizationStateCreateInfo*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_rasterization_state_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_rasterization_state_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_rasterization_state_create_flags new_flags)
  {
    _flags = new_flags;
  }

  VkBool32& depth_clamp_enable()
  {
    return _depth_clamp_enable;
  }

  constexpr const VkBool32& depth_clamp_enable() const
  {
    return _depth_clamp_enable;
  }

  void depth_clamp_enable(VkBool32 new_depth_clamp_enable)
  {
    _depth_clamp_enable = new_depth_clamp_enable;
  }

  VkBool32& rasterizer_discard_enable()
  {
    return _rasterizer_discard_enable;
  }

  constexpr const VkBool32& rasterizer_discard_enable() const
  {
    return _rasterizer_discard_enable;
  }

  void rasterizer_discard_enable(VkBool32 new_rasterizer_discard_enable)
  {
    _rasterizer_discard_enable = new_rasterizer_discard_enable;
  }

  vk::polygon_mode& polygon_mode()
  {
    return _polygon_mode;
  }

  constexpr const vk::polygon_mode& polygon_mode() const
  {
    return _polygon_mode;
  }

  void polygon_mode(vk::polygon_mode new_polygon_mode)
  {
    _polygon_mode = new_polygon_mode;
  }

  vk::cull_mode_flags& cull_mode()
  {
    return _cull_mode;
  }

  constexpr const vk::cull_mode_flags& cull_mode() const
  {
    return _cull_mode;
  }

  void cull_mode(vk::cull_mode_flags new_cull_mode)
  {
    _cull_mode = new_cull_mode;
  }

  vk::front_face& front_face()
  {
    return _front_face;
  }

  constexpr const vk::front_face& front_face() const
  {
    return _front_face;
  }

  void front_face(vk::front_face new_front_face)
  {
    _front_face = new_front_face;
  }

  VkBool32& depth_bias_enable()
  {
    return _depth_bias_enable;
  }

  constexpr const VkBool32& depth_bias_enable() const
  {
    return _depth_bias_enable;
  }

  void depth_bias_enable(VkBool32 new_depth_bias_enable)
  {
    _depth_bias_enable = new_depth_bias_enable;
  }

  float& depth_bias_constant_factor()
  {
    return _depth_bias_constant_factor;
  }

  constexpr const float& depth_bias_constant_factor() const
  {
    return _depth_bias_constant_factor;
  }

  void depth_bias_constant_factor(float new_depth_bias_constant_factor)
  {
    _depth_bias_constant_factor = new_depth_bias_constant_factor;
  }

  float& depth_bias_clamp()
  {
    return _depth_bias_clamp;
  }

  constexpr const float& depth_bias_clamp() const
  {
    return _depth_bias_clamp;
  }

  void depth_bias_clamp(float new_depth_bias_clamp)
  {
    _depth_bias_clamp = new_depth_bias_clamp;
  }

  float& depth_bias_slope_factor()
  {
    return _depth_bias_slope_factor;
  }

  constexpr const float& depth_bias_slope_factor() const
  {
    return _depth_bias_slope_factor;
  }

  void depth_bias_slope_factor(float new_depth_bias_slope_factor)
  {
    _depth_bias_slope_factor = new_depth_bias_slope_factor;
  }

  float& line_width()
  {
    return _line_width;
  }

  constexpr const float& line_width() const
  {
    return _line_width;
  }

  void line_width(float new_line_width)
  {
    _line_width = new_line_width;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_rasterization_state_create_info;
  const void* _next = nullptr;
  vk::pipeline_rasterization_state_create_flags _flags =
    vk::pipeline_rasterization_state_create_flag::none;
  VkBool32 _depth_clamp_enable = VK_FALSE;
  VkBool32 _rasterizer_discard_enable = VK_FALSE;
  /// optional (GL45)
  vk::polygon_mode _polygon_mode = vk::polygon_mode::fill;
  vk::cull_mode_flags _cull_mode = vk::cull_mode_flag::none;
  vk::front_face _front_face = vk::front_face::counter_clockwise;
  VkBool32 _depth_bias_enable = VK_FALSE;
  float _depth_bias_constant_factor = 0.0f;
  float _depth_bias_clamp = 0.0f;
  float _depth_bias_slope_factor = 0.0f;
  float _line_width = 0.0f;
};
static_assert(sizeof(pipeline_rasterization_state_create_info) ==
                sizeof(::VkPipelineRasterizationStateCreateInfo),
              "struct and wrapper have different size!");

enum class pipeline_multisample_state_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_multisample_state_create_flags =
  shift::core::bit_field<pipeline_multisample_state_create_flag,
                         VkPipelineMultisampleStateCreateFlags>;
inline constexpr pipeline_multisample_state_create_flags operator|(
  pipeline_multisample_state_create_flag lhs,
  pipeline_multisample_state_create_flag rhs)
{
  return pipeline_multisample_state_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkPipelineMultisampleStateCreateInfo.
class pipeline_multisample_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_multisample_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_multisample_state_create_info(
    const void* initial_next,
    vk::pipeline_multisample_state_create_flags initial_flags,
    vk::sample_count_flag initial_rasterization_samples,
    VkBool32 initial_sample_shading_enable, float initial_min_sample_shading,
    const VkSampleMask* initial_sample_mask,
    VkBool32 initial_alpha_to_coverage_enable,
    VkBool32 initial_alpha_to_one_enable) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _rasterization_samples(std::move(initial_rasterization_samples)),
    _sample_shading_enable(std::move(initial_sample_shading_enable)),
    _min_sample_shading(std::move(initial_min_sample_shading)),
    _sample_mask(std::move(initial_sample_mask)),
    _alpha_to_coverage_enable(std::move(initial_alpha_to_coverage_enable)),
    _alpha_to_one_enable(std::move(initial_alpha_to_one_enable))
  {
  }

  /// Copy constructor.
  constexpr pipeline_multisample_state_create_info(
    const pipeline_multisample_state_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _rasterization_samples(other._rasterization_samples),
    _sample_shading_enable(other._sample_shading_enable),
    _min_sample_shading(other._min_sample_shading),
    _sample_mask(other._sample_mask),
    _alpha_to_coverage_enable(other._alpha_to_coverage_enable),
    _alpha_to_one_enable(other._alpha_to_one_enable)
  {
  }

  /// Move constructor.
  constexpr pipeline_multisample_state_create_info(
    pipeline_multisample_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _rasterization_samples(std::move(other._rasterization_samples)),
    _sample_shading_enable(std::move(other._sample_shading_enable)),
    _min_sample_shading(std::move(other._min_sample_shading)),
    _sample_mask(std::move(other._sample_mask)),
    _alpha_to_coverage_enable(std::move(other._alpha_to_coverage_enable)),
    _alpha_to_one_enable(std::move(other._alpha_to_one_enable))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_multisample_state_create_info& operator=(
    const pipeline_multisample_state_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _rasterization_samples = other._rasterization_samples;
    _sample_shading_enable = other._sample_shading_enable;
    _min_sample_shading = other._min_sample_shading;
    _sample_mask = other._sample_mask;
    _alpha_to_coverage_enable = other._alpha_to_coverage_enable;
    _alpha_to_one_enable = other._alpha_to_one_enable;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_multisample_state_create_info& operator=(
    pipeline_multisample_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _rasterization_samples = std::move(other._rasterization_samples);
    _sample_shading_enable = std::move(other._sample_shading_enable);
    _min_sample_shading = std::move(other._min_sample_shading);
    _sample_mask = std::move(other._sample_mask);
    _alpha_to_coverage_enable = std::move(other._alpha_to_coverage_enable);
    _alpha_to_one_enable = std::move(other._alpha_to_one_enable);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineMultisampleStateCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineMultisampleStateCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_multisample_state_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_multisample_state_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_multisample_state_create_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::sample_count_flag& rasterization_samples()
  {
    return _rasterization_samples;
  }

  constexpr const vk::sample_count_flag& rasterization_samples() const
  {
    return _rasterization_samples;
  }

  void rasterization_samples(vk::sample_count_flag new_rasterization_samples)
  {
    _rasterization_samples = new_rasterization_samples;
  }

  VkBool32& sample_shading_enable()
  {
    return _sample_shading_enable;
  }

  constexpr const VkBool32& sample_shading_enable() const
  {
    return _sample_shading_enable;
  }

  void sample_shading_enable(VkBool32 new_sample_shading_enable)
  {
    _sample_shading_enable = new_sample_shading_enable;
  }

  float& min_sample_shading()
  {
    return _min_sample_shading;
  }

  constexpr const float& min_sample_shading() const
  {
    return _min_sample_shading;
  }

  void min_sample_shading(float new_min_sample_shading)
  {
    _min_sample_shading = new_min_sample_shading;
  }

  const VkSampleMask* sample_mask()
  {
    return _sample_mask;
  }

  constexpr const VkSampleMask* sample_mask() const
  {
    return _sample_mask;
  }

  void sample_mask(const VkSampleMask* new_sample_mask)
  {
    _sample_mask = new_sample_mask;
  }

  VkBool32& alpha_to_coverage_enable()
  {
    return _alpha_to_coverage_enable;
  }

  constexpr const VkBool32& alpha_to_coverage_enable() const
  {
    return _alpha_to_coverage_enable;
  }

  void alpha_to_coverage_enable(VkBool32 new_alpha_to_coverage_enable)
  {
    _alpha_to_coverage_enable = new_alpha_to_coverage_enable;
  }

  VkBool32& alpha_to_one_enable()
  {
    return _alpha_to_one_enable;
  }

  constexpr const VkBool32& alpha_to_one_enable() const
  {
    return _alpha_to_one_enable;
  }

  void alpha_to_one_enable(VkBool32 new_alpha_to_one_enable)
  {
    _alpha_to_one_enable = new_alpha_to_one_enable;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_multisample_state_create_info;
  const void* _next = nullptr;
  vk::pipeline_multisample_state_create_flags _flags =
    vk::pipeline_multisample_state_create_flag::none;
  /// Number of samples used for rasterization
  vk::sample_count_flag _rasterization_samples = vk::sample_count_flag::none;
  /// optional (GL45)
  VkBool32 _sample_shading_enable = VK_FALSE;
  /// optional (GL45)
  float _min_sample_shading = 0.0f;
  /// Array of sampleMask words
  const VkSampleMask* _sample_mask = nullptr;
  VkBool32 _alpha_to_coverage_enable = VK_FALSE;
  VkBool32 _alpha_to_one_enable = VK_FALSE;
};
static_assert(sizeof(pipeline_multisample_state_create_info) ==
                sizeof(::VkPipelineMultisampleStateCreateInfo),
              "struct and wrapper have different size!");

enum class pipeline_depth_stencil_state_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_depth_stencil_state_create_flags =
  shift::core::bit_field<pipeline_depth_stencil_state_create_flag,
                         VkPipelineDepthStencilStateCreateFlags>;
inline constexpr pipeline_depth_stencil_state_create_flags operator|(
  pipeline_depth_stencil_state_create_flag lhs,
  pipeline_depth_stencil_state_create_flag rhs)
{
  return pipeline_depth_stencil_state_create_flags{lhs} | rhs;
}
enum class compare_op
{
  /// @see VK_COMPARE_OP_NEVER
  never = 0,
  /// @see VK_COMPARE_OP_LESS
  less = 1,
  /// @see VK_COMPARE_OP_EQUAL
  equal = 2,
  /// @see VK_COMPARE_OP_LESS_OR_EQUAL
  less_or_equal = 3,
  /// @see VK_COMPARE_OP_GREATER
  greater = 4,
  /// @see VK_COMPARE_OP_NOT_EQUAL
  not_equal = 5,
  /// @see VK_COMPARE_OP_GREATER_OR_EQUAL
  greater_or_equal = 6,
  /// @see VK_COMPARE_OP_ALWAYS
  always = 7,
};
enum class stencil_op
{
  /// @see VK_STENCIL_OP_KEEP
  keep = 0,
  /// @see VK_STENCIL_OP_ZERO
  zero = 1,
  /// @see VK_STENCIL_OP_REPLACE
  replace = 2,
  /// @see VK_STENCIL_OP_INCREMENT_AND_CLAMP
  increment_and_clamp = 3,
  /// @see VK_STENCIL_OP_DECREMENT_AND_CLAMP
  decrement_and_clamp = 4,
  /// @see VK_STENCIL_OP_INVERT
  invert = 5,
  /// @see VK_STENCIL_OP_INCREMENT_AND_WRAP
  increment_and_wrap = 6,
  /// @see VK_STENCIL_OP_DECREMENT_AND_WRAP
  decrement_and_wrap = 7,
};

/// Enhanced replacement type for VkStencilOpState.
class stencil_op_state
{
public:
  /// Default constructor.
  constexpr stencil_op_state() = default;

  /// Constructor.
  constexpr stencil_op_state(vk::stencil_op initial_fail_op,
                             vk::stencil_op initial_pass_op,
                             vk::stencil_op initial_depth_fail_op,
                             vk::compare_op initial_compare_op,
                             uint32_t initial_compare_mask,
                             uint32_t initial_write_mask,
                             uint32_t initial_reference) noexcept
  : _fail_op(std::move(initial_fail_op)),
    _pass_op(std::move(initial_pass_op)),
    _depth_fail_op(std::move(initial_depth_fail_op)),
    _compare_op(std::move(initial_compare_op)),
    _compare_mask(std::move(initial_compare_mask)),
    _write_mask(std::move(initial_write_mask)),
    _reference(std::move(initial_reference))
  {
  }

  /// Copy constructor.
  constexpr stencil_op_state(const stencil_op_state& other) = default;

  /// Move constructor.
  constexpr stencil_op_state(stencil_op_state&& other) = default;

  /// Copy assignment operator.
  constexpr stencil_op_state& operator=(const stencil_op_state& other) =
    default;

  /// Move assignment operator.
  constexpr stencil_op_state& operator=(stencil_op_state&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkStencilOpState&() const
  {
    return *reinterpret_cast<const VkStencilOpState*>(this);
  }

  vk::stencil_op& fail_op()
  {
    return _fail_op;
  }

  constexpr const vk::stencil_op& fail_op() const
  {
    return _fail_op;
  }

  void fail_op(vk::stencil_op new_fail_op)
  {
    _fail_op = new_fail_op;
  }

  vk::stencil_op& pass_op()
  {
    return _pass_op;
  }

  constexpr const vk::stencil_op& pass_op() const
  {
    return _pass_op;
  }

  void pass_op(vk::stencil_op new_pass_op)
  {
    _pass_op = new_pass_op;
  }

  vk::stencil_op& depth_fail_op()
  {
    return _depth_fail_op;
  }

  constexpr const vk::stencil_op& depth_fail_op() const
  {
    return _depth_fail_op;
  }

  void depth_fail_op(vk::stencil_op new_depth_fail_op)
  {
    _depth_fail_op = new_depth_fail_op;
  }

  vk::compare_op& compare_op()
  {
    return _compare_op;
  }

  constexpr const vk::compare_op& compare_op() const
  {
    return _compare_op;
  }

  void compare_op(vk::compare_op new_compare_op)
  {
    _compare_op = new_compare_op;
  }

  uint32_t& compare_mask()
  {
    return _compare_mask;
  }

  constexpr const uint32_t& compare_mask() const
  {
    return _compare_mask;
  }

  void compare_mask(uint32_t new_compare_mask)
  {
    _compare_mask = new_compare_mask;
  }

  uint32_t& write_mask()
  {
    return _write_mask;
  }

  constexpr const uint32_t& write_mask() const
  {
    return _write_mask;
  }

  void write_mask(uint32_t new_write_mask)
  {
    _write_mask = new_write_mask;
  }

  uint32_t& reference()
  {
    return _reference;
  }

  constexpr const uint32_t& reference() const
  {
    return _reference;
  }

  void reference(uint32_t new_reference)
  {
    _reference = new_reference;
  }

private:
  vk::stencil_op _fail_op = vk::stencil_op::keep;
  vk::stencil_op _pass_op = vk::stencil_op::keep;
  vk::stencil_op _depth_fail_op = vk::stencil_op::keep;
  vk::compare_op _compare_op = vk::compare_op::never;
  uint32_t _compare_mask = 0;
  uint32_t _write_mask = 0;
  uint32_t _reference = 0;
};
static_assert(sizeof(stencil_op_state) == sizeof(::VkStencilOpState),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPipelineDepthStencilStateCreateInfo.
class pipeline_depth_stencil_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_depth_stencil_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_depth_stencil_state_create_info(
    const void* initial_next,
    vk::pipeline_depth_stencil_state_create_flags initial_flags,
    VkBool32 initial_depth_test_enable, VkBool32 initial_depth_write_enable,
    vk::compare_op initial_depth_compare_op,
    VkBool32 initial_depth_bounds_test_enable,
    VkBool32 initial_stencil_test_enable, vk::stencil_op_state initial_front,
    vk::stencil_op_state initial_back, float initial_min_depth_bounds,
    float initial_max_depth_bounds) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _depth_test_enable(std::move(initial_depth_test_enable)),
    _depth_write_enable(std::move(initial_depth_write_enable)),
    _depth_compare_op(std::move(initial_depth_compare_op)),
    _depth_bounds_test_enable(std::move(initial_depth_bounds_test_enable)),
    _stencil_test_enable(std::move(initial_stencil_test_enable)),
    _front(std::move(initial_front)),
    _back(std::move(initial_back)),
    _min_depth_bounds(std::move(initial_min_depth_bounds)),
    _max_depth_bounds(std::move(initial_max_depth_bounds))
  {
  }

  /// Copy constructor.
  constexpr pipeline_depth_stencil_state_create_info(
    const pipeline_depth_stencil_state_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _depth_test_enable(other._depth_test_enable),
    _depth_write_enable(other._depth_write_enable),
    _depth_compare_op(other._depth_compare_op),
    _depth_bounds_test_enable(other._depth_bounds_test_enable),
    _stencil_test_enable(other._stencil_test_enable),
    _front(other._front),
    _back(other._back),
    _min_depth_bounds(other._min_depth_bounds),
    _max_depth_bounds(other._max_depth_bounds)
  {
  }

  /// Move constructor.
  constexpr pipeline_depth_stencil_state_create_info(
    pipeline_depth_stencil_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _depth_test_enable(std::move(other._depth_test_enable)),
    _depth_write_enable(std::move(other._depth_write_enable)),
    _depth_compare_op(std::move(other._depth_compare_op)),
    _depth_bounds_test_enable(std::move(other._depth_bounds_test_enable)),
    _stencil_test_enable(std::move(other._stencil_test_enable)),
    _front(std::move(other._front)),
    _back(std::move(other._back)),
    _min_depth_bounds(std::move(other._min_depth_bounds)),
    _max_depth_bounds(std::move(other._max_depth_bounds))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_depth_stencil_state_create_info& operator=(
    const pipeline_depth_stencil_state_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _depth_test_enable = other._depth_test_enable;
    _depth_write_enable = other._depth_write_enable;
    _depth_compare_op = other._depth_compare_op;
    _depth_bounds_test_enable = other._depth_bounds_test_enable;
    _stencil_test_enable = other._stencil_test_enable;
    _front = other._front;
    _back = other._back;
    _min_depth_bounds = other._min_depth_bounds;
    _max_depth_bounds = other._max_depth_bounds;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_depth_stencil_state_create_info& operator=(
    pipeline_depth_stencil_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _depth_test_enable = std::move(other._depth_test_enable);
    _depth_write_enable = std::move(other._depth_write_enable);
    _depth_compare_op = std::move(other._depth_compare_op);
    _depth_bounds_test_enable = std::move(other._depth_bounds_test_enable);
    _stencil_test_enable = std::move(other._stencil_test_enable);
    _front = std::move(other._front);
    _back = std::move(other._back);
    _min_depth_bounds = std::move(other._min_depth_bounds);
    _max_depth_bounds = std::move(other._max_depth_bounds);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineDepthStencilStateCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineDepthStencilStateCreateInfo*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_depth_stencil_state_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_depth_stencil_state_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_depth_stencil_state_create_flags new_flags)
  {
    _flags = new_flags;
  }

  VkBool32& depth_test_enable()
  {
    return _depth_test_enable;
  }

  constexpr const VkBool32& depth_test_enable() const
  {
    return _depth_test_enable;
  }

  void depth_test_enable(VkBool32 new_depth_test_enable)
  {
    _depth_test_enable = new_depth_test_enable;
  }

  VkBool32& depth_write_enable()
  {
    return _depth_write_enable;
  }

  constexpr const VkBool32& depth_write_enable() const
  {
    return _depth_write_enable;
  }

  void depth_write_enable(VkBool32 new_depth_write_enable)
  {
    _depth_write_enable = new_depth_write_enable;
  }

  vk::compare_op& depth_compare_op()
  {
    return _depth_compare_op;
  }

  constexpr const vk::compare_op& depth_compare_op() const
  {
    return _depth_compare_op;
  }

  void depth_compare_op(vk::compare_op new_depth_compare_op)
  {
    _depth_compare_op = new_depth_compare_op;
  }

  VkBool32& depth_bounds_test_enable()
  {
    return _depth_bounds_test_enable;
  }

  constexpr const VkBool32& depth_bounds_test_enable() const
  {
    return _depth_bounds_test_enable;
  }

  void depth_bounds_test_enable(VkBool32 new_depth_bounds_test_enable)
  {
    _depth_bounds_test_enable = new_depth_bounds_test_enable;
  }

  VkBool32& stencil_test_enable()
  {
    return _stencil_test_enable;
  }

  constexpr const VkBool32& stencil_test_enable() const
  {
    return _stencil_test_enable;
  }

  void stencil_test_enable(VkBool32 new_stencil_test_enable)
  {
    _stencil_test_enable = new_stencil_test_enable;
  }

  vk::stencil_op_state& front()
  {
    return _front;
  }

  constexpr const vk::stencil_op_state& front() const
  {
    return _front;
  }

  void front(vk::stencil_op_state new_front)
  {
    _front = new_front;
  }

  vk::stencil_op_state& back()
  {
    return _back;
  }

  constexpr const vk::stencil_op_state& back() const
  {
    return _back;
  }

  void back(vk::stencil_op_state new_back)
  {
    _back = new_back;
  }

  float& min_depth_bounds()
  {
    return _min_depth_bounds;
  }

  constexpr const float& min_depth_bounds() const
  {
    return _min_depth_bounds;
  }

  void min_depth_bounds(float new_min_depth_bounds)
  {
    _min_depth_bounds = new_min_depth_bounds;
  }

  float& max_depth_bounds()
  {
    return _max_depth_bounds;
  }

  constexpr const float& max_depth_bounds() const
  {
    return _max_depth_bounds;
  }

  void max_depth_bounds(float new_max_depth_bounds)
  {
    _max_depth_bounds = new_max_depth_bounds;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_depth_stencil_state_create_info;
  const void* _next = nullptr;
  vk::pipeline_depth_stencil_state_create_flags _flags =
    vk::pipeline_depth_stencil_state_create_flag::none;
  VkBool32 _depth_test_enable = VK_FALSE;
  VkBool32 _depth_write_enable = VK_FALSE;
  vk::compare_op _depth_compare_op = vk::compare_op::never;
  /// optional (depth_bounds_test)
  VkBool32 _depth_bounds_test_enable = VK_FALSE;
  VkBool32 _stencil_test_enable = VK_FALSE;
  vk::stencil_op_state _front = vk::stencil_op_state{};
  vk::stencil_op_state _back = vk::stencil_op_state{};
  float _min_depth_bounds = 0.0f;
  float _max_depth_bounds = 0.0f;
};
static_assert(sizeof(pipeline_depth_stencil_state_create_info) ==
                sizeof(::VkPipelineDepthStencilStateCreateInfo),
              "struct and wrapper have different size!");

enum class pipeline_color_blend_state_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_color_blend_state_create_flags =
  shift::core::bit_field<pipeline_color_blend_state_create_flag,
                         VkPipelineColorBlendStateCreateFlags>;
inline constexpr pipeline_color_blend_state_create_flags operator|(
  pipeline_color_blend_state_create_flag lhs,
  pipeline_color_blend_state_create_flag rhs)
{
  return pipeline_color_blend_state_create_flags{lhs} | rhs;
}
enum class logic_op
{
  /// @see VK_LOGIC_OP_CLEAR
  clear_op = 0,
  /// @see VK_LOGIC_OP_AND
  and_op = 1,
  /// @see VK_LOGIC_OP_AND_REVERSE
  and_reverse_op = 2,
  /// @see VK_LOGIC_OP_COPY
  copy_op = 3,
  /// @see VK_LOGIC_OP_AND_INVERTED
  and_inverted_op = 4,
  /// @see VK_LOGIC_OP_NO_OP
  no_op = 5,
  /// @see VK_LOGIC_OP_XOR
  xor_op = 6,
  /// @see VK_LOGIC_OP_OR
  or_op = 7,
  /// @see VK_LOGIC_OP_NOR
  nor_op = 8,
  /// @see VK_LOGIC_OP_EQUIVALENT
  equivalent_op = 9,
  /// @see VK_LOGIC_OP_INVERT
  invert_op = 10,
  /// @see VK_LOGIC_OP_OR_REVERSE
  or_reverse_op = 11,
  /// @see VK_LOGIC_OP_COPY_INVERTED
  copy_inverted_op = 12,
  /// @see VK_LOGIC_OP_OR_INVERTED
  or_inverted_op = 13,
  /// @see VK_LOGIC_OP_NAND
  nand_op = 14,
  /// @see VK_LOGIC_OP_SET
  set_op = 15,
};
enum class blend_factor
{
  /// @see VK_BLEND_FACTOR_ZERO
  zero = 0,
  /// @see VK_BLEND_FACTOR_ONE
  one = 1,
  /// @see VK_BLEND_FACTOR_SRC_COLOR
  src_color = 2,
  /// @see VK_BLEND_FACTOR_ONE_MINUS_SRC_COLOR
  one_minus_src_color = 3,
  /// @see VK_BLEND_FACTOR_DST_COLOR
  dst_color = 4,
  /// @see VK_BLEND_FACTOR_ONE_MINUS_DST_COLOR
  one_minus_dst_color = 5,
  /// @see VK_BLEND_FACTOR_SRC_ALPHA
  src_alpha = 6,
  /// @see VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA
  one_minus_src_alpha = 7,
  /// @see VK_BLEND_FACTOR_DST_ALPHA
  dst_alpha = 8,
  /// @see VK_BLEND_FACTOR_ONE_MINUS_DST_ALPHA
  one_minus_dst_alpha = 9,
  /// @see VK_BLEND_FACTOR_CONSTANT_COLOR
  constant_color = 10,
  /// @see VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_COLOR
  one_minus_constant_color = 11,
  /// @see VK_BLEND_FACTOR_CONSTANT_ALPHA
  constant_alpha = 12,
  /// @see VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_ALPHA
  one_minus_constant_alpha = 13,
  /// @see VK_BLEND_FACTOR_SRC_ALPHA_SATURATE
  src_alpha_saturate = 14,
  /// @see VK_BLEND_FACTOR_SRC1_COLOR
  src1_color = 15,
  /// @see VK_BLEND_FACTOR_ONE_MINUS_SRC1_COLOR
  one_minus_src1_color = 16,
  /// @see VK_BLEND_FACTOR_SRC1_ALPHA
  src1_alpha = 17,
  /// @see VK_BLEND_FACTOR_ONE_MINUS_SRC1_ALPHA
  one_minus_src1_alpha = 18,
};
enum class blend_op
{
  /// @see VK_BLEND_OP_ADD
  add = 0,
  /// @see VK_BLEND_OP_SUBTRACT
  subtract = 1,
  /// @see VK_BLEND_OP_REVERSE_SUBTRACT
  reverse_subtract = 2,
  /// @see VK_BLEND_OP_MIN
  min = 3,
  /// @see VK_BLEND_OP_MAX
  max = 4,
  /// @see VK_BLEND_OP_ZERO_EXT
  zero_ext = 1000148000,
  /// @see VK_BLEND_OP_SRC_EXT
  src_ext = 1000148001,
  /// @see VK_BLEND_OP_DST_EXT
  dst_ext = 1000148002,
  /// @see VK_BLEND_OP_SRC_OVER_EXT
  src_over_ext = 1000148003,
  /// @see VK_BLEND_OP_DST_OVER_EXT
  dst_over_ext = 1000148004,
  /// @see VK_BLEND_OP_SRC_IN_EXT
  src_in_ext = 1000148005,
  /// @see VK_BLEND_OP_DST_IN_EXT
  dst_in_ext = 1000148006,
  /// @see VK_BLEND_OP_SRC_OUT_EXT
  src_out_ext = 1000148007,
  /// @see VK_BLEND_OP_DST_OUT_EXT
  dst_out_ext = 1000148008,
  /// @see VK_BLEND_OP_SRC_ATOP_EXT
  src_atop_ext = 1000148009,
  /// @see VK_BLEND_OP_DST_ATOP_EXT
  dst_atop_ext = 1000148010,
  /// @see VK_BLEND_OP_XOR_EXT
  xor_ext = 1000148011,
  /// @see VK_BLEND_OP_MULTIPLY_EXT
  multiply_ext = 1000148012,
  /// @see VK_BLEND_OP_SCREEN_EXT
  screen_ext = 1000148013,
  /// @see VK_BLEND_OP_OVERLAY_EXT
  overlay_ext = 1000148014,
  /// @see VK_BLEND_OP_DARKEN_EXT
  darken_ext = 1000148015,
  /// @see VK_BLEND_OP_LIGHTEN_EXT
  lighten_ext = 1000148016,
  /// @see VK_BLEND_OP_COLORDODGE_EXT
  colordodge_ext = 1000148017,
  /// @see VK_BLEND_OP_COLORBURN_EXT
  colorburn_ext = 1000148018,
  /// @see VK_BLEND_OP_HARDLIGHT_EXT
  hardlight_ext = 1000148019,
  /// @see VK_BLEND_OP_SOFTLIGHT_EXT
  softlight_ext = 1000148020,
  /// @see VK_BLEND_OP_DIFFERENCE_EXT
  difference_ext = 1000148021,
  /// @see VK_BLEND_OP_EXCLUSION_EXT
  exclusion_ext = 1000148022,
  /// @see VK_BLEND_OP_INVERT_EXT
  invert_ext = 1000148023,
  /// @see VK_BLEND_OP_INVERT_RGB_EXT
  invert_rgb_ext = 1000148024,
  /// @see VK_BLEND_OP_LINEARDODGE_EXT
  lineardodge_ext = 1000148025,
  /// @see VK_BLEND_OP_LINEARBURN_EXT
  linearburn_ext = 1000148026,
  /// @see VK_BLEND_OP_VIVIDLIGHT_EXT
  vividlight_ext = 1000148027,
  /// @see VK_BLEND_OP_LINEARLIGHT_EXT
  linearlight_ext = 1000148028,
  /// @see VK_BLEND_OP_PINLIGHT_EXT
  pinlight_ext = 1000148029,
  /// @see VK_BLEND_OP_HARDMIX_EXT
  hardmix_ext = 1000148030,
  /// @see VK_BLEND_OP_HSL_HUE_EXT
  hsl_hue_ext = 1000148031,
  /// @see VK_BLEND_OP_HSL_SATURATION_EXT
  hsl_saturation_ext = 1000148032,
  /// @see VK_BLEND_OP_HSL_COLOR_EXT
  hsl_color_ext = 1000148033,
  /// @see VK_BLEND_OP_HSL_LUMINOSITY_EXT
  hsl_luminosity_ext = 1000148034,
  /// @see VK_BLEND_OP_PLUS_EXT
  plus_ext = 1000148035,
  /// @see VK_BLEND_OP_PLUS_CLAMPED_EXT
  plus_clamped_ext = 1000148036,
  /// @see VK_BLEND_OP_PLUS_CLAMPED_ALPHA_EXT
  plus_clamped_alpha_ext = 1000148037,
  /// @see VK_BLEND_OP_PLUS_DARKER_EXT
  plus_darker_ext = 1000148038,
  /// @see VK_BLEND_OP_MINUS_EXT
  minus_ext = 1000148039,
  /// @see VK_BLEND_OP_MINUS_CLAMPED_EXT
  minus_clamped_ext = 1000148040,
  /// @see VK_BLEND_OP_CONTRAST_EXT
  contrast_ext = 1000148041,
  /// @see VK_BLEND_OP_INVERT_OVG_EXT
  invert_ovg_ext = 1000148042,
  /// @see VK_BLEND_OP_RED_EXT
  red_ext = 1000148043,
  /// @see VK_BLEND_OP_GREEN_EXT
  green_ext = 1000148044,
  /// @see VK_BLEND_OP_BLUE_EXT
  blue_ext = 1000148045,
};
enum class color_component_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_COLOR_COMPONENT_R_BIT
  r_bit = 1 << 0,
  /// @see VK_COLOR_COMPONENT_G_BIT
  g_bit = 1 << 1,
  /// @see VK_COLOR_COMPONENT_B_BIT
  b_bit = 1 << 2,
  /// @see VK_COLOR_COMPONENT_A_BIT
  a_bit = 1 << 3,
};
using color_component_flags =
  shift::core::bit_field<color_component_flag, VkColorComponentFlags>;
inline constexpr color_component_flags operator|(color_component_flag lhs,
                                                 color_component_flag rhs)
{
  return color_component_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkPipelineColorBlendAttachmentState.
class pipeline_color_blend_attachment_state
{
public:
  /// Default constructor.
  constexpr pipeline_color_blend_attachment_state() = default;

  /// Constructor.
  constexpr pipeline_color_blend_attachment_state(
    VkBool32 initial_blend_enable,
    vk::blend_factor initial_src_color_blend_factor,
    vk::blend_factor initial_dst_color_blend_factor,
    vk::blend_op initial_color_blend_op,
    vk::blend_factor initial_src_alpha_blend_factor,
    vk::blend_factor initial_dst_alpha_blend_factor,
    vk::blend_op initial_alpha_blend_op,
    vk::color_component_flags initial_color_write_mask) noexcept
  : _blend_enable(std::move(initial_blend_enable)),
    _src_color_blend_factor(std::move(initial_src_color_blend_factor)),
    _dst_color_blend_factor(std::move(initial_dst_color_blend_factor)),
    _color_blend_op(std::move(initial_color_blend_op)),
    _src_alpha_blend_factor(std::move(initial_src_alpha_blend_factor)),
    _dst_alpha_blend_factor(std::move(initial_dst_alpha_blend_factor)),
    _alpha_blend_op(std::move(initial_alpha_blend_op)),
    _color_write_mask(std::move(initial_color_write_mask))
  {
  }

  /// Copy constructor.
  constexpr pipeline_color_blend_attachment_state(
    const pipeline_color_blend_attachment_state& other) = default;

  /// Move constructor.
  constexpr pipeline_color_blend_attachment_state(
    pipeline_color_blend_attachment_state&& other) = default;

  /// Copy assignment operator.
  constexpr pipeline_color_blend_attachment_state& operator=(
    const pipeline_color_blend_attachment_state& other) = default;

  /// Move assignment operator.
  constexpr pipeline_color_blend_attachment_state& operator=(
    pipeline_color_blend_attachment_state&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineColorBlendAttachmentState&() const
  {
    return *reinterpret_cast<const VkPipelineColorBlendAttachmentState*>(this);
  }

  VkBool32& blend_enable()
  {
    return _blend_enable;
  }

  constexpr const VkBool32& blend_enable() const
  {
    return _blend_enable;
  }

  void blend_enable(VkBool32 new_blend_enable)
  {
    _blend_enable = new_blend_enable;
  }

  vk::blend_factor& src_color_blend_factor()
  {
    return _src_color_blend_factor;
  }

  constexpr const vk::blend_factor& src_color_blend_factor() const
  {
    return _src_color_blend_factor;
  }

  void src_color_blend_factor(vk::blend_factor new_src_color_blend_factor)
  {
    _src_color_blend_factor = new_src_color_blend_factor;
  }

  vk::blend_factor& dst_color_blend_factor()
  {
    return _dst_color_blend_factor;
  }

  constexpr const vk::blend_factor& dst_color_blend_factor() const
  {
    return _dst_color_blend_factor;
  }

  void dst_color_blend_factor(vk::blend_factor new_dst_color_blend_factor)
  {
    _dst_color_blend_factor = new_dst_color_blend_factor;
  }

  vk::blend_op& color_blend_op()
  {
    return _color_blend_op;
  }

  constexpr const vk::blend_op& color_blend_op() const
  {
    return _color_blend_op;
  }

  void color_blend_op(vk::blend_op new_color_blend_op)
  {
    _color_blend_op = new_color_blend_op;
  }

  vk::blend_factor& src_alpha_blend_factor()
  {
    return _src_alpha_blend_factor;
  }

  constexpr const vk::blend_factor& src_alpha_blend_factor() const
  {
    return _src_alpha_blend_factor;
  }

  void src_alpha_blend_factor(vk::blend_factor new_src_alpha_blend_factor)
  {
    _src_alpha_blend_factor = new_src_alpha_blend_factor;
  }

  vk::blend_factor& dst_alpha_blend_factor()
  {
    return _dst_alpha_blend_factor;
  }

  constexpr const vk::blend_factor& dst_alpha_blend_factor() const
  {
    return _dst_alpha_blend_factor;
  }

  void dst_alpha_blend_factor(vk::blend_factor new_dst_alpha_blend_factor)
  {
    _dst_alpha_blend_factor = new_dst_alpha_blend_factor;
  }

  vk::blend_op& alpha_blend_op()
  {
    return _alpha_blend_op;
  }

  constexpr const vk::blend_op& alpha_blend_op() const
  {
    return _alpha_blend_op;
  }

  void alpha_blend_op(vk::blend_op new_alpha_blend_op)
  {
    _alpha_blend_op = new_alpha_blend_op;
  }

  vk::color_component_flags& color_write_mask()
  {
    return _color_write_mask;
  }

  constexpr const vk::color_component_flags& color_write_mask() const
  {
    return _color_write_mask;
  }

  void color_write_mask(vk::color_component_flags new_color_write_mask)
  {
    _color_write_mask = new_color_write_mask;
  }

private:
  VkBool32 _blend_enable = VK_FALSE;
  vk::blend_factor _src_color_blend_factor = vk::blend_factor::zero;
  vk::blend_factor _dst_color_blend_factor = vk::blend_factor::zero;
  vk::blend_op _color_blend_op = vk::blend_op::add;
  vk::blend_factor _src_alpha_blend_factor = vk::blend_factor::zero;
  vk::blend_factor _dst_alpha_blend_factor = vk::blend_factor::zero;
  vk::blend_op _alpha_blend_op = vk::blend_op::add;
  vk::color_component_flags _color_write_mask = vk::color_component_flag::none;
};
static_assert(sizeof(pipeline_color_blend_attachment_state) ==
                sizeof(::VkPipelineColorBlendAttachmentState),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPipelineColorBlendStateCreateInfo.
class pipeline_color_blend_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_color_blend_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_color_blend_state_create_info(
    const void* initial_next,
    vk::pipeline_color_blend_state_create_flags initial_flags,
    VkBool32 initial_logic_op_enable, vk::logic_op initial_logic_op,
    uint32_t initial_attachment_count,
    const vk::pipeline_color_blend_attachment_state* initial_attachments,
    std::array<float, 4> initial_blend_constants) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _logic_op_enable(std::move(initial_logic_op_enable)),
    _logic_op(std::move(initial_logic_op)),
    _attachment_count(std::move(initial_attachment_count)),
    _attachments(std::move(initial_attachments)),
    _blend_constants(std::move(initial_blend_constants))
  {
  }

  /// Copy constructor.
  constexpr pipeline_color_blend_state_create_info(
    const pipeline_color_blend_state_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _logic_op_enable(other._logic_op_enable),
    _logic_op(other._logic_op),
    _attachment_count(other._attachment_count),
    _attachments(other._attachments),
    _blend_constants(other._blend_constants)
  {
  }

  /// Move constructor.
  constexpr pipeline_color_blend_state_create_info(
    pipeline_color_blend_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _logic_op_enable(std::move(other._logic_op_enable)),
    _logic_op(std::move(other._logic_op)),
    _attachment_count(std::move(other._attachment_count)),
    _attachments(std::move(other._attachments)),
    _blend_constants(std::move(other._blend_constants))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_color_blend_state_create_info& operator=(
    const pipeline_color_blend_state_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _logic_op_enable = other._logic_op_enable;
    _logic_op = other._logic_op;
    _attachment_count = other._attachment_count;
    _attachments = other._attachments;
    _blend_constants = other._blend_constants;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_color_blend_state_create_info& operator=(
    pipeline_color_blend_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _logic_op_enable = std::move(other._logic_op_enable);
    _logic_op = std::move(other._logic_op);
    _attachment_count = std::move(other._attachment_count);
    _attachments = std::move(other._attachments);
    _blend_constants = std::move(other._blend_constants);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineColorBlendStateCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineColorBlendStateCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_color_blend_state_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_color_blend_state_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_color_blend_state_create_flags new_flags)
  {
    _flags = new_flags;
  }

  VkBool32& logic_op_enable()
  {
    return _logic_op_enable;
  }

  constexpr const VkBool32& logic_op_enable() const
  {
    return _logic_op_enable;
  }

  void logic_op_enable(VkBool32 new_logic_op_enable)
  {
    _logic_op_enable = new_logic_op_enable;
  }

  vk::logic_op& logic_op()
  {
    return _logic_op;
  }

  constexpr const vk::logic_op& logic_op() const
  {
    return _logic_op;
  }

  void logic_op(vk::logic_op new_logic_op)
  {
    _logic_op = new_logic_op;
  }

  uint32_t& attachment_count()
  {
    return _attachment_count;
  }

  constexpr const uint32_t& attachment_count() const
  {
    return _attachment_count;
  }

  void attachment_count(uint32_t new_attachment_count)
  {
    _attachment_count = new_attachment_count;
  }

  const vk::pipeline_color_blend_attachment_state* attachments()
  {
    return _attachments;
  }

  constexpr const vk::pipeline_color_blend_attachment_state* attachments() const
  {
    return _attachments;
  }

  void attachments(
    const vk::pipeline_color_blend_attachment_state* new_attachments)
  {
    _attachments = new_attachments;
  }

  template <std::size_t Count>
  void attachments(const std::array<vk::pipeline_color_blend_attachment_state,
                                    Count>& new_attachments)
  {
    _attachment_count = static_cast<uint32_t>(new_attachments.size());
    _attachments = new_attachments.data();
  }

  void attachments(const std::vector<vk::pipeline_color_blend_attachment_state>&
                     new_attachments)
  {
    _attachment_count = static_cast<uint32_t>(new_attachments.size());
    _attachments = new_attachments.data();
  }

  std::array<float, 4>& blend_constants()
  {
    return _blend_constants;
  }

  constexpr const std::array<float, 4>& blend_constants() const
  {
    return _blend_constants;
  }

  void blend_constants(std::array<float, 4> new_blend_constants)
  {
    _blend_constants = new_blend_constants;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_color_blend_state_create_info;
  const void* _next = nullptr;
  vk::pipeline_color_blend_state_create_flags _flags =
    vk::pipeline_color_blend_state_create_flag::none;
  VkBool32 _logic_op_enable = VK_FALSE;
  vk::logic_op _logic_op = vk::logic_op::clear_op;
  /// # of pAttachments
  uint32_t _attachment_count = 0;
  const vk::pipeline_color_blend_attachment_state* _attachments = nullptr;
  std::array<float, 4> _blend_constants = {};
};
static_assert(sizeof(pipeline_color_blend_state_create_info) ==
                sizeof(::VkPipelineColorBlendStateCreateInfo),
              "struct and wrapper have different size!");

enum class pipeline_dynamic_state_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_dynamic_state_create_flags =
  shift::core::bit_field<pipeline_dynamic_state_create_flag,
                         VkPipelineDynamicStateCreateFlags>;
inline constexpr pipeline_dynamic_state_create_flags operator|(
  pipeline_dynamic_state_create_flag lhs,
  pipeline_dynamic_state_create_flag rhs)
{
  return pipeline_dynamic_state_create_flags{lhs} | rhs;
}
enum class dynamic_state
{
  /// @see VK_DYNAMIC_STATE_VIEWPORT
  viewport = 0,
  /// @see VK_DYNAMIC_STATE_SCISSOR
  scissor = 1,
  /// @see VK_DYNAMIC_STATE_LINE_WIDTH
  line_width = 2,
  /// @see VK_DYNAMIC_STATE_DEPTH_BIAS
  depth_bias = 3,
  /// @see VK_DYNAMIC_STATE_BLEND_CONSTANTS
  blend_constants = 4,
  /// @see VK_DYNAMIC_STATE_DEPTH_BOUNDS
  depth_bounds = 5,
  /// @see VK_DYNAMIC_STATE_STENCIL_COMPARE_MASK
  stencil_compare_mask = 6,
  /// @see VK_DYNAMIC_STATE_STENCIL_WRITE_MASK
  stencil_write_mask = 7,
  /// @see VK_DYNAMIC_STATE_STENCIL_REFERENCE
  stencil_reference = 8,
  /// @see VK_DYNAMIC_STATE_VIEWPORT_W_SCALING_NV
  viewport_w_scaling_nv = 1000087000,
  /// @see VK_DYNAMIC_STATE_DISCARD_RECTANGLE_EXT
  discard_rectangle_ext = 1000099000,
  /// @see VK_DYNAMIC_STATE_SAMPLE_LOCATIONS_EXT
  sample_locations_ext = 1000143000,
  /// @see VK_DYNAMIC_STATE_VIEWPORT_SHADING_RATE_PALETTE_NV
  viewport_shading_rate_palette_nv = 1000164004,
  /// @see VK_DYNAMIC_STATE_VIEWPORT_COARSE_SAMPLE_ORDER_NV
  viewport_coarse_sample_order_nv = 1000164006,
  /// @see VK_DYNAMIC_STATE_EXCLUSIVE_SCISSOR_NV
  exclusive_scissor_nv = 1000205001,
};

/// Enhanced replacement type for VkPipelineDynamicStateCreateInfo.
class pipeline_dynamic_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_dynamic_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_dynamic_state_create_info(
    const void* initial_next,
    vk::pipeline_dynamic_state_create_flags initial_flags,
    uint32_t initial_dynamic_state_count,
    const vk::dynamic_state* initial_dynamic_states) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _dynamic_state_count(std::move(initial_dynamic_state_count)),
    _dynamic_states(std::move(initial_dynamic_states))
  {
  }

  /// Copy constructor.
  constexpr pipeline_dynamic_state_create_info(
    const pipeline_dynamic_state_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _dynamic_state_count(other._dynamic_state_count),
    _dynamic_states(other._dynamic_states)
  {
  }

  /// Move constructor.
  constexpr pipeline_dynamic_state_create_info(
    pipeline_dynamic_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _dynamic_state_count(std::move(other._dynamic_state_count)),
    _dynamic_states(std::move(other._dynamic_states))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_dynamic_state_create_info& operator=(
    const pipeline_dynamic_state_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _dynamic_state_count = other._dynamic_state_count;
    _dynamic_states = other._dynamic_states;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_dynamic_state_create_info& operator=(
    pipeline_dynamic_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _dynamic_state_count = std::move(other._dynamic_state_count);
    _dynamic_states = std::move(other._dynamic_states);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineDynamicStateCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineDynamicStateCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_dynamic_state_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_dynamic_state_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_dynamic_state_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& dynamic_state_count()
  {
    return _dynamic_state_count;
  }

  constexpr const uint32_t& dynamic_state_count() const
  {
    return _dynamic_state_count;
  }

  void dynamic_state_count(uint32_t new_dynamic_state_count)
  {
    _dynamic_state_count = new_dynamic_state_count;
  }

  const vk::dynamic_state* dynamic_states()
  {
    return _dynamic_states;
  }

  constexpr const vk::dynamic_state* dynamic_states() const
  {
    return _dynamic_states;
  }

  void dynamic_states(const vk::dynamic_state* new_dynamic_states)
  {
    _dynamic_states = new_dynamic_states;
  }

  template <std::size_t Count>
  void dynamic_states(
    const std::array<vk::dynamic_state, Count>& new_dynamic_states)
  {
    _dynamic_state_count = static_cast<uint32_t>(new_dynamic_states.size());
    _dynamic_states = new_dynamic_states.data();
  }

  void dynamic_states(const std::vector<vk::dynamic_state>& new_dynamic_states)
  {
    _dynamic_state_count = static_cast<uint32_t>(new_dynamic_states.size());
    _dynamic_states = new_dynamic_states.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_dynamic_state_create_info;
  const void* _next = nullptr;
  vk::pipeline_dynamic_state_create_flags _flags =
    vk::pipeline_dynamic_state_create_flag::none;
  uint32_t _dynamic_state_count = 0;
  const vk::dynamic_state* _dynamic_states = nullptr;
};
static_assert(sizeof(pipeline_dynamic_state_create_info) ==
                sizeof(::VkPipelineDynamicStateCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkGraphicsPipelineCreateInfo.
class graphics_pipeline_create_info
{
public:
  /// Default constructor.
  constexpr graphics_pipeline_create_info() = default;

  /// Constructor.
  constexpr graphics_pipeline_create_info(
    const void* initial_next, vk::pipeline_create_flags initial_flags,
    uint32_t initial_stage_count,
    const vk::pipeline_shader_stage_create_info* initial_stages,
    const vk::pipeline_vertex_input_state_create_info*
      initial_vertex_input_state,
    const vk::pipeline_input_assembly_state_create_info*
      initial_input_assembly_state,
    const vk::pipeline_tessellation_state_create_info*
      initial_tessellation_state,
    const vk::pipeline_viewport_state_create_info* initial_viewport_state,
    const vk::pipeline_rasterization_state_create_info*
      initial_rasterization_state,
    const vk::pipeline_multisample_state_create_info* initial_multisample_state,
    const vk::pipeline_depth_stencil_state_create_info*
      initial_depth_stencil_state,
    const vk::pipeline_color_blend_state_create_info* initial_color_blend_state,
    const vk::pipeline_dynamic_state_create_info* initial_dynamic_state,
    VkPipelineLayout initial_layout, VkRenderPass initial_render_pass,
    uint32_t initial_subpass, VkPipeline initial_base_pipeline_handle,
    int32_t initial_base_pipeline_index) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _stage_count(std::move(initial_stage_count)),
    _stages(std::move(initial_stages)),
    _vertex_input_state(std::move(initial_vertex_input_state)),
    _input_assembly_state(std::move(initial_input_assembly_state)),
    _tessellation_state(std::move(initial_tessellation_state)),
    _viewport_state(std::move(initial_viewport_state)),
    _rasterization_state(std::move(initial_rasterization_state)),
    _multisample_state(std::move(initial_multisample_state)),
    _depth_stencil_state(std::move(initial_depth_stencil_state)),
    _color_blend_state(std::move(initial_color_blend_state)),
    _dynamic_state(std::move(initial_dynamic_state)),
    _layout(std::move(initial_layout)),
    _render_pass(std::move(initial_render_pass)),
    _subpass(std::move(initial_subpass)),
    _base_pipeline_handle(std::move(initial_base_pipeline_handle)),
    _base_pipeline_index(std::move(initial_base_pipeline_index))
  {
  }

  /// Copy constructor.
  constexpr graphics_pipeline_create_info(
    const graphics_pipeline_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _stage_count(other._stage_count),
    _stages(other._stages),
    _vertex_input_state(other._vertex_input_state),
    _input_assembly_state(other._input_assembly_state),
    _tessellation_state(other._tessellation_state),
    _viewport_state(other._viewport_state),
    _rasterization_state(other._rasterization_state),
    _multisample_state(other._multisample_state),
    _depth_stencil_state(other._depth_stencil_state),
    _color_blend_state(other._color_blend_state),
    _dynamic_state(other._dynamic_state),
    _layout(other._layout),
    _render_pass(other._render_pass),
    _subpass(other._subpass),
    _base_pipeline_handle(other._base_pipeline_handle),
    _base_pipeline_index(other._base_pipeline_index)
  {
  }

  /// Move constructor.
  constexpr graphics_pipeline_create_info(
    graphics_pipeline_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _stage_count(std::move(other._stage_count)),
    _stages(std::move(other._stages)),
    _vertex_input_state(std::move(other._vertex_input_state)),
    _input_assembly_state(std::move(other._input_assembly_state)),
    _tessellation_state(std::move(other._tessellation_state)),
    _viewport_state(std::move(other._viewport_state)),
    _rasterization_state(std::move(other._rasterization_state)),
    _multisample_state(std::move(other._multisample_state)),
    _depth_stencil_state(std::move(other._depth_stencil_state)),
    _color_blend_state(std::move(other._color_blend_state)),
    _dynamic_state(std::move(other._dynamic_state)),
    _layout(std::move(other._layout)),
    _render_pass(std::move(other._render_pass)),
    _subpass(std::move(other._subpass)),
    _base_pipeline_handle(std::move(other._base_pipeline_handle)),
    _base_pipeline_index(std::move(other._base_pipeline_index))
  {
  }

  /// Copy assignment operator.
  constexpr graphics_pipeline_create_info& operator=(
    const graphics_pipeline_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _stage_count = other._stage_count;
    _stages = other._stages;
    _vertex_input_state = other._vertex_input_state;
    _input_assembly_state = other._input_assembly_state;
    _tessellation_state = other._tessellation_state;
    _viewport_state = other._viewport_state;
    _rasterization_state = other._rasterization_state;
    _multisample_state = other._multisample_state;
    _depth_stencil_state = other._depth_stencil_state;
    _color_blend_state = other._color_blend_state;
    _dynamic_state = other._dynamic_state;
    _layout = other._layout;
    _render_pass = other._render_pass;
    _subpass = other._subpass;
    _base_pipeline_handle = other._base_pipeline_handle;
    _base_pipeline_index = other._base_pipeline_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr graphics_pipeline_create_info& operator=(
    graphics_pipeline_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _stage_count = std::move(other._stage_count);
    _stages = std::move(other._stages);
    _vertex_input_state = std::move(other._vertex_input_state);
    _input_assembly_state = std::move(other._input_assembly_state);
    _tessellation_state = std::move(other._tessellation_state);
    _viewport_state = std::move(other._viewport_state);
    _rasterization_state = std::move(other._rasterization_state);
    _multisample_state = std::move(other._multisample_state);
    _depth_stencil_state = std::move(other._depth_stencil_state);
    _color_blend_state = std::move(other._color_blend_state);
    _dynamic_state = std::move(other._dynamic_state);
    _layout = std::move(other._layout);
    _render_pass = std::move(other._render_pass);
    _subpass = std::move(other._subpass);
    _base_pipeline_handle = std::move(other._base_pipeline_handle);
    _base_pipeline_index = std::move(other._base_pipeline_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkGraphicsPipelineCreateInfo&() const
  {
    return *reinterpret_cast<const VkGraphicsPipelineCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& stage_count()
  {
    return _stage_count;
  }

  constexpr const uint32_t& stage_count() const
  {
    return _stage_count;
  }

  void stage_count(uint32_t new_stage_count)
  {
    _stage_count = new_stage_count;
  }

  const vk::pipeline_shader_stage_create_info* stages()
  {
    return _stages;
  }

  constexpr const vk::pipeline_shader_stage_create_info* stages() const
  {
    return _stages;
  }

  void stages(const vk::pipeline_shader_stage_create_info* new_stages)
  {
    _stages = new_stages;
  }

  template <std::size_t Count>
  void stages(
    const std::array<vk::pipeline_shader_stage_create_info, Count>& new_stages)
  {
    _stage_count = static_cast<uint32_t>(new_stages.size());
    _stages = new_stages.data();
  }

  void stages(
    const std::vector<vk::pipeline_shader_stage_create_info>& new_stages)
  {
    _stage_count = static_cast<uint32_t>(new_stages.size());
    _stages = new_stages.data();
  }

  const vk::pipeline_vertex_input_state_create_info* vertex_input_state()
  {
    return _vertex_input_state;
  }

  constexpr const vk::pipeline_vertex_input_state_create_info*
  vertex_input_state() const
  {
    return _vertex_input_state;
  }

  void vertex_input_state(
    const vk::pipeline_vertex_input_state_create_info* new_vertex_input_state)
  {
    _vertex_input_state = new_vertex_input_state;
  }

  const vk::pipeline_input_assembly_state_create_info* input_assembly_state()
  {
    return _input_assembly_state;
  }

  constexpr const vk::pipeline_input_assembly_state_create_info*
  input_assembly_state() const
  {
    return _input_assembly_state;
  }

  void input_assembly_state(const vk::pipeline_input_assembly_state_create_info*
                              new_input_assembly_state)
  {
    _input_assembly_state = new_input_assembly_state;
  }

  const vk::pipeline_tessellation_state_create_info* tessellation_state()
  {
    return _tessellation_state;
  }

  constexpr const vk::pipeline_tessellation_state_create_info*
  tessellation_state() const
  {
    return _tessellation_state;
  }

  void tessellation_state(
    const vk::pipeline_tessellation_state_create_info* new_tessellation_state)
  {
    _tessellation_state = new_tessellation_state;
  }

  const vk::pipeline_viewport_state_create_info* viewport_state()
  {
    return _viewport_state;
  }

  constexpr const vk::pipeline_viewport_state_create_info* viewport_state()
    const
  {
    return _viewport_state;
  }

  void viewport_state(
    const vk::pipeline_viewport_state_create_info* new_viewport_state)
  {
    _viewport_state = new_viewport_state;
  }

  const vk::pipeline_rasterization_state_create_info* rasterization_state()
  {
    return _rasterization_state;
  }

  constexpr const vk::pipeline_rasterization_state_create_info*
  rasterization_state() const
  {
    return _rasterization_state;
  }

  void rasterization_state(
    const vk::pipeline_rasterization_state_create_info* new_rasterization_state)
  {
    _rasterization_state = new_rasterization_state;
  }

  const vk::pipeline_multisample_state_create_info* multisample_state()
  {
    return _multisample_state;
  }

  constexpr const vk::pipeline_multisample_state_create_info*
  multisample_state() const
  {
    return _multisample_state;
  }

  void multisample_state(
    const vk::pipeline_multisample_state_create_info* new_multisample_state)
  {
    _multisample_state = new_multisample_state;
  }

  const vk::pipeline_depth_stencil_state_create_info* depth_stencil_state()
  {
    return _depth_stencil_state;
  }

  constexpr const vk::pipeline_depth_stencil_state_create_info*
  depth_stencil_state() const
  {
    return _depth_stencil_state;
  }

  void depth_stencil_state(
    const vk::pipeline_depth_stencil_state_create_info* new_depth_stencil_state)
  {
    _depth_stencil_state = new_depth_stencil_state;
  }

  const vk::pipeline_color_blend_state_create_info* color_blend_state()
  {
    return _color_blend_state;
  }

  constexpr const vk::pipeline_color_blend_state_create_info*
  color_blend_state() const
  {
    return _color_blend_state;
  }

  void color_blend_state(
    const vk::pipeline_color_blend_state_create_info* new_color_blend_state)
  {
    _color_blend_state = new_color_blend_state;
  }

  const vk::pipeline_dynamic_state_create_info* dynamic_state()
  {
    return _dynamic_state;
  }

  constexpr const vk::pipeline_dynamic_state_create_info* dynamic_state() const
  {
    return _dynamic_state;
  }

  void dynamic_state(
    const vk::pipeline_dynamic_state_create_info* new_dynamic_state)
  {
    _dynamic_state = new_dynamic_state;
  }

  VkPipelineLayout& layout()
  {
    return _layout;
  }

  constexpr const VkPipelineLayout& layout() const
  {
    return _layout;
  }

  void layout(VkPipelineLayout new_layout)
  {
    _layout = new_layout;
  }

  VkRenderPass& render_pass()
  {
    return _render_pass;
  }

  constexpr const VkRenderPass& render_pass() const
  {
    return _render_pass;
  }

  void render_pass(VkRenderPass new_render_pass)
  {
    _render_pass = new_render_pass;
  }

  uint32_t& subpass()
  {
    return _subpass;
  }

  constexpr const uint32_t& subpass() const
  {
    return _subpass;
  }

  void subpass(uint32_t new_subpass)
  {
    _subpass = new_subpass;
  }

  VkPipeline& base_pipeline_handle()
  {
    return _base_pipeline_handle;
  }

  constexpr const VkPipeline& base_pipeline_handle() const
  {
    return _base_pipeline_handle;
  }

  void base_pipeline_handle(VkPipeline new_base_pipeline_handle)
  {
    _base_pipeline_handle = new_base_pipeline_handle;
  }

  int32_t& base_pipeline_index()
  {
    return _base_pipeline_index;
  }

  constexpr const int32_t& base_pipeline_index() const
  {
    return _base_pipeline_index;
  }

  void base_pipeline_index(int32_t new_base_pipeline_index)
  {
    _base_pipeline_index = new_base_pipeline_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::graphics_pipeline_create_info;
  const void* _next = nullptr;
  /// Pipeline creation flags
  vk::pipeline_create_flags _flags = vk::pipeline_create_flag::none;
  uint32_t _stage_count = 0;
  /// One entry for each active shader stage
  const vk::pipeline_shader_stage_create_info* _stages = nullptr;
  const vk::pipeline_vertex_input_state_create_info* _vertex_input_state =
    nullptr;
  const vk::pipeline_input_assembly_state_create_info* _input_assembly_state =
    nullptr;
  const vk::pipeline_tessellation_state_create_info* _tessellation_state =
    nullptr;
  const vk::pipeline_viewport_state_create_info* _viewport_state = nullptr;
  const vk::pipeline_rasterization_state_create_info* _rasterization_state =
    nullptr;
  const vk::pipeline_multisample_state_create_info* _multisample_state =
    nullptr;
  const vk::pipeline_depth_stencil_state_create_info* _depth_stencil_state =
    nullptr;
  const vk::pipeline_color_blend_state_create_info* _color_blend_state =
    nullptr;
  const vk::pipeline_dynamic_state_create_info* _dynamic_state = nullptr;
  /// Interface layout of the pipeline
  VkPipelineLayout _layout = nullptr;
  VkRenderPass _render_pass = nullptr;
  uint32_t _subpass = 0;
  /// If VK_PIPELINE_CREATE_DERIVATIVE_BIT is set and this value is nonzero, it
  /// specifies the handle of the base pipeline this is a derivative of
  VkPipeline _base_pipeline_handle = nullptr;
  /// If VK_PIPELINE_CREATE_DERIVATIVE_BIT is set and this value is not -1, it
  /// specifies an index into pCreateInfos of the base pipeline this is a
  /// derivative of
  int32_t _base_pipeline_index = 0;
};
static_assert(sizeof(graphics_pipeline_create_info) ==
                sizeof(::VkGraphicsPipelineCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_graphics_pipelines(
  VkDevice device, VkPipelineCache pipeline_cache, uint32_t create_info_count,
  const vk::graphics_pipeline_create_info* create_infos,
  const vk::allocation_callbacks* allocator, VkPipeline* pipelines)
{
  return static_cast<vk::result>(vkCreateGraphicsPipelines(
    static_cast<VkDevice>(device), static_cast<VkPipelineCache>(pipeline_cache),
    static_cast<uint32_t>(create_info_count),
    reinterpret_cast<const VkGraphicsPipelineCreateInfo*>(create_infos),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkPipeline*>(pipelines)));
}

/// Enhanced replacement type for VkComputePipelineCreateInfo.
class compute_pipeline_create_info
{
public:
  /// Default constructor.
  constexpr compute_pipeline_create_info() = default;

  /// Constructor.
  constexpr compute_pipeline_create_info(
    const void* initial_next, vk::pipeline_create_flags initial_flags,
    vk::pipeline_shader_stage_create_info initial_stage,
    VkPipelineLayout initial_layout, VkPipeline initial_base_pipeline_handle,
    int32_t initial_base_pipeline_index) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _stage(std::move(initial_stage)),
    _layout(std::move(initial_layout)),
    _base_pipeline_handle(std::move(initial_base_pipeline_handle)),
    _base_pipeline_index(std::move(initial_base_pipeline_index))
  {
  }

  /// Copy constructor.
  constexpr compute_pipeline_create_info(
    const compute_pipeline_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _stage(other._stage),
    _layout(other._layout),
    _base_pipeline_handle(other._base_pipeline_handle),
    _base_pipeline_index(other._base_pipeline_index)
  {
  }

  /// Move constructor.
  constexpr compute_pipeline_create_info(
    compute_pipeline_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _stage(std::move(other._stage)),
    _layout(std::move(other._layout)),
    _base_pipeline_handle(std::move(other._base_pipeline_handle)),
    _base_pipeline_index(std::move(other._base_pipeline_index))
  {
  }

  /// Copy assignment operator.
  constexpr compute_pipeline_create_info& operator=(
    const compute_pipeline_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _stage = other._stage;
    _layout = other._layout;
    _base_pipeline_handle = other._base_pipeline_handle;
    _base_pipeline_index = other._base_pipeline_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr compute_pipeline_create_info& operator=(
    compute_pipeline_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _stage = std::move(other._stage);
    _layout = std::move(other._layout);
    _base_pipeline_handle = std::move(other._base_pipeline_handle);
    _base_pipeline_index = std::move(other._base_pipeline_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkComputePipelineCreateInfo&() const
  {
    return *reinterpret_cast<const VkComputePipelineCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_create_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::pipeline_shader_stage_create_info& stage()
  {
    return _stage;
  }

  constexpr const vk::pipeline_shader_stage_create_info& stage() const
  {
    return _stage;
  }

  void stage(vk::pipeline_shader_stage_create_info new_stage)
  {
    _stage = new_stage;
  }

  VkPipelineLayout& layout()
  {
    return _layout;
  }

  constexpr const VkPipelineLayout& layout() const
  {
    return _layout;
  }

  void layout(VkPipelineLayout new_layout)
  {
    _layout = new_layout;
  }

  VkPipeline& base_pipeline_handle()
  {
    return _base_pipeline_handle;
  }

  constexpr const VkPipeline& base_pipeline_handle() const
  {
    return _base_pipeline_handle;
  }

  void base_pipeline_handle(VkPipeline new_base_pipeline_handle)
  {
    _base_pipeline_handle = new_base_pipeline_handle;
  }

  int32_t& base_pipeline_index()
  {
    return _base_pipeline_index;
  }

  constexpr const int32_t& base_pipeline_index() const
  {
    return _base_pipeline_index;
  }

  void base_pipeline_index(int32_t new_base_pipeline_index)
  {
    _base_pipeline_index = new_base_pipeline_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::compute_pipeline_create_info;
  const void* _next = nullptr;
  /// Pipeline creation flags
  vk::pipeline_create_flags _flags = vk::pipeline_create_flag::none;
  vk::pipeline_shader_stage_create_info _stage =
    vk::pipeline_shader_stage_create_info{};
  /// Interface layout of the pipeline
  VkPipelineLayout _layout = nullptr;
  /// If VK_PIPELINE_CREATE_DERIVATIVE_BIT is set and this value is nonzero, it
  /// specifies the handle of the base pipeline this is a derivative of
  VkPipeline _base_pipeline_handle = nullptr;
  /// If VK_PIPELINE_CREATE_DERIVATIVE_BIT is set and this value is not -1, it
  /// specifies an index into pCreateInfos of the base pipeline this is a
  /// derivative of
  int32_t _base_pipeline_index = 0;
};
static_assert(sizeof(compute_pipeline_create_info) ==
                sizeof(::VkComputePipelineCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_compute_pipelines(
  VkDevice device, VkPipelineCache pipeline_cache, uint32_t create_info_count,
  const vk::compute_pipeline_create_info* create_infos,
  const vk::allocation_callbacks* allocator, VkPipeline* pipelines)
{
  return static_cast<vk::result>(vkCreateComputePipelines(
    static_cast<VkDevice>(device), static_cast<VkPipelineCache>(pipeline_cache),
    static_cast<uint32_t>(create_info_count),
    reinterpret_cast<const VkComputePipelineCreateInfo*>(create_infos),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkPipeline*>(pipelines)));
}
inline void destroy_pipeline(VkDevice device, VkPipeline pipeline,
                             const vk::allocation_callbacks* allocator)
{
  vkDestroyPipeline(static_cast<VkDevice>(device),
                    static_cast<VkPipeline>(pipeline),
                    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
enum class pipeline_layout_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using pipeline_layout_create_flags =
  shift::core::bit_field<pipeline_layout_create_flag,
                         VkPipelineLayoutCreateFlags>;
inline constexpr pipeline_layout_create_flags operator|(
  pipeline_layout_create_flag lhs, pipeline_layout_create_flag rhs)
{
  return pipeline_layout_create_flags{lhs} | rhs;
}
using shader_stage_flags =
  shift::core::bit_field<shader_stage_flag, VkShaderStageFlags>;
inline constexpr shader_stage_flags operator|(shader_stage_flag lhs,
                                              shader_stage_flag rhs)
{
  return shader_stage_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkPushConstantRange.
class push_constant_range
{
public:
  /// Default constructor.
  constexpr push_constant_range() = default;

  /// Constructor.
  constexpr push_constant_range(vk::shader_stage_flags initial_stage_flags,
                                uint32_t initial_offset,
                                uint32_t initial_size) noexcept
  : _stage_flags(std::move(initial_stage_flags)),
    _offset(std::move(initial_offset)),
    _size(std::move(initial_size))
  {
  }

  /// Copy constructor.
  constexpr push_constant_range(const push_constant_range& other) = default;

  /// Move constructor.
  constexpr push_constant_range(push_constant_range&& other) = default;

  /// Copy assignment operator.
  constexpr push_constant_range& operator=(const push_constant_range& other) =
    default;

  /// Move assignment operator.
  constexpr push_constant_range& operator=(push_constant_range&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkPushConstantRange&() const
  {
    return *reinterpret_cast<const VkPushConstantRange*>(this);
  }

  vk::shader_stage_flags& stage_flags()
  {
    return _stage_flags;
  }

  constexpr const vk::shader_stage_flags& stage_flags() const
  {
    return _stage_flags;
  }

  void stage_flags(vk::shader_stage_flags new_stage_flags)
  {
    _stage_flags = new_stage_flags;
  }

  uint32_t& offset()
  {
    return _offset;
  }

  constexpr const uint32_t& offset() const
  {
    return _offset;
  }

  void offset(uint32_t new_offset)
  {
    _offset = new_offset;
  }

  uint32_t& size()
  {
    return _size;
  }

  constexpr const uint32_t& size() const
  {
    return _size;
  }

  void size(uint32_t new_size)
  {
    _size = new_size;
  }

private:
  /// Which stages use the range
  vk::shader_stage_flags _stage_flags = vk::shader_stage_flag::none;
  /// Start of the range, in bytes
  uint32_t _offset = 0;
  /// Size of the range, in bytes
  uint32_t _size = 0;
};
static_assert(sizeof(push_constant_range) == sizeof(::VkPushConstantRange),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPipelineLayoutCreateInfo.
class pipeline_layout_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_layout_create_info() = default;

  /// Constructor.
  constexpr pipeline_layout_create_info(
    const void* initial_next, vk::pipeline_layout_create_flags initial_flags,
    uint32_t initial_set_layout_count,
    const VkDescriptorSetLayout* initial_set_layouts,
    uint32_t initial_push_constant_range_count,
    const vk::push_constant_range* initial_push_constant_ranges) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _set_layout_count(std::move(initial_set_layout_count)),
    _set_layouts(std::move(initial_set_layouts)),
    _push_constant_range_count(std::move(initial_push_constant_range_count)),
    _push_constant_ranges(std::move(initial_push_constant_ranges))
  {
  }

  /// Copy constructor.
  constexpr pipeline_layout_create_info(
    const pipeline_layout_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _set_layout_count(other._set_layout_count),
    _set_layouts(other._set_layouts),
    _push_constant_range_count(other._push_constant_range_count),
    _push_constant_ranges(other._push_constant_ranges)
  {
  }

  /// Move constructor.
  constexpr pipeline_layout_create_info(
    pipeline_layout_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _set_layout_count(std::move(other._set_layout_count)),
    _set_layouts(std::move(other._set_layouts)),
    _push_constant_range_count(std::move(other._push_constant_range_count)),
    _push_constant_ranges(std::move(other._push_constant_ranges))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_layout_create_info& operator=(
    const pipeline_layout_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _set_layout_count = other._set_layout_count;
    _set_layouts = other._set_layouts;
    _push_constant_range_count = other._push_constant_range_count;
    _push_constant_ranges = other._push_constant_ranges;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_layout_create_info& operator=(
    pipeline_layout_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _set_layout_count = std::move(other._set_layout_count);
    _set_layouts = std::move(other._set_layouts);
    _push_constant_range_count = std::move(other._push_constant_range_count);
    _push_constant_ranges = std::move(other._push_constant_ranges);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineLayoutCreateInfo&() const
  {
    return *reinterpret_cast<const VkPipelineLayoutCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_layout_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_layout_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_layout_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& set_layout_count()
  {
    return _set_layout_count;
  }

  constexpr const uint32_t& set_layout_count() const
  {
    return _set_layout_count;
  }

  void set_layout_count(uint32_t new_set_layout_count)
  {
    _set_layout_count = new_set_layout_count;
  }

  const VkDescriptorSetLayout* set_layouts()
  {
    return _set_layouts;
  }

  constexpr const VkDescriptorSetLayout* set_layouts() const
  {
    return _set_layouts;
  }

  void set_layouts(const VkDescriptorSetLayout* new_set_layouts)
  {
    _set_layouts = new_set_layouts;
  }

  template <std::size_t Count>
  void set_layouts(
    const std::array<VkDescriptorSetLayout, Count>& new_set_layouts)
  {
    _set_layout_count = static_cast<uint32_t>(new_set_layouts.size());
    _set_layouts = new_set_layouts.data();
  }

  void set_layouts(const std::vector<VkDescriptorSetLayout>& new_set_layouts)
  {
    _set_layout_count = static_cast<uint32_t>(new_set_layouts.size());
    _set_layouts = new_set_layouts.data();
  }

  uint32_t& push_constant_range_count()
  {
    return _push_constant_range_count;
  }

  constexpr const uint32_t& push_constant_range_count() const
  {
    return _push_constant_range_count;
  }

  void push_constant_range_count(uint32_t new_push_constant_range_count)
  {
    _push_constant_range_count = new_push_constant_range_count;
  }

  const vk::push_constant_range* push_constant_ranges()
  {
    return _push_constant_ranges;
  }

  constexpr const vk::push_constant_range* push_constant_ranges() const
  {
    return _push_constant_ranges;
  }

  void push_constant_ranges(
    const vk::push_constant_range* new_push_constant_ranges)
  {
    _push_constant_ranges = new_push_constant_ranges;
  }

  template <std::size_t Count>
  void push_constant_ranges(
    const std::array<vk::push_constant_range, Count>& new_push_constant_ranges)
  {
    _push_constant_range_count =
      static_cast<uint32_t>(new_push_constant_ranges.size());
    _push_constant_ranges = new_push_constant_ranges.data();
  }

  void push_constant_ranges(
    const std::vector<vk::push_constant_range>& new_push_constant_ranges)
  {
    _push_constant_range_count =
      static_cast<uint32_t>(new_push_constant_ranges.size());
    _push_constant_ranges = new_push_constant_ranges.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_layout_create_info;
  const void* _next = nullptr;
  vk::pipeline_layout_create_flags _flags =
    vk::pipeline_layout_create_flag::none;
  /// Number of descriptor sets interfaced by the pipeline
  uint32_t _set_layout_count = 0;
  /// Array of setCount number of descriptor set layout objects defining the
  /// layout of the
  const VkDescriptorSetLayout* _set_layouts = nullptr;
  /// Number of push-constant ranges used by the pipeline
  uint32_t _push_constant_range_count = 0;
  /// Array of pushConstantRangeCount number of ranges used by various shader
  /// stages
  const vk::push_constant_range* _push_constant_ranges = nullptr;
};
static_assert(sizeof(pipeline_layout_create_info) ==
                sizeof(::VkPipelineLayoutCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_pipeline_layout(
  VkDevice device, const vk::pipeline_layout_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkPipelineLayout* pipeline_layout)
{
  return static_cast<vk::result>(vkCreatePipelineLayout(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkPipelineLayoutCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkPipelineLayout*>(pipeline_layout)));
}
inline void destroy_pipeline_layout(VkDevice device,
                                    VkPipelineLayout pipeline_layout,
                                    const vk::allocation_callbacks* allocator)
{
  vkDestroyPipelineLayout(
    static_cast<VkDevice>(device),
    static_cast<VkPipelineLayout>(pipeline_layout),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
enum class sampler_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using sampler_create_flags =
  shift::core::bit_field<sampler_create_flag, VkSamplerCreateFlags>;
inline constexpr sampler_create_flags operator|(sampler_create_flag lhs,
                                                sampler_create_flag rhs)
{
  return sampler_create_flags{lhs} | rhs;
}
enum class filter
{
  /// @see VK_FILTER_NEAREST
  nearest = 0,
  /// @see VK_FILTER_LINEAR
  linear = 1,
  /// @see VK_FILTER_CUBIC_IMG
  cubic_img = 1000015000,
};
enum class sampler_mipmap_mode
{
  /// Choose nearest mip level
  /// @see VK_SAMPLER_MIPMAP_MODE_NEAREST
  nearest = 0,
  /// Linear filter between mip levels
  /// @see VK_SAMPLER_MIPMAP_MODE_LINEAR
  linear = 1,
};
enum class sampler_address_mode
{
  /// @see VK_SAMPLER_ADDRESS_MODE_REPEAT
  repeat = 0,
  /// @see VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT
  mirrored_repeat = 1,
  /// @see VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE
  clamp_to_edge = 2,
  /// @see VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER
  clamp_to_border = 3,
  /// Note that this defines what was previously a core enum, and so uses the
  /// 'value' attribute rather than 'offset', and does not have a suffix. This
  /// is a special case, and should not be repeated
  /// @see VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE
  mirror_clamp_to_edge = 4,
};
enum class border_color
{
  /// @see VK_BORDER_COLOR_FLOAT_TRANSPARENT_BLACK
  float_transparent_black = 0,
  /// @see VK_BORDER_COLOR_INT_TRANSPARENT_BLACK
  int_transparent_black = 1,
  /// @see VK_BORDER_COLOR_FLOAT_OPAQUE_BLACK
  float_opaque_black = 2,
  /// @see VK_BORDER_COLOR_INT_OPAQUE_BLACK
  int_opaque_black = 3,
  /// @see VK_BORDER_COLOR_FLOAT_OPAQUE_WHITE
  float_opaque_white = 4,
  /// @see VK_BORDER_COLOR_INT_OPAQUE_WHITE
  int_opaque_white = 5,
};

/// Enhanced replacement type for VkSamplerCreateInfo.
class sampler_create_info
{
public:
  /// Default constructor.
  constexpr sampler_create_info() = default;

  /// Constructor.
  constexpr sampler_create_info(
    const void* initial_next, vk::sampler_create_flags initial_flags,
    vk::filter initial_mag_filter, vk::filter initial_min_filter,
    vk::sampler_mipmap_mode initial_mipmap_mode,
    vk::sampler_address_mode initial_address_mode_u,
    vk::sampler_address_mode initial_address_mode_v,
    vk::sampler_address_mode initial_address_mode_w, float initial_mip_lod_bias,
    VkBool32 initial_anisotropy_enable, float initial_max_anisotropy,
    VkBool32 initial_compare_enable, vk::compare_op initial_compare_op,
    float initial_min_lod, float initial_max_lod,
    vk::border_color initial_border_color,
    VkBool32 initial_unnormalized_coordinates) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _mag_filter(std::move(initial_mag_filter)),
    _min_filter(std::move(initial_min_filter)),
    _mipmap_mode(std::move(initial_mipmap_mode)),
    _address_mode_u(std::move(initial_address_mode_u)),
    _address_mode_v(std::move(initial_address_mode_v)),
    _address_mode_w(std::move(initial_address_mode_w)),
    _mip_lod_bias(std::move(initial_mip_lod_bias)),
    _anisotropy_enable(std::move(initial_anisotropy_enable)),
    _max_anisotropy(std::move(initial_max_anisotropy)),
    _compare_enable(std::move(initial_compare_enable)),
    _compare_op(std::move(initial_compare_op)),
    _min_lod(std::move(initial_min_lod)),
    _max_lod(std::move(initial_max_lod)),
    _border_color(std::move(initial_border_color)),
    _unnormalized_coordinates(std::move(initial_unnormalized_coordinates))
  {
  }

  /// Copy constructor.
  constexpr sampler_create_info(const sampler_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _mag_filter(other._mag_filter),
    _min_filter(other._min_filter),
    _mipmap_mode(other._mipmap_mode),
    _address_mode_u(other._address_mode_u),
    _address_mode_v(other._address_mode_v),
    _address_mode_w(other._address_mode_w),
    _mip_lod_bias(other._mip_lod_bias),
    _anisotropy_enable(other._anisotropy_enable),
    _max_anisotropy(other._max_anisotropy),
    _compare_enable(other._compare_enable),
    _compare_op(other._compare_op),
    _min_lod(other._min_lod),
    _max_lod(other._max_lod),
    _border_color(other._border_color),
    _unnormalized_coordinates(other._unnormalized_coordinates)
  {
  }

  /// Move constructor.
  constexpr sampler_create_info(sampler_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _mag_filter(std::move(other._mag_filter)),
    _min_filter(std::move(other._min_filter)),
    _mipmap_mode(std::move(other._mipmap_mode)),
    _address_mode_u(std::move(other._address_mode_u)),
    _address_mode_v(std::move(other._address_mode_v)),
    _address_mode_w(std::move(other._address_mode_w)),
    _mip_lod_bias(std::move(other._mip_lod_bias)),
    _anisotropy_enable(std::move(other._anisotropy_enable)),
    _max_anisotropy(std::move(other._max_anisotropy)),
    _compare_enable(std::move(other._compare_enable)),
    _compare_op(std::move(other._compare_op)),
    _min_lod(std::move(other._min_lod)),
    _max_lod(std::move(other._max_lod)),
    _border_color(std::move(other._border_color)),
    _unnormalized_coordinates(std::move(other._unnormalized_coordinates))
  {
  }

  /// Copy assignment operator.
  constexpr sampler_create_info& operator=(
    const sampler_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _mag_filter = other._mag_filter;
    _min_filter = other._min_filter;
    _mipmap_mode = other._mipmap_mode;
    _address_mode_u = other._address_mode_u;
    _address_mode_v = other._address_mode_v;
    _address_mode_w = other._address_mode_w;
    _mip_lod_bias = other._mip_lod_bias;
    _anisotropy_enable = other._anisotropy_enable;
    _max_anisotropy = other._max_anisotropy;
    _compare_enable = other._compare_enable;
    _compare_op = other._compare_op;
    _min_lod = other._min_lod;
    _max_lod = other._max_lod;
    _border_color = other._border_color;
    _unnormalized_coordinates = other._unnormalized_coordinates;
    return *this;
  }

  /// Move assignment operator.
  constexpr sampler_create_info& operator=(sampler_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _mag_filter = std::move(other._mag_filter);
    _min_filter = std::move(other._min_filter);
    _mipmap_mode = std::move(other._mipmap_mode);
    _address_mode_u = std::move(other._address_mode_u);
    _address_mode_v = std::move(other._address_mode_v);
    _address_mode_w = std::move(other._address_mode_w);
    _mip_lod_bias = std::move(other._mip_lod_bias);
    _anisotropy_enable = std::move(other._anisotropy_enable);
    _max_anisotropy = std::move(other._max_anisotropy);
    _compare_enable = std::move(other._compare_enable);
    _compare_op = std::move(other._compare_op);
    _min_lod = std::move(other._min_lod);
    _max_lod = std::move(other._max_lod);
    _border_color = std::move(other._border_color);
    _unnormalized_coordinates = std::move(other._unnormalized_coordinates);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSamplerCreateInfo&() const
  {
    return *reinterpret_cast<const VkSamplerCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::sampler_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::sampler_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::sampler_create_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::filter& mag_filter()
  {
    return _mag_filter;
  }

  constexpr const vk::filter& mag_filter() const
  {
    return _mag_filter;
  }

  void mag_filter(vk::filter new_mag_filter)
  {
    _mag_filter = new_mag_filter;
  }

  vk::filter& min_filter()
  {
    return _min_filter;
  }

  constexpr const vk::filter& min_filter() const
  {
    return _min_filter;
  }

  void min_filter(vk::filter new_min_filter)
  {
    _min_filter = new_min_filter;
  }

  vk::sampler_mipmap_mode& mipmap_mode()
  {
    return _mipmap_mode;
  }

  constexpr const vk::sampler_mipmap_mode& mipmap_mode() const
  {
    return _mipmap_mode;
  }

  void mipmap_mode(vk::sampler_mipmap_mode new_mipmap_mode)
  {
    _mipmap_mode = new_mipmap_mode;
  }

  vk::sampler_address_mode& address_mode_u()
  {
    return _address_mode_u;
  }

  constexpr const vk::sampler_address_mode& address_mode_u() const
  {
    return _address_mode_u;
  }

  void address_mode_u(vk::sampler_address_mode new_address_mode_u)
  {
    _address_mode_u = new_address_mode_u;
  }

  vk::sampler_address_mode& address_mode_v()
  {
    return _address_mode_v;
  }

  constexpr const vk::sampler_address_mode& address_mode_v() const
  {
    return _address_mode_v;
  }

  void address_mode_v(vk::sampler_address_mode new_address_mode_v)
  {
    _address_mode_v = new_address_mode_v;
  }

  vk::sampler_address_mode& address_mode_w()
  {
    return _address_mode_w;
  }

  constexpr const vk::sampler_address_mode& address_mode_w() const
  {
    return _address_mode_w;
  }

  void address_mode_w(vk::sampler_address_mode new_address_mode_w)
  {
    _address_mode_w = new_address_mode_w;
  }

  float& mip_lod_bias()
  {
    return _mip_lod_bias;
  }

  constexpr const float& mip_lod_bias() const
  {
    return _mip_lod_bias;
  }

  void mip_lod_bias(float new_mip_lod_bias)
  {
    _mip_lod_bias = new_mip_lod_bias;
  }

  VkBool32& anisotropy_enable()
  {
    return _anisotropy_enable;
  }

  constexpr const VkBool32& anisotropy_enable() const
  {
    return _anisotropy_enable;
  }

  void anisotropy_enable(VkBool32 new_anisotropy_enable)
  {
    _anisotropy_enable = new_anisotropy_enable;
  }

  float& max_anisotropy()
  {
    return _max_anisotropy;
  }

  constexpr const float& max_anisotropy() const
  {
    return _max_anisotropy;
  }

  void max_anisotropy(float new_max_anisotropy)
  {
    _max_anisotropy = new_max_anisotropy;
  }

  VkBool32& compare_enable()
  {
    return _compare_enable;
  }

  constexpr const VkBool32& compare_enable() const
  {
    return _compare_enable;
  }

  void compare_enable(VkBool32 new_compare_enable)
  {
    _compare_enable = new_compare_enable;
  }

  vk::compare_op& compare_op()
  {
    return _compare_op;
  }

  constexpr const vk::compare_op& compare_op() const
  {
    return _compare_op;
  }

  void compare_op(vk::compare_op new_compare_op)
  {
    _compare_op = new_compare_op;
  }

  float& min_lod()
  {
    return _min_lod;
  }

  constexpr const float& min_lod() const
  {
    return _min_lod;
  }

  void min_lod(float new_min_lod)
  {
    _min_lod = new_min_lod;
  }

  float& max_lod()
  {
    return _max_lod;
  }

  constexpr const float& max_lod() const
  {
    return _max_lod;
  }

  void max_lod(float new_max_lod)
  {
    _max_lod = new_max_lod;
  }

  vk::border_color& border_color()
  {
    return _border_color;
  }

  constexpr const vk::border_color& border_color() const
  {
    return _border_color;
  }

  void border_color(vk::border_color new_border_color)
  {
    _border_color = new_border_color;
  }

  VkBool32& unnormalized_coordinates()
  {
    return _unnormalized_coordinates;
  }

  constexpr const VkBool32& unnormalized_coordinates() const
  {
    return _unnormalized_coordinates;
  }

  void unnormalized_coordinates(VkBool32 new_unnormalized_coordinates)
  {
    _unnormalized_coordinates = new_unnormalized_coordinates;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::sampler_create_info;
  const void* _next = nullptr;
  vk::sampler_create_flags _flags = vk::sampler_create_flag::none;
  /// Filter mode for magnification
  vk::filter _mag_filter = vk::filter::nearest;
  /// Filter mode for minifiation
  vk::filter _min_filter = vk::filter::nearest;
  /// Mipmap selection mode
  vk::sampler_mipmap_mode _mipmap_mode = vk::sampler_mipmap_mode::nearest;
  vk::sampler_address_mode _address_mode_u = vk::sampler_address_mode::repeat;
  vk::sampler_address_mode _address_mode_v = vk::sampler_address_mode::repeat;
  vk::sampler_address_mode _address_mode_w = vk::sampler_address_mode::repeat;
  float _mip_lod_bias = 0.0f;
  VkBool32 _anisotropy_enable = VK_FALSE;
  float _max_anisotropy = 0.0f;
  VkBool32 _compare_enable = VK_FALSE;
  vk::compare_op _compare_op = vk::compare_op::never;
  float _min_lod = 0.0f;
  float _max_lod = 0.0f;
  vk::border_color _border_color = vk::border_color::float_transparent_black;
  VkBool32 _unnormalized_coordinates = VK_FALSE;
};
static_assert(sizeof(sampler_create_info) == sizeof(::VkSamplerCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_sampler(VkDevice device,
                                 const vk::sampler_create_info* create_info,
                                 const vk::allocation_callbacks* allocator,
                                 VkSampler* sampler)
{
  return static_cast<vk::result>(
    vkCreateSampler(static_cast<VkDevice>(device),
                    reinterpret_cast<const VkSamplerCreateInfo*>(create_info),
                    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
                    reinterpret_cast<VkSampler*>(sampler)));
}
inline void destroy_sampler(VkDevice device, VkSampler sampler,
                            const vk::allocation_callbacks* allocator)
{
  vkDestroySampler(static_cast<VkDevice>(device),
                   static_cast<VkSampler>(sampler),
                   reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
enum class descriptor_set_layout_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Descriptors are pushed via flink:vkCmdPushDescriptorSetKHR
  /// @see VK_DESCRIPTOR_SET_LAYOUT_CREATE_PUSH_DESCRIPTOR_BIT_KHR
  push_descriptor_bit_khr = 1 << 0,
  /// @see VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT_EXT
  update_after_bind_pool_bit_ext = 1 << 1,
};
using descriptor_set_layout_create_flags =
  shift::core::bit_field<descriptor_set_layout_create_flag,
                         VkDescriptorSetLayoutCreateFlags>;
inline constexpr descriptor_set_layout_create_flags operator|(
  descriptor_set_layout_create_flag lhs, descriptor_set_layout_create_flag rhs)
{
  return descriptor_set_layout_create_flags{lhs} | rhs;
}
enum class descriptor_type
{
  /// @see VK_DESCRIPTOR_TYPE_SAMPLER
  sampler = 0,
  /// @see VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER
  combined_image_sampler = 1,
  /// @see VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE
  sampled_image = 2,
  /// @see VK_DESCRIPTOR_TYPE_STORAGE_IMAGE
  storage_image = 3,
  /// @see VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER
  uniform_texel_buffer = 4,
  /// @see VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER
  storage_texel_buffer = 5,
  /// @see VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER
  uniform_buffer = 6,
  /// @see VK_DESCRIPTOR_TYPE_STORAGE_BUFFER
  storage_buffer = 7,
  /// @see VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC
  uniform_buffer_dynamic = 8,
  /// @see VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC
  storage_buffer_dynamic = 9,
  /// @see VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT
  input_attachment = 10,
  /// @see VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT
  inline_uniform_block_ext = 1000138000,
  /// @see VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_NVX
  acceleration_structure_nvx = 1000165000,
};

/// Enhanced replacement type for VkDescriptorSetLayoutBinding.
class descriptor_set_layout_binding
{
public:
  /// Default constructor.
  constexpr descriptor_set_layout_binding() = default;

  /// Constructor.
  constexpr descriptor_set_layout_binding(
    uint32_t initial_binding, vk::descriptor_type initial_descriptor_type,
    uint32_t initial_descriptor_count,
    vk::shader_stage_flags initial_stage_flags,
    const VkSampler* initial_immutable_samplers) noexcept
  : _binding(std::move(initial_binding)),
    _descriptor_type(std::move(initial_descriptor_type)),
    _descriptor_count(std::move(initial_descriptor_count)),
    _stage_flags(std::move(initial_stage_flags)),
    _immutable_samplers(std::move(initial_immutable_samplers))
  {
  }

  /// Copy constructor.
  constexpr descriptor_set_layout_binding(
    const descriptor_set_layout_binding& other) = default;

  /// Move constructor.
  constexpr descriptor_set_layout_binding(
    descriptor_set_layout_binding&& other) = default;

  /// Copy assignment operator.
  constexpr descriptor_set_layout_binding& operator=(
    const descriptor_set_layout_binding& other) = default;

  /// Move assignment operator.
  constexpr descriptor_set_layout_binding& operator=(
    descriptor_set_layout_binding&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorSetLayoutBinding&() const
  {
    return *reinterpret_cast<const VkDescriptorSetLayoutBinding*>(this);
  }

  uint32_t& binding()
  {
    return _binding;
  }

  constexpr const uint32_t& binding() const
  {
    return _binding;
  }

  void binding(uint32_t new_binding)
  {
    _binding = new_binding;
  }

  vk::descriptor_type& descriptor_type()
  {
    return _descriptor_type;
  }

  constexpr const vk::descriptor_type& descriptor_type() const
  {
    return _descriptor_type;
  }

  void descriptor_type(vk::descriptor_type new_descriptor_type)
  {
    _descriptor_type = new_descriptor_type;
  }

  uint32_t& descriptor_count()
  {
    return _descriptor_count;
  }

  constexpr const uint32_t& descriptor_count() const
  {
    return _descriptor_count;
  }

  void descriptor_count(uint32_t new_descriptor_count)
  {
    _descriptor_count = new_descriptor_count;
  }

  vk::shader_stage_flags& stage_flags()
  {
    return _stage_flags;
  }

  constexpr const vk::shader_stage_flags& stage_flags() const
  {
    return _stage_flags;
  }

  void stage_flags(vk::shader_stage_flags new_stage_flags)
  {
    _stage_flags = new_stage_flags;
  }

  const VkSampler* immutable_samplers()
  {
    return _immutable_samplers;
  }

  constexpr const VkSampler* immutable_samplers() const
  {
    return _immutable_samplers;
  }

  void immutable_samplers(const VkSampler* new_immutable_samplers)
  {
    _immutable_samplers = new_immutable_samplers;
  }

  template <std::size_t Count>
  void immutable_samplers(
    const std::array<VkSampler, Count>& new_immutable_samplers)
  {
    _descriptor_count = static_cast<uint32_t>(new_immutable_samplers.size());
    _immutable_samplers = new_immutable_samplers.data();
  }

  void immutable_samplers(const std::vector<VkSampler>& new_immutable_samplers)
  {
    _descriptor_count = static_cast<uint32_t>(new_immutable_samplers.size());
    _immutable_samplers = new_immutable_samplers.data();
  }

private:
  /// Binding number for this entry
  uint32_t _binding = 0;
  /// Type of the descriptors in this binding
  vk::descriptor_type _descriptor_type = vk::descriptor_type::sampler;
  /// Number of descriptors in this binding
  uint32_t _descriptor_count = 0;
  /// Shader stages this binding is visible to
  vk::shader_stage_flags _stage_flags = vk::shader_stage_flag::none;
  /// Immutable samplers (used if descriptor type is SAMPLER or
  /// COMBINED_IMAGE_SAMPLER, is either NULL or contains count number of
  /// elements)
  const VkSampler* _immutable_samplers = nullptr;
};
static_assert(sizeof(descriptor_set_layout_binding) ==
                sizeof(::VkDescriptorSetLayoutBinding),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDescriptorSetLayoutCreateInfo.
class descriptor_set_layout_create_info
{
public:
  /// Default constructor.
  constexpr descriptor_set_layout_create_info() = default;

  /// Constructor.
  constexpr descriptor_set_layout_create_info(
    const void* initial_next,
    vk::descriptor_set_layout_create_flags initial_flags,
    uint32_t initial_binding_count,
    const vk::descriptor_set_layout_binding* initial_bindings) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _binding_count(std::move(initial_binding_count)),
    _bindings(std::move(initial_bindings))
  {
  }

  /// Copy constructor.
  constexpr descriptor_set_layout_create_info(
    const descriptor_set_layout_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _binding_count(other._binding_count),
    _bindings(other._bindings)
  {
  }

  /// Move constructor.
  constexpr descriptor_set_layout_create_info(
    descriptor_set_layout_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _binding_count(std::move(other._binding_count)),
    _bindings(std::move(other._bindings))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_set_layout_create_info& operator=(
    const descriptor_set_layout_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _binding_count = other._binding_count;
    _bindings = other._bindings;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_set_layout_create_info& operator=(
    descriptor_set_layout_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _binding_count = std::move(other._binding_count);
    _bindings = std::move(other._bindings);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorSetLayoutCreateInfo&() const
  {
    return *reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::descriptor_set_layout_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::descriptor_set_layout_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::descriptor_set_layout_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& binding_count()
  {
    return _binding_count;
  }

  constexpr const uint32_t& binding_count() const
  {
    return _binding_count;
  }

  void binding_count(uint32_t new_binding_count)
  {
    _binding_count = new_binding_count;
  }

  const vk::descriptor_set_layout_binding* bindings()
  {
    return _bindings;
  }

  constexpr const vk::descriptor_set_layout_binding* bindings() const
  {
    return _bindings;
  }

  void bindings(const vk::descriptor_set_layout_binding* new_bindings)
  {
    _bindings = new_bindings;
  }

  template <std::size_t Count>
  void bindings(
    const std::array<vk::descriptor_set_layout_binding, Count>& new_bindings)
  {
    _binding_count = static_cast<uint32_t>(new_bindings.size());
    _bindings = new_bindings.data();
  }

  void bindings(
    const std::vector<vk::descriptor_set_layout_binding>& new_bindings)
  {
    _binding_count = static_cast<uint32_t>(new_bindings.size());
    _bindings = new_bindings.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::descriptor_set_layout_create_info;
  const void* _next = nullptr;
  vk::descriptor_set_layout_create_flags _flags =
    vk::descriptor_set_layout_create_flag::none;
  /// Number of bindings in the descriptor set layout
  uint32_t _binding_count = 0;
  /// Array of descriptor set layout bindings
  const vk::descriptor_set_layout_binding* _bindings = nullptr;
};
static_assert(sizeof(descriptor_set_layout_create_info) ==
                sizeof(::VkDescriptorSetLayoutCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_descriptor_set_layout(
  VkDevice device, const vk::descriptor_set_layout_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkDescriptorSetLayout* set_layout)
{
  return static_cast<vk::result>(vkCreateDescriptorSetLayout(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkDescriptorSetLayout*>(set_layout)));
}
inline void destroy_descriptor_set_layout(
  VkDevice device, VkDescriptorSetLayout descriptor_set_layout,
  const vk::allocation_callbacks* allocator)
{
  vkDestroyDescriptorSetLayout(
    static_cast<VkDevice>(device),
    static_cast<VkDescriptorSetLayout>(descriptor_set_layout),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
enum class descriptor_pool_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Descriptor sets may be freed individually
  /// @see VK_DESCRIPTOR_POOL_CREATE_FREE_DESCRIPTOR_SET_BIT
  free_descriptor_set_bit = 1 << 0,
  /// @see VK_DESCRIPTOR_POOL_CREATE_UPDATE_AFTER_BIND_BIT_EXT
  update_after_bind_bit_ext = 1 << 1,
};
using descriptor_pool_create_flags =
  shift::core::bit_field<descriptor_pool_create_flag,
                         VkDescriptorPoolCreateFlags>;
inline constexpr descriptor_pool_create_flags operator|(
  descriptor_pool_create_flag lhs, descriptor_pool_create_flag rhs)
{
  return descriptor_pool_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkDescriptorPoolSize.
class descriptor_pool_size
{
public:
  /// Default constructor.
  constexpr descriptor_pool_size() = default;

  /// Constructor.
  constexpr descriptor_pool_size(vk::descriptor_type initial_type,
                                 uint32_t initial_descriptor_count) noexcept
  : _type(std::move(initial_type)),
    _descriptor_count(std::move(initial_descriptor_count))
  {
  }

  /// Copy constructor.
  constexpr descriptor_pool_size(const descriptor_pool_size& other) = default;

  /// Move constructor.
  constexpr descriptor_pool_size(descriptor_pool_size&& other) = default;

  /// Copy assignment operator.
  constexpr descriptor_pool_size& operator=(const descriptor_pool_size& other) =
    default;

  /// Move assignment operator.
  constexpr descriptor_pool_size& operator=(descriptor_pool_size&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorPoolSize&() const
  {
    return *reinterpret_cast<const VkDescriptorPoolSize*>(this);
  }

  vk::descriptor_type& type()
  {
    return _type;
  }

  constexpr const vk::descriptor_type& type() const
  {
    return _type;
  }

  void type(vk::descriptor_type new_type)
  {
    _type = new_type;
  }

  uint32_t& descriptor_count()
  {
    return _descriptor_count;
  }

  constexpr const uint32_t& descriptor_count() const
  {
    return _descriptor_count;
  }

  void descriptor_count(uint32_t new_descriptor_count)
  {
    _descriptor_count = new_descriptor_count;
  }

private:
  vk::descriptor_type _type = vk::descriptor_type::sampler;
  uint32_t _descriptor_count = 0;
};
static_assert(sizeof(descriptor_pool_size) == sizeof(::VkDescriptorPoolSize),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDescriptorPoolCreateInfo.
class descriptor_pool_create_info
{
public:
  /// Default constructor.
  constexpr descriptor_pool_create_info() = default;

  /// Constructor.
  constexpr descriptor_pool_create_info(
    const void* initial_next, vk::descriptor_pool_create_flags initial_flags,
    uint32_t initial_max_sets, uint32_t initial_pool_size_count,
    const vk::descriptor_pool_size* initial_pool_sizes) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _max_sets(std::move(initial_max_sets)),
    _pool_size_count(std::move(initial_pool_size_count)),
    _pool_sizes(std::move(initial_pool_sizes))
  {
  }

  /// Copy constructor.
  constexpr descriptor_pool_create_info(
    const descriptor_pool_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _max_sets(other._max_sets),
    _pool_size_count(other._pool_size_count),
    _pool_sizes(other._pool_sizes)
  {
  }

  /// Move constructor.
  constexpr descriptor_pool_create_info(
    descriptor_pool_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _max_sets(std::move(other._max_sets)),
    _pool_size_count(std::move(other._pool_size_count)),
    _pool_sizes(std::move(other._pool_sizes))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_pool_create_info& operator=(
    const descriptor_pool_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _max_sets = other._max_sets;
    _pool_size_count = other._pool_size_count;
    _pool_sizes = other._pool_sizes;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_pool_create_info& operator=(
    descriptor_pool_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _max_sets = std::move(other._max_sets);
    _pool_size_count = std::move(other._pool_size_count);
    _pool_sizes = std::move(other._pool_sizes);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorPoolCreateInfo&() const
  {
    return *reinterpret_cast<const VkDescriptorPoolCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::descriptor_pool_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::descriptor_pool_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::descriptor_pool_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& max_sets()
  {
    return _max_sets;
  }

  constexpr const uint32_t& max_sets() const
  {
    return _max_sets;
  }

  void max_sets(uint32_t new_max_sets)
  {
    _max_sets = new_max_sets;
  }

  uint32_t& pool_size_count()
  {
    return _pool_size_count;
  }

  constexpr const uint32_t& pool_size_count() const
  {
    return _pool_size_count;
  }

  void pool_size_count(uint32_t new_pool_size_count)
  {
    _pool_size_count = new_pool_size_count;
  }

  const vk::descriptor_pool_size* pool_sizes()
  {
    return _pool_sizes;
  }

  constexpr const vk::descriptor_pool_size* pool_sizes() const
  {
    return _pool_sizes;
  }

  void pool_sizes(const vk::descriptor_pool_size* new_pool_sizes)
  {
    _pool_sizes = new_pool_sizes;
  }

  template <std::size_t Count>
  void pool_sizes(
    const std::array<vk::descriptor_pool_size, Count>& new_pool_sizes)
  {
    _pool_size_count = static_cast<uint32_t>(new_pool_sizes.size());
    _pool_sizes = new_pool_sizes.data();
  }

  void pool_sizes(const std::vector<vk::descriptor_pool_size>& new_pool_sizes)
  {
    _pool_size_count = static_cast<uint32_t>(new_pool_sizes.size());
    _pool_sizes = new_pool_sizes.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::descriptor_pool_create_info;
  const void* _next = nullptr;
  vk::descriptor_pool_create_flags _flags =
    vk::descriptor_pool_create_flag::none;
  uint32_t _max_sets = 0;
  uint32_t _pool_size_count = 0;
  const vk::descriptor_pool_size* _pool_sizes = nullptr;
};
static_assert(sizeof(descriptor_pool_create_info) ==
                sizeof(::VkDescriptorPoolCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_descriptor_pool(
  VkDevice device, const vk::descriptor_pool_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkDescriptorPool* descriptor_pool)
{
  return static_cast<vk::result>(vkCreateDescriptorPool(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDescriptorPoolCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkDescriptorPool*>(descriptor_pool)));
}
inline void destroy_descriptor_pool(VkDevice device,
                                    VkDescriptorPool descriptor_pool,
                                    const vk::allocation_callbacks* allocator)
{
  vkDestroyDescriptorPool(
    static_cast<VkDevice>(device),
    static_cast<VkDescriptorPool>(descriptor_pool),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
using descriptor_pool_reset_flags = VkFlags;
inline vk::result reset_descriptor_pool(VkDevice device,
                                        VkDescriptorPool descriptor_pool,
                                        vk::descriptor_pool_reset_flags flags)
{
  return static_cast<vk::result>(
    vkResetDescriptorPool(static_cast<VkDevice>(device),
                          static_cast<VkDescriptorPool>(descriptor_pool),
                          static_cast<VkDescriptorPoolResetFlags>(flags)));
}

/// Enhanced replacement type for VkDescriptorSetAllocateInfo.
class descriptor_set_allocate_info
{
public:
  /// Default constructor.
  constexpr descriptor_set_allocate_info() = default;

  /// Constructor.
  constexpr descriptor_set_allocate_info(
    const void* initial_next, VkDescriptorPool initial_descriptor_pool,
    uint32_t initial_descriptor_set_count,
    const VkDescriptorSetLayout* initial_set_layouts) noexcept
  : _next(std::move(initial_next)),
    _descriptor_pool(std::move(initial_descriptor_pool)),
    _descriptor_set_count(std::move(initial_descriptor_set_count)),
    _set_layouts(std::move(initial_set_layouts))
  {
  }

  /// Copy constructor.
  constexpr descriptor_set_allocate_info(
    const descriptor_set_allocate_info& other) noexcept
  : _next(other._next),
    _descriptor_pool(other._descriptor_pool),
    _descriptor_set_count(other._descriptor_set_count),
    _set_layouts(other._set_layouts)
  {
  }

  /// Move constructor.
  constexpr descriptor_set_allocate_info(
    descriptor_set_allocate_info&& other) noexcept
  : _next(std::move(other._next)),
    _descriptor_pool(std::move(other._descriptor_pool)),
    _descriptor_set_count(std::move(other._descriptor_set_count)),
    _set_layouts(std::move(other._set_layouts))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_set_allocate_info& operator=(
    const descriptor_set_allocate_info& other) noexcept
  {
    _next = other._next;
    _descriptor_pool = other._descriptor_pool;
    _descriptor_set_count = other._descriptor_set_count;
    _set_layouts = other._set_layouts;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_set_allocate_info& operator=(
    descriptor_set_allocate_info&& other) noexcept
  {
    _next = std::move(other._next);
    _descriptor_pool = std::move(other._descriptor_pool);
    _descriptor_set_count = std::move(other._descriptor_set_count);
    _set_layouts = std::move(other._set_layouts);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorSetAllocateInfo&() const
  {
    return *reinterpret_cast<const VkDescriptorSetAllocateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkDescriptorPool& descriptor_pool()
  {
    return _descriptor_pool;
  }

  constexpr const VkDescriptorPool& descriptor_pool() const
  {
    return _descriptor_pool;
  }

  void descriptor_pool(VkDescriptorPool new_descriptor_pool)
  {
    _descriptor_pool = new_descriptor_pool;
  }

  uint32_t& descriptor_set_count()
  {
    return _descriptor_set_count;
  }

  constexpr const uint32_t& descriptor_set_count() const
  {
    return _descriptor_set_count;
  }

  void descriptor_set_count(uint32_t new_descriptor_set_count)
  {
    _descriptor_set_count = new_descriptor_set_count;
  }

  const VkDescriptorSetLayout* set_layouts()
  {
    return _set_layouts;
  }

  constexpr const VkDescriptorSetLayout* set_layouts() const
  {
    return _set_layouts;
  }

  void set_layouts(const VkDescriptorSetLayout* new_set_layouts)
  {
    _set_layouts = new_set_layouts;
  }

  template <std::size_t Count>
  void set_layouts(
    const std::array<VkDescriptorSetLayout, Count>& new_set_layouts)
  {
    _descriptor_set_count = static_cast<uint32_t>(new_set_layouts.size());
    _set_layouts = new_set_layouts.data();
  }

  void set_layouts(const std::vector<VkDescriptorSetLayout>& new_set_layouts)
  {
    _descriptor_set_count = static_cast<uint32_t>(new_set_layouts.size());
    _set_layouts = new_set_layouts.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::descriptor_set_allocate_info;
  const void* _next = nullptr;
  VkDescriptorPool _descriptor_pool = nullptr;
  uint32_t _descriptor_set_count = 0;
  const VkDescriptorSetLayout* _set_layouts = nullptr;
};
static_assert(sizeof(descriptor_set_allocate_info) ==
                sizeof(::VkDescriptorSetAllocateInfo),
              "struct and wrapper have different size!");

inline vk::result allocate_descriptor_sets(
  VkDevice device, const vk::descriptor_set_allocate_info* allocate_info,
  VkDescriptorSet* descriptor_sets)
{
  return static_cast<vk::result>(vkAllocateDescriptorSets(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDescriptorSetAllocateInfo*>(allocate_info),
    reinterpret_cast<VkDescriptorSet*>(descriptor_sets)));
}
inline vk::result free_descriptor_sets(VkDevice device,
                                       VkDescriptorPool descriptor_pool,
                                       uint32_t descriptor_set_count,
                                       const VkDescriptorSet* descriptor_sets)
{
  return static_cast<vk::result>(vkFreeDescriptorSets(
    static_cast<VkDevice>(device),
    static_cast<VkDescriptorPool>(descriptor_pool),
    static_cast<uint32_t>(descriptor_set_count),
    reinterpret_cast<const VkDescriptorSet*>(descriptor_sets)));
}

/// Enhanced replacement type for VkDescriptorImageInfo.
class descriptor_image_info
{
public:
  /// Default constructor.
  constexpr descriptor_image_info() = default;

  /// Constructor.
  constexpr descriptor_image_info(
    VkSampler initial_sampler, VkImageView initial_image_view,
    vk::image_layout initial_image_layout) noexcept
  : _sampler(std::move(initial_sampler)),
    _image_view(std::move(initial_image_view)),
    _image_layout(std::move(initial_image_layout))
  {
  }

  /// Copy constructor.
  constexpr descriptor_image_info(const descriptor_image_info& other) = default;

  /// Move constructor.
  constexpr descriptor_image_info(descriptor_image_info&& other) = default;

  /// Copy assignment operator.
  constexpr descriptor_image_info& operator=(
    const descriptor_image_info& other) = default;

  /// Move assignment operator.
  constexpr descriptor_image_info& operator=(descriptor_image_info&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorImageInfo&() const
  {
    return *reinterpret_cast<const VkDescriptorImageInfo*>(this);
  }

  VkSampler& sampler()
  {
    return _sampler;
  }

  constexpr const VkSampler& sampler() const
  {
    return _sampler;
  }

  void sampler(VkSampler new_sampler)
  {
    _sampler = new_sampler;
  }

  VkImageView& image_view()
  {
    return _image_view;
  }

  constexpr const VkImageView& image_view() const
  {
    return _image_view;
  }

  void image_view(VkImageView new_image_view)
  {
    _image_view = new_image_view;
  }

  vk::image_layout& image_layout()
  {
    return _image_layout;
  }

  constexpr const vk::image_layout& image_layout() const
  {
    return _image_layout;
  }

  void image_layout(vk::image_layout new_image_layout)
  {
    _image_layout = new_image_layout;
  }

private:
  /// Sampler to write to the descriptor in case it is a SAMPLER or
  /// COMBINED_IMAGE_SAMPLER descriptor. Ignored otherwise.
  VkSampler _sampler = nullptr;
  /// Image view to write to the descriptor in case it is a SAMPLED_IMAGE,
  /// STORAGE_IMAGE, COMBINED_IMAGE_SAMPLER, or INPUT_ATTACHMENT descriptor.
  /// Ignored otherwise.
  VkImageView _image_view = nullptr;
  /// Layout the image is expected to be in when accessed using this descriptor
  /// (only used if imageView is not VK_NULL_HANDLE).
  vk::image_layout _image_layout = vk::image_layout::undefined;
};
static_assert(sizeof(descriptor_image_info) == sizeof(::VkDescriptorImageInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDescriptorBufferInfo.
class descriptor_buffer_info
{
public:
  /// Default constructor.
  constexpr descriptor_buffer_info() = default;

  /// Constructor.
  constexpr descriptor_buffer_info(VkBuffer initial_buffer,
                                   VkDeviceSize initial_offset,
                                   VkDeviceSize initial_range) noexcept
  : _buffer(std::move(initial_buffer)),
    _offset(std::move(initial_offset)),
    _range(std::move(initial_range))
  {
  }

  /// Copy constructor.
  constexpr descriptor_buffer_info(const descriptor_buffer_info& other) =
    default;

  /// Move constructor.
  constexpr descriptor_buffer_info(descriptor_buffer_info&& other) = default;

  /// Copy assignment operator.
  constexpr descriptor_buffer_info& operator=(
    const descriptor_buffer_info& other) = default;

  /// Move assignment operator.
  constexpr descriptor_buffer_info& operator=(descriptor_buffer_info&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorBufferInfo&() const
  {
    return *reinterpret_cast<const VkDescriptorBufferInfo*>(this);
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

  VkDeviceSize& offset()
  {
    return _offset;
  }

  constexpr const VkDeviceSize& offset() const
  {
    return _offset;
  }

  void offset(VkDeviceSize new_offset)
  {
    _offset = new_offset;
  }

  VkDeviceSize& range()
  {
    return _range;
  }

  constexpr const VkDeviceSize& range() const
  {
    return _range;
  }

  void range(VkDeviceSize new_range)
  {
    _range = new_range;
  }

private:
  /// Buffer used for this descriptor slot.
  VkBuffer _buffer = nullptr;
  /// Base offset from buffer start in bytes to update in the descriptor set.
  VkDeviceSize _offset = 0;
  /// Size in bytes of the buffer resource for this descriptor update.
  VkDeviceSize _range = 0;
};
static_assert(sizeof(descriptor_buffer_info) ==
                sizeof(::VkDescriptorBufferInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkWriteDescriptorSet.
class write_descriptor_set
{
public:
  /// Default constructor.
  constexpr write_descriptor_set() = default;

  /// Constructor.
  constexpr write_descriptor_set(
    const void* initial_next, VkDescriptorSet initial_dst_set,
    uint32_t initial_dst_binding, uint32_t initial_dst_array_element,
    uint32_t initial_descriptor_count,
    vk::descriptor_type initial_descriptor_type,
    const vk::descriptor_image_info* initial_image_info,
    const vk::descriptor_buffer_info* initial_buffer_info,
    const VkBufferView* initial_texel_buffer_view) noexcept
  : _next(std::move(initial_next)),
    _dst_set(std::move(initial_dst_set)),
    _dst_binding(std::move(initial_dst_binding)),
    _dst_array_element(std::move(initial_dst_array_element)),
    _descriptor_count(std::move(initial_descriptor_count)),
    _descriptor_type(std::move(initial_descriptor_type)),
    _image_info(std::move(initial_image_info)),
    _buffer_info(std::move(initial_buffer_info)),
    _texel_buffer_view(std::move(initial_texel_buffer_view))
  {
  }

  /// Copy constructor.
  constexpr write_descriptor_set(const write_descriptor_set& other) noexcept
  : _next(other._next),
    _dst_set(other._dst_set),
    _dst_binding(other._dst_binding),
    _dst_array_element(other._dst_array_element),
    _descriptor_count(other._descriptor_count),
    _descriptor_type(other._descriptor_type),
    _image_info(other._image_info),
    _buffer_info(other._buffer_info),
    _texel_buffer_view(other._texel_buffer_view)
  {
  }

  /// Move constructor.
  constexpr write_descriptor_set(write_descriptor_set&& other) noexcept
  : _next(std::move(other._next)),
    _dst_set(std::move(other._dst_set)),
    _dst_binding(std::move(other._dst_binding)),
    _dst_array_element(std::move(other._dst_array_element)),
    _descriptor_count(std::move(other._descriptor_count)),
    _descriptor_type(std::move(other._descriptor_type)),
    _image_info(std::move(other._image_info)),
    _buffer_info(std::move(other._buffer_info)),
    _texel_buffer_view(std::move(other._texel_buffer_view))
  {
  }

  /// Copy assignment operator.
  constexpr write_descriptor_set& operator=(
    const write_descriptor_set& other) noexcept
  {
    _next = other._next;
    _dst_set = other._dst_set;
    _dst_binding = other._dst_binding;
    _dst_array_element = other._dst_array_element;
    _descriptor_count = other._descriptor_count;
    _descriptor_type = other._descriptor_type;
    _image_info = other._image_info;
    _buffer_info = other._buffer_info;
    _texel_buffer_view = other._texel_buffer_view;
    return *this;
  }

  /// Move assignment operator.
  constexpr write_descriptor_set& operator=(
    write_descriptor_set&& other) noexcept
  {
    _next = std::move(other._next);
    _dst_set = std::move(other._dst_set);
    _dst_binding = std::move(other._dst_binding);
    _dst_array_element = std::move(other._dst_array_element);
    _descriptor_count = std::move(other._descriptor_count);
    _descriptor_type = std::move(other._descriptor_type);
    _image_info = std::move(other._image_info);
    _buffer_info = std::move(other._buffer_info);
    _texel_buffer_view = std::move(other._texel_buffer_view);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkWriteDescriptorSet&() const
  {
    return *reinterpret_cast<const VkWriteDescriptorSet*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkDescriptorSet& dst_set()
  {
    return _dst_set;
  }

  constexpr const VkDescriptorSet& dst_set() const
  {
    return _dst_set;
  }

  void dst_set(VkDescriptorSet new_dst_set)
  {
    _dst_set = new_dst_set;
  }

  uint32_t& dst_binding()
  {
    return _dst_binding;
  }

  constexpr const uint32_t& dst_binding() const
  {
    return _dst_binding;
  }

  void dst_binding(uint32_t new_dst_binding)
  {
    _dst_binding = new_dst_binding;
  }

  uint32_t& dst_array_element()
  {
    return _dst_array_element;
  }

  constexpr const uint32_t& dst_array_element() const
  {
    return _dst_array_element;
  }

  void dst_array_element(uint32_t new_dst_array_element)
  {
    _dst_array_element = new_dst_array_element;
  }

  uint32_t& descriptor_count()
  {
    return _descriptor_count;
  }

  constexpr const uint32_t& descriptor_count() const
  {
    return _descriptor_count;
  }

  void descriptor_count(uint32_t new_descriptor_count)
  {
    _descriptor_count = new_descriptor_count;
  }

  vk::descriptor_type& descriptor_type()
  {
    return _descriptor_type;
  }

  constexpr const vk::descriptor_type& descriptor_type() const
  {
    return _descriptor_type;
  }

  void descriptor_type(vk::descriptor_type new_descriptor_type)
  {
    _descriptor_type = new_descriptor_type;
  }

  const vk::descriptor_image_info* image_info()
  {
    return _image_info;
  }

  constexpr const vk::descriptor_image_info* image_info() const
  {
    return _image_info;
  }

  void image_info(const vk::descriptor_image_info* new_image_info)
  {
    _image_info = new_image_info;
  }

  template <std::size_t Count>
  void image_info(
    const std::array<vk::descriptor_image_info, Count>& new_image_info)
  {
    _descriptor_count = static_cast<uint32_t>(new_image_info.size());
    _image_info = new_image_info.data();
  }

  void image_info(const std::vector<vk::descriptor_image_info>& new_image_info)
  {
    _descriptor_count = static_cast<uint32_t>(new_image_info.size());
    _image_info = new_image_info.data();
  }

  const vk::descriptor_buffer_info* buffer_info()
  {
    return _buffer_info;
  }

  constexpr const vk::descriptor_buffer_info* buffer_info() const
  {
    return _buffer_info;
  }

  void buffer_info(const vk::descriptor_buffer_info* new_buffer_info)
  {
    _buffer_info = new_buffer_info;
  }

  template <std::size_t Count>
  void buffer_info(
    const std::array<vk::descriptor_buffer_info, Count>& new_buffer_info)
  {
    _descriptor_count = static_cast<uint32_t>(new_buffer_info.size());
    _buffer_info = new_buffer_info.data();
  }

  void buffer_info(
    const std::vector<vk::descriptor_buffer_info>& new_buffer_info)
  {
    _descriptor_count = static_cast<uint32_t>(new_buffer_info.size());
    _buffer_info = new_buffer_info.data();
  }

  const VkBufferView* texel_buffer_view()
  {
    return _texel_buffer_view;
  }

  constexpr const VkBufferView* texel_buffer_view() const
  {
    return _texel_buffer_view;
  }

  void texel_buffer_view(const VkBufferView* new_texel_buffer_view)
  {
    _texel_buffer_view = new_texel_buffer_view;
  }

  template <std::size_t Count>
  void texel_buffer_view(
    const std::array<VkBufferView, Count>& new_texel_buffer_view)
  {
    _descriptor_count = static_cast<uint32_t>(new_texel_buffer_view.size());
    _texel_buffer_view = new_texel_buffer_view.data();
  }

  void texel_buffer_view(const std::vector<VkBufferView>& new_texel_buffer_view)
  {
    _descriptor_count = static_cast<uint32_t>(new_texel_buffer_view.size());
    _texel_buffer_view = new_texel_buffer_view.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::write_descriptor_set;
  const void* _next = nullptr;
  /// Destination descriptor set
  VkDescriptorSet _dst_set = nullptr;
  /// Binding within the destination descriptor set to write
  uint32_t _dst_binding = 0;
  /// Array element within the destination binding to write
  uint32_t _dst_array_element = 0;
  /// Number of descriptors to write (determines the size of the array pointed
  /// by pDescriptors)
  uint32_t _descriptor_count = 0;
  /// Descriptor type to write (determines which members of the array pointed by
  /// pDescriptors are going to be used)
  vk::descriptor_type _descriptor_type = vk::descriptor_type::sampler;
  /// Sampler, image view, and layout for SAMPLER, COMBINED_IMAGE_SAMPLER,
  /// {SAMPLED,STORAGE}_IMAGE, and INPUT_ATTACHMENT descriptor types.
  const vk::descriptor_image_info* _image_info = nullptr;
  /// Raw buffer, size, and offset for {UNIFORM,STORAGE}_BUFFER[_DYNAMIC]
  /// descriptor types.
  const vk::descriptor_buffer_info* _buffer_info = nullptr;
  /// Buffer view to write to the descriptor for {UNIFORM,STORAGE}_TEXEL_BUFFER
  /// descriptor types.
  const VkBufferView* _texel_buffer_view = nullptr;
};
static_assert(sizeof(write_descriptor_set) == sizeof(::VkWriteDescriptorSet),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkCopyDescriptorSet.
class copy_descriptor_set
{
public:
  /// Default constructor.
  constexpr copy_descriptor_set() = default;

  /// Constructor.
  constexpr copy_descriptor_set(const void* initial_next,
                                VkDescriptorSet initial_src_set,
                                uint32_t initial_src_binding,
                                uint32_t initial_src_array_element,
                                VkDescriptorSet initial_dst_set,
                                uint32_t initial_dst_binding,
                                uint32_t initial_dst_array_element,
                                uint32_t initial_descriptor_count) noexcept
  : _next(std::move(initial_next)),
    _src_set(std::move(initial_src_set)),
    _src_binding(std::move(initial_src_binding)),
    _src_array_element(std::move(initial_src_array_element)),
    _dst_set(std::move(initial_dst_set)),
    _dst_binding(std::move(initial_dst_binding)),
    _dst_array_element(std::move(initial_dst_array_element)),
    _descriptor_count(std::move(initial_descriptor_count))
  {
  }

  /// Copy constructor.
  constexpr copy_descriptor_set(const copy_descriptor_set& other) noexcept
  : _next(other._next),
    _src_set(other._src_set),
    _src_binding(other._src_binding),
    _src_array_element(other._src_array_element),
    _dst_set(other._dst_set),
    _dst_binding(other._dst_binding),
    _dst_array_element(other._dst_array_element),
    _descriptor_count(other._descriptor_count)
  {
  }

  /// Move constructor.
  constexpr copy_descriptor_set(copy_descriptor_set&& other) noexcept
  : _next(std::move(other._next)),
    _src_set(std::move(other._src_set)),
    _src_binding(std::move(other._src_binding)),
    _src_array_element(std::move(other._src_array_element)),
    _dst_set(std::move(other._dst_set)),
    _dst_binding(std::move(other._dst_binding)),
    _dst_array_element(std::move(other._dst_array_element)),
    _descriptor_count(std::move(other._descriptor_count))
  {
  }

  /// Copy assignment operator.
  constexpr copy_descriptor_set& operator=(
    const copy_descriptor_set& other) noexcept
  {
    _next = other._next;
    _src_set = other._src_set;
    _src_binding = other._src_binding;
    _src_array_element = other._src_array_element;
    _dst_set = other._dst_set;
    _dst_binding = other._dst_binding;
    _dst_array_element = other._dst_array_element;
    _descriptor_count = other._descriptor_count;
    return *this;
  }

  /// Move assignment operator.
  constexpr copy_descriptor_set& operator=(copy_descriptor_set&& other) noexcept
  {
    _next = std::move(other._next);
    _src_set = std::move(other._src_set);
    _src_binding = std::move(other._src_binding);
    _src_array_element = std::move(other._src_array_element);
    _dst_set = std::move(other._dst_set);
    _dst_binding = std::move(other._dst_binding);
    _dst_array_element = std::move(other._dst_array_element);
    _descriptor_count = std::move(other._descriptor_count);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkCopyDescriptorSet&() const
  {
    return *reinterpret_cast<const VkCopyDescriptorSet*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkDescriptorSet& src_set()
  {
    return _src_set;
  }

  constexpr const VkDescriptorSet& src_set() const
  {
    return _src_set;
  }

  void src_set(VkDescriptorSet new_src_set)
  {
    _src_set = new_src_set;
  }

  uint32_t& src_binding()
  {
    return _src_binding;
  }

  constexpr const uint32_t& src_binding() const
  {
    return _src_binding;
  }

  void src_binding(uint32_t new_src_binding)
  {
    _src_binding = new_src_binding;
  }

  uint32_t& src_array_element()
  {
    return _src_array_element;
  }

  constexpr const uint32_t& src_array_element() const
  {
    return _src_array_element;
  }

  void src_array_element(uint32_t new_src_array_element)
  {
    _src_array_element = new_src_array_element;
  }

  VkDescriptorSet& dst_set()
  {
    return _dst_set;
  }

  constexpr const VkDescriptorSet& dst_set() const
  {
    return _dst_set;
  }

  void dst_set(VkDescriptorSet new_dst_set)
  {
    _dst_set = new_dst_set;
  }

  uint32_t& dst_binding()
  {
    return _dst_binding;
  }

  constexpr const uint32_t& dst_binding() const
  {
    return _dst_binding;
  }

  void dst_binding(uint32_t new_dst_binding)
  {
    _dst_binding = new_dst_binding;
  }

  uint32_t& dst_array_element()
  {
    return _dst_array_element;
  }

  constexpr const uint32_t& dst_array_element() const
  {
    return _dst_array_element;
  }

  void dst_array_element(uint32_t new_dst_array_element)
  {
    _dst_array_element = new_dst_array_element;
  }

  uint32_t& descriptor_count()
  {
    return _descriptor_count;
  }

  constexpr const uint32_t& descriptor_count() const
  {
    return _descriptor_count;
  }

  void descriptor_count(uint32_t new_descriptor_count)
  {
    _descriptor_count = new_descriptor_count;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::copy_descriptor_set;
  const void* _next = nullptr;
  /// Source descriptor set
  VkDescriptorSet _src_set = nullptr;
  /// Binding within the source descriptor set to copy from
  uint32_t _src_binding = 0;
  /// Array element within the source binding to copy from
  uint32_t _src_array_element = 0;
  /// Destination descriptor set
  VkDescriptorSet _dst_set = nullptr;
  /// Binding within the destination descriptor set to copy to
  uint32_t _dst_binding = 0;
  /// Array element within the destination binding to copy to
  uint32_t _dst_array_element = 0;
  /// Number of descriptors to write (determines the size of the array pointed
  /// by pDescriptors)
  uint32_t _descriptor_count = 0;
};
static_assert(sizeof(copy_descriptor_set) == sizeof(::VkCopyDescriptorSet),
              "struct and wrapper have different size!");

inline void update_descriptor_sets(
  VkDevice device, uint32_t descriptor_write_count,
  const vk::write_descriptor_set* descriptor_writes,
  uint32_t descriptor_copy_count,
  const vk::copy_descriptor_set* descriptor_copies)
{
  vkUpdateDescriptorSets(
    static_cast<VkDevice>(device),
    static_cast<uint32_t>(descriptor_write_count),
    reinterpret_cast<const VkWriteDescriptorSet*>(descriptor_writes),
    static_cast<uint32_t>(descriptor_copy_count),
    reinterpret_cast<const VkCopyDescriptorSet*>(descriptor_copies));
}
enum class framebuffer_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using framebuffer_create_flags =
  shift::core::bit_field<framebuffer_create_flag, VkFramebufferCreateFlags>;
inline constexpr framebuffer_create_flags operator|(framebuffer_create_flag lhs,
                                                    framebuffer_create_flag rhs)
{
  return framebuffer_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkFramebufferCreateInfo.
class framebuffer_create_info
{
public:
  /// Default constructor.
  constexpr framebuffer_create_info() = default;

  /// Constructor.
  constexpr framebuffer_create_info(
    const void* initial_next, vk::framebuffer_create_flags initial_flags,
    VkRenderPass initial_render_pass, uint32_t initial_attachment_count,
    const VkImageView* initial_attachments, uint32_t initial_width,
    uint32_t initial_height, uint32_t initial_layers) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _render_pass(std::move(initial_render_pass)),
    _attachment_count(std::move(initial_attachment_count)),
    _attachments(std::move(initial_attachments)),
    _width(std::move(initial_width)),
    _height(std::move(initial_height)),
    _layers(std::move(initial_layers))
  {
  }

  /// Copy constructor.
  constexpr framebuffer_create_info(
    const framebuffer_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _render_pass(other._render_pass),
    _attachment_count(other._attachment_count),
    _attachments(other._attachments),
    _width(other._width),
    _height(other._height),
    _layers(other._layers)
  {
  }

  /// Move constructor.
  constexpr framebuffer_create_info(framebuffer_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _render_pass(std::move(other._render_pass)),
    _attachment_count(std::move(other._attachment_count)),
    _attachments(std::move(other._attachments)),
    _width(std::move(other._width)),
    _height(std::move(other._height)),
    _layers(std::move(other._layers))
  {
  }

  /// Copy assignment operator.
  constexpr framebuffer_create_info& operator=(
    const framebuffer_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _render_pass = other._render_pass;
    _attachment_count = other._attachment_count;
    _attachments = other._attachments;
    _width = other._width;
    _height = other._height;
    _layers = other._layers;
    return *this;
  }

  /// Move assignment operator.
  constexpr framebuffer_create_info& operator=(
    framebuffer_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _render_pass = std::move(other._render_pass);
    _attachment_count = std::move(other._attachment_count);
    _attachments = std::move(other._attachments);
    _width = std::move(other._width);
    _height = std::move(other._height);
    _layers = std::move(other._layers);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkFramebufferCreateInfo&() const
  {
    return *reinterpret_cast<const VkFramebufferCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::framebuffer_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::framebuffer_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::framebuffer_create_flags new_flags)
  {
    _flags = new_flags;
  }

  VkRenderPass& render_pass()
  {
    return _render_pass;
  }

  constexpr const VkRenderPass& render_pass() const
  {
    return _render_pass;
  }

  void render_pass(VkRenderPass new_render_pass)
  {
    _render_pass = new_render_pass;
  }

  uint32_t& attachment_count()
  {
    return _attachment_count;
  }

  constexpr const uint32_t& attachment_count() const
  {
    return _attachment_count;
  }

  void attachment_count(uint32_t new_attachment_count)
  {
    _attachment_count = new_attachment_count;
  }

  const VkImageView* attachments()
  {
    return _attachments;
  }

  constexpr const VkImageView* attachments() const
  {
    return _attachments;
  }

  void attachments(const VkImageView* new_attachments)
  {
    _attachments = new_attachments;
  }

  template <std::size_t Count>
  void attachments(const std::array<VkImageView, Count>& new_attachments)
  {
    _attachment_count = static_cast<uint32_t>(new_attachments.size());
    _attachments = new_attachments.data();
  }

  void attachments(const std::vector<VkImageView>& new_attachments)
  {
    _attachment_count = static_cast<uint32_t>(new_attachments.size());
    _attachments = new_attachments.data();
  }

  uint32_t& width()
  {
    return _width;
  }

  constexpr const uint32_t& width() const
  {
    return _width;
  }

  void width(uint32_t new_width)
  {
    _width = new_width;
  }

  uint32_t& height()
  {
    return _height;
  }

  constexpr const uint32_t& height() const
  {
    return _height;
  }

  void height(uint32_t new_height)
  {
    _height = new_height;
  }

  uint32_t& layers()
  {
    return _layers;
  }

  constexpr const uint32_t& layers() const
  {
    return _layers;
  }

  void layers(uint32_t new_layers)
  {
    _layers = new_layers;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::framebuffer_create_info;
  const void* _next = nullptr;
  vk::framebuffer_create_flags _flags = vk::framebuffer_create_flag::none;
  VkRenderPass _render_pass = nullptr;
  uint32_t _attachment_count = 0;
  const VkImageView* _attachments = nullptr;
  uint32_t _width = 0;
  uint32_t _height = 0;
  uint32_t _layers = 0;
};
static_assert(sizeof(framebuffer_create_info) ==
                sizeof(::VkFramebufferCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_framebuffer(
  VkDevice device, const vk::framebuffer_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkFramebuffer* framebuffer)
{
  return static_cast<vk::result>(vkCreateFramebuffer(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkFramebufferCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkFramebuffer*>(framebuffer)));
}
inline void destroy_framebuffer(VkDevice device, VkFramebuffer framebuffer,
                                const vk::allocation_callbacks* allocator)
{
  vkDestroyFramebuffer(
    static_cast<VkDevice>(device), static_cast<VkFramebuffer>(framebuffer),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
enum class render_pass_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using render_pass_create_flags =
  shift::core::bit_field<render_pass_create_flag, VkRenderPassCreateFlags>;
inline constexpr render_pass_create_flags operator|(render_pass_create_flag lhs,
                                                    render_pass_create_flag rhs)
{
  return render_pass_create_flags{lhs} | rhs;
}
enum class attachment_description_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// The attachment may alias physical memory of another attachment in the same
  /// render pass
  /// @see VK_ATTACHMENT_DESCRIPTION_MAY_ALIAS_BIT
  may_alias_bit = 1 << 0,
};
using attachment_description_flags =
  shift::core::bit_field<attachment_description_flag,
                         VkAttachmentDescriptionFlags>;
inline constexpr attachment_description_flags operator|(
  attachment_description_flag lhs, attachment_description_flag rhs)
{
  return attachment_description_flags{lhs} | rhs;
}
enum class attachment_load_op
{
  /// @see VK_ATTACHMENT_LOAD_OP_LOAD
  load = 0,
  /// @see VK_ATTACHMENT_LOAD_OP_CLEAR
  clear = 1,
  /// @see VK_ATTACHMENT_LOAD_OP_DONT_CARE
  dont_care = 2,
};
enum class attachment_store_op
{
  /// @see VK_ATTACHMENT_STORE_OP_STORE
  store = 0,
  /// @see VK_ATTACHMENT_STORE_OP_DONT_CARE
  dont_care = 1,
};

/// Enhanced replacement type for VkAttachmentDescription.
class attachment_description
{
public:
  /// Default constructor.
  constexpr attachment_description() = default;

  /// Constructor.
  constexpr attachment_description(
    vk::attachment_description_flags initial_flags, vk::format initial_format,
    vk::sample_count_flag initial_samples,
    vk::attachment_load_op initial_load_op,
    vk::attachment_store_op initial_store_op,
    vk::attachment_load_op initial_stencil_load_op,
    vk::attachment_store_op initial_stencil_store_op,
    vk::image_layout initial_initial_layout,
    vk::image_layout initial_final_layout) noexcept
  : _flags(std::move(initial_flags)),
    _format(std::move(initial_format)),
    _samples(std::move(initial_samples)),
    _load_op(std::move(initial_load_op)),
    _store_op(std::move(initial_store_op)),
    _stencil_load_op(std::move(initial_stencil_load_op)),
    _stencil_store_op(std::move(initial_stencil_store_op)),
    _initial_layout(std::move(initial_initial_layout)),
    _final_layout(std::move(initial_final_layout))
  {
  }

  /// Copy constructor.
  constexpr attachment_description(const attachment_description& other) =
    default;

  /// Move constructor.
  constexpr attachment_description(attachment_description&& other) = default;

  /// Copy assignment operator.
  constexpr attachment_description& operator=(
    const attachment_description& other) = default;

  /// Move assignment operator.
  constexpr attachment_description& operator=(attachment_description&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkAttachmentDescription&() const
  {
    return *reinterpret_cast<const VkAttachmentDescription*>(this);
  }

  vk::attachment_description_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::attachment_description_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::attachment_description_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  vk::sample_count_flag& samples()
  {
    return _samples;
  }

  constexpr const vk::sample_count_flag& samples() const
  {
    return _samples;
  }

  void samples(vk::sample_count_flag new_samples)
  {
    _samples = new_samples;
  }

  vk::attachment_load_op& load_op()
  {
    return _load_op;
  }

  constexpr const vk::attachment_load_op& load_op() const
  {
    return _load_op;
  }

  void load_op(vk::attachment_load_op new_load_op)
  {
    _load_op = new_load_op;
  }

  vk::attachment_store_op& store_op()
  {
    return _store_op;
  }

  constexpr const vk::attachment_store_op& store_op() const
  {
    return _store_op;
  }

  void store_op(vk::attachment_store_op new_store_op)
  {
    _store_op = new_store_op;
  }

  vk::attachment_load_op& stencil_load_op()
  {
    return _stencil_load_op;
  }

  constexpr const vk::attachment_load_op& stencil_load_op() const
  {
    return _stencil_load_op;
  }

  void stencil_load_op(vk::attachment_load_op new_stencil_load_op)
  {
    _stencil_load_op = new_stencil_load_op;
  }

  vk::attachment_store_op& stencil_store_op()
  {
    return _stencil_store_op;
  }

  constexpr const vk::attachment_store_op& stencil_store_op() const
  {
    return _stencil_store_op;
  }

  void stencil_store_op(vk::attachment_store_op new_stencil_store_op)
  {
    _stencil_store_op = new_stencil_store_op;
  }

  vk::image_layout& initial_layout()
  {
    return _initial_layout;
  }

  constexpr const vk::image_layout& initial_layout() const
  {
    return _initial_layout;
  }

  void initial_layout(vk::image_layout new_initial_layout)
  {
    _initial_layout = new_initial_layout;
  }

  vk::image_layout& final_layout()
  {
    return _final_layout;
  }

  constexpr const vk::image_layout& final_layout() const
  {
    return _final_layout;
  }

  void final_layout(vk::image_layout new_final_layout)
  {
    _final_layout = new_final_layout;
  }

private:
  vk::attachment_description_flags _flags =
    vk::attachment_description_flag::none;
  vk::format _format = vk::format::undefined;
  vk::sample_count_flag _samples = vk::sample_count_flag::none;
  /// Load operation for color or depth data
  vk::attachment_load_op _load_op = vk::attachment_load_op::load;
  /// Store operation for color or depth data
  vk::attachment_store_op _store_op = vk::attachment_store_op::store;
  /// Load operation for stencil data
  vk::attachment_load_op _stencil_load_op = vk::attachment_load_op::load;
  /// Store operation for stencil data
  vk::attachment_store_op _stencil_store_op = vk::attachment_store_op::store;
  vk::image_layout _initial_layout = vk::image_layout::undefined;
  vk::image_layout _final_layout = vk::image_layout::undefined;
};
static_assert(sizeof(attachment_description) ==
                sizeof(::VkAttachmentDescription),
              "struct and wrapper have different size!");

enum class subpass_description_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_SUBPASS_DESCRIPTION_PER_VIEW_ATTRIBUTES_BIT_NVX
  per_view_attributes_bit_nvx = 1 << 0,
  /// @see VK_SUBPASS_DESCRIPTION_PER_VIEW_POSITION_X_ONLY_BIT_NVX
  per_view_position_x_only_bit_nvx = 1 << 1,
};
using subpass_description_flags =
  shift::core::bit_field<subpass_description_flag, VkSubpassDescriptionFlags>;
inline constexpr subpass_description_flags operator|(
  subpass_description_flag lhs, subpass_description_flag rhs)
{
  return subpass_description_flags{lhs} | rhs;
}
enum class pipeline_bind_point
{
  /// @see VK_PIPELINE_BIND_POINT_GRAPHICS
  graphics = 0,
  /// @see VK_PIPELINE_BIND_POINT_COMPUTE
  compute = 1,
  /// @see VK_PIPELINE_BIND_POINT_RAYTRACING_NVX
  raytracing_nvx = 1000165000,
};

/// Enhanced replacement type for VkAttachmentReference.
class attachment_reference
{
public:
  /// Default constructor.
  constexpr attachment_reference() = default;

  /// Constructor.
  constexpr attachment_reference(uint32_t initial_attachment,
                                 vk::image_layout initial_layout) noexcept
  : _attachment(std::move(initial_attachment)),
    _layout(std::move(initial_layout))
  {
  }

  /// Copy constructor.
  constexpr attachment_reference(const attachment_reference& other) = default;

  /// Move constructor.
  constexpr attachment_reference(attachment_reference&& other) = default;

  /// Copy assignment operator.
  constexpr attachment_reference& operator=(const attachment_reference& other) =
    default;

  /// Move assignment operator.
  constexpr attachment_reference& operator=(attachment_reference&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkAttachmentReference&() const
  {
    return *reinterpret_cast<const VkAttachmentReference*>(this);
  }

  uint32_t& attachment()
  {
    return _attachment;
  }

  constexpr const uint32_t& attachment() const
  {
    return _attachment;
  }

  void attachment(uint32_t new_attachment)
  {
    _attachment = new_attachment;
  }

  vk::image_layout& layout()
  {
    return _layout;
  }

  constexpr const vk::image_layout& layout() const
  {
    return _layout;
  }

  void layout(vk::image_layout new_layout)
  {
    _layout = new_layout;
  }

private:
  uint32_t _attachment = 0;
  vk::image_layout _layout = vk::image_layout::undefined;
};
static_assert(sizeof(attachment_reference) == sizeof(::VkAttachmentReference),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSubpassDescription.
class subpass_description
{
public:
  /// Default constructor.
  constexpr subpass_description() = default;

  /// Constructor.
  constexpr subpass_description(
    vk::subpass_description_flags initial_flags,
    vk::pipeline_bind_point initial_pipeline_bind_point,
    uint32_t initial_input_attachment_count,
    const vk::attachment_reference* initial_input_attachments,
    uint32_t initial_color_attachment_count,
    const vk::attachment_reference* initial_color_attachments,
    const vk::attachment_reference* initial_resolve_attachments,
    const vk::attachment_reference* initial_depth_stencil_attachment,
    uint32_t initial_preserve_attachment_count,
    const uint32_t* initial_preserve_attachments) noexcept
  : _flags(std::move(initial_flags)),
    _pipeline_bind_point(std::move(initial_pipeline_bind_point)),
    _input_attachment_count(std::move(initial_input_attachment_count)),
    _input_attachments(std::move(initial_input_attachments)),
    _color_attachment_count(std::move(initial_color_attachment_count)),
    _color_attachments(std::move(initial_color_attachments)),
    _resolve_attachments(std::move(initial_resolve_attachments)),
    _depth_stencil_attachment(std::move(initial_depth_stencil_attachment)),
    _preserve_attachment_count(std::move(initial_preserve_attachment_count)),
    _preserve_attachments(std::move(initial_preserve_attachments))
  {
  }

  /// Copy constructor.
  constexpr subpass_description(const subpass_description& other) = default;

  /// Move constructor.
  constexpr subpass_description(subpass_description&& other) = default;

  /// Copy assignment operator.
  constexpr subpass_description& operator=(const subpass_description& other) =
    default;

  /// Move assignment operator.
  constexpr subpass_description& operator=(subpass_description&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkSubpassDescription&() const
  {
    return *reinterpret_cast<const VkSubpassDescription*>(this);
  }

  vk::subpass_description_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::subpass_description_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::subpass_description_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::pipeline_bind_point& pipeline_bind_point()
  {
    return _pipeline_bind_point;
  }

  constexpr const vk::pipeline_bind_point& pipeline_bind_point() const
  {
    return _pipeline_bind_point;
  }

  void pipeline_bind_point(vk::pipeline_bind_point new_pipeline_bind_point)
  {
    _pipeline_bind_point = new_pipeline_bind_point;
  }

  uint32_t& input_attachment_count()
  {
    return _input_attachment_count;
  }

  constexpr const uint32_t& input_attachment_count() const
  {
    return _input_attachment_count;
  }

  void input_attachment_count(uint32_t new_input_attachment_count)
  {
    _input_attachment_count = new_input_attachment_count;
  }

  const vk::attachment_reference* input_attachments()
  {
    return _input_attachments;
  }

  constexpr const vk::attachment_reference* input_attachments() const
  {
    return _input_attachments;
  }

  void input_attachments(const vk::attachment_reference* new_input_attachments)
  {
    _input_attachments = new_input_attachments;
  }

  template <std::size_t Count>
  void input_attachments(
    const std::array<vk::attachment_reference, Count>& new_input_attachments)
  {
    _input_attachment_count =
      static_cast<uint32_t>(new_input_attachments.size());
    _input_attachments = new_input_attachments.data();
  }

  void input_attachments(
    const std::vector<vk::attachment_reference>& new_input_attachments)
  {
    _input_attachment_count =
      static_cast<uint32_t>(new_input_attachments.size());
    _input_attachments = new_input_attachments.data();
  }

  uint32_t& color_attachment_count()
  {
    return _color_attachment_count;
  }

  constexpr const uint32_t& color_attachment_count() const
  {
    return _color_attachment_count;
  }

  void color_attachment_count(uint32_t new_color_attachment_count)
  {
    _color_attachment_count = new_color_attachment_count;
  }

  const vk::attachment_reference* color_attachments()
  {
    return _color_attachments;
  }

  constexpr const vk::attachment_reference* color_attachments() const
  {
    return _color_attachments;
  }

  void color_attachments(const vk::attachment_reference* new_color_attachments)
  {
    _color_attachments = new_color_attachments;
  }

  template <std::size_t Count>
  void color_attachments(
    const std::array<vk::attachment_reference, Count>& new_color_attachments)
  {
    _color_attachment_count =
      static_cast<uint32_t>(new_color_attachments.size());
    _color_attachments = new_color_attachments.data();
  }

  void color_attachments(
    const std::vector<vk::attachment_reference>& new_color_attachments)
  {
    _color_attachment_count =
      static_cast<uint32_t>(new_color_attachments.size());
    _color_attachments = new_color_attachments.data();
  }

  const vk::attachment_reference* resolve_attachments()
  {
    return _resolve_attachments;
  }

  constexpr const vk::attachment_reference* resolve_attachments() const
  {
    return _resolve_attachments;
  }

  void resolve_attachments(
    const vk::attachment_reference* new_resolve_attachments)
  {
    _resolve_attachments = new_resolve_attachments;
  }

  template <std::size_t Count>
  void resolve_attachments(
    const std::array<vk::attachment_reference, Count>& new_resolve_attachments)
  {
    _color_attachment_count =
      static_cast<uint32_t>(new_resolve_attachments.size());
    _resolve_attachments = new_resolve_attachments.data();
  }

  void resolve_attachments(
    const std::vector<vk::attachment_reference>& new_resolve_attachments)
  {
    _color_attachment_count =
      static_cast<uint32_t>(new_resolve_attachments.size());
    _resolve_attachments = new_resolve_attachments.data();
  }

  const vk::attachment_reference* depth_stencil_attachment()
  {
    return _depth_stencil_attachment;
  }

  constexpr const vk::attachment_reference* depth_stencil_attachment() const
  {
    return _depth_stencil_attachment;
  }

  void depth_stencil_attachment(
    const vk::attachment_reference* new_depth_stencil_attachment)
  {
    _depth_stencil_attachment = new_depth_stencil_attachment;
  }

  uint32_t& preserve_attachment_count()
  {
    return _preserve_attachment_count;
  }

  constexpr const uint32_t& preserve_attachment_count() const
  {
    return _preserve_attachment_count;
  }

  void preserve_attachment_count(uint32_t new_preserve_attachment_count)
  {
    _preserve_attachment_count = new_preserve_attachment_count;
  }

  const uint32_t* preserve_attachments()
  {
    return _preserve_attachments;
  }

  constexpr const uint32_t* preserve_attachments() const
  {
    return _preserve_attachments;
  }

  void preserve_attachments(const uint32_t* new_preserve_attachments)
  {
    _preserve_attachments = new_preserve_attachments;
  }

  template <std::size_t Count>
  void preserve_attachments(
    const std::array<uint32_t, Count>& new_preserve_attachments)
  {
    _preserve_attachment_count =
      static_cast<uint32_t>(new_preserve_attachments.size());
    _preserve_attachments = new_preserve_attachments.data();
  }

  void preserve_attachments(
    const std::vector<uint32_t>& new_preserve_attachments)
  {
    _preserve_attachment_count =
      static_cast<uint32_t>(new_preserve_attachments.size());
    _preserve_attachments = new_preserve_attachments.data();
  }

private:
  vk::subpass_description_flags _flags = vk::subpass_description_flag::none;
  /// Must be VK_PIPELINE_BIND_POINT_GRAPHICS for now
  vk::pipeline_bind_point _pipeline_bind_point =
    vk::pipeline_bind_point::graphics;
  uint32_t _input_attachment_count = 0;
  const vk::attachment_reference* _input_attachments = nullptr;
  uint32_t _color_attachment_count = 0;
  const vk::attachment_reference* _color_attachments = nullptr;
  const vk::attachment_reference* _resolve_attachments = nullptr;
  const vk::attachment_reference* _depth_stencil_attachment = nullptr;
  uint32_t _preserve_attachment_count = 0;
  const uint32_t* _preserve_attachments = nullptr;
};
static_assert(sizeof(subpass_description) == sizeof(::VkSubpassDescription),
              "struct and wrapper have different size!");

enum class dependency_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Dependency is per pixel region
  /// @see VK_DEPENDENCY_BY_REGION_BIT
  by_region_bit = 1 << 0,
  /// Dependency is across devices
  /// @see VK_DEPENDENCY_DEVICE_GROUP_BIT
  device_group_bit = 1 << 2,
  /// @see VK_DEPENDENCY_VIEW_LOCAL_BIT
  view_local_bit = 1 << 1,
};
using dependency_flags =
  shift::core::bit_field<dependency_flag, VkDependencyFlags>;
inline constexpr dependency_flags operator|(dependency_flag lhs,
                                            dependency_flag rhs)
{
  return dependency_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkSubpassDependency.
class subpass_dependency
{
public:
  /// Default constructor.
  constexpr subpass_dependency() = default;

  /// Constructor.
  constexpr subpass_dependency(
    uint32_t initial_src_subpass, uint32_t initial_dst_subpass,
    vk::pipeline_stage_flags initial_src_stage_mask,
    vk::pipeline_stage_flags initial_dst_stage_mask,
    vk::access_flags initial_src_access_mask,
    vk::access_flags initial_dst_access_mask,
    vk::dependency_flags initial_dependency_flags) noexcept
  : _src_subpass(std::move(initial_src_subpass)),
    _dst_subpass(std::move(initial_dst_subpass)),
    _src_stage_mask(std::move(initial_src_stage_mask)),
    _dst_stage_mask(std::move(initial_dst_stage_mask)),
    _src_access_mask(std::move(initial_src_access_mask)),
    _dst_access_mask(std::move(initial_dst_access_mask)),
    _dependency_flags(std::move(initial_dependency_flags))
  {
  }

  /// Copy constructor.
  constexpr subpass_dependency(const subpass_dependency& other) = default;

  /// Move constructor.
  constexpr subpass_dependency(subpass_dependency&& other) = default;

  /// Copy assignment operator.
  constexpr subpass_dependency& operator=(const subpass_dependency& other) =
    default;

  /// Move assignment operator.
  constexpr subpass_dependency& operator=(subpass_dependency&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSubpassDependency&() const
  {
    return *reinterpret_cast<const VkSubpassDependency*>(this);
  }

  uint32_t& src_subpass()
  {
    return _src_subpass;
  }

  constexpr const uint32_t& src_subpass() const
  {
    return _src_subpass;
  }

  void src_subpass(uint32_t new_src_subpass)
  {
    _src_subpass = new_src_subpass;
  }

  uint32_t& dst_subpass()
  {
    return _dst_subpass;
  }

  constexpr const uint32_t& dst_subpass() const
  {
    return _dst_subpass;
  }

  void dst_subpass(uint32_t new_dst_subpass)
  {
    _dst_subpass = new_dst_subpass;
  }

  vk::pipeline_stage_flags& src_stage_mask()
  {
    return _src_stage_mask;
  }

  constexpr const vk::pipeline_stage_flags& src_stage_mask() const
  {
    return _src_stage_mask;
  }

  void src_stage_mask(vk::pipeline_stage_flags new_src_stage_mask)
  {
    _src_stage_mask = new_src_stage_mask;
  }

  vk::pipeline_stage_flags& dst_stage_mask()
  {
    return _dst_stage_mask;
  }

  constexpr const vk::pipeline_stage_flags& dst_stage_mask() const
  {
    return _dst_stage_mask;
  }

  void dst_stage_mask(vk::pipeline_stage_flags new_dst_stage_mask)
  {
    _dst_stage_mask = new_dst_stage_mask;
  }

  vk::access_flags& src_access_mask()
  {
    return _src_access_mask;
  }

  constexpr const vk::access_flags& src_access_mask() const
  {
    return _src_access_mask;
  }

  void src_access_mask(vk::access_flags new_src_access_mask)
  {
    _src_access_mask = new_src_access_mask;
  }

  vk::access_flags& dst_access_mask()
  {
    return _dst_access_mask;
  }

  constexpr const vk::access_flags& dst_access_mask() const
  {
    return _dst_access_mask;
  }

  void dst_access_mask(vk::access_flags new_dst_access_mask)
  {
    _dst_access_mask = new_dst_access_mask;
  }

  vk::dependency_flags& dependency_flags()
  {
    return _dependency_flags;
  }

  constexpr const vk::dependency_flags& dependency_flags() const
  {
    return _dependency_flags;
  }

  void dependency_flags(vk::dependency_flags new_dependency_flags)
  {
    _dependency_flags = new_dependency_flags;
  }

private:
  uint32_t _src_subpass = 0;
  uint32_t _dst_subpass = 0;
  vk::pipeline_stage_flags _src_stage_mask = vk::pipeline_stage_flag::none;
  vk::pipeline_stage_flags _dst_stage_mask = vk::pipeline_stage_flag::none;
  /// Memory accesses from the source of the dependency to synchronize
  vk::access_flags _src_access_mask = vk::access_flag::none;
  /// Memory accesses from the destination of the dependency to synchronize
  vk::access_flags _dst_access_mask = vk::access_flag::none;
  vk::dependency_flags _dependency_flags = vk::dependency_flag::none;
};
static_assert(sizeof(subpass_dependency) == sizeof(::VkSubpassDependency),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkRenderPassCreateInfo.
class render_pass_create_info
{
public:
  /// Default constructor.
  constexpr render_pass_create_info() = default;

  /// Constructor.
  constexpr render_pass_create_info(
    const void* initial_next, vk::render_pass_create_flags initial_flags,
    uint32_t initial_attachment_count,
    const vk::attachment_description* initial_attachments,
    uint32_t initial_subpass_count,
    const vk::subpass_description* initial_subpasses,
    uint32_t initial_dependency_count,
    const vk::subpass_dependency* initial_dependencies) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _attachment_count(std::move(initial_attachment_count)),
    _attachments(std::move(initial_attachments)),
    _subpass_count(std::move(initial_subpass_count)),
    _subpasses(std::move(initial_subpasses)),
    _dependency_count(std::move(initial_dependency_count)),
    _dependencies(std::move(initial_dependencies))
  {
  }

  /// Copy constructor.
  constexpr render_pass_create_info(
    const render_pass_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _attachment_count(other._attachment_count),
    _attachments(other._attachments),
    _subpass_count(other._subpass_count),
    _subpasses(other._subpasses),
    _dependency_count(other._dependency_count),
    _dependencies(other._dependencies)
  {
  }

  /// Move constructor.
  constexpr render_pass_create_info(render_pass_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _attachment_count(std::move(other._attachment_count)),
    _attachments(std::move(other._attachments)),
    _subpass_count(std::move(other._subpass_count)),
    _subpasses(std::move(other._subpasses)),
    _dependency_count(std::move(other._dependency_count)),
    _dependencies(std::move(other._dependencies))
  {
  }

  /// Copy assignment operator.
  constexpr render_pass_create_info& operator=(
    const render_pass_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _attachment_count = other._attachment_count;
    _attachments = other._attachments;
    _subpass_count = other._subpass_count;
    _subpasses = other._subpasses;
    _dependency_count = other._dependency_count;
    _dependencies = other._dependencies;
    return *this;
  }

  /// Move assignment operator.
  constexpr render_pass_create_info& operator=(
    render_pass_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _attachment_count = std::move(other._attachment_count);
    _attachments = std::move(other._attachments);
    _subpass_count = std::move(other._subpass_count);
    _subpasses = std::move(other._subpasses);
    _dependency_count = std::move(other._dependency_count);
    _dependencies = std::move(other._dependencies);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkRenderPassCreateInfo&() const
  {
    return *reinterpret_cast<const VkRenderPassCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::render_pass_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::render_pass_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::render_pass_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& attachment_count()
  {
    return _attachment_count;
  }

  constexpr const uint32_t& attachment_count() const
  {
    return _attachment_count;
  }

  void attachment_count(uint32_t new_attachment_count)
  {
    _attachment_count = new_attachment_count;
  }

  const vk::attachment_description* attachments()
  {
    return _attachments;
  }

  constexpr const vk::attachment_description* attachments() const
  {
    return _attachments;
  }

  void attachments(const vk::attachment_description* new_attachments)
  {
    _attachments = new_attachments;
  }

  template <std::size_t Count>
  void attachments(
    const std::array<vk::attachment_description, Count>& new_attachments)
  {
    _attachment_count = static_cast<uint32_t>(new_attachments.size());
    _attachments = new_attachments.data();
  }

  void attachments(
    const std::vector<vk::attachment_description>& new_attachments)
  {
    _attachment_count = static_cast<uint32_t>(new_attachments.size());
    _attachments = new_attachments.data();
  }

  uint32_t& subpass_count()
  {
    return _subpass_count;
  }

  constexpr const uint32_t& subpass_count() const
  {
    return _subpass_count;
  }

  void subpass_count(uint32_t new_subpass_count)
  {
    _subpass_count = new_subpass_count;
  }

  const vk::subpass_description* subpasses()
  {
    return _subpasses;
  }

  constexpr const vk::subpass_description* subpasses() const
  {
    return _subpasses;
  }

  void subpasses(const vk::subpass_description* new_subpasses)
  {
    _subpasses = new_subpasses;
  }

  template <std::size_t Count>
  void subpasses(
    const std::array<vk::subpass_description, Count>& new_subpasses)
  {
    _subpass_count = static_cast<uint32_t>(new_subpasses.size());
    _subpasses = new_subpasses.data();
  }

  void subpasses(const std::vector<vk::subpass_description>& new_subpasses)
  {
    _subpass_count = static_cast<uint32_t>(new_subpasses.size());
    _subpasses = new_subpasses.data();
  }

  uint32_t& dependency_count()
  {
    return _dependency_count;
  }

  constexpr const uint32_t& dependency_count() const
  {
    return _dependency_count;
  }

  void dependency_count(uint32_t new_dependency_count)
  {
    _dependency_count = new_dependency_count;
  }

  const vk::subpass_dependency* dependencies()
  {
    return _dependencies;
  }

  constexpr const vk::subpass_dependency* dependencies() const
  {
    return _dependencies;
  }

  void dependencies(const vk::subpass_dependency* new_dependencies)
  {
    _dependencies = new_dependencies;
  }

  template <std::size_t Count>
  void dependencies(
    const std::array<vk::subpass_dependency, Count>& new_dependencies)
  {
    _dependency_count = static_cast<uint32_t>(new_dependencies.size());
    _dependencies = new_dependencies.data();
  }

  void dependencies(const std::vector<vk::subpass_dependency>& new_dependencies)
  {
    _dependency_count = static_cast<uint32_t>(new_dependencies.size());
    _dependencies = new_dependencies.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::render_pass_create_info;
  const void* _next = nullptr;
  vk::render_pass_create_flags _flags = vk::render_pass_create_flag::none;
  uint32_t _attachment_count = 0;
  const vk::attachment_description* _attachments = nullptr;
  uint32_t _subpass_count = 0;
  const vk::subpass_description* _subpasses = nullptr;
  uint32_t _dependency_count = 0;
  const vk::subpass_dependency* _dependencies = nullptr;
};
static_assert(sizeof(render_pass_create_info) ==
                sizeof(::VkRenderPassCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_render_pass(
  VkDevice device, const vk::render_pass_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkRenderPass* render_pass)
{
  return static_cast<vk::result>(vkCreateRenderPass(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkRenderPassCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkRenderPass*>(render_pass)));
}
inline void destroy_render_pass(VkDevice device, VkRenderPass render_pass,
                                const vk::allocation_callbacks* allocator)
{
  vkDestroyRenderPass(
    static_cast<VkDevice>(device), static_cast<VkRenderPass>(render_pass),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline void get_render_area_granularity(VkDevice device,
                                        VkRenderPass render_pass,
                                        vk::extent_2d* granularity)
{
  vkGetRenderAreaGranularity(static_cast<VkDevice>(device),
                             static_cast<VkRenderPass>(render_pass),
                             reinterpret_cast<VkExtent2D*>(granularity));
}
enum class command_pool_create_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Command buffers have a short lifetime
  /// @see VK_COMMAND_POOL_CREATE_TRANSIENT_BIT
  transient_bit = 1 << 0,
  /// Command buffers may release their memory individually
  /// @see VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT
  reset_command_buffer_bit = 1 << 1,
  /// Command buffers allocated from pool are protected command buffers
  /// @see VK_COMMAND_POOL_CREATE_PROTECTED_BIT
  protected_bit = 1 << 2,
};
using command_pool_create_flags =
  shift::core::bit_field<command_pool_create_flag, VkCommandPoolCreateFlags>;
inline constexpr command_pool_create_flags operator|(
  command_pool_create_flag lhs, command_pool_create_flag rhs)
{
  return command_pool_create_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkCommandPoolCreateInfo.
class command_pool_create_info
{
public:
  /// Default constructor.
  constexpr command_pool_create_info() = default;

  /// Constructor.
  constexpr command_pool_create_info(
    const void* initial_next, vk::command_pool_create_flags initial_flags,
    uint32_t initial_queue_family_index) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _queue_family_index(std::move(initial_queue_family_index))
  {
  }

  /// Copy constructor.
  constexpr command_pool_create_info(
    const command_pool_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _queue_family_index(other._queue_family_index)
  {
  }

  /// Move constructor.
  constexpr command_pool_create_info(command_pool_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _queue_family_index(std::move(other._queue_family_index))
  {
  }

  /// Copy assignment operator.
  constexpr command_pool_create_info& operator=(
    const command_pool_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _queue_family_index = other._queue_family_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr command_pool_create_info& operator=(
    command_pool_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _queue_family_index = std::move(other._queue_family_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkCommandPoolCreateInfo&() const
  {
    return *reinterpret_cast<const VkCommandPoolCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::command_pool_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::command_pool_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::command_pool_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& queue_family_index()
  {
    return _queue_family_index;
  }

  constexpr const uint32_t& queue_family_index() const
  {
    return _queue_family_index;
  }

  void queue_family_index(uint32_t new_queue_family_index)
  {
    _queue_family_index = new_queue_family_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::command_pool_create_info;
  const void* _next = nullptr;
  /// Command pool creation flags
  vk::command_pool_create_flags _flags = vk::command_pool_create_flag::none;
  uint32_t _queue_family_index = 0;
};
static_assert(sizeof(command_pool_create_info) ==
                sizeof(::VkCommandPoolCreateInfo),
              "struct and wrapper have different size!");

inline vk::result create_command_pool(
  VkDevice device, const vk::command_pool_create_info* create_info,
  const vk::allocation_callbacks* allocator, VkCommandPool* command_pool)
{
  return static_cast<vk::result>(vkCreateCommandPool(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkCommandPoolCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkCommandPool*>(command_pool)));
}
inline void destroy_command_pool(VkDevice device, VkCommandPool command_pool,
                                 const vk::allocation_callbacks* allocator)
{
  vkDestroyCommandPool(
    static_cast<VkDevice>(device), static_cast<VkCommandPool>(command_pool),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
enum class command_pool_reset_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Release resources owned by the pool
  /// @see VK_COMMAND_POOL_RESET_RELEASE_RESOURCES_BIT
  release_resources_bit = 1 << 0,
};
using command_pool_reset_flags =
  shift::core::bit_field<command_pool_reset_flag, VkCommandPoolResetFlags>;
inline constexpr command_pool_reset_flags operator|(command_pool_reset_flag lhs,
                                                    command_pool_reset_flag rhs)
{
  return command_pool_reset_flags{lhs} | rhs;
}
inline vk::result reset_command_pool(VkDevice device,
                                     VkCommandPool command_pool,
                                     vk::command_pool_reset_flags flags)
{
  return static_cast<vk::result>(vkResetCommandPool(
    static_cast<VkDevice>(device), static_cast<VkCommandPool>(command_pool),
    static_cast<VkCommandPoolResetFlags>(flags)));
}
enum class command_buffer_level
{
  /// @see VK_COMMAND_BUFFER_LEVEL_PRIMARY
  primary = 0,
  /// @see VK_COMMAND_BUFFER_LEVEL_SECONDARY
  secondary = 1,
};

/// Enhanced replacement type for VkCommandBufferAllocateInfo.
class command_buffer_allocate_info
{
public:
  /// Default constructor.
  constexpr command_buffer_allocate_info() = default;

  /// Constructor.
  constexpr command_buffer_allocate_info(
    const void* initial_next, VkCommandPool initial_command_pool,
    vk::command_buffer_level initial_level,
    uint32_t initial_command_buffer_count) noexcept
  : _next(std::move(initial_next)),
    _command_pool(std::move(initial_command_pool)),
    _level(std::move(initial_level)),
    _command_buffer_count(std::move(initial_command_buffer_count))
  {
  }

  /// Copy constructor.
  constexpr command_buffer_allocate_info(
    const command_buffer_allocate_info& other) noexcept
  : _next(other._next),
    _command_pool(other._command_pool),
    _level(other._level),
    _command_buffer_count(other._command_buffer_count)
  {
  }

  /// Move constructor.
  constexpr command_buffer_allocate_info(
    command_buffer_allocate_info&& other) noexcept
  : _next(std::move(other._next)),
    _command_pool(std::move(other._command_pool)),
    _level(std::move(other._level)),
    _command_buffer_count(std::move(other._command_buffer_count))
  {
  }

  /// Copy assignment operator.
  constexpr command_buffer_allocate_info& operator=(
    const command_buffer_allocate_info& other) noexcept
  {
    _next = other._next;
    _command_pool = other._command_pool;
    _level = other._level;
    _command_buffer_count = other._command_buffer_count;
    return *this;
  }

  /// Move assignment operator.
  constexpr command_buffer_allocate_info& operator=(
    command_buffer_allocate_info&& other) noexcept
  {
    _next = std::move(other._next);
    _command_pool = std::move(other._command_pool);
    _level = std::move(other._level);
    _command_buffer_count = std::move(other._command_buffer_count);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkCommandBufferAllocateInfo&() const
  {
    return *reinterpret_cast<const VkCommandBufferAllocateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkCommandPool& command_pool()
  {
    return _command_pool;
  }

  constexpr const VkCommandPool& command_pool() const
  {
    return _command_pool;
  }

  void command_pool(VkCommandPool new_command_pool)
  {
    _command_pool = new_command_pool;
  }

  vk::command_buffer_level& level()
  {
    return _level;
  }

  constexpr const vk::command_buffer_level& level() const
  {
    return _level;
  }

  void level(vk::command_buffer_level new_level)
  {
    _level = new_level;
  }

  uint32_t& command_buffer_count()
  {
    return _command_buffer_count;
  }

  constexpr const uint32_t& command_buffer_count() const
  {
    return _command_buffer_count;
  }

  void command_buffer_count(uint32_t new_command_buffer_count)
  {
    _command_buffer_count = new_command_buffer_count;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::command_buffer_allocate_info;
  const void* _next = nullptr;
  VkCommandPool _command_pool = nullptr;
  vk::command_buffer_level _level = vk::command_buffer_level::primary;
  uint32_t _command_buffer_count = 0;
};
static_assert(sizeof(command_buffer_allocate_info) ==
                sizeof(::VkCommandBufferAllocateInfo),
              "struct and wrapper have different size!");

inline vk::result allocate_command_buffers(
  VkDevice device, const vk::command_buffer_allocate_info* allocate_info,
  VkCommandBuffer* command_buffers)
{
  return static_cast<vk::result>(vkAllocateCommandBuffers(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkCommandBufferAllocateInfo*>(allocate_info),
    reinterpret_cast<VkCommandBuffer*>(command_buffers)));
}
inline void free_command_buffers(VkDevice device, VkCommandPool command_pool,
                                 uint32_t command_buffer_count,
                                 const VkCommandBuffer* command_buffers)
{
  vkFreeCommandBuffers(
    static_cast<VkDevice>(device), static_cast<VkCommandPool>(command_pool),
    static_cast<uint32_t>(command_buffer_count),
    reinterpret_cast<const VkCommandBuffer*>(command_buffers));
}
enum class command_buffer_usage_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT
  one_time_submit_bit = 1 << 0,
  /// @see VK_COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT
  render_pass_continue_bit = 1 << 1,
  /// Command buffer may be submitted/executed more than once simultaneously
  /// @see VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT
  simultaneous_use_bit = 1 << 2,
};
using command_buffer_usage_flags =
  shift::core::bit_field<command_buffer_usage_flag, VkCommandBufferUsageFlags>;
inline constexpr command_buffer_usage_flags operator|(
  command_buffer_usage_flag lhs, command_buffer_usage_flag rhs)
{
  return command_buffer_usage_flags{lhs} | rhs;
}
enum class query_control_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Require precise results to be collected by the query
  /// @see VK_QUERY_CONTROL_PRECISE_BIT
  precise_bit = 1 << 0,
};
using query_control_flags =
  shift::core::bit_field<query_control_flag, VkQueryControlFlags>;
inline constexpr query_control_flags operator|(query_control_flag lhs,
                                               query_control_flag rhs)
{
  return query_control_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkCommandBufferInheritanceInfo.
class command_buffer_inheritance_info
{
public:
  /// Default constructor.
  constexpr command_buffer_inheritance_info() = default;

  /// Constructor.
  constexpr command_buffer_inheritance_info(
    const void* initial_next, VkRenderPass initial_render_pass,
    uint32_t initial_subpass, VkFramebuffer initial_framebuffer,
    VkBool32 initial_occlusion_query_enable,
    vk::query_control_flags initial_query_flags,
    vk::query_pipeline_statistic_flags initial_pipeline_statistics) noexcept
  : _next(std::move(initial_next)),
    _render_pass(std::move(initial_render_pass)),
    _subpass(std::move(initial_subpass)),
    _framebuffer(std::move(initial_framebuffer)),
    _occlusion_query_enable(std::move(initial_occlusion_query_enable)),
    _query_flags(std::move(initial_query_flags)),
    _pipeline_statistics(std::move(initial_pipeline_statistics))
  {
  }

  /// Copy constructor.
  constexpr command_buffer_inheritance_info(
    const command_buffer_inheritance_info& other) noexcept
  : _next(other._next),
    _render_pass(other._render_pass),
    _subpass(other._subpass),
    _framebuffer(other._framebuffer),
    _occlusion_query_enable(other._occlusion_query_enable),
    _query_flags(other._query_flags),
    _pipeline_statistics(other._pipeline_statistics)
  {
  }

  /// Move constructor.
  constexpr command_buffer_inheritance_info(
    command_buffer_inheritance_info&& other) noexcept
  : _next(std::move(other._next)),
    _render_pass(std::move(other._render_pass)),
    _subpass(std::move(other._subpass)),
    _framebuffer(std::move(other._framebuffer)),
    _occlusion_query_enable(std::move(other._occlusion_query_enable)),
    _query_flags(std::move(other._query_flags)),
    _pipeline_statistics(std::move(other._pipeline_statistics))
  {
  }

  /// Copy assignment operator.
  constexpr command_buffer_inheritance_info& operator=(
    const command_buffer_inheritance_info& other) noexcept
  {
    _next = other._next;
    _render_pass = other._render_pass;
    _subpass = other._subpass;
    _framebuffer = other._framebuffer;
    _occlusion_query_enable = other._occlusion_query_enable;
    _query_flags = other._query_flags;
    _pipeline_statistics = other._pipeline_statistics;
    return *this;
  }

  /// Move assignment operator.
  constexpr command_buffer_inheritance_info& operator=(
    command_buffer_inheritance_info&& other) noexcept
  {
    _next = std::move(other._next);
    _render_pass = std::move(other._render_pass);
    _subpass = std::move(other._subpass);
    _framebuffer = std::move(other._framebuffer);
    _occlusion_query_enable = std::move(other._occlusion_query_enable);
    _query_flags = std::move(other._query_flags);
    _pipeline_statistics = std::move(other._pipeline_statistics);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkCommandBufferInheritanceInfo&() const
  {
    return *reinterpret_cast<const VkCommandBufferInheritanceInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkRenderPass& render_pass()
  {
    return _render_pass;
  }

  constexpr const VkRenderPass& render_pass() const
  {
    return _render_pass;
  }

  void render_pass(VkRenderPass new_render_pass)
  {
    _render_pass = new_render_pass;
  }

  uint32_t& subpass()
  {
    return _subpass;
  }

  constexpr const uint32_t& subpass() const
  {
    return _subpass;
  }

  void subpass(uint32_t new_subpass)
  {
    _subpass = new_subpass;
  }

  VkFramebuffer& framebuffer()
  {
    return _framebuffer;
  }

  constexpr const VkFramebuffer& framebuffer() const
  {
    return _framebuffer;
  }

  void framebuffer(VkFramebuffer new_framebuffer)
  {
    _framebuffer = new_framebuffer;
  }

  VkBool32& occlusion_query_enable()
  {
    return _occlusion_query_enable;
  }

  constexpr const VkBool32& occlusion_query_enable() const
  {
    return _occlusion_query_enable;
  }

  void occlusion_query_enable(VkBool32 new_occlusion_query_enable)
  {
    _occlusion_query_enable = new_occlusion_query_enable;
  }

  vk::query_control_flags& query_flags()
  {
    return _query_flags;
  }

  constexpr const vk::query_control_flags& query_flags() const
  {
    return _query_flags;
  }

  void query_flags(vk::query_control_flags new_query_flags)
  {
    _query_flags = new_query_flags;
  }

  vk::query_pipeline_statistic_flags& pipeline_statistics()
  {
    return _pipeline_statistics;
  }

  constexpr const vk::query_pipeline_statistic_flags& pipeline_statistics()
    const
  {
    return _pipeline_statistics;
  }

  void pipeline_statistics(
    vk::query_pipeline_statistic_flags new_pipeline_statistics)
  {
    _pipeline_statistics = new_pipeline_statistics;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::command_buffer_inheritance_info;
  const void* _next = nullptr;
  /// Render pass for secondary command buffers
  VkRenderPass _render_pass = nullptr;
  uint32_t _subpass = 0;
  /// Framebuffer for secondary command buffers
  VkFramebuffer _framebuffer = nullptr;
  /// Whether this secondary command buffer may be executed during an occlusion
  /// query
  VkBool32 _occlusion_query_enable = VK_FALSE;
  /// Query flags used by this secondary command buffer, if executed during an
  /// occlusion query
  vk::query_control_flags _query_flags = vk::query_control_flag::none;
  /// Pipeline statistics that may be counted for this secondary command buffer
  vk::query_pipeline_statistic_flags _pipeline_statistics =
    vk::query_pipeline_statistic_flag::none;
};
static_assert(sizeof(command_buffer_inheritance_info) ==
                sizeof(::VkCommandBufferInheritanceInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkCommandBufferBeginInfo.
class command_buffer_begin_info
{
public:
  /// Default constructor.
  constexpr command_buffer_begin_info() = default;

  /// Constructor.
  constexpr command_buffer_begin_info(
    const void* initial_next, vk::command_buffer_usage_flags initial_flags,
    const vk::command_buffer_inheritance_info*
      initial_inheritance_info) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _inheritance_info(std::move(initial_inheritance_info))
  {
  }

  /// Copy constructor.
  constexpr command_buffer_begin_info(
    const command_buffer_begin_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _inheritance_info(other._inheritance_info)
  {
  }

  /// Move constructor.
  constexpr command_buffer_begin_info(
    command_buffer_begin_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _inheritance_info(std::move(other._inheritance_info))
  {
  }

  /// Copy assignment operator.
  constexpr command_buffer_begin_info& operator=(
    const command_buffer_begin_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _inheritance_info = other._inheritance_info;
    return *this;
  }

  /// Move assignment operator.
  constexpr command_buffer_begin_info& operator=(
    command_buffer_begin_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _inheritance_info = std::move(other._inheritance_info);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkCommandBufferBeginInfo&() const
  {
    return *reinterpret_cast<const VkCommandBufferBeginInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::command_buffer_usage_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::command_buffer_usage_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::command_buffer_usage_flags new_flags)
  {
    _flags = new_flags;
  }

  const vk::command_buffer_inheritance_info* inheritance_info()
  {
    return _inheritance_info;
  }

  constexpr const vk::command_buffer_inheritance_info* inheritance_info() const
  {
    return _inheritance_info;
  }

  void inheritance_info(
    const vk::command_buffer_inheritance_info* new_inheritance_info)
  {
    _inheritance_info = new_inheritance_info;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::command_buffer_begin_info;
  const void* _next = nullptr;
  /// Command buffer usage flags
  vk::command_buffer_usage_flags _flags = vk::command_buffer_usage_flag::none;
  /// Pointer to inheritance info for secondary command buffers
  const vk::command_buffer_inheritance_info* _inheritance_info = nullptr;
};
static_assert(sizeof(command_buffer_begin_info) ==
                sizeof(::VkCommandBufferBeginInfo),
              "struct and wrapper have different size!");

inline vk::result begin_command_buffer(
  VkCommandBuffer command_buffer,
  const vk::command_buffer_begin_info* begin_info)
{
  return static_cast<vk::result>(vkBeginCommandBuffer(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkCommandBufferBeginInfo*>(begin_info)));
}
inline vk::result end_command_buffer(VkCommandBuffer command_buffer)
{
  return static_cast<vk::result>(
    vkEndCommandBuffer(static_cast<VkCommandBuffer>(command_buffer)));
}
enum class command_buffer_reset_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Release resources owned by the buffer
  /// @see VK_COMMAND_BUFFER_RESET_RELEASE_RESOURCES_BIT
  release_resources_bit = 1 << 0,
};
using command_buffer_reset_flags =
  shift::core::bit_field<command_buffer_reset_flag, VkCommandBufferResetFlags>;
inline constexpr command_buffer_reset_flags operator|(
  command_buffer_reset_flag lhs, command_buffer_reset_flag rhs)
{
  return command_buffer_reset_flags{lhs} | rhs;
}
inline vk::result reset_command_buffer(VkCommandBuffer command_buffer,
                                       vk::command_buffer_reset_flags flags)
{
  return static_cast<vk::result>(
    vkResetCommandBuffer(static_cast<VkCommandBuffer>(command_buffer),
                         static_cast<VkCommandBufferResetFlags>(flags)));
}
inline void cmd_bind_pipeline(VkCommandBuffer command_buffer,
                              vk::pipeline_bind_point pipeline_bind_point,
                              VkPipeline pipeline)
{
  vkCmdBindPipeline(static_cast<VkCommandBuffer>(command_buffer),
                    static_cast<VkPipelineBindPoint>(pipeline_bind_point),
                    static_cast<VkPipeline>(pipeline));
}
inline void cmd_set_viewport(VkCommandBuffer command_buffer,
                             uint32_t first_viewport, uint32_t viewport_count,
                             const vk::viewport* viewports)
{
  vkCmdSetViewport(static_cast<VkCommandBuffer>(command_buffer),
                   static_cast<uint32_t>(first_viewport),
                   static_cast<uint32_t>(viewport_count),
                   reinterpret_cast<const VkViewport*>(viewports));
}
inline void cmd_set_scissor(VkCommandBuffer command_buffer,
                            uint32_t first_scissor, uint32_t scissor_count,
                            const vk::rect_2d* scissors)
{
  vkCmdSetScissor(static_cast<VkCommandBuffer>(command_buffer),
                  static_cast<uint32_t>(first_scissor),
                  static_cast<uint32_t>(scissor_count),
                  reinterpret_cast<const VkRect2D*>(scissors));
}
inline void cmd_set_line_width(VkCommandBuffer command_buffer, float line_width)
{
  vkCmdSetLineWidth(static_cast<VkCommandBuffer>(command_buffer),
                    static_cast<float>(line_width));
}
inline void cmd_set_depth_bias(VkCommandBuffer command_buffer,
                               float depth_bias_constant_factor,
                               float depth_bias_clamp,
                               float depth_bias_slope_factor)
{
  vkCmdSetDepthBias(static_cast<VkCommandBuffer>(command_buffer),
                    static_cast<float>(depth_bias_constant_factor),
                    static_cast<float>(depth_bias_clamp),
                    static_cast<float>(depth_bias_slope_factor));
}
inline void cmd_set_blend_constants(VkCommandBuffer command_buffer,
                                    std::array<const float, 4> blend_constants)
{
  vkCmdSetBlendConstants(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const float*>(blend_constants.data()));
}
inline void cmd_set_depth_bounds(VkCommandBuffer command_buffer,
                                 float min_depth_bounds, float max_depth_bounds)
{
  vkCmdSetDepthBounds(static_cast<VkCommandBuffer>(command_buffer),
                      static_cast<float>(min_depth_bounds),
                      static_cast<float>(max_depth_bounds));
}
enum class stencil_face_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Front face
  /// @see VK_STENCIL_FACE_FRONT_BIT
  front_bit = 1 << 0,
  /// Back face
  /// @see VK_STENCIL_FACE_BACK_BIT
  back_bit = 1 << 1,
  /// Front and back faces
  /// @see VK_STENCIL_FRONT_AND_BACK
  stencil_front_and_back = 0x00000003,
};
using stencil_face_flags =
  shift::core::bit_field<stencil_face_flag, VkStencilFaceFlags>;
inline constexpr stencil_face_flags operator|(stencil_face_flag lhs,
                                              stencil_face_flag rhs)
{
  return stencil_face_flags{lhs} | rhs;
}
inline void cmd_set_stencil_compare_mask(VkCommandBuffer command_buffer,
                                         vk::stencil_face_flags face_mask,
                                         uint32_t compare_mask)
{
  vkCmdSetStencilCompareMask(static_cast<VkCommandBuffer>(command_buffer),
                             static_cast<VkStencilFaceFlags>(face_mask),
                             static_cast<uint32_t>(compare_mask));
}
inline void cmd_set_stencil_write_mask(VkCommandBuffer command_buffer,
                                       vk::stencil_face_flags face_mask,
                                       uint32_t write_mask)
{
  vkCmdSetStencilWriteMask(static_cast<VkCommandBuffer>(command_buffer),
                           static_cast<VkStencilFaceFlags>(face_mask),
                           static_cast<uint32_t>(write_mask));
}
inline void cmd_set_stencil_reference(VkCommandBuffer command_buffer,
                                      vk::stencil_face_flags face_mask,
                                      uint32_t reference)
{
  vkCmdSetStencilReference(static_cast<VkCommandBuffer>(command_buffer),
                           static_cast<VkStencilFaceFlags>(face_mask),
                           static_cast<uint32_t>(reference));
}
inline void cmd_bind_descriptor_sets(
  VkCommandBuffer command_buffer, vk::pipeline_bind_point pipeline_bind_point,
  VkPipelineLayout layout, uint32_t first_set, uint32_t descriptor_set_count,
  const VkDescriptorSet* descriptor_sets, uint32_t dynamic_offset_count,
  const uint32_t* dynamic_offsets)
{
  vkCmdBindDescriptorSets(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<VkPipelineBindPoint>(pipeline_bind_point),
    static_cast<VkPipelineLayout>(layout), static_cast<uint32_t>(first_set),
    static_cast<uint32_t>(descriptor_set_count),
    reinterpret_cast<const VkDescriptorSet*>(descriptor_sets),
    static_cast<uint32_t>(dynamic_offset_count),
    reinterpret_cast<const uint32_t*>(dynamic_offsets));
}
enum class index_type
{
  /// @see VK_INDEX_TYPE_UINT16
  uint16 = 0,
  /// @see VK_INDEX_TYPE_UINT32
  uint32 = 1,
};
inline void cmd_bind_index_buffer(VkCommandBuffer command_buffer,
                                  VkBuffer buffer, VkDeviceSize offset,
                                  vk::index_type index_type)
{
  vkCmdBindIndexBuffer(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceSize>(offset), static_cast<VkIndexType>(index_type));
}
inline void cmd_bind_vertex_buffers(VkCommandBuffer command_buffer,
                                    uint32_t first_binding,
                                    uint32_t binding_count,
                                    const VkBuffer* buffers,
                                    const VkDeviceSize* offsets)
{
  vkCmdBindVertexBuffers(static_cast<VkCommandBuffer>(command_buffer),
                         static_cast<uint32_t>(first_binding),
                         static_cast<uint32_t>(binding_count),
                         reinterpret_cast<const VkBuffer*>(buffers),
                         reinterpret_cast<const VkDeviceSize*>(offsets));
}
inline void cmd_draw(VkCommandBuffer command_buffer, uint32_t vertex_count,
                     uint32_t instance_count, uint32_t first_vertex,
                     uint32_t first_instance)
{
  vkCmdDraw(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<uint32_t>(vertex_count), static_cast<uint32_t>(instance_count),
    static_cast<uint32_t>(first_vertex), static_cast<uint32_t>(first_instance));
}
inline void cmd_draw_indexed(VkCommandBuffer command_buffer,
                             uint32_t index_count, uint32_t instance_count,
                             uint32_t first_index, int32_t vertex_offset,
                             uint32_t first_instance)
{
  vkCmdDrawIndexed(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<uint32_t>(index_count), static_cast<uint32_t>(instance_count),
    static_cast<uint32_t>(first_index), static_cast<int32_t>(vertex_offset),
    static_cast<uint32_t>(first_instance));
}
inline void cmd_draw_indirect(VkCommandBuffer command_buffer, VkBuffer buffer,
                              VkDeviceSize offset, uint32_t draw_count,
                              uint32_t stride)
{
  vkCmdDrawIndirect(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceSize>(offset), static_cast<uint32_t>(draw_count),
    static_cast<uint32_t>(stride));
}
inline void cmd_draw_indexed_indirect(VkCommandBuffer command_buffer,
                                      VkBuffer buffer, VkDeviceSize offset,
                                      uint32_t draw_count, uint32_t stride)
{
  vkCmdDrawIndexedIndirect(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceSize>(offset), static_cast<uint32_t>(draw_count),
    static_cast<uint32_t>(stride));
}
inline void cmd_dispatch(VkCommandBuffer command_buffer, uint32_t group_count_x,
                         uint32_t group_count_y, uint32_t group_count_z)
{
  vkCmdDispatch(static_cast<VkCommandBuffer>(command_buffer),
                static_cast<uint32_t>(group_count_x),
                static_cast<uint32_t>(group_count_y),
                static_cast<uint32_t>(group_count_z));
}
inline void cmd_dispatch_indirect(VkCommandBuffer command_buffer,
                                  VkBuffer buffer, VkDeviceSize offset)
{
  vkCmdDispatchIndirect(static_cast<VkCommandBuffer>(command_buffer),
                        static_cast<VkBuffer>(buffer),
                        static_cast<VkDeviceSize>(offset));
}

/// Enhanced replacement type for VkBufferCopy.
class buffer_copy
{
public:
  /// Default constructor.
  constexpr buffer_copy() = default;

  /// Constructor.
  constexpr buffer_copy(VkDeviceSize initial_src_offset,
                        VkDeviceSize initial_dst_offset,
                        VkDeviceSize initial_size) noexcept
  : _src_offset(std::move(initial_src_offset)),
    _dst_offset(std::move(initial_dst_offset)),
    _size(std::move(initial_size))
  {
  }

  /// Copy constructor.
  constexpr buffer_copy(const buffer_copy& other) = default;

  /// Move constructor.
  constexpr buffer_copy(buffer_copy&& other) = default;

  /// Copy assignment operator.
  constexpr buffer_copy& operator=(const buffer_copy& other) = default;

  /// Move assignment operator.
  constexpr buffer_copy& operator=(buffer_copy&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkBufferCopy&() const
  {
    return *reinterpret_cast<const VkBufferCopy*>(this);
  }

  VkDeviceSize& src_offset()
  {
    return _src_offset;
  }

  constexpr const VkDeviceSize& src_offset() const
  {
    return _src_offset;
  }

  void src_offset(VkDeviceSize new_src_offset)
  {
    _src_offset = new_src_offset;
  }

  VkDeviceSize& dst_offset()
  {
    return _dst_offset;
  }

  constexpr const VkDeviceSize& dst_offset() const
  {
    return _dst_offset;
  }

  void dst_offset(VkDeviceSize new_dst_offset)
  {
    _dst_offset = new_dst_offset;
  }

  VkDeviceSize& size()
  {
    return _size;
  }

  constexpr const VkDeviceSize& size() const
  {
    return _size;
  }

  void size(VkDeviceSize new_size)
  {
    _size = new_size;
  }

private:
  /// Specified in bytes
  VkDeviceSize _src_offset = 0;
  /// Specified in bytes
  VkDeviceSize _dst_offset = 0;
  /// Specified in bytes
  VkDeviceSize _size = 0;
};
static_assert(sizeof(buffer_copy) == sizeof(::VkBufferCopy),
              "struct and wrapper have different size!");

inline void cmd_copy_buffer(VkCommandBuffer command_buffer, VkBuffer src_buffer,
                            VkBuffer dst_buffer, uint32_t region_count,
                            const vk::buffer_copy* regions)
{
  vkCmdCopyBuffer(static_cast<VkCommandBuffer>(command_buffer),
                  static_cast<VkBuffer>(src_buffer),
                  static_cast<VkBuffer>(dst_buffer),
                  static_cast<uint32_t>(region_count),
                  reinterpret_cast<const VkBufferCopy*>(regions));
}

/// Enhanced replacement type for VkImageSubresourceLayers.
class image_subresource_layers
{
public:
  /// Default constructor.
  constexpr image_subresource_layers() = default;

  /// Constructor.
  constexpr image_subresource_layers(vk::image_aspect_flags initial_aspect_mask,
                                     uint32_t initial_mip_level,
                                     uint32_t initial_base_array_layer,
                                     uint32_t initial_layer_count) noexcept
  : _aspect_mask(std::move(initial_aspect_mask)),
    _mip_level(std::move(initial_mip_level)),
    _base_array_layer(std::move(initial_base_array_layer)),
    _layer_count(std::move(initial_layer_count))
  {
  }

  /// Copy constructor.
  constexpr image_subresource_layers(const image_subresource_layers& other) =
    default;

  /// Move constructor.
  constexpr image_subresource_layers(image_subresource_layers&& other) =
    default;

  /// Copy assignment operator.
  constexpr image_subresource_layers& operator=(
    const image_subresource_layers& other) = default;

  /// Move assignment operator.
  constexpr image_subresource_layers& operator=(
    image_subresource_layers&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkImageSubresourceLayers&() const
  {
    return *reinterpret_cast<const VkImageSubresourceLayers*>(this);
  }

  vk::image_aspect_flags& aspect_mask()
  {
    return _aspect_mask;
  }

  constexpr const vk::image_aspect_flags& aspect_mask() const
  {
    return _aspect_mask;
  }

  void aspect_mask(vk::image_aspect_flags new_aspect_mask)
  {
    _aspect_mask = new_aspect_mask;
  }

  uint32_t& mip_level()
  {
    return _mip_level;
  }

  constexpr const uint32_t& mip_level() const
  {
    return _mip_level;
  }

  void mip_level(uint32_t new_mip_level)
  {
    _mip_level = new_mip_level;
  }

  uint32_t& base_array_layer()
  {
    return _base_array_layer;
  }

  constexpr const uint32_t& base_array_layer() const
  {
    return _base_array_layer;
  }

  void base_array_layer(uint32_t new_base_array_layer)
  {
    _base_array_layer = new_base_array_layer;
  }

  uint32_t& layer_count()
  {
    return _layer_count;
  }

  constexpr const uint32_t& layer_count() const
  {
    return _layer_count;
  }

  void layer_count(uint32_t new_layer_count)
  {
    _layer_count = new_layer_count;
  }

private:
  vk::image_aspect_flags _aspect_mask = vk::image_aspect_flag::none;
  uint32_t _mip_level = 0;
  uint32_t _base_array_layer = 0;
  uint32_t _layer_count = 0;
};
static_assert(sizeof(image_subresource_layers) ==
                sizeof(::VkImageSubresourceLayers),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImageCopy.
class image_copy
{
public:
  /// Default constructor.
  constexpr image_copy() = default;

  /// Constructor.
  constexpr image_copy(vk::image_subresource_layers initial_src_subresource,
                       vk::offset_3d initial_src_offset,
                       vk::image_subresource_layers initial_dst_subresource,
                       vk::offset_3d initial_dst_offset,
                       vk::extent_3d initial_extent) noexcept
  : _src_subresource(std::move(initial_src_subresource)),
    _src_offset(std::move(initial_src_offset)),
    _dst_subresource(std::move(initial_dst_subresource)),
    _dst_offset(std::move(initial_dst_offset)),
    _extent(std::move(initial_extent))
  {
  }

  /// Copy constructor.
  constexpr image_copy(const image_copy& other) = default;

  /// Move constructor.
  constexpr image_copy(image_copy&& other) = default;

  /// Copy assignment operator.
  constexpr image_copy& operator=(const image_copy& other) = default;

  /// Move assignment operator.
  constexpr image_copy& operator=(image_copy&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkImageCopy&() const
  {
    return *reinterpret_cast<const VkImageCopy*>(this);
  }

  vk::image_subresource_layers& src_subresource()
  {
    return _src_subresource;
  }

  constexpr const vk::image_subresource_layers& src_subresource() const
  {
    return _src_subresource;
  }

  void src_subresource(vk::image_subresource_layers new_src_subresource)
  {
    _src_subresource = new_src_subresource;
  }

  vk::offset_3d& src_offset()
  {
    return _src_offset;
  }

  constexpr const vk::offset_3d& src_offset() const
  {
    return _src_offset;
  }

  void src_offset(vk::offset_3d new_src_offset)
  {
    _src_offset = new_src_offset;
  }

  vk::image_subresource_layers& dst_subresource()
  {
    return _dst_subresource;
  }

  constexpr const vk::image_subresource_layers& dst_subresource() const
  {
    return _dst_subresource;
  }

  void dst_subresource(vk::image_subresource_layers new_dst_subresource)
  {
    _dst_subresource = new_dst_subresource;
  }

  vk::offset_3d& dst_offset()
  {
    return _dst_offset;
  }

  constexpr const vk::offset_3d& dst_offset() const
  {
    return _dst_offset;
  }

  void dst_offset(vk::offset_3d new_dst_offset)
  {
    _dst_offset = new_dst_offset;
  }

  vk::extent_3d& extent()
  {
    return _extent;
  }

  constexpr const vk::extent_3d& extent() const
  {
    return _extent;
  }

  void extent(vk::extent_3d new_extent)
  {
    _extent = new_extent;
  }

private:
  vk::image_subresource_layers _src_subresource =
    vk::image_subresource_layers{};
  /// Specified in pixels for both compressed and uncompressed images
  vk::offset_3d _src_offset = vk::offset_3d{};
  vk::image_subresource_layers _dst_subresource =
    vk::image_subresource_layers{};
  /// Specified in pixels for both compressed and uncompressed images
  vk::offset_3d _dst_offset = vk::offset_3d{};
  /// Specified in pixels for both compressed and uncompressed images
  vk::extent_3d _extent = vk::extent_3d{};
};
static_assert(sizeof(image_copy) == sizeof(::VkImageCopy),
              "struct and wrapper have different size!");

inline void cmd_copy_image(VkCommandBuffer command_buffer, VkImage src_image,
                           vk::image_layout src_image_layout, VkImage dst_image,
                           vk::image_layout dst_image_layout,
                           uint32_t region_count, const vk::image_copy* regions)
{
  vkCmdCopyImage(static_cast<VkCommandBuffer>(command_buffer),
                 static_cast<VkImage>(src_image),
                 static_cast<VkImageLayout>(src_image_layout),
                 static_cast<VkImage>(dst_image),
                 static_cast<VkImageLayout>(dst_image_layout),
                 static_cast<uint32_t>(region_count),
                 reinterpret_cast<const VkImageCopy*>(regions));
}

/// Enhanced replacement type for VkImageBlit.
class image_blit
{
public:
  /// Default constructor.
  constexpr image_blit() = default;

  /// Constructor.
  constexpr image_blit(
    vk::image_subresource_layers initial_src_subresource,
    std::array<vk::offset_3d, 2> initial_src_offsets,
    vk::image_subresource_layers initial_dst_subresource,
    std::array<vk::offset_3d, 2> initial_dst_offsets) noexcept
  : _src_subresource(std::move(initial_src_subresource)),
    _src_offsets(std::move(initial_src_offsets)),
    _dst_subresource(std::move(initial_dst_subresource)),
    _dst_offsets(std::move(initial_dst_offsets))
  {
  }

  /// Copy constructor.
  constexpr image_blit(const image_blit& other) = default;

  /// Move constructor.
  constexpr image_blit(image_blit&& other) = default;

  /// Copy assignment operator.
  constexpr image_blit& operator=(const image_blit& other) = default;

  /// Move assignment operator.
  constexpr image_blit& operator=(image_blit&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkImageBlit&() const
  {
    return *reinterpret_cast<const VkImageBlit*>(this);
  }

  vk::image_subresource_layers& src_subresource()
  {
    return _src_subresource;
  }

  constexpr const vk::image_subresource_layers& src_subresource() const
  {
    return _src_subresource;
  }

  void src_subresource(vk::image_subresource_layers new_src_subresource)
  {
    _src_subresource = new_src_subresource;
  }

  std::array<vk::offset_3d, 2>& src_offsets()
  {
    return _src_offsets;
  }

  constexpr const std::array<vk::offset_3d, 2>& src_offsets() const
  {
    return _src_offsets;
  }

  void src_offsets(std::array<vk::offset_3d, 2> new_src_offsets)
  {
    _src_offsets = new_src_offsets;
  }

  vk::image_subresource_layers& dst_subresource()
  {
    return _dst_subresource;
  }

  constexpr const vk::image_subresource_layers& dst_subresource() const
  {
    return _dst_subresource;
  }

  void dst_subresource(vk::image_subresource_layers new_dst_subresource)
  {
    _dst_subresource = new_dst_subresource;
  }

  std::array<vk::offset_3d, 2>& dst_offsets()
  {
    return _dst_offsets;
  }

  constexpr const std::array<vk::offset_3d, 2>& dst_offsets() const
  {
    return _dst_offsets;
  }

  void dst_offsets(std::array<vk::offset_3d, 2> new_dst_offsets)
  {
    _dst_offsets = new_dst_offsets;
  }

private:
  vk::image_subresource_layers _src_subresource =
    vk::image_subresource_layers{};
  /// Specified in pixels for both compressed and uncompressed images
  std::array<vk::offset_3d, 2> _src_offsets = {};
  vk::image_subresource_layers _dst_subresource =
    vk::image_subresource_layers{};
  /// Specified in pixels for both compressed and uncompressed images
  std::array<vk::offset_3d, 2> _dst_offsets = {};
};
static_assert(sizeof(image_blit) == sizeof(::VkImageBlit),
              "struct and wrapper have different size!");

inline void cmd_blit_image(VkCommandBuffer command_buffer, VkImage src_image,
                           vk::image_layout src_image_layout, VkImage dst_image,
                           vk::image_layout dst_image_layout,
                           uint32_t region_count, const vk::image_blit* regions,
                           vk::filter filter)
{
  vkCmdBlitImage(static_cast<VkCommandBuffer>(command_buffer),
                 static_cast<VkImage>(src_image),
                 static_cast<VkImageLayout>(src_image_layout),
                 static_cast<VkImage>(dst_image),
                 static_cast<VkImageLayout>(dst_image_layout),
                 static_cast<uint32_t>(region_count),
                 reinterpret_cast<const VkImageBlit*>(regions),
                 static_cast<VkFilter>(filter));
}

/// Enhanced replacement type for VkBufferImageCopy.
class buffer_image_copy
{
public:
  /// Default constructor.
  constexpr buffer_image_copy() = default;

  /// Constructor.
  constexpr buffer_image_copy(
    VkDeviceSize initial_buffer_offset, uint32_t initial_buffer_row_length,
    uint32_t initial_buffer_image_height,
    vk::image_subresource_layers initial_image_subresource,
    vk::offset_3d initial_image_offset,
    vk::extent_3d initial_image_extent) noexcept
  : _buffer_offset(std::move(initial_buffer_offset)),
    _buffer_row_length(std::move(initial_buffer_row_length)),
    _buffer_image_height(std::move(initial_buffer_image_height)),
    _image_subresource(std::move(initial_image_subresource)),
    _image_offset(std::move(initial_image_offset)),
    _image_extent(std::move(initial_image_extent))
  {
  }

  /// Copy constructor.
  constexpr buffer_image_copy(const buffer_image_copy& other) = default;

  /// Move constructor.
  constexpr buffer_image_copy(buffer_image_copy&& other) = default;

  /// Copy assignment operator.
  constexpr buffer_image_copy& operator=(const buffer_image_copy& other) =
    default;

  /// Move assignment operator.
  constexpr buffer_image_copy& operator=(buffer_image_copy&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkBufferImageCopy&() const
  {
    return *reinterpret_cast<const VkBufferImageCopy*>(this);
  }

  VkDeviceSize& buffer_offset()
  {
    return _buffer_offset;
  }

  constexpr const VkDeviceSize& buffer_offset() const
  {
    return _buffer_offset;
  }

  void buffer_offset(VkDeviceSize new_buffer_offset)
  {
    _buffer_offset = new_buffer_offset;
  }

  uint32_t& buffer_row_length()
  {
    return _buffer_row_length;
  }

  constexpr const uint32_t& buffer_row_length() const
  {
    return _buffer_row_length;
  }

  void buffer_row_length(uint32_t new_buffer_row_length)
  {
    _buffer_row_length = new_buffer_row_length;
  }

  uint32_t& buffer_image_height()
  {
    return _buffer_image_height;
  }

  constexpr const uint32_t& buffer_image_height() const
  {
    return _buffer_image_height;
  }

  void buffer_image_height(uint32_t new_buffer_image_height)
  {
    _buffer_image_height = new_buffer_image_height;
  }

  vk::image_subresource_layers& image_subresource()
  {
    return _image_subresource;
  }

  constexpr const vk::image_subresource_layers& image_subresource() const
  {
    return _image_subresource;
  }

  void image_subresource(vk::image_subresource_layers new_image_subresource)
  {
    _image_subresource = new_image_subresource;
  }

  vk::offset_3d& image_offset()
  {
    return _image_offset;
  }

  constexpr const vk::offset_3d& image_offset() const
  {
    return _image_offset;
  }

  void image_offset(vk::offset_3d new_image_offset)
  {
    _image_offset = new_image_offset;
  }

  vk::extent_3d& image_extent()
  {
    return _image_extent;
  }

  constexpr const vk::extent_3d& image_extent() const
  {
    return _image_extent;
  }

  void image_extent(vk::extent_3d new_image_extent)
  {
    _image_extent = new_image_extent;
  }

private:
  /// Specified in bytes
  VkDeviceSize _buffer_offset = 0;
  /// Specified in texels
  uint32_t _buffer_row_length = 0;
  uint32_t _buffer_image_height = 0;
  vk::image_subresource_layers _image_subresource =
    vk::image_subresource_layers{};
  /// Specified in pixels for both compressed and uncompressed images
  vk::offset_3d _image_offset = vk::offset_3d{};
  /// Specified in pixels for both compressed and uncompressed images
  vk::extent_3d _image_extent = vk::extent_3d{};
};
static_assert(sizeof(buffer_image_copy) == sizeof(::VkBufferImageCopy),
              "struct and wrapper have different size!");

inline void cmd_copy_buffer_to_image(VkCommandBuffer command_buffer,
                                     VkBuffer src_buffer, VkImage dst_image,
                                     vk::image_layout dst_image_layout,
                                     uint32_t region_count,
                                     const vk::buffer_image_copy* regions)
{
  vkCmdCopyBufferToImage(static_cast<VkCommandBuffer>(command_buffer),
                         static_cast<VkBuffer>(src_buffer),
                         static_cast<VkImage>(dst_image),
                         static_cast<VkImageLayout>(dst_image_layout),
                         static_cast<uint32_t>(region_count),
                         reinterpret_cast<const VkBufferImageCopy*>(regions));
}
inline void cmd_copy_image_to_buffer(VkCommandBuffer command_buffer,
                                     VkImage src_image,
                                     vk::image_layout src_image_layout,
                                     VkBuffer dst_buffer, uint32_t region_count,
                                     const vk::buffer_image_copy* regions)
{
  vkCmdCopyImageToBuffer(static_cast<VkCommandBuffer>(command_buffer),
                         static_cast<VkImage>(src_image),
                         static_cast<VkImageLayout>(src_image_layout),
                         static_cast<VkBuffer>(dst_buffer),
                         static_cast<uint32_t>(region_count),
                         reinterpret_cast<const VkBufferImageCopy*>(regions));
}
inline void cmd_update_buffer(VkCommandBuffer command_buffer,
                              VkBuffer dst_buffer, VkDeviceSize dst_offset,
                              VkDeviceSize data_size, const void* data)
{
  vkCmdUpdateBuffer(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<VkBuffer>(dst_buffer), static_cast<VkDeviceSize>(dst_offset),
    static_cast<VkDeviceSize>(data_size), reinterpret_cast<const void*>(data));
}
inline void cmd_fill_buffer(VkCommandBuffer command_buffer, VkBuffer dst_buffer,
                            VkDeviceSize dst_offset, VkDeviceSize size,
                            uint32_t data)
{
  vkCmdFillBuffer(static_cast<VkCommandBuffer>(command_buffer),
                  static_cast<VkBuffer>(dst_buffer),
                  static_cast<VkDeviceSize>(dst_offset),
                  static_cast<VkDeviceSize>(size), static_cast<uint32_t>(data));
}

union clear_color_value {
  /// Default constructor.
  constexpr clear_color_value() noexcept
  {
  }
  /// Constructor.
  constexpr clear_color_value(std::array<float, 4> initial_float32)
  : float32(initial_float32)
  {
  }
  /// Constructor.
  constexpr clear_color_value(std::array<int32_t, 4> initial_int32)
  : int32(initial_int32)
  {
  }
  /// Constructor.
  constexpr clear_color_value(std::array<uint32_t, 4> initial_uint32)
  : uint32(initial_uint32)
  {
  }
  /// Conversion operator to original Vulkan type.
  operator const VkClearColorValue&() const
  {
    return *reinterpret_cast<const VkClearColorValue*>(this);
  }
  std::array<float, 4> float32 = {};
  std::array<int32_t, 4> int32;
  std::array<uint32_t, 4> uint32;
};
static_assert(sizeof(clear_color_value) == sizeof(::VkClearColorValue),
              "struct and wrapper have different size!");
inline void cmd_clear_color_image(VkCommandBuffer command_buffer, VkImage image,
                                  vk::image_layout image_layout,
                                  const vk::clear_color_value* color,
                                  uint32_t range_count,
                                  const vk::image_subresource_range* ranges)
{
  vkCmdClearColorImage(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkImage>(image),
    static_cast<VkImageLayout>(image_layout),
    reinterpret_cast<const VkClearColorValue*>(color),
    static_cast<uint32_t>(range_count),
    reinterpret_cast<const VkImageSubresourceRange*>(ranges));
}

/// Enhanced replacement type for VkClearDepthStencilValue.
class clear_depth_stencil_value
{
public:
  /// Default constructor.
  constexpr clear_depth_stencil_value() = default;

  /// Constructor.
  constexpr clear_depth_stencil_value(float initial_depth,
                                      uint32_t initial_stencil) noexcept
  : _depth(std::move(initial_depth)), _stencil(std::move(initial_stencil))
  {
  }

  /// Copy constructor.
  constexpr clear_depth_stencil_value(const clear_depth_stencil_value& other) =
    default;

  /// Move constructor.
  constexpr clear_depth_stencil_value(clear_depth_stencil_value&& other) =
    default;

  /// Copy assignment operator.
  constexpr clear_depth_stencil_value& operator=(
    const clear_depth_stencil_value& other) = default;

  /// Move assignment operator.
  constexpr clear_depth_stencil_value& operator=(
    clear_depth_stencil_value&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkClearDepthStencilValue&() const
  {
    return *reinterpret_cast<const VkClearDepthStencilValue*>(this);
  }

  float& depth()
  {
    return _depth;
  }

  constexpr const float& depth() const
  {
    return _depth;
  }

  void depth(float new_depth)
  {
    _depth = new_depth;
  }

  uint32_t& stencil()
  {
    return _stencil;
  }

  constexpr const uint32_t& stencil() const
  {
    return _stencil;
  }

  void stencil(uint32_t new_stencil)
  {
    _stencil = new_stencil;
  }

private:
  float _depth = 0.0f;
  uint32_t _stencil = 0;
};
static_assert(sizeof(clear_depth_stencil_value) ==
                sizeof(::VkClearDepthStencilValue),
              "struct and wrapper have different size!");

inline void cmd_clear_depth_stencil_image(
  VkCommandBuffer command_buffer, VkImage image, vk::image_layout image_layout,
  const vk::clear_depth_stencil_value* depth_stencil, uint32_t range_count,
  const vk::image_subresource_range* ranges)
{
  vkCmdClearDepthStencilImage(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkImage>(image),
    static_cast<VkImageLayout>(image_layout),
    reinterpret_cast<const VkClearDepthStencilValue*>(depth_stencil),
    static_cast<uint32_t>(range_count),
    reinterpret_cast<const VkImageSubresourceRange*>(ranges));
}

union clear_value {
  /// Default constructor.
  constexpr clear_value() noexcept
  {
  }
  /// Constructor.
  constexpr clear_value(vk::clear_color_value initial_color)
  : color(initial_color)
  {
  }
  /// Constructor.
  constexpr clear_value(vk::clear_depth_stencil_value initial_depth_stencil)
  : depth_stencil(initial_depth_stencil)
  {
  }
  /// Conversion operator to original Vulkan type.
  operator const VkClearValue&() const
  {
    return *reinterpret_cast<const VkClearValue*>(this);
  }
  vk::clear_color_value color = vk::clear_color_value{};
  vk::clear_depth_stencil_value depth_stencil;
};
static_assert(sizeof(clear_value) == sizeof(::VkClearValue),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkClearAttachment.
class clear_attachment
{
public:
  /// Default constructor.
  constexpr clear_attachment() = default;

  /// Constructor.
  constexpr clear_attachment(vk::image_aspect_flags initial_aspect_mask,
                             uint32_t initial_color_attachment,
                             vk::clear_value initial_clear_value) noexcept
  : _aspect_mask(std::move(initial_aspect_mask)),
    _color_attachment(std::move(initial_color_attachment)),
    _clear_value(std::move(initial_clear_value))
  {
  }

  /// Copy constructor.
  constexpr clear_attachment(const clear_attachment& other) = default;

  /// Move constructor.
  constexpr clear_attachment(clear_attachment&& other) = default;

  /// Copy assignment operator.
  constexpr clear_attachment& operator=(const clear_attachment& other) =
    default;

  /// Move assignment operator.
  constexpr clear_attachment& operator=(clear_attachment&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkClearAttachment&() const
  {
    return *reinterpret_cast<const VkClearAttachment*>(this);
  }

  vk::image_aspect_flags& aspect_mask()
  {
    return _aspect_mask;
  }

  constexpr const vk::image_aspect_flags& aspect_mask() const
  {
    return _aspect_mask;
  }

  void aspect_mask(vk::image_aspect_flags new_aspect_mask)
  {
    _aspect_mask = new_aspect_mask;
  }

  uint32_t& color_attachment()
  {
    return _color_attachment;
  }

  constexpr const uint32_t& color_attachment() const
  {
    return _color_attachment;
  }

  void color_attachment(uint32_t new_color_attachment)
  {
    _color_attachment = new_color_attachment;
  }

  vk::clear_value& clear_value()
  {
    return _clear_value;
  }

  constexpr const vk::clear_value& clear_value() const
  {
    return _clear_value;
  }

  void clear_value(vk::clear_value new_clear_value)
  {
    _clear_value = new_clear_value;
  }

private:
  vk::image_aspect_flags _aspect_mask = vk::image_aspect_flag::none;
  uint32_t _color_attachment = 0;
  vk::clear_value _clear_value = vk::clear_value{};
};
static_assert(sizeof(clear_attachment) == sizeof(::VkClearAttachment),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkClearRect.
class clear_rect
{
public:
  /// Default constructor.
  constexpr clear_rect() = default;

  /// Constructor.
  constexpr clear_rect(vk::rect_2d initial_rect,
                       uint32_t initial_base_array_layer,
                       uint32_t initial_layer_count) noexcept
  : _rect(std::move(initial_rect)),
    _base_array_layer(std::move(initial_base_array_layer)),
    _layer_count(std::move(initial_layer_count))
  {
  }

  /// Copy constructor.
  constexpr clear_rect(const clear_rect& other) = default;

  /// Move constructor.
  constexpr clear_rect(clear_rect&& other) = default;

  /// Copy assignment operator.
  constexpr clear_rect& operator=(const clear_rect& other) = default;

  /// Move assignment operator.
  constexpr clear_rect& operator=(clear_rect&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkClearRect&() const
  {
    return *reinterpret_cast<const VkClearRect*>(this);
  }

  vk::rect_2d& rect()
  {
    return _rect;
  }

  constexpr const vk::rect_2d& rect() const
  {
    return _rect;
  }

  void rect(vk::rect_2d new_rect)
  {
    _rect = new_rect;
  }

  uint32_t& base_array_layer()
  {
    return _base_array_layer;
  }

  constexpr const uint32_t& base_array_layer() const
  {
    return _base_array_layer;
  }

  void base_array_layer(uint32_t new_base_array_layer)
  {
    _base_array_layer = new_base_array_layer;
  }

  uint32_t& layer_count()
  {
    return _layer_count;
  }

  constexpr const uint32_t& layer_count() const
  {
    return _layer_count;
  }

  void layer_count(uint32_t new_layer_count)
  {
    _layer_count = new_layer_count;
  }

private:
  vk::rect_2d _rect = vk::rect_2d{};
  uint32_t _base_array_layer = 0;
  uint32_t _layer_count = 0;
};
static_assert(sizeof(clear_rect) == sizeof(::VkClearRect),
              "struct and wrapper have different size!");

inline void cmd_clear_attachments(VkCommandBuffer command_buffer,
                                  uint32_t attachment_count,
                                  const vk::clear_attachment* attachments,
                                  uint32_t rect_count,
                                  const vk::clear_rect* rects)
{
  vkCmdClearAttachments(static_cast<VkCommandBuffer>(command_buffer),
                        static_cast<uint32_t>(attachment_count),
                        reinterpret_cast<const VkClearAttachment*>(attachments),
                        static_cast<uint32_t>(rect_count),
                        reinterpret_cast<const VkClearRect*>(rects));
}

/// Enhanced replacement type for VkImageResolve.
class image_resolve
{
public:
  /// Default constructor.
  constexpr image_resolve() = default;

  /// Constructor.
  constexpr image_resolve(vk::image_subresource_layers initial_src_subresource,
                          vk::offset_3d initial_src_offset,
                          vk::image_subresource_layers initial_dst_subresource,
                          vk::offset_3d initial_dst_offset,
                          vk::extent_3d initial_extent) noexcept
  : _src_subresource(std::move(initial_src_subresource)),
    _src_offset(std::move(initial_src_offset)),
    _dst_subresource(std::move(initial_dst_subresource)),
    _dst_offset(std::move(initial_dst_offset)),
    _extent(std::move(initial_extent))
  {
  }

  /// Copy constructor.
  constexpr image_resolve(const image_resolve& other) = default;

  /// Move constructor.
  constexpr image_resolve(image_resolve&& other) = default;

  /// Copy assignment operator.
  constexpr image_resolve& operator=(const image_resolve& other) = default;

  /// Move assignment operator.
  constexpr image_resolve& operator=(image_resolve&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkImageResolve&() const
  {
    return *reinterpret_cast<const VkImageResolve*>(this);
  }

  vk::image_subresource_layers& src_subresource()
  {
    return _src_subresource;
  }

  constexpr const vk::image_subresource_layers& src_subresource() const
  {
    return _src_subresource;
  }

  void src_subresource(vk::image_subresource_layers new_src_subresource)
  {
    _src_subresource = new_src_subresource;
  }

  vk::offset_3d& src_offset()
  {
    return _src_offset;
  }

  constexpr const vk::offset_3d& src_offset() const
  {
    return _src_offset;
  }

  void src_offset(vk::offset_3d new_src_offset)
  {
    _src_offset = new_src_offset;
  }

  vk::image_subresource_layers& dst_subresource()
  {
    return _dst_subresource;
  }

  constexpr const vk::image_subresource_layers& dst_subresource() const
  {
    return _dst_subresource;
  }

  void dst_subresource(vk::image_subresource_layers new_dst_subresource)
  {
    _dst_subresource = new_dst_subresource;
  }

  vk::offset_3d& dst_offset()
  {
    return _dst_offset;
  }

  constexpr const vk::offset_3d& dst_offset() const
  {
    return _dst_offset;
  }

  void dst_offset(vk::offset_3d new_dst_offset)
  {
    _dst_offset = new_dst_offset;
  }

  vk::extent_3d& extent()
  {
    return _extent;
  }

  constexpr const vk::extent_3d& extent() const
  {
    return _extent;
  }

  void extent(vk::extent_3d new_extent)
  {
    _extent = new_extent;
  }

private:
  vk::image_subresource_layers _src_subresource =
    vk::image_subresource_layers{};
  vk::offset_3d _src_offset = vk::offset_3d{};
  vk::image_subresource_layers _dst_subresource =
    vk::image_subresource_layers{};
  vk::offset_3d _dst_offset = vk::offset_3d{};
  vk::extent_3d _extent = vk::extent_3d{};
};
static_assert(sizeof(image_resolve) == sizeof(::VkImageResolve),
              "struct and wrapper have different size!");

inline void cmd_resolve_image(VkCommandBuffer command_buffer, VkImage src_image,
                              vk::image_layout src_image_layout,
                              VkImage dst_image,
                              vk::image_layout dst_image_layout,
                              uint32_t region_count,
                              const vk::image_resolve* regions)
{
  vkCmdResolveImage(static_cast<VkCommandBuffer>(command_buffer),
                    static_cast<VkImage>(src_image),
                    static_cast<VkImageLayout>(src_image_layout),
                    static_cast<VkImage>(dst_image),
                    static_cast<VkImageLayout>(dst_image_layout),
                    static_cast<uint32_t>(region_count),
                    reinterpret_cast<const VkImageResolve*>(regions));
}
inline void cmd_set_event(VkCommandBuffer command_buffer, VkEvent event,
                          vk::pipeline_stage_flags stage_mask)
{
  vkCmdSetEvent(static_cast<VkCommandBuffer>(command_buffer),
                static_cast<VkEvent>(event),
                static_cast<VkPipelineStageFlags>(stage_mask));
}
inline void cmd_reset_event(VkCommandBuffer command_buffer, VkEvent event,
                            vk::pipeline_stage_flags stage_mask)
{
  vkCmdResetEvent(static_cast<VkCommandBuffer>(command_buffer),
                  static_cast<VkEvent>(event),
                  static_cast<VkPipelineStageFlags>(stage_mask));
}
inline void cmd_wait_events(
  VkCommandBuffer command_buffer, uint32_t event_count, const VkEvent* events,
  vk::pipeline_stage_flags src_stage_mask,
  vk::pipeline_stage_flags dst_stage_mask, uint32_t memory_barrier_count,
  const vk::memory_barrier* memory_barriers,
  uint32_t buffer_memory_barrier_count,
  const vk::buffer_memory_barrier* buffer_memory_barriers,
  uint32_t image_memory_barrier_count,
  const vk::image_memory_barrier* image_memory_barriers)
{
  vkCmdWaitEvents(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<uint32_t>(event_count),
    reinterpret_cast<const VkEvent*>(events),
    static_cast<VkPipelineStageFlags>(src_stage_mask),
    static_cast<VkPipelineStageFlags>(dst_stage_mask),
    static_cast<uint32_t>(memory_barrier_count),
    reinterpret_cast<const VkMemoryBarrier*>(memory_barriers),
    static_cast<uint32_t>(buffer_memory_barrier_count),
    reinterpret_cast<const VkBufferMemoryBarrier*>(buffer_memory_barriers),
    static_cast<uint32_t>(image_memory_barrier_count),
    reinterpret_cast<const VkImageMemoryBarrier*>(image_memory_barriers));
}
inline void cmd_pipeline_barrier(
  VkCommandBuffer command_buffer, vk::pipeline_stage_flags src_stage_mask,
  vk::pipeline_stage_flags dst_stage_mask,
  vk::dependency_flags dependency_flags, uint32_t memory_barrier_count,
  const vk::memory_barrier* memory_barriers,
  uint32_t buffer_memory_barrier_count,
  const vk::buffer_memory_barrier* buffer_memory_barriers,
  uint32_t image_memory_barrier_count,
  const vk::image_memory_barrier* image_memory_barriers)
{
  vkCmdPipelineBarrier(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<VkPipelineStageFlags>(src_stage_mask),
    static_cast<VkPipelineStageFlags>(dst_stage_mask),
    static_cast<VkDependencyFlags>(dependency_flags),
    static_cast<uint32_t>(memory_barrier_count),
    reinterpret_cast<const VkMemoryBarrier*>(memory_barriers),
    static_cast<uint32_t>(buffer_memory_barrier_count),
    reinterpret_cast<const VkBufferMemoryBarrier*>(buffer_memory_barriers),
    static_cast<uint32_t>(image_memory_barrier_count),
    reinterpret_cast<const VkImageMemoryBarrier*>(image_memory_barriers));
}
inline void cmd_begin_query(VkCommandBuffer command_buffer,
                            VkQueryPool query_pool, uint32_t query,
                            vk::query_control_flags flags)
{
  vkCmdBeginQuery(static_cast<VkCommandBuffer>(command_buffer),
                  static_cast<VkQueryPool>(query_pool),
                  static_cast<uint32_t>(query),
                  static_cast<VkQueryControlFlags>(flags));
}
inline void cmd_end_query(VkCommandBuffer command_buffer,
                          VkQueryPool query_pool, uint32_t query)
{
  vkCmdEndQuery(static_cast<VkCommandBuffer>(command_buffer),
                static_cast<VkQueryPool>(query_pool),
                static_cast<uint32_t>(query));
}
inline void cmd_reset_query_pool(VkCommandBuffer command_buffer,
                                 VkQueryPool query_pool, uint32_t first_query,
                                 uint32_t query_count)
{
  vkCmdResetQueryPool(static_cast<VkCommandBuffer>(command_buffer),
                      static_cast<VkQueryPool>(query_pool),
                      static_cast<uint32_t>(first_query),
                      static_cast<uint32_t>(query_count));
}
inline void cmd_write_timestamp(VkCommandBuffer command_buffer,
                                vk::pipeline_stage_flag pipeline_stage,
                                VkQueryPool query_pool, uint32_t query)
{
  vkCmdWriteTimestamp(static_cast<VkCommandBuffer>(command_buffer),
                      static_cast<VkPipelineStageFlagBits>(pipeline_stage),
                      static_cast<VkQueryPool>(query_pool),
                      static_cast<uint32_t>(query));
}
inline void cmd_copy_query_pool_results(
  VkCommandBuffer command_buffer, VkQueryPool query_pool, uint32_t first_query,
  uint32_t query_count, VkBuffer dst_buffer, VkDeviceSize dst_offset,
  VkDeviceSize stride, vk::query_result_flags flags)
{
  vkCmdCopyQueryPoolResults(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<VkQueryPool>(query_pool), static_cast<uint32_t>(first_query),
    static_cast<uint32_t>(query_count), static_cast<VkBuffer>(dst_buffer),
    static_cast<VkDeviceSize>(dst_offset), static_cast<VkDeviceSize>(stride),
    static_cast<VkQueryResultFlags>(flags));
}
inline void cmd_push_constants(VkCommandBuffer command_buffer,
                               VkPipelineLayout layout,
                               vk::shader_stage_flags stage_flags,
                               uint32_t offset, uint32_t size,
                               const void* values)
{
  vkCmdPushConstants(static_cast<VkCommandBuffer>(command_buffer),
                     static_cast<VkPipelineLayout>(layout),
                     static_cast<VkShaderStageFlags>(stage_flags),
                     static_cast<uint32_t>(offset), static_cast<uint32_t>(size),
                     reinterpret_cast<const void*>(values));
}

/// Enhanced replacement type for VkRenderPassBeginInfo.
class render_pass_begin_info
{
public:
  /// Default constructor.
  constexpr render_pass_begin_info() = default;

  /// Constructor.
  constexpr render_pass_begin_info(
    const void* initial_next, VkRenderPass initial_render_pass,
    VkFramebuffer initial_framebuffer, vk::rect_2d initial_render_area,
    uint32_t initial_clear_value_count,
    const vk::clear_value* initial_clear_values) noexcept
  : _next(std::move(initial_next)),
    _render_pass(std::move(initial_render_pass)),
    _framebuffer(std::move(initial_framebuffer)),
    _render_area(std::move(initial_render_area)),
    _clear_value_count(std::move(initial_clear_value_count)),
    _clear_values(std::move(initial_clear_values))
  {
  }

  /// Copy constructor.
  constexpr render_pass_begin_info(const render_pass_begin_info& other) noexcept
  : _next(other._next),
    _render_pass(other._render_pass),
    _framebuffer(other._framebuffer),
    _render_area(other._render_area),
    _clear_value_count(other._clear_value_count),
    _clear_values(other._clear_values)
  {
  }

  /// Move constructor.
  constexpr render_pass_begin_info(render_pass_begin_info&& other) noexcept
  : _next(std::move(other._next)),
    _render_pass(std::move(other._render_pass)),
    _framebuffer(std::move(other._framebuffer)),
    _render_area(std::move(other._render_area)),
    _clear_value_count(std::move(other._clear_value_count)),
    _clear_values(std::move(other._clear_values))
  {
  }

  /// Copy assignment operator.
  constexpr render_pass_begin_info& operator=(
    const render_pass_begin_info& other) noexcept
  {
    _next = other._next;
    _render_pass = other._render_pass;
    _framebuffer = other._framebuffer;
    _render_area = other._render_area;
    _clear_value_count = other._clear_value_count;
    _clear_values = other._clear_values;
    return *this;
  }

  /// Move assignment operator.
  constexpr render_pass_begin_info& operator=(
    render_pass_begin_info&& other) noexcept
  {
    _next = std::move(other._next);
    _render_pass = std::move(other._render_pass);
    _framebuffer = std::move(other._framebuffer);
    _render_area = std::move(other._render_area);
    _clear_value_count = std::move(other._clear_value_count);
    _clear_values = std::move(other._clear_values);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkRenderPassBeginInfo&() const
  {
    return *reinterpret_cast<const VkRenderPassBeginInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkRenderPass& render_pass()
  {
    return _render_pass;
  }

  constexpr const VkRenderPass& render_pass() const
  {
    return _render_pass;
  }

  void render_pass(VkRenderPass new_render_pass)
  {
    _render_pass = new_render_pass;
  }

  VkFramebuffer& framebuffer()
  {
    return _framebuffer;
  }

  constexpr const VkFramebuffer& framebuffer() const
  {
    return _framebuffer;
  }

  void framebuffer(VkFramebuffer new_framebuffer)
  {
    _framebuffer = new_framebuffer;
  }

  vk::rect_2d& render_area()
  {
    return _render_area;
  }

  constexpr const vk::rect_2d& render_area() const
  {
    return _render_area;
  }

  void render_area(vk::rect_2d new_render_area)
  {
    _render_area = new_render_area;
  }

  uint32_t& clear_value_count()
  {
    return _clear_value_count;
  }

  constexpr const uint32_t& clear_value_count() const
  {
    return _clear_value_count;
  }

  void clear_value_count(uint32_t new_clear_value_count)
  {
    _clear_value_count = new_clear_value_count;
  }

  const vk::clear_value* clear_values()
  {
    return _clear_values;
  }

  constexpr const vk::clear_value* clear_values() const
  {
    return _clear_values;
  }

  void clear_values(const vk::clear_value* new_clear_values)
  {
    _clear_values = new_clear_values;
  }

  template <std::size_t Count>
  void clear_values(const std::array<vk::clear_value, Count>& new_clear_values)
  {
    _clear_value_count = static_cast<uint32_t>(new_clear_values.size());
    _clear_values = new_clear_values.data();
  }

  void clear_values(const std::vector<vk::clear_value>& new_clear_values)
  {
    _clear_value_count = static_cast<uint32_t>(new_clear_values.size());
    _clear_values = new_clear_values.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::render_pass_begin_info;
  const void* _next = nullptr;
  VkRenderPass _render_pass = nullptr;
  VkFramebuffer _framebuffer = nullptr;
  vk::rect_2d _render_area = vk::rect_2d{};
  uint32_t _clear_value_count = 0;
  const vk::clear_value* _clear_values = nullptr;
};
static_assert(sizeof(render_pass_begin_info) == sizeof(::VkRenderPassBeginInfo),
              "struct and wrapper have different size!");

enum class subpass_contents
{
  /// @see VK_SUBPASS_CONTENTS_INLINE
  inline_commands = 0,
  /// @see VK_SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS
  secondary_command_buffers = 1,
};
inline void cmd_begin_render_pass(
  VkCommandBuffer command_buffer,
  const vk::render_pass_begin_info* render_pass_begin,
  vk::subpass_contents contents)
{
  vkCmdBeginRenderPass(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkRenderPassBeginInfo*>(render_pass_begin),
    static_cast<VkSubpassContents>(contents));
}
inline void cmd_next_subpass(VkCommandBuffer command_buffer,
                             vk::subpass_contents contents)
{
  vkCmdNextSubpass(static_cast<VkCommandBuffer>(command_buffer),
                   static_cast<VkSubpassContents>(contents));
}
inline void cmd_end_render_pass(VkCommandBuffer command_buffer)
{
  vkCmdEndRenderPass(static_cast<VkCommandBuffer>(command_buffer));
}
inline void cmd_execute_commands(VkCommandBuffer command_buffer,
                                 uint32_t command_buffer_count,
                                 const VkCommandBuffer* command_buffers)
{
  vkCmdExecuteCommands(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<uint32_t>(command_buffer_count),
    reinterpret_cast<const VkCommandBuffer*>(command_buffers));
}
enum class subgroup_feature_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Basic subgroup operations
  /// @see VK_SUBGROUP_FEATURE_BASIC_BIT
  basic_bit = 1 << 0,
  /// Vote subgroup operations
  /// @see VK_SUBGROUP_FEATURE_VOTE_BIT
  vote_bit = 1 << 1,
  /// Arithmetic subgroup operations
  /// @see VK_SUBGROUP_FEATURE_ARITHMETIC_BIT
  arithmetic_bit = 1 << 2,
  /// Ballot subgroup operations
  /// @see VK_SUBGROUP_FEATURE_BALLOT_BIT
  ballot_bit = 1 << 3,
  /// Shuffle subgroup operations
  /// @see VK_SUBGROUP_FEATURE_SHUFFLE_BIT
  shuffle_bit = 1 << 4,
  /// Shuffle relative subgroup operations
  /// @see VK_SUBGROUP_FEATURE_SHUFFLE_RELATIVE_BIT
  shuffle_relative_bit = 1 << 5,
  /// Clustered subgroup operations
  /// @see VK_SUBGROUP_FEATURE_CLUSTERED_BIT
  clustered_bit = 1 << 6,
  /// Quad subgroup operations
  /// @see VK_SUBGROUP_FEATURE_QUAD_BIT
  quad_bit = 1 << 7,
  /// @see VK_SUBGROUP_FEATURE_PARTITIONED_BIT_NV
  partitioned_bit_nv = 1 << 8,
};
using subgroup_feature_flags =
  shift::core::bit_field<subgroup_feature_flag, VkSubgroupFeatureFlags>;
inline constexpr subgroup_feature_flags operator|(subgroup_feature_flag lhs,
                                                  subgroup_feature_flag rhs)
{
  return subgroup_feature_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkPhysicalDeviceSubgroupProperties.
class physical_device_subgroup_properties
{
public:
  /// Default constructor.
  constexpr physical_device_subgroup_properties() = default;

  /// Constructor.
  constexpr physical_device_subgroup_properties(
    void* initial_next, uint32_t initial_subgroup_size,
    vk::shader_stage_flags initial_supported_stages,
    vk::subgroup_feature_flags initial_supported_operations,
    VkBool32 initial_quad_operations_in_all_stages) noexcept
  : _next(std::move(initial_next)),
    _subgroup_size(std::move(initial_subgroup_size)),
    _supported_stages(std::move(initial_supported_stages)),
    _supported_operations(std::move(initial_supported_operations)),
    _quad_operations_in_all_stages(
      std::move(initial_quad_operations_in_all_stages))
  {
  }

  /// Copy constructor.
  constexpr physical_device_subgroup_properties(
    const physical_device_subgroup_properties& other) noexcept
  : _next(other._next),
    _subgroup_size(other._subgroup_size),
    _supported_stages(other._supported_stages),
    _supported_operations(other._supported_operations),
    _quad_operations_in_all_stages(other._quad_operations_in_all_stages)
  {
  }

  /// Move constructor.
  constexpr physical_device_subgroup_properties(
    physical_device_subgroup_properties&& other) noexcept
  : _next(std::move(other._next)),
    _subgroup_size(std::move(other._subgroup_size)),
    _supported_stages(std::move(other._supported_stages)),
    _supported_operations(std::move(other._supported_operations)),
    _quad_operations_in_all_stages(
      std::move(other._quad_operations_in_all_stages))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_subgroup_properties& operator=(
    const physical_device_subgroup_properties& other) noexcept
  {
    _next = other._next;
    _subgroup_size = other._subgroup_size;
    _supported_stages = other._supported_stages;
    _supported_operations = other._supported_operations;
    _quad_operations_in_all_stages = other._quad_operations_in_all_stages;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_subgroup_properties& operator=(
    physical_device_subgroup_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _subgroup_size = std::move(other._subgroup_size);
    _supported_stages = std::move(other._supported_stages);
    _supported_operations = std::move(other._supported_operations);
    _quad_operations_in_all_stages =
      std::move(other._quad_operations_in_all_stages);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceSubgroupProperties&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceSubgroupProperties*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& subgroup_size()
  {
    return _subgroup_size;
  }

  constexpr const uint32_t& subgroup_size() const
  {
    return _subgroup_size;
  }

  void subgroup_size(uint32_t new_subgroup_size)
  {
    _subgroup_size = new_subgroup_size;
  }

  vk::shader_stage_flags& supported_stages()
  {
    return _supported_stages;
  }

  constexpr const vk::shader_stage_flags& supported_stages() const
  {
    return _supported_stages;
  }

  void supported_stages(vk::shader_stage_flags new_supported_stages)
  {
    _supported_stages = new_supported_stages;
  }

  vk::subgroup_feature_flags& supported_operations()
  {
    return _supported_operations;
  }

  constexpr const vk::subgroup_feature_flags& supported_operations() const
  {
    return _supported_operations;
  }

  void supported_operations(vk::subgroup_feature_flags new_supported_operations)
  {
    _supported_operations = new_supported_operations;
  }

  VkBool32& quad_operations_in_all_stages()
  {
    return _quad_operations_in_all_stages;
  }

  constexpr const VkBool32& quad_operations_in_all_stages() const
  {
    return _quad_operations_in_all_stages;
  }

  void quad_operations_in_all_stages(VkBool32 new_quad_operations_in_all_stages)
  {
    _quad_operations_in_all_stages = new_quad_operations_in_all_stages;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_subgroup_properties;
  void* _next = nullptr;
  /// The size of a subgroup for this queue.
  uint32_t _subgroup_size = 0;
  /// Bitfield of what shader stages support subgroup operations
  vk::shader_stage_flags _supported_stages = vk::shader_stage_flag::none;
  /// Bitfield of what subgroup operations are supported.
  vk::subgroup_feature_flags _supported_operations =
    vk::subgroup_feature_flag::none;
  /// Flag to specify whether quad operations are available in all stages.
  VkBool32 _quad_operations_in_all_stages = VK_FALSE;
};
static_assert(sizeof(physical_device_subgroup_properties) ==
                sizeof(::VkPhysicalDeviceSubgroupProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkBindBufferMemoryInfo.
class bind_buffer_memory_info
{
public:
  /// Default constructor.
  constexpr bind_buffer_memory_info() = default;

  /// Constructor.
  constexpr bind_buffer_memory_info(const void* initial_next,
                                    VkBuffer initial_buffer,
                                    VkDeviceMemory initial_memory,
                                    VkDeviceSize initial_memory_offset) noexcept
  : _next(std::move(initial_next)),
    _buffer(std::move(initial_buffer)),
    _memory(std::move(initial_memory)),
    _memory_offset(std::move(initial_memory_offset))
  {
  }

  /// Copy constructor.
  constexpr bind_buffer_memory_info(
    const bind_buffer_memory_info& other) noexcept
  : _next(other._next),
    _buffer(other._buffer),
    _memory(other._memory),
    _memory_offset(other._memory_offset)
  {
  }

  /// Move constructor.
  constexpr bind_buffer_memory_info(bind_buffer_memory_info&& other) noexcept
  : _next(std::move(other._next)),
    _buffer(std::move(other._buffer)),
    _memory(std::move(other._memory)),
    _memory_offset(std::move(other._memory_offset))
  {
  }

  /// Copy assignment operator.
  constexpr bind_buffer_memory_info& operator=(
    const bind_buffer_memory_info& other) noexcept
  {
    _next = other._next;
    _buffer = other._buffer;
    _memory = other._memory;
    _memory_offset = other._memory_offset;
    return *this;
  }

  /// Move assignment operator.
  constexpr bind_buffer_memory_info& operator=(
    bind_buffer_memory_info&& other) noexcept
  {
    _next = std::move(other._next);
    _buffer = std::move(other._buffer);
    _memory = std::move(other._memory);
    _memory_offset = std::move(other._memory_offset);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBindBufferMemoryInfo&() const
  {
    return *reinterpret_cast<const VkBindBufferMemoryInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

  VkDeviceMemory& memory()
  {
    return _memory;
  }

  constexpr const VkDeviceMemory& memory() const
  {
    return _memory;
  }

  void memory(VkDeviceMemory new_memory)
  {
    _memory = new_memory;
  }

  VkDeviceSize& memory_offset()
  {
    return _memory_offset;
  }

  constexpr const VkDeviceSize& memory_offset() const
  {
    return _memory_offset;
  }

  void memory_offset(VkDeviceSize new_memory_offset)
  {
    _memory_offset = new_memory_offset;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::bind_buffer_memory_info;
  const void* _next = nullptr;
  VkBuffer _buffer = nullptr;
  VkDeviceMemory _memory = nullptr;
  VkDeviceSize _memory_offset = 0;
};
static_assert(sizeof(bind_buffer_memory_info) ==
                sizeof(::VkBindBufferMemoryInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkBindImageMemoryInfo.
class bind_image_memory_info
{
public:
  /// Default constructor.
  constexpr bind_image_memory_info() = default;

  /// Constructor.
  constexpr bind_image_memory_info(const void* initial_next,
                                   VkImage initial_image,
                                   VkDeviceMemory initial_memory,
                                   VkDeviceSize initial_memory_offset) noexcept
  : _next(std::move(initial_next)),
    _image(std::move(initial_image)),
    _memory(std::move(initial_memory)),
    _memory_offset(std::move(initial_memory_offset))
  {
  }

  /// Copy constructor.
  constexpr bind_image_memory_info(const bind_image_memory_info& other) noexcept
  : _next(other._next),
    _image(other._image),
    _memory(other._memory),
    _memory_offset(other._memory_offset)
  {
  }

  /// Move constructor.
  constexpr bind_image_memory_info(bind_image_memory_info&& other) noexcept
  : _next(std::move(other._next)),
    _image(std::move(other._image)),
    _memory(std::move(other._memory)),
    _memory_offset(std::move(other._memory_offset))
  {
  }

  /// Copy assignment operator.
  constexpr bind_image_memory_info& operator=(
    const bind_image_memory_info& other) noexcept
  {
    _next = other._next;
    _image = other._image;
    _memory = other._memory;
    _memory_offset = other._memory_offset;
    return *this;
  }

  /// Move assignment operator.
  constexpr bind_image_memory_info& operator=(
    bind_image_memory_info&& other) noexcept
  {
    _next = std::move(other._next);
    _image = std::move(other._image);
    _memory = std::move(other._memory);
    _memory_offset = std::move(other._memory_offset);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBindImageMemoryInfo&() const
  {
    return *reinterpret_cast<const VkBindImageMemoryInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkImage& image()
  {
    return _image;
  }

  constexpr const VkImage& image() const
  {
    return _image;
  }

  void image(VkImage new_image)
  {
    _image = new_image;
  }

  VkDeviceMemory& memory()
  {
    return _memory;
  }

  constexpr const VkDeviceMemory& memory() const
  {
    return _memory;
  }

  void memory(VkDeviceMemory new_memory)
  {
    _memory = new_memory;
  }

  VkDeviceSize& memory_offset()
  {
    return _memory_offset;
  }

  constexpr const VkDeviceSize& memory_offset() const
  {
    return _memory_offset;
  }

  void memory_offset(VkDeviceSize new_memory_offset)
  {
    _memory_offset = new_memory_offset;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::bind_image_memory_info;
  const void* _next = nullptr;
  VkImage _image = nullptr;
  VkDeviceMemory _memory = nullptr;
  VkDeviceSize _memory_offset = 0;
};
static_assert(sizeof(bind_image_memory_info) == sizeof(::VkBindImageMemoryInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDevice16BitStorageFeatures.
class physical_device_16_bit_storage_features
{
public:
  /// Default constructor.
  constexpr physical_device_16_bit_storage_features() = default;

  /// Constructor.
  constexpr physical_device_16_bit_storage_features(
    void* initial_next, VkBool32 initial_storage_buffer_16_bit_access,
    VkBool32 initial_uniform_and_storage_buffer_16_bit_access,
    VkBool32 initial_storage_push_constant_16,
    VkBool32 initial_storage_input_output_16) noexcept
  : _next(std::move(initial_next)),
    _storage_buffer_16_bit_access(
      std::move(initial_storage_buffer_16_bit_access)),
    _uniform_and_storage_buffer_16_bit_access(
      std::move(initial_uniform_and_storage_buffer_16_bit_access)),
    _storage_push_constant_16(std::move(initial_storage_push_constant_16)),
    _storage_input_output_16(std::move(initial_storage_input_output_16))
  {
  }

  /// Copy constructor.
  constexpr physical_device_16_bit_storage_features(
    const physical_device_16_bit_storage_features& other) noexcept
  : _next(other._next),
    _storage_buffer_16_bit_access(other._storage_buffer_16_bit_access),
    _uniform_and_storage_buffer_16_bit_access(
      other._uniform_and_storage_buffer_16_bit_access),
    _storage_push_constant_16(other._storage_push_constant_16),
    _storage_input_output_16(other._storage_input_output_16)
  {
  }

  /// Move constructor.
  constexpr physical_device_16_bit_storage_features(
    physical_device_16_bit_storage_features&& other) noexcept
  : _next(std::move(other._next)),
    _storage_buffer_16_bit_access(
      std::move(other._storage_buffer_16_bit_access)),
    _uniform_and_storage_buffer_16_bit_access(
      std::move(other._uniform_and_storage_buffer_16_bit_access)),
    _storage_push_constant_16(std::move(other._storage_push_constant_16)),
    _storage_input_output_16(std::move(other._storage_input_output_16))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_16_bit_storage_features& operator=(
    const physical_device_16_bit_storage_features& other) noexcept
  {
    _next = other._next;
    _storage_buffer_16_bit_access = other._storage_buffer_16_bit_access;
    _uniform_and_storage_buffer_16_bit_access =
      other._uniform_and_storage_buffer_16_bit_access;
    _storage_push_constant_16 = other._storage_push_constant_16;
    _storage_input_output_16 = other._storage_input_output_16;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_16_bit_storage_features& operator=(
    physical_device_16_bit_storage_features&& other) noexcept
  {
    _next = std::move(other._next);
    _storage_buffer_16_bit_access =
      std::move(other._storage_buffer_16_bit_access);
    _uniform_and_storage_buffer_16_bit_access =
      std::move(other._uniform_and_storage_buffer_16_bit_access);
    _storage_push_constant_16 = std::move(other._storage_push_constant_16);
    _storage_input_output_16 = std::move(other._storage_input_output_16);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDevice16BitStorageFeatures&() const
  {
    return *reinterpret_cast<const VkPhysicalDevice16BitStorageFeatures*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& storage_buffer_16_bit_access()
  {
    return _storage_buffer_16_bit_access;
  }

  constexpr const VkBool32& storage_buffer_16_bit_access() const
  {
    return _storage_buffer_16_bit_access;
  }

  void storage_buffer_16_bit_access(VkBool32 new_storage_buffer_16_bit_access)
  {
    _storage_buffer_16_bit_access = new_storage_buffer_16_bit_access;
  }

  VkBool32& uniform_and_storage_buffer_16_bit_access()
  {
    return _uniform_and_storage_buffer_16_bit_access;
  }

  constexpr const VkBool32& uniform_and_storage_buffer_16_bit_access() const
  {
    return _uniform_and_storage_buffer_16_bit_access;
  }

  void uniform_and_storage_buffer_16_bit_access(
    VkBool32 new_uniform_and_storage_buffer_16_bit_access)
  {
    _uniform_and_storage_buffer_16_bit_access =
      new_uniform_and_storage_buffer_16_bit_access;
  }

  VkBool32& storage_push_constant_16()
  {
    return _storage_push_constant_16;
  }

  constexpr const VkBool32& storage_push_constant_16() const
  {
    return _storage_push_constant_16;
  }

  void storage_push_constant_16(VkBool32 new_storage_push_constant_16)
  {
    _storage_push_constant_16 = new_storage_push_constant_16;
  }

  VkBool32& storage_input_output_16()
  {
    return _storage_input_output_16;
  }

  constexpr const VkBool32& storage_input_output_16() const
  {
    return _storage_input_output_16;
  }

  void storage_input_output_16(VkBool32 new_storage_input_output_16)
  {
    _storage_input_output_16 = new_storage_input_output_16;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_16_bit_storage_features;
  void* _next = nullptr;
  /// 16-bit integer/floating-point variables supported in BufferBlock
  VkBool32 _storage_buffer_16_bit_access = VK_FALSE;
  /// 16-bit integer/floating-point variables supported in BufferBlock and Block
  VkBool32 _uniform_and_storage_buffer_16_bit_access = VK_FALSE;
  /// 16-bit integer/floating-point variables supported in PushConstant
  VkBool32 _storage_push_constant_16 = VK_FALSE;
  /// 16-bit integer/floating-point variables supported in shader inputs and
  /// outputs
  VkBool32 _storage_input_output_16 = VK_FALSE;
};
static_assert(sizeof(physical_device_16_bit_storage_features) ==
                sizeof(::VkPhysicalDevice16BitStorageFeatures),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkMemoryDedicatedRequirements.
class memory_dedicated_requirements
{
public:
  /// Default constructor.
  constexpr memory_dedicated_requirements() = default;

  /// Constructor.
  constexpr memory_dedicated_requirements(
    void* initial_next, VkBool32 initial_prefers_dedicated_allocation,
    VkBool32 initial_requires_dedicated_allocation) noexcept
  : _next(std::move(initial_next)),
    _prefers_dedicated_allocation(
      std::move(initial_prefers_dedicated_allocation)),
    _requires_dedicated_allocation(
      std::move(initial_requires_dedicated_allocation))
  {
  }

  /// Copy constructor.
  constexpr memory_dedicated_requirements(
    const memory_dedicated_requirements& other) noexcept
  : _next(other._next),
    _prefers_dedicated_allocation(other._prefers_dedicated_allocation),
    _requires_dedicated_allocation(other._requires_dedicated_allocation)
  {
  }

  /// Move constructor.
  constexpr memory_dedicated_requirements(
    memory_dedicated_requirements&& other) noexcept
  : _next(std::move(other._next)),
    _prefers_dedicated_allocation(
      std::move(other._prefers_dedicated_allocation)),
    _requires_dedicated_allocation(
      std::move(other._requires_dedicated_allocation))
  {
  }

  /// Copy assignment operator.
  constexpr memory_dedicated_requirements& operator=(
    const memory_dedicated_requirements& other) noexcept
  {
    _next = other._next;
    _prefers_dedicated_allocation = other._prefers_dedicated_allocation;
    _requires_dedicated_allocation = other._requires_dedicated_allocation;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_dedicated_requirements& operator=(
    memory_dedicated_requirements&& other) noexcept
  {
    _next = std::move(other._next);
    _prefers_dedicated_allocation =
      std::move(other._prefers_dedicated_allocation);
    _requires_dedicated_allocation =
      std::move(other._requires_dedicated_allocation);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryDedicatedRequirements&() const
  {
    return *reinterpret_cast<const VkMemoryDedicatedRequirements*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& prefers_dedicated_allocation()
  {
    return _prefers_dedicated_allocation;
  }

  constexpr const VkBool32& prefers_dedicated_allocation() const
  {
    return _prefers_dedicated_allocation;
  }

  void prefers_dedicated_allocation(VkBool32 new_prefers_dedicated_allocation)
  {
    _prefers_dedicated_allocation = new_prefers_dedicated_allocation;
  }

  VkBool32& requires_dedicated_allocation()
  {
    return _requires_dedicated_allocation;
  }

  constexpr const VkBool32& requires_dedicated_allocation() const
  {
    return _requires_dedicated_allocation;
  }

  void requires_dedicated_allocation(VkBool32 new_requires_dedicated_allocation)
  {
    _requires_dedicated_allocation = new_requires_dedicated_allocation;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_dedicated_requirements;
  void* _next = nullptr;
  VkBool32 _prefers_dedicated_allocation = VK_FALSE;
  VkBool32 _requires_dedicated_allocation = VK_FALSE;
};
static_assert(sizeof(memory_dedicated_requirements) ==
                sizeof(::VkMemoryDedicatedRequirements),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkMemoryDedicatedAllocateInfo.
class memory_dedicated_allocate_info
{
public:
  /// Default constructor.
  constexpr memory_dedicated_allocate_info() = default;

  /// Constructor.
  constexpr memory_dedicated_allocate_info(const void* initial_next,
                                           VkImage initial_image,
                                           VkBuffer initial_buffer) noexcept
  : _next(std::move(initial_next)),
    _image(std::move(initial_image)),
    _buffer(std::move(initial_buffer))
  {
  }

  /// Copy constructor.
  constexpr memory_dedicated_allocate_info(
    const memory_dedicated_allocate_info& other) noexcept
  : _next(other._next), _image(other._image), _buffer(other._buffer)
  {
  }

  /// Move constructor.
  constexpr memory_dedicated_allocate_info(
    memory_dedicated_allocate_info&& other) noexcept
  : _next(std::move(other._next)),
    _image(std::move(other._image)),
    _buffer(std::move(other._buffer))
  {
  }

  /// Copy assignment operator.
  constexpr memory_dedicated_allocate_info& operator=(
    const memory_dedicated_allocate_info& other) noexcept
  {
    _next = other._next;
    _image = other._image;
    _buffer = other._buffer;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_dedicated_allocate_info& operator=(
    memory_dedicated_allocate_info&& other) noexcept
  {
    _next = std::move(other._next);
    _image = std::move(other._image);
    _buffer = std::move(other._buffer);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryDedicatedAllocateInfo&() const
  {
    return *reinterpret_cast<const VkMemoryDedicatedAllocateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkImage& image()
  {
    return _image;
  }

  constexpr const VkImage& image() const
  {
    return _image;
  }

  void image(VkImage new_image)
  {
    _image = new_image;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_dedicated_allocate_info;
  const void* _next = nullptr;
  /// Image that this allocation will be bound to
  VkImage _image = nullptr;
  /// Buffer that this allocation will be bound to
  VkBuffer _buffer = nullptr;
};
static_assert(sizeof(memory_dedicated_allocate_info) ==
                sizeof(::VkMemoryDedicatedAllocateInfo),
              "struct and wrapper have different size!");

enum class peer_memory_feature_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Can read with vkCmdCopy commands
  /// @see VK_PEER_MEMORY_FEATURE_COPY_SRC_BIT
  copy_src_bit = 1 << 0,
  /// Can write with vkCmdCopy commands
  /// @see VK_PEER_MEMORY_FEATURE_COPY_DST_BIT
  copy_dst_bit = 1 << 1,
  /// Can read with any access type/command
  /// @see VK_PEER_MEMORY_FEATURE_GENERIC_SRC_BIT
  generic_src_bit = 1 << 2,
  /// Can write with and access type/command
  /// @see VK_PEER_MEMORY_FEATURE_GENERIC_DST_BIT
  generic_dst_bit = 1 << 3,
};
using peer_memory_feature_flags =
  shift::core::bit_field<peer_memory_feature_flag, VkPeerMemoryFeatureFlags>;
inline constexpr peer_memory_feature_flags operator|(
  peer_memory_feature_flag lhs, peer_memory_feature_flag rhs)
{
  return peer_memory_feature_flags{lhs} | rhs;
}
enum class memory_allocate_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Force allocation on specific devices
  /// @see VK_MEMORY_ALLOCATE_DEVICE_MASK_BIT
  device_mask_bit = 1 << 0,
};
using memory_allocate_flags =
  shift::core::bit_field<memory_allocate_flag, VkMemoryAllocateFlags>;
inline constexpr memory_allocate_flags operator|(memory_allocate_flag lhs,
                                                 memory_allocate_flag rhs)
{
  return memory_allocate_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkMemoryAllocateFlagsInfo.
class memory_allocate_flags_info
{
public:
  /// Default constructor.
  constexpr memory_allocate_flags_info() = default;

  /// Constructor.
  constexpr memory_allocate_flags_info(const void* initial_next,
                                       vk::memory_allocate_flags initial_flags,
                                       uint32_t initial_device_mask) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _device_mask(std::move(initial_device_mask))
  {
  }

  /// Copy constructor.
  constexpr memory_allocate_flags_info(
    const memory_allocate_flags_info& other) noexcept
  : _next(other._next), _flags(other._flags), _device_mask(other._device_mask)
  {
  }

  /// Move constructor.
  constexpr memory_allocate_flags_info(
    memory_allocate_flags_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _device_mask(std::move(other._device_mask))
  {
  }

  /// Copy assignment operator.
  constexpr memory_allocate_flags_info& operator=(
    const memory_allocate_flags_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _device_mask = other._device_mask;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_allocate_flags_info& operator=(
    memory_allocate_flags_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _device_mask = std::move(other._device_mask);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryAllocateFlagsInfo&() const
  {
    return *reinterpret_cast<const VkMemoryAllocateFlagsInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::memory_allocate_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::memory_allocate_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::memory_allocate_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& device_mask()
  {
    return _device_mask;
  }

  constexpr const uint32_t& device_mask() const
  {
    return _device_mask;
  }

  void device_mask(uint32_t new_device_mask)
  {
    _device_mask = new_device_mask;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_allocate_flags_info;
  const void* _next = nullptr;
  vk::memory_allocate_flags _flags = vk::memory_allocate_flag::none;
  uint32_t _device_mask = 0;
};
static_assert(sizeof(memory_allocate_flags_info) ==
                sizeof(::VkMemoryAllocateFlagsInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceGroupRenderPassBeginInfo.
class device_group_render_pass_begin_info
{
public:
  /// Default constructor.
  constexpr device_group_render_pass_begin_info() = default;

  /// Constructor.
  constexpr device_group_render_pass_begin_info(
    const void* initial_next, uint32_t initial_device_mask,
    uint32_t initial_device_render_area_count,
    const vk::rect_2d* initial_device_render_areas) noexcept
  : _next(std::move(initial_next)),
    _device_mask(std::move(initial_device_mask)),
    _device_render_area_count(std::move(initial_device_render_area_count)),
    _device_render_areas(std::move(initial_device_render_areas))
  {
  }

  /// Copy constructor.
  constexpr device_group_render_pass_begin_info(
    const device_group_render_pass_begin_info& other) noexcept
  : _next(other._next),
    _device_mask(other._device_mask),
    _device_render_area_count(other._device_render_area_count),
    _device_render_areas(other._device_render_areas)
  {
  }

  /// Move constructor.
  constexpr device_group_render_pass_begin_info(
    device_group_render_pass_begin_info&& other) noexcept
  : _next(std::move(other._next)),
    _device_mask(std::move(other._device_mask)),
    _device_render_area_count(std::move(other._device_render_area_count)),
    _device_render_areas(std::move(other._device_render_areas))
  {
  }

  /// Copy assignment operator.
  constexpr device_group_render_pass_begin_info& operator=(
    const device_group_render_pass_begin_info& other) noexcept
  {
    _next = other._next;
    _device_mask = other._device_mask;
    _device_render_area_count = other._device_render_area_count;
    _device_render_areas = other._device_render_areas;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_group_render_pass_begin_info& operator=(
    device_group_render_pass_begin_info&& other) noexcept
  {
    _next = std::move(other._next);
    _device_mask = std::move(other._device_mask);
    _device_render_area_count = std::move(other._device_render_area_count);
    _device_render_areas = std::move(other._device_render_areas);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGroupRenderPassBeginInfo&() const
  {
    return *reinterpret_cast<const VkDeviceGroupRenderPassBeginInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& device_mask()
  {
    return _device_mask;
  }

  constexpr const uint32_t& device_mask() const
  {
    return _device_mask;
  }

  void device_mask(uint32_t new_device_mask)
  {
    _device_mask = new_device_mask;
  }

  uint32_t& device_render_area_count()
  {
    return _device_render_area_count;
  }

  constexpr const uint32_t& device_render_area_count() const
  {
    return _device_render_area_count;
  }

  void device_render_area_count(uint32_t new_device_render_area_count)
  {
    _device_render_area_count = new_device_render_area_count;
  }

  const vk::rect_2d* device_render_areas()
  {
    return _device_render_areas;
  }

  constexpr const vk::rect_2d* device_render_areas() const
  {
    return _device_render_areas;
  }

  void device_render_areas(const vk::rect_2d* new_device_render_areas)
  {
    _device_render_areas = new_device_render_areas;
  }

  template <std::size_t Count>
  void device_render_areas(
    const std::array<vk::rect_2d, Count>& new_device_render_areas)
  {
    _device_render_area_count =
      static_cast<uint32_t>(new_device_render_areas.size());
    _device_render_areas = new_device_render_areas.data();
  }

  void device_render_areas(
    const std::vector<vk::rect_2d>& new_device_render_areas)
  {
    _device_render_area_count =
      static_cast<uint32_t>(new_device_render_areas.size());
    _device_render_areas = new_device_render_areas.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_group_render_pass_begin_info;
  const void* _next = nullptr;
  uint32_t _device_mask = 0;
  uint32_t _device_render_area_count = 0;
  const vk::rect_2d* _device_render_areas = nullptr;
};
static_assert(sizeof(device_group_render_pass_begin_info) ==
                sizeof(::VkDeviceGroupRenderPassBeginInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceGroupCommandBufferBeginInfo.
class device_group_command_buffer_begin_info
{
public:
  /// Default constructor.
  constexpr device_group_command_buffer_begin_info() = default;

  /// Constructor.
  constexpr device_group_command_buffer_begin_info(
    const void* initial_next, uint32_t initial_device_mask) noexcept
  : _next(std::move(initial_next)), _device_mask(std::move(initial_device_mask))
  {
  }

  /// Copy constructor.
  constexpr device_group_command_buffer_begin_info(
    const device_group_command_buffer_begin_info& other) noexcept
  : _next(other._next), _device_mask(other._device_mask)
  {
  }

  /// Move constructor.
  constexpr device_group_command_buffer_begin_info(
    device_group_command_buffer_begin_info&& other) noexcept
  : _next(std::move(other._next)), _device_mask(std::move(other._device_mask))
  {
  }

  /// Copy assignment operator.
  constexpr device_group_command_buffer_begin_info& operator=(
    const device_group_command_buffer_begin_info& other) noexcept
  {
    _next = other._next;
    _device_mask = other._device_mask;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_group_command_buffer_begin_info& operator=(
    device_group_command_buffer_begin_info&& other) noexcept
  {
    _next = std::move(other._next);
    _device_mask = std::move(other._device_mask);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGroupCommandBufferBeginInfo&() const
  {
    return *reinterpret_cast<const VkDeviceGroupCommandBufferBeginInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& device_mask()
  {
    return _device_mask;
  }

  constexpr const uint32_t& device_mask() const
  {
    return _device_mask;
  }

  void device_mask(uint32_t new_device_mask)
  {
    _device_mask = new_device_mask;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_group_command_buffer_begin_info;
  const void* _next = nullptr;
  uint32_t _device_mask = 0;
};
static_assert(sizeof(device_group_command_buffer_begin_info) ==
                sizeof(::VkDeviceGroupCommandBufferBeginInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceGroupSubmitInfo.
class device_group_submit_info
{
public:
  /// Default constructor.
  constexpr device_group_submit_info() = default;

  /// Constructor.
  constexpr device_group_submit_info(
    const void* initial_next, uint32_t initial_wait_semaphore_count,
    const uint32_t* initial_wait_semaphore_device_indices,
    uint32_t initial_command_buffer_count,
    const uint32_t* initial_command_buffer_device_masks,
    uint32_t initial_signal_semaphore_count,
    const uint32_t* initial_signal_semaphore_device_indices) noexcept
  : _next(std::move(initial_next)),
    _wait_semaphore_count(std::move(initial_wait_semaphore_count)),
    _wait_semaphore_device_indices(
      std::move(initial_wait_semaphore_device_indices)),
    _command_buffer_count(std::move(initial_command_buffer_count)),
    _command_buffer_device_masks(
      std::move(initial_command_buffer_device_masks)),
    _signal_semaphore_count(std::move(initial_signal_semaphore_count)),
    _signal_semaphore_device_indices(
      std::move(initial_signal_semaphore_device_indices))
  {
  }

  /// Copy constructor.
  constexpr device_group_submit_info(
    const device_group_submit_info& other) noexcept
  : _next(other._next),
    _wait_semaphore_count(other._wait_semaphore_count),
    _wait_semaphore_device_indices(other._wait_semaphore_device_indices),
    _command_buffer_count(other._command_buffer_count),
    _command_buffer_device_masks(other._command_buffer_device_masks),
    _signal_semaphore_count(other._signal_semaphore_count),
    _signal_semaphore_device_indices(other._signal_semaphore_device_indices)
  {
  }

  /// Move constructor.
  constexpr device_group_submit_info(device_group_submit_info&& other) noexcept
  : _next(std::move(other._next)),
    _wait_semaphore_count(std::move(other._wait_semaphore_count)),
    _wait_semaphore_device_indices(
      std::move(other._wait_semaphore_device_indices)),
    _command_buffer_count(std::move(other._command_buffer_count)),
    _command_buffer_device_masks(std::move(other._command_buffer_device_masks)),
    _signal_semaphore_count(std::move(other._signal_semaphore_count)),
    _signal_semaphore_device_indices(
      std::move(other._signal_semaphore_device_indices))
  {
  }

  /// Copy assignment operator.
  constexpr device_group_submit_info& operator=(
    const device_group_submit_info& other) noexcept
  {
    _next = other._next;
    _wait_semaphore_count = other._wait_semaphore_count;
    _wait_semaphore_device_indices = other._wait_semaphore_device_indices;
    _command_buffer_count = other._command_buffer_count;
    _command_buffer_device_masks = other._command_buffer_device_masks;
    _signal_semaphore_count = other._signal_semaphore_count;
    _signal_semaphore_device_indices = other._signal_semaphore_device_indices;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_group_submit_info& operator=(
    device_group_submit_info&& other) noexcept
  {
    _next = std::move(other._next);
    _wait_semaphore_count = std::move(other._wait_semaphore_count);
    _wait_semaphore_device_indices =
      std::move(other._wait_semaphore_device_indices);
    _command_buffer_count = std::move(other._command_buffer_count);
    _command_buffer_device_masks =
      std::move(other._command_buffer_device_masks);
    _signal_semaphore_count = std::move(other._signal_semaphore_count);
    _signal_semaphore_device_indices =
      std::move(other._signal_semaphore_device_indices);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGroupSubmitInfo&() const
  {
    return *reinterpret_cast<const VkDeviceGroupSubmitInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& wait_semaphore_count()
  {
    return _wait_semaphore_count;
  }

  constexpr const uint32_t& wait_semaphore_count() const
  {
    return _wait_semaphore_count;
  }

  void wait_semaphore_count(uint32_t new_wait_semaphore_count)
  {
    _wait_semaphore_count = new_wait_semaphore_count;
  }

  const uint32_t* wait_semaphore_device_indices()
  {
    return _wait_semaphore_device_indices;
  }

  constexpr const uint32_t* wait_semaphore_device_indices() const
  {
    return _wait_semaphore_device_indices;
  }

  void wait_semaphore_device_indices(
    const uint32_t* new_wait_semaphore_device_indices)
  {
    _wait_semaphore_device_indices = new_wait_semaphore_device_indices;
  }

  template <std::size_t Count>
  void wait_semaphore_device_indices(
    const std::array<uint32_t, Count>& new_wait_semaphore_device_indices)
  {
    _wait_semaphore_count =
      static_cast<uint32_t>(new_wait_semaphore_device_indices.size());
    _wait_semaphore_device_indices = new_wait_semaphore_device_indices.data();
  }

  void wait_semaphore_device_indices(
    const std::vector<uint32_t>& new_wait_semaphore_device_indices)
  {
    _wait_semaphore_count =
      static_cast<uint32_t>(new_wait_semaphore_device_indices.size());
    _wait_semaphore_device_indices = new_wait_semaphore_device_indices.data();
  }

  uint32_t& command_buffer_count()
  {
    return _command_buffer_count;
  }

  constexpr const uint32_t& command_buffer_count() const
  {
    return _command_buffer_count;
  }

  void command_buffer_count(uint32_t new_command_buffer_count)
  {
    _command_buffer_count = new_command_buffer_count;
  }

  const uint32_t* command_buffer_device_masks()
  {
    return _command_buffer_device_masks;
  }

  constexpr const uint32_t* command_buffer_device_masks() const
  {
    return _command_buffer_device_masks;
  }

  void command_buffer_device_masks(
    const uint32_t* new_command_buffer_device_masks)
  {
    _command_buffer_device_masks = new_command_buffer_device_masks;
  }

  template <std::size_t Count>
  void command_buffer_device_masks(
    const std::array<uint32_t, Count>& new_command_buffer_device_masks)
  {
    _command_buffer_count =
      static_cast<uint32_t>(new_command_buffer_device_masks.size());
    _command_buffer_device_masks = new_command_buffer_device_masks.data();
  }

  void command_buffer_device_masks(
    const std::vector<uint32_t>& new_command_buffer_device_masks)
  {
    _command_buffer_count =
      static_cast<uint32_t>(new_command_buffer_device_masks.size());
    _command_buffer_device_masks = new_command_buffer_device_masks.data();
  }

  uint32_t& signal_semaphore_count()
  {
    return _signal_semaphore_count;
  }

  constexpr const uint32_t& signal_semaphore_count() const
  {
    return _signal_semaphore_count;
  }

  void signal_semaphore_count(uint32_t new_signal_semaphore_count)
  {
    _signal_semaphore_count = new_signal_semaphore_count;
  }

  const uint32_t* signal_semaphore_device_indices()
  {
    return _signal_semaphore_device_indices;
  }

  constexpr const uint32_t* signal_semaphore_device_indices() const
  {
    return _signal_semaphore_device_indices;
  }

  void signal_semaphore_device_indices(
    const uint32_t* new_signal_semaphore_device_indices)
  {
    _signal_semaphore_device_indices = new_signal_semaphore_device_indices;
  }

  template <std::size_t Count>
  void signal_semaphore_device_indices(
    const std::array<uint32_t, Count>& new_signal_semaphore_device_indices)
  {
    _signal_semaphore_count =
      static_cast<uint32_t>(new_signal_semaphore_device_indices.size());
    _signal_semaphore_device_indices =
      new_signal_semaphore_device_indices.data();
  }

  void signal_semaphore_device_indices(
    const std::vector<uint32_t>& new_signal_semaphore_device_indices)
  {
    _signal_semaphore_count =
      static_cast<uint32_t>(new_signal_semaphore_device_indices.size());
    _signal_semaphore_device_indices =
      new_signal_semaphore_device_indices.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_group_submit_info;
  const void* _next = nullptr;
  uint32_t _wait_semaphore_count = 0;
  const uint32_t* _wait_semaphore_device_indices = nullptr;
  uint32_t _command_buffer_count = 0;
  const uint32_t* _command_buffer_device_masks = nullptr;
  uint32_t _signal_semaphore_count = 0;
  const uint32_t* _signal_semaphore_device_indices = nullptr;
};
static_assert(sizeof(device_group_submit_info) ==
                sizeof(::VkDeviceGroupSubmitInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceGroupBindSparseInfo.
class device_group_bind_sparse_info
{
public:
  /// Default constructor.
  constexpr device_group_bind_sparse_info() = default;

  /// Constructor.
  constexpr device_group_bind_sparse_info(
    const void* initial_next, uint32_t initial_resource_device_index,
    uint32_t initial_memory_device_index) noexcept
  : _next(std::move(initial_next)),
    _resource_device_index(std::move(initial_resource_device_index)),
    _memory_device_index(std::move(initial_memory_device_index))
  {
  }

  /// Copy constructor.
  constexpr device_group_bind_sparse_info(
    const device_group_bind_sparse_info& other) noexcept
  : _next(other._next),
    _resource_device_index(other._resource_device_index),
    _memory_device_index(other._memory_device_index)
  {
  }

  /// Move constructor.
  constexpr device_group_bind_sparse_info(
    device_group_bind_sparse_info&& other) noexcept
  : _next(std::move(other._next)),
    _resource_device_index(std::move(other._resource_device_index)),
    _memory_device_index(std::move(other._memory_device_index))
  {
  }

  /// Copy assignment operator.
  constexpr device_group_bind_sparse_info& operator=(
    const device_group_bind_sparse_info& other) noexcept
  {
    _next = other._next;
    _resource_device_index = other._resource_device_index;
    _memory_device_index = other._memory_device_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_group_bind_sparse_info& operator=(
    device_group_bind_sparse_info&& other) noexcept
  {
    _next = std::move(other._next);
    _resource_device_index = std::move(other._resource_device_index);
    _memory_device_index = std::move(other._memory_device_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGroupBindSparseInfo&() const
  {
    return *reinterpret_cast<const VkDeviceGroupBindSparseInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& resource_device_index()
  {
    return _resource_device_index;
  }

  constexpr const uint32_t& resource_device_index() const
  {
    return _resource_device_index;
  }

  void resource_device_index(uint32_t new_resource_device_index)
  {
    _resource_device_index = new_resource_device_index;
  }

  uint32_t& memory_device_index()
  {
    return _memory_device_index;
  }

  constexpr const uint32_t& memory_device_index() const
  {
    return _memory_device_index;
  }

  void memory_device_index(uint32_t new_memory_device_index)
  {
    _memory_device_index = new_memory_device_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_group_bind_sparse_info;
  const void* _next = nullptr;
  uint32_t _resource_device_index = 0;
  uint32_t _memory_device_index = 0;
};
static_assert(sizeof(device_group_bind_sparse_info) ==
                sizeof(::VkDeviceGroupBindSparseInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkBindBufferMemoryDeviceGroupInfo.
class bind_buffer_memory_device_group_info
{
public:
  /// Default constructor.
  constexpr bind_buffer_memory_device_group_info() = default;

  /// Constructor.
  constexpr bind_buffer_memory_device_group_info(
    const void* initial_next, uint32_t initial_device_index_count,
    const uint32_t* initial_device_indices) noexcept
  : _next(std::move(initial_next)),
    _device_index_count(std::move(initial_device_index_count)),
    _device_indices(std::move(initial_device_indices))
  {
  }

  /// Copy constructor.
  constexpr bind_buffer_memory_device_group_info(
    const bind_buffer_memory_device_group_info& other) noexcept
  : _next(other._next),
    _device_index_count(other._device_index_count),
    _device_indices(other._device_indices)
  {
  }

  /// Move constructor.
  constexpr bind_buffer_memory_device_group_info(
    bind_buffer_memory_device_group_info&& other) noexcept
  : _next(std::move(other._next)),
    _device_index_count(std::move(other._device_index_count)),
    _device_indices(std::move(other._device_indices))
  {
  }

  /// Copy assignment operator.
  constexpr bind_buffer_memory_device_group_info& operator=(
    const bind_buffer_memory_device_group_info& other) noexcept
  {
    _next = other._next;
    _device_index_count = other._device_index_count;
    _device_indices = other._device_indices;
    return *this;
  }

  /// Move assignment operator.
  constexpr bind_buffer_memory_device_group_info& operator=(
    bind_buffer_memory_device_group_info&& other) noexcept
  {
    _next = std::move(other._next);
    _device_index_count = std::move(other._device_index_count);
    _device_indices = std::move(other._device_indices);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBindBufferMemoryDeviceGroupInfo&() const
  {
    return *reinterpret_cast<const VkBindBufferMemoryDeviceGroupInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& device_index_count()
  {
    return _device_index_count;
  }

  constexpr const uint32_t& device_index_count() const
  {
    return _device_index_count;
  }

  void device_index_count(uint32_t new_device_index_count)
  {
    _device_index_count = new_device_index_count;
  }

  const uint32_t* device_indices()
  {
    return _device_indices;
  }

  constexpr const uint32_t* device_indices() const
  {
    return _device_indices;
  }

  void device_indices(const uint32_t* new_device_indices)
  {
    _device_indices = new_device_indices;
  }

  template <std::size_t Count>
  void device_indices(const std::array<uint32_t, Count>& new_device_indices)
  {
    _device_index_count = static_cast<uint32_t>(new_device_indices.size());
    _device_indices = new_device_indices.data();
  }

  void device_indices(const std::vector<uint32_t>& new_device_indices)
  {
    _device_index_count = static_cast<uint32_t>(new_device_indices.size());
    _device_indices = new_device_indices.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::bind_buffer_memory_device_group_info;
  const void* _next = nullptr;
  uint32_t _device_index_count = 0;
  const uint32_t* _device_indices = nullptr;
};
static_assert(sizeof(bind_buffer_memory_device_group_info) ==
                sizeof(::VkBindBufferMemoryDeviceGroupInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkBindImageMemoryDeviceGroupInfo.
class bind_image_memory_device_group_info
{
public:
  /// Default constructor.
  constexpr bind_image_memory_device_group_info() = default;

  /// Constructor.
  constexpr bind_image_memory_device_group_info(
    const void* initial_next, uint32_t initial_device_index_count,
    const uint32_t* initial_device_indices,
    uint32_t initial_split_instance_bind_region_count,
    const vk::rect_2d* initial_split_instance_bind_regions) noexcept
  : _next(std::move(initial_next)),
    _device_index_count(std::move(initial_device_index_count)),
    _device_indices(std::move(initial_device_indices)),
    _split_instance_bind_region_count(
      std::move(initial_split_instance_bind_region_count)),
    _split_instance_bind_regions(std::move(initial_split_instance_bind_regions))
  {
  }

  /// Copy constructor.
  constexpr bind_image_memory_device_group_info(
    const bind_image_memory_device_group_info& other) noexcept
  : _next(other._next),
    _device_index_count(other._device_index_count),
    _device_indices(other._device_indices),
    _split_instance_bind_region_count(other._split_instance_bind_region_count),
    _split_instance_bind_regions(other._split_instance_bind_regions)
  {
  }

  /// Move constructor.
  constexpr bind_image_memory_device_group_info(
    bind_image_memory_device_group_info&& other) noexcept
  : _next(std::move(other._next)),
    _device_index_count(std::move(other._device_index_count)),
    _device_indices(std::move(other._device_indices)),
    _split_instance_bind_region_count(
      std::move(other._split_instance_bind_region_count)),
    _split_instance_bind_regions(std::move(other._split_instance_bind_regions))
  {
  }

  /// Copy assignment operator.
  constexpr bind_image_memory_device_group_info& operator=(
    const bind_image_memory_device_group_info& other) noexcept
  {
    _next = other._next;
    _device_index_count = other._device_index_count;
    _device_indices = other._device_indices;
    _split_instance_bind_region_count = other._split_instance_bind_region_count;
    _split_instance_bind_regions = other._split_instance_bind_regions;
    return *this;
  }

  /// Move assignment operator.
  constexpr bind_image_memory_device_group_info& operator=(
    bind_image_memory_device_group_info&& other) noexcept
  {
    _next = std::move(other._next);
    _device_index_count = std::move(other._device_index_count);
    _device_indices = std::move(other._device_indices);
    _split_instance_bind_region_count =
      std::move(other._split_instance_bind_region_count);
    _split_instance_bind_regions =
      std::move(other._split_instance_bind_regions);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBindImageMemoryDeviceGroupInfo&() const
  {
    return *reinterpret_cast<const VkBindImageMemoryDeviceGroupInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& device_index_count()
  {
    return _device_index_count;
  }

  constexpr const uint32_t& device_index_count() const
  {
    return _device_index_count;
  }

  void device_index_count(uint32_t new_device_index_count)
  {
    _device_index_count = new_device_index_count;
  }

  const uint32_t* device_indices()
  {
    return _device_indices;
  }

  constexpr const uint32_t* device_indices() const
  {
    return _device_indices;
  }

  void device_indices(const uint32_t* new_device_indices)
  {
    _device_indices = new_device_indices;
  }

  template <std::size_t Count>
  void device_indices(const std::array<uint32_t, Count>& new_device_indices)
  {
    _device_index_count = static_cast<uint32_t>(new_device_indices.size());
    _device_indices = new_device_indices.data();
  }

  void device_indices(const std::vector<uint32_t>& new_device_indices)
  {
    _device_index_count = static_cast<uint32_t>(new_device_indices.size());
    _device_indices = new_device_indices.data();
  }

  uint32_t& split_instance_bind_region_count()
  {
    return _split_instance_bind_region_count;
  }

  constexpr const uint32_t& split_instance_bind_region_count() const
  {
    return _split_instance_bind_region_count;
  }

  void split_instance_bind_region_count(
    uint32_t new_split_instance_bind_region_count)
  {
    _split_instance_bind_region_count = new_split_instance_bind_region_count;
  }

  const vk::rect_2d* split_instance_bind_regions()
  {
    return _split_instance_bind_regions;
  }

  constexpr const vk::rect_2d* split_instance_bind_regions() const
  {
    return _split_instance_bind_regions;
  }

  void split_instance_bind_regions(
    const vk::rect_2d* new_split_instance_bind_regions)
  {
    _split_instance_bind_regions = new_split_instance_bind_regions;
  }

  template <std::size_t Count>
  void split_instance_bind_regions(
    const std::array<vk::rect_2d, Count>& new_split_instance_bind_regions)
  {
    _split_instance_bind_region_count =
      static_cast<uint32_t>(new_split_instance_bind_regions.size());
    _split_instance_bind_regions = new_split_instance_bind_regions.data();
  }

  void split_instance_bind_regions(
    const std::vector<vk::rect_2d>& new_split_instance_bind_regions)
  {
    _split_instance_bind_region_count =
      static_cast<uint32_t>(new_split_instance_bind_regions.size());
    _split_instance_bind_regions = new_split_instance_bind_regions.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::bind_image_memory_device_group_info;
  const void* _next = nullptr;
  uint32_t _device_index_count = 0;
  const uint32_t* _device_indices = nullptr;
  uint32_t _split_instance_bind_region_count = 0;
  const vk::rect_2d* _split_instance_bind_regions = nullptr;
};
static_assert(sizeof(bind_image_memory_device_group_info) ==
                sizeof(::VkBindImageMemoryDeviceGroupInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceGroupProperties.
class physical_device_group_properties
{
public:
  /// Default constructor.
  constexpr physical_device_group_properties() = default;

  /// Constructor.
  constexpr physical_device_group_properties(
    void* initial_next, uint32_t initial_physical_device_count,
    std::array<VkPhysicalDevice, VK_MAX_DEVICE_GROUP_SIZE>
      initial_physical_devices,
    VkBool32 initial_subset_allocation) noexcept
  : _next(std::move(initial_next)),
    _physical_device_count(std::move(initial_physical_device_count)),
    _physical_devices(std::move(initial_physical_devices)),
    _subset_allocation(std::move(initial_subset_allocation))
  {
  }

  /// Copy constructor.
  constexpr physical_device_group_properties(
    const physical_device_group_properties& other) noexcept
  : _next(other._next),
    _physical_device_count(other._physical_device_count),
    _physical_devices(other._physical_devices),
    _subset_allocation(other._subset_allocation)
  {
  }

  /// Move constructor.
  constexpr physical_device_group_properties(
    physical_device_group_properties&& other) noexcept
  : _next(std::move(other._next)),
    _physical_device_count(std::move(other._physical_device_count)),
    _physical_devices(std::move(other._physical_devices)),
    _subset_allocation(std::move(other._subset_allocation))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_group_properties& operator=(
    const physical_device_group_properties& other) noexcept
  {
    _next = other._next;
    _physical_device_count = other._physical_device_count;
    _physical_devices = other._physical_devices;
    _subset_allocation = other._subset_allocation;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_group_properties& operator=(
    physical_device_group_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _physical_device_count = std::move(other._physical_device_count);
    _physical_devices = std::move(other._physical_devices);
    _subset_allocation = std::move(other._subset_allocation);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceGroupProperties&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceGroupProperties*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& physical_device_count()
  {
    return _physical_device_count;
  }

  constexpr const uint32_t& physical_device_count() const
  {
    return _physical_device_count;
  }

  void physical_device_count(uint32_t new_physical_device_count)
  {
    _physical_device_count = new_physical_device_count;
  }

  std::array<VkPhysicalDevice, VK_MAX_DEVICE_GROUP_SIZE>& physical_devices()
  {
    return _physical_devices;
  }

  constexpr const std::array<VkPhysicalDevice, VK_MAX_DEVICE_GROUP_SIZE>&
  physical_devices() const
  {
    return _physical_devices;
  }

  void physical_devices(
    std::array<VkPhysicalDevice, VK_MAX_DEVICE_GROUP_SIZE> new_physical_devices)
  {
    _physical_devices = new_physical_devices;
  }

  VkBool32& subset_allocation()
  {
    return _subset_allocation;
  }

  constexpr const VkBool32& subset_allocation() const
  {
    return _subset_allocation;
  }

  void subset_allocation(VkBool32 new_subset_allocation)
  {
    _subset_allocation = new_subset_allocation;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_group_properties;
  void* _next = nullptr;
  uint32_t _physical_device_count = 0;
  std::array<VkPhysicalDevice, VK_MAX_DEVICE_GROUP_SIZE> _physical_devices = {};
  VkBool32 _subset_allocation = VK_FALSE;
};
static_assert(sizeof(physical_device_group_properties) ==
                sizeof(::VkPhysicalDeviceGroupProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceGroupDeviceCreateInfo.
class device_group_device_create_info
{
public:
  /// Default constructor.
  constexpr device_group_device_create_info() = default;

  /// Constructor.
  constexpr device_group_device_create_info(
    const void* initial_next, uint32_t initial_physical_device_count,
    const VkPhysicalDevice* initial_physical_devices) noexcept
  : _next(std::move(initial_next)),
    _physical_device_count(std::move(initial_physical_device_count)),
    _physical_devices(std::move(initial_physical_devices))
  {
  }

  /// Copy constructor.
  constexpr device_group_device_create_info(
    const device_group_device_create_info& other) noexcept
  : _next(other._next),
    _physical_device_count(other._physical_device_count),
    _physical_devices(other._physical_devices)
  {
  }

  /// Move constructor.
  constexpr device_group_device_create_info(
    device_group_device_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _physical_device_count(std::move(other._physical_device_count)),
    _physical_devices(std::move(other._physical_devices))
  {
  }

  /// Copy assignment operator.
  constexpr device_group_device_create_info& operator=(
    const device_group_device_create_info& other) noexcept
  {
    _next = other._next;
    _physical_device_count = other._physical_device_count;
    _physical_devices = other._physical_devices;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_group_device_create_info& operator=(
    device_group_device_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _physical_device_count = std::move(other._physical_device_count);
    _physical_devices = std::move(other._physical_devices);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGroupDeviceCreateInfo&() const
  {
    return *reinterpret_cast<const VkDeviceGroupDeviceCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& physical_device_count()
  {
    return _physical_device_count;
  }

  constexpr const uint32_t& physical_device_count() const
  {
    return _physical_device_count;
  }

  void physical_device_count(uint32_t new_physical_device_count)
  {
    _physical_device_count = new_physical_device_count;
  }

  const VkPhysicalDevice* physical_devices()
  {
    return _physical_devices;
  }

  constexpr const VkPhysicalDevice* physical_devices() const
  {
    return _physical_devices;
  }

  void physical_devices(const VkPhysicalDevice* new_physical_devices)
  {
    _physical_devices = new_physical_devices;
  }

  template <std::size_t Count>
  void physical_devices(
    const std::array<VkPhysicalDevice, Count>& new_physical_devices)
  {
    _physical_device_count = static_cast<uint32_t>(new_physical_devices.size());
    _physical_devices = new_physical_devices.data();
  }

  void physical_devices(
    const std::vector<VkPhysicalDevice>& new_physical_devices)
  {
    _physical_device_count = static_cast<uint32_t>(new_physical_devices.size());
    _physical_devices = new_physical_devices.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_group_device_create_info;
  const void* _next = nullptr;
  uint32_t _physical_device_count = 0;
  const VkPhysicalDevice* _physical_devices = nullptr;
};
static_assert(sizeof(device_group_device_create_info) ==
                sizeof(::VkDeviceGroupDeviceCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkBufferMemoryRequirementsInfo2.
class buffer_memory_requirements_info_2
{
public:
  /// Default constructor.
  constexpr buffer_memory_requirements_info_2() = default;

  /// Constructor.
  constexpr buffer_memory_requirements_info_2(const void* initial_next,
                                              VkBuffer initial_buffer) noexcept
  : _next(std::move(initial_next)), _buffer(std::move(initial_buffer))
  {
  }

  /// Copy constructor.
  constexpr buffer_memory_requirements_info_2(
    const buffer_memory_requirements_info_2& other) noexcept
  : _next(other._next), _buffer(other._buffer)
  {
  }

  /// Move constructor.
  constexpr buffer_memory_requirements_info_2(
    buffer_memory_requirements_info_2&& other) noexcept
  : _next(std::move(other._next)), _buffer(std::move(other._buffer))
  {
  }

  /// Copy assignment operator.
  constexpr buffer_memory_requirements_info_2& operator=(
    const buffer_memory_requirements_info_2& other) noexcept
  {
    _next = other._next;
    _buffer = other._buffer;
    return *this;
  }

  /// Move assignment operator.
  constexpr buffer_memory_requirements_info_2& operator=(
    buffer_memory_requirements_info_2&& other) noexcept
  {
    _next = std::move(other._next);
    _buffer = std::move(other._buffer);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBufferMemoryRequirementsInfo2&() const
  {
    return *reinterpret_cast<const VkBufferMemoryRequirementsInfo2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::buffer_memory_requirements_info_2;
  const void* _next = nullptr;
  VkBuffer _buffer = nullptr;
};
static_assert(sizeof(buffer_memory_requirements_info_2) ==
                sizeof(::VkBufferMemoryRequirementsInfo2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImageMemoryRequirementsInfo2.
class image_memory_requirements_info_2
{
public:
  /// Default constructor.
  constexpr image_memory_requirements_info_2() = default;

  /// Constructor.
  constexpr image_memory_requirements_info_2(const void* initial_next,
                                             VkImage initial_image) noexcept
  : _next(std::move(initial_next)), _image(std::move(initial_image))
  {
  }

  /// Copy constructor.
  constexpr image_memory_requirements_info_2(
    const image_memory_requirements_info_2& other) noexcept
  : _next(other._next), _image(other._image)
  {
  }

  /// Move constructor.
  constexpr image_memory_requirements_info_2(
    image_memory_requirements_info_2&& other) noexcept
  : _next(std::move(other._next)), _image(std::move(other._image))
  {
  }

  /// Copy assignment operator.
  constexpr image_memory_requirements_info_2& operator=(
    const image_memory_requirements_info_2& other) noexcept
  {
    _next = other._next;
    _image = other._image;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_memory_requirements_info_2& operator=(
    image_memory_requirements_info_2&& other) noexcept
  {
    _next = std::move(other._next);
    _image = std::move(other._image);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageMemoryRequirementsInfo2&() const
  {
    return *reinterpret_cast<const VkImageMemoryRequirementsInfo2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkImage& image()
  {
    return _image;
  }

  constexpr const VkImage& image() const
  {
    return _image;
  }

  void image(VkImage new_image)
  {
    _image = new_image;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_memory_requirements_info_2;
  const void* _next = nullptr;
  VkImage _image = nullptr;
};
static_assert(sizeof(image_memory_requirements_info_2) ==
                sizeof(::VkImageMemoryRequirementsInfo2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImageSparseMemoryRequirementsInfo2.
class image_sparse_memory_requirements_info_2
{
public:
  /// Default constructor.
  constexpr image_sparse_memory_requirements_info_2() = default;

  /// Constructor.
  constexpr image_sparse_memory_requirements_info_2(
    const void* initial_next, VkImage initial_image) noexcept
  : _next(std::move(initial_next)), _image(std::move(initial_image))
  {
  }

  /// Copy constructor.
  constexpr image_sparse_memory_requirements_info_2(
    const image_sparse_memory_requirements_info_2& other) noexcept
  : _next(other._next), _image(other._image)
  {
  }

  /// Move constructor.
  constexpr image_sparse_memory_requirements_info_2(
    image_sparse_memory_requirements_info_2&& other) noexcept
  : _next(std::move(other._next)), _image(std::move(other._image))
  {
  }

  /// Copy assignment operator.
  constexpr image_sparse_memory_requirements_info_2& operator=(
    const image_sparse_memory_requirements_info_2& other) noexcept
  {
    _next = other._next;
    _image = other._image;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_sparse_memory_requirements_info_2& operator=(
    image_sparse_memory_requirements_info_2&& other) noexcept
  {
    _next = std::move(other._next);
    _image = std::move(other._image);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageSparseMemoryRequirementsInfo2&() const
  {
    return *reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkImage& image()
  {
    return _image;
  }

  constexpr const VkImage& image() const
  {
    return _image;
  }

  void image(VkImage new_image)
  {
    _image = new_image;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_sparse_memory_requirements_info_2;
  const void* _next = nullptr;
  VkImage _image = nullptr;
};
static_assert(sizeof(image_sparse_memory_requirements_info_2) ==
                sizeof(::VkImageSparseMemoryRequirementsInfo2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkMemoryRequirements2.
class memory_requirements_2
{
public:
  /// Default constructor.
  constexpr memory_requirements_2() = default;

  /// Constructor.
  constexpr memory_requirements_2(
    void* initial_next,
    vk::memory_requirements initial_memory_requirements) noexcept
  : _next(std::move(initial_next)),
    _memory_requirements(std::move(initial_memory_requirements))
  {
  }

  /// Copy constructor.
  constexpr memory_requirements_2(const memory_requirements_2& other) noexcept
  : _next(other._next), _memory_requirements(other._memory_requirements)
  {
  }

  /// Move constructor.
  constexpr memory_requirements_2(memory_requirements_2&& other) noexcept
  : _next(std::move(other._next)),
    _memory_requirements(std::move(other._memory_requirements))
  {
  }

  /// Copy assignment operator.
  constexpr memory_requirements_2& operator=(
    const memory_requirements_2& other) noexcept
  {
    _next = other._next;
    _memory_requirements = other._memory_requirements;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_requirements_2& operator=(
    memory_requirements_2&& other) noexcept
  {
    _next = std::move(other._next);
    _memory_requirements = std::move(other._memory_requirements);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryRequirements2&() const
  {
    return *reinterpret_cast<const VkMemoryRequirements2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::memory_requirements& memory_requirements()
  {
    return _memory_requirements;
  }

  constexpr const vk::memory_requirements& memory_requirements() const
  {
    return _memory_requirements;
  }

  void memory_requirements(vk::memory_requirements new_memory_requirements)
  {
    _memory_requirements = new_memory_requirements;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_requirements_2;
  void* _next = nullptr;
  vk::memory_requirements _memory_requirements = vk::memory_requirements{};
};
static_assert(sizeof(memory_requirements_2) == sizeof(::VkMemoryRequirements2),
              "struct and wrapper have different size!");

using memory_requirements_2_khr = memory_requirements_2;

/// Enhanced replacement type for VkSparseImageMemoryRequirements2.
class sparse_image_memory_requirements_2
{
public:
  /// Default constructor.
  constexpr sparse_image_memory_requirements_2() = default;

  /// Constructor.
  constexpr sparse_image_memory_requirements_2(
    void* initial_next,
    vk::sparse_image_memory_requirements initial_memory_requirements) noexcept
  : _next(std::move(initial_next)),
    _memory_requirements(std::move(initial_memory_requirements))
  {
  }

  /// Copy constructor.
  constexpr sparse_image_memory_requirements_2(
    const sparse_image_memory_requirements_2& other) noexcept
  : _next(other._next), _memory_requirements(other._memory_requirements)
  {
  }

  /// Move constructor.
  constexpr sparse_image_memory_requirements_2(
    sparse_image_memory_requirements_2&& other) noexcept
  : _next(std::move(other._next)),
    _memory_requirements(std::move(other._memory_requirements))
  {
  }

  /// Copy assignment operator.
  constexpr sparse_image_memory_requirements_2& operator=(
    const sparse_image_memory_requirements_2& other) noexcept
  {
    _next = other._next;
    _memory_requirements = other._memory_requirements;
    return *this;
  }

  /// Move assignment operator.
  constexpr sparse_image_memory_requirements_2& operator=(
    sparse_image_memory_requirements_2&& other) noexcept
  {
    _next = std::move(other._next);
    _memory_requirements = std::move(other._memory_requirements);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSparseImageMemoryRequirements2&() const
  {
    return *reinterpret_cast<const VkSparseImageMemoryRequirements2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::sparse_image_memory_requirements& memory_requirements()
  {
    return _memory_requirements;
  }

  constexpr const vk::sparse_image_memory_requirements& memory_requirements()
    const
  {
    return _memory_requirements;
  }

  void memory_requirements(
    vk::sparse_image_memory_requirements new_memory_requirements)
  {
    _memory_requirements = new_memory_requirements;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::sparse_image_memory_requirements_2;
  void* _next = nullptr;
  vk::sparse_image_memory_requirements _memory_requirements =
    vk::sparse_image_memory_requirements{};
};
static_assert(sizeof(sparse_image_memory_requirements_2) ==
                sizeof(::VkSparseImageMemoryRequirements2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceFeatures2.
class physical_device_features_2
{
public:
  /// Default constructor.
  constexpr physical_device_features_2() = default;

  /// Constructor.
  constexpr physical_device_features_2(
    void* initial_next, vk::physical_device_features initial_features) noexcept
  : _next(std::move(initial_next)), _features(std::move(initial_features))
  {
  }

  /// Copy constructor.
  constexpr physical_device_features_2(
    const physical_device_features_2& other) noexcept
  : _next(other._next), _features(other._features)
  {
  }

  /// Move constructor.
  constexpr physical_device_features_2(
    physical_device_features_2&& other) noexcept
  : _next(std::move(other._next)), _features(std::move(other._features))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_features_2& operator=(
    const physical_device_features_2& other) noexcept
  {
    _next = other._next;
    _features = other._features;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_features_2& operator=(
    physical_device_features_2&& other) noexcept
  {
    _next = std::move(other._next);
    _features = std::move(other._features);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceFeatures2&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceFeatures2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::physical_device_features& features()
  {
    return _features;
  }

  constexpr const vk::physical_device_features& features() const
  {
    return _features;
  }

  void features(vk::physical_device_features new_features)
  {
    _features = new_features;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_features_2;
  void* _next = nullptr;
  vk::physical_device_features _features = vk::physical_device_features{};
};
static_assert(sizeof(physical_device_features_2) ==
                sizeof(::VkPhysicalDeviceFeatures2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceProperties2.
class physical_device_properties_2
{
public:
  /// Default constructor.
  constexpr physical_device_properties_2() = default;

  /// Constructor.
  constexpr physical_device_properties_2(
    void* initial_next,
    vk::physical_device_properties initial_properties) noexcept
  : _next(std::move(initial_next)), _properties(std::move(initial_properties))
  {
  }

  /// Copy constructor.
  constexpr physical_device_properties_2(
    const physical_device_properties_2& other) noexcept
  : _next(other._next), _properties(other._properties)
  {
  }

  /// Move constructor.
  constexpr physical_device_properties_2(
    physical_device_properties_2&& other) noexcept
  : _next(std::move(other._next)), _properties(std::move(other._properties))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_properties_2& operator=(
    const physical_device_properties_2& other) noexcept
  {
    _next = other._next;
    _properties = other._properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_properties_2& operator=(
    physical_device_properties_2&& other) noexcept
  {
    _next = std::move(other._next);
    _properties = std::move(other._properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceProperties2&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceProperties2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::physical_device_properties& properties()
  {
    return _properties;
  }

  constexpr const vk::physical_device_properties& properties() const
  {
    return _properties;
  }

  void properties(vk::physical_device_properties new_properties)
  {
    _properties = new_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_properties_2;
  void* _next = nullptr;
  vk::physical_device_properties _properties = vk::physical_device_properties{};
};
static_assert(sizeof(physical_device_properties_2) ==
                sizeof(::VkPhysicalDeviceProperties2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkFormatProperties2.
class format_properties_2
{
public:
  /// Default constructor.
  constexpr format_properties_2() = default;

  /// Constructor.
  constexpr format_properties_2(
    void* initial_next,
    vk::format_properties initial_format_properties) noexcept
  : _next(std::move(initial_next)),
    _format_properties(std::move(initial_format_properties))
  {
  }

  /// Copy constructor.
  constexpr format_properties_2(const format_properties_2& other) noexcept
  : _next(other._next), _format_properties(other._format_properties)
  {
  }

  /// Move constructor.
  constexpr format_properties_2(format_properties_2&& other) noexcept
  : _next(std::move(other._next)),
    _format_properties(std::move(other._format_properties))
  {
  }

  /// Copy assignment operator.
  constexpr format_properties_2& operator=(
    const format_properties_2& other) noexcept
  {
    _next = other._next;
    _format_properties = other._format_properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr format_properties_2& operator=(format_properties_2&& other) noexcept
  {
    _next = std::move(other._next);
    _format_properties = std::move(other._format_properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkFormatProperties2&() const
  {
    return *reinterpret_cast<const VkFormatProperties2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::format_properties& format_properties()
  {
    return _format_properties;
  }

  constexpr const vk::format_properties& format_properties() const
  {
    return _format_properties;
  }

  void format_properties(vk::format_properties new_format_properties)
  {
    _format_properties = new_format_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::format_properties_2;
  void* _next = nullptr;
  vk::format_properties _format_properties = vk::format_properties{};
};
static_assert(sizeof(format_properties_2) == sizeof(::VkFormatProperties2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImageFormatProperties2.
class image_format_properties_2
{
public:
  /// Default constructor.
  constexpr image_format_properties_2() = default;

  /// Constructor.
  constexpr image_format_properties_2(
    void* initial_next,
    vk::image_format_properties initial_image_format_properties) noexcept
  : _next(std::move(initial_next)),
    _image_format_properties(std::move(initial_image_format_properties))
  {
  }

  /// Copy constructor.
  constexpr image_format_properties_2(
    const image_format_properties_2& other) noexcept
  : _next(other._next), _image_format_properties(other._image_format_properties)
  {
  }

  /// Move constructor.
  constexpr image_format_properties_2(
    image_format_properties_2&& other) noexcept
  : _next(std::move(other._next)),
    _image_format_properties(std::move(other._image_format_properties))
  {
  }

  /// Copy assignment operator.
  constexpr image_format_properties_2& operator=(
    const image_format_properties_2& other) noexcept
  {
    _next = other._next;
    _image_format_properties = other._image_format_properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_format_properties_2& operator=(
    image_format_properties_2&& other) noexcept
  {
    _next = std::move(other._next);
    _image_format_properties = std::move(other._image_format_properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageFormatProperties2&() const
  {
    return *reinterpret_cast<const VkImageFormatProperties2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::image_format_properties& image_format_properties()
  {
    return _image_format_properties;
  }

  constexpr const vk::image_format_properties& image_format_properties() const
  {
    return _image_format_properties;
  }

  void image_format_properties(
    vk::image_format_properties new_image_format_properties)
  {
    _image_format_properties = new_image_format_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_format_properties_2;
  void* _next = nullptr;
  vk::image_format_properties _image_format_properties =
    vk::image_format_properties{};
};
static_assert(sizeof(image_format_properties_2) ==
                sizeof(::VkImageFormatProperties2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceImageFormatInfo2.
class physical_device_image_format_info_2
{
public:
  /// Default constructor.
  constexpr physical_device_image_format_info_2() = default;

  /// Constructor.
  constexpr physical_device_image_format_info_2(
    const void* initial_next, vk::format initial_format,
    vk::image_type initial_type, vk::image_tiling initial_tiling,
    vk::image_usage_flags initial_usage,
    vk::image_create_flags initial_flags) noexcept
  : _next(std::move(initial_next)),
    _format(std::move(initial_format)),
    _type(std::move(initial_type)),
    _tiling(std::move(initial_tiling)),
    _usage(std::move(initial_usage)),
    _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr physical_device_image_format_info_2(
    const physical_device_image_format_info_2& other) noexcept
  : _next(other._next),
    _format(other._format),
    _type(other._type),
    _tiling(other._tiling),
    _usage(other._usage),
    _flags(other._flags)
  {
  }

  /// Move constructor.
  constexpr physical_device_image_format_info_2(
    physical_device_image_format_info_2&& other) noexcept
  : _next(std::move(other._next)),
    _format(std::move(other._format)),
    _type(std::move(other._type)),
    _tiling(std::move(other._tiling)),
    _usage(std::move(other._usage)),
    _flags(std::move(other._flags))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_image_format_info_2& operator=(
    const physical_device_image_format_info_2& other) noexcept
  {
    _next = other._next;
    _format = other._format;
    _type = other._type;
    _tiling = other._tiling;
    _usage = other._usage;
    _flags = other._flags;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_image_format_info_2& operator=(
    physical_device_image_format_info_2&& other) noexcept
  {
    _next = std::move(other._next);
    _format = std::move(other._format);
    _type = std::move(other._type);
    _tiling = std::move(other._tiling);
    _usage = std::move(other._usage);
    _flags = std::move(other._flags);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceImageFormatInfo2&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceImageFormatInfo2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  vk::image_type& type()
  {
    return _type;
  }

  constexpr const vk::image_type& type() const
  {
    return _type;
  }

  void type(vk::image_type new_type)
  {
    _type = new_type;
  }

  vk::image_tiling& tiling()
  {
    return _tiling;
  }

  constexpr const vk::image_tiling& tiling() const
  {
    return _tiling;
  }

  void tiling(vk::image_tiling new_tiling)
  {
    _tiling = new_tiling;
  }

  vk::image_usage_flags& usage()
  {
    return _usage;
  }

  constexpr const vk::image_usage_flags& usage() const
  {
    return _usage;
  }

  void usage(vk::image_usage_flags new_usage)
  {
    _usage = new_usage;
  }

  vk::image_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::image_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::image_create_flags new_flags)
  {
    _flags = new_flags;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_image_format_info_2;
  const void* _next = nullptr;
  vk::format _format = vk::format::undefined;
  vk::image_type _type = vk::image_type::_1d;
  vk::image_tiling _tiling = vk::image_tiling::optimal;
  vk::image_usage_flags _usage = vk::image_usage_flag::none;
  vk::image_create_flags _flags = vk::image_create_flag::none;
};
static_assert(sizeof(physical_device_image_format_info_2) ==
                sizeof(::VkPhysicalDeviceImageFormatInfo2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkQueueFamilyProperties2.
class queue_family_properties_2
{
public:
  /// Default constructor.
  constexpr queue_family_properties_2() = default;

  /// Constructor.
  constexpr queue_family_properties_2(
    void* initial_next,
    vk::queue_family_properties initial_queue_family_properties) noexcept
  : _next(std::move(initial_next)),
    _queue_family_properties(std::move(initial_queue_family_properties))
  {
  }

  /// Copy constructor.
  constexpr queue_family_properties_2(
    const queue_family_properties_2& other) noexcept
  : _next(other._next), _queue_family_properties(other._queue_family_properties)
  {
  }

  /// Move constructor.
  constexpr queue_family_properties_2(
    queue_family_properties_2&& other) noexcept
  : _next(std::move(other._next)),
    _queue_family_properties(std::move(other._queue_family_properties))
  {
  }

  /// Copy assignment operator.
  constexpr queue_family_properties_2& operator=(
    const queue_family_properties_2& other) noexcept
  {
    _next = other._next;
    _queue_family_properties = other._queue_family_properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr queue_family_properties_2& operator=(
    queue_family_properties_2&& other) noexcept
  {
    _next = std::move(other._next);
    _queue_family_properties = std::move(other._queue_family_properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkQueueFamilyProperties2&() const
  {
    return *reinterpret_cast<const VkQueueFamilyProperties2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::queue_family_properties& queue_family_properties()
  {
    return _queue_family_properties;
  }

  constexpr const vk::queue_family_properties& queue_family_properties() const
  {
    return _queue_family_properties;
  }

  void queue_family_properties(
    vk::queue_family_properties new_queue_family_properties)
  {
    _queue_family_properties = new_queue_family_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::queue_family_properties_2;
  void* _next = nullptr;
  vk::queue_family_properties _queue_family_properties =
    vk::queue_family_properties{};
};
static_assert(sizeof(queue_family_properties_2) ==
                sizeof(::VkQueueFamilyProperties2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceMemoryProperties2.
class physical_device_memory_properties_2
{
public:
  /// Default constructor.
  constexpr physical_device_memory_properties_2() = default;

  /// Constructor.
  constexpr physical_device_memory_properties_2(
    void* initial_next,
    vk::physical_device_memory_properties initial_memory_properties) noexcept
  : _next(std::move(initial_next)),
    _memory_properties(std::move(initial_memory_properties))
  {
  }

  /// Copy constructor.
  constexpr physical_device_memory_properties_2(
    const physical_device_memory_properties_2& other) noexcept
  : _next(other._next), _memory_properties(other._memory_properties)
  {
  }

  /// Move constructor.
  constexpr physical_device_memory_properties_2(
    physical_device_memory_properties_2&& other) noexcept
  : _next(std::move(other._next)),
    _memory_properties(std::move(other._memory_properties))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_memory_properties_2& operator=(
    const physical_device_memory_properties_2& other) noexcept
  {
    _next = other._next;
    _memory_properties = other._memory_properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_memory_properties_2& operator=(
    physical_device_memory_properties_2&& other) noexcept
  {
    _next = std::move(other._next);
    _memory_properties = std::move(other._memory_properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceMemoryProperties2&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceMemoryProperties2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::physical_device_memory_properties& memory_properties()
  {
    return _memory_properties;
  }

  constexpr const vk::physical_device_memory_properties& memory_properties()
    const
  {
    return _memory_properties;
  }

  void memory_properties(
    vk::physical_device_memory_properties new_memory_properties)
  {
    _memory_properties = new_memory_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_memory_properties_2;
  void* _next = nullptr;
  vk::physical_device_memory_properties _memory_properties =
    vk::physical_device_memory_properties{};
};
static_assert(sizeof(physical_device_memory_properties_2) ==
                sizeof(::VkPhysicalDeviceMemoryProperties2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSparseImageFormatProperties2.
class sparse_image_format_properties_2
{
public:
  /// Default constructor.
  constexpr sparse_image_format_properties_2() = default;

  /// Constructor.
  constexpr sparse_image_format_properties_2(
    void* initial_next,
    vk::sparse_image_format_properties initial_properties) noexcept
  : _next(std::move(initial_next)), _properties(std::move(initial_properties))
  {
  }

  /// Copy constructor.
  constexpr sparse_image_format_properties_2(
    const sparse_image_format_properties_2& other) noexcept
  : _next(other._next), _properties(other._properties)
  {
  }

  /// Move constructor.
  constexpr sparse_image_format_properties_2(
    sparse_image_format_properties_2&& other) noexcept
  : _next(std::move(other._next)), _properties(std::move(other._properties))
  {
  }

  /// Copy assignment operator.
  constexpr sparse_image_format_properties_2& operator=(
    const sparse_image_format_properties_2& other) noexcept
  {
    _next = other._next;
    _properties = other._properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr sparse_image_format_properties_2& operator=(
    sparse_image_format_properties_2&& other) noexcept
  {
    _next = std::move(other._next);
    _properties = std::move(other._properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSparseImageFormatProperties2&() const
  {
    return *reinterpret_cast<const VkSparseImageFormatProperties2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::sparse_image_format_properties& properties()
  {
    return _properties;
  }

  constexpr const vk::sparse_image_format_properties& properties() const
  {
    return _properties;
  }

  void properties(vk::sparse_image_format_properties new_properties)
  {
    _properties = new_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::sparse_image_format_properties_2;
  void* _next = nullptr;
  vk::sparse_image_format_properties _properties =
    vk::sparse_image_format_properties{};
};
static_assert(sizeof(sparse_image_format_properties_2) ==
                sizeof(::VkSparseImageFormatProperties2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceSparseImageFormatInfo2.
class physical_device_sparse_image_format_info_2
{
public:
  /// Default constructor.
  constexpr physical_device_sparse_image_format_info_2() = default;

  /// Constructor.
  constexpr physical_device_sparse_image_format_info_2(
    const void* initial_next, vk::format initial_format,
    vk::image_type initial_type, vk::sample_count_flag initial_samples,
    vk::image_usage_flags initial_usage,
    vk::image_tiling initial_tiling) noexcept
  : _next(std::move(initial_next)),
    _format(std::move(initial_format)),
    _type(std::move(initial_type)),
    _samples(std::move(initial_samples)),
    _usage(std::move(initial_usage)),
    _tiling(std::move(initial_tiling))
  {
  }

  /// Copy constructor.
  constexpr physical_device_sparse_image_format_info_2(
    const physical_device_sparse_image_format_info_2& other) noexcept
  : _next(other._next),
    _format(other._format),
    _type(other._type),
    _samples(other._samples),
    _usage(other._usage),
    _tiling(other._tiling)
  {
  }

  /// Move constructor.
  constexpr physical_device_sparse_image_format_info_2(
    physical_device_sparse_image_format_info_2&& other) noexcept
  : _next(std::move(other._next)),
    _format(std::move(other._format)),
    _type(std::move(other._type)),
    _samples(std::move(other._samples)),
    _usage(std::move(other._usage)),
    _tiling(std::move(other._tiling))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_sparse_image_format_info_2& operator=(
    const physical_device_sparse_image_format_info_2& other) noexcept
  {
    _next = other._next;
    _format = other._format;
    _type = other._type;
    _samples = other._samples;
    _usage = other._usage;
    _tiling = other._tiling;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_sparse_image_format_info_2& operator=(
    physical_device_sparse_image_format_info_2&& other) noexcept
  {
    _next = std::move(other._next);
    _format = std::move(other._format);
    _type = std::move(other._type);
    _samples = std::move(other._samples);
    _usage = std::move(other._usage);
    _tiling = std::move(other._tiling);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceSparseImageFormatInfo2&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  vk::image_type& type()
  {
    return _type;
  }

  constexpr const vk::image_type& type() const
  {
    return _type;
  }

  void type(vk::image_type new_type)
  {
    _type = new_type;
  }

  vk::sample_count_flag& samples()
  {
    return _samples;
  }

  constexpr const vk::sample_count_flag& samples() const
  {
    return _samples;
  }

  void samples(vk::sample_count_flag new_samples)
  {
    _samples = new_samples;
  }

  vk::image_usage_flags& usage()
  {
    return _usage;
  }

  constexpr const vk::image_usage_flags& usage() const
  {
    return _usage;
  }

  void usage(vk::image_usage_flags new_usage)
  {
    _usage = new_usage;
  }

  vk::image_tiling& tiling()
  {
    return _tiling;
  }

  constexpr const vk::image_tiling& tiling() const
  {
    return _tiling;
  }

  void tiling(vk::image_tiling new_tiling)
  {
    _tiling = new_tiling;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_sparse_image_format_info_2;
  const void* _next = nullptr;
  vk::format _format = vk::format::undefined;
  vk::image_type _type = vk::image_type::_1d;
  vk::sample_count_flag _samples = vk::sample_count_flag::none;
  vk::image_usage_flags _usage = vk::image_usage_flag::none;
  vk::image_tiling _tiling = vk::image_tiling::optimal;
};
static_assert(sizeof(physical_device_sparse_image_format_info_2) ==
                sizeof(::VkPhysicalDeviceSparseImageFormatInfo2),
              "struct and wrapper have different size!");

using command_pool_trim_flags = VkFlags;
enum class point_clipping_behavior
{
  /// @see VK_POINT_CLIPPING_BEHAVIOR_ALL_CLIP_PLANES
  all_clip_planes = 0,
  /// @see VK_POINT_CLIPPING_BEHAVIOR_USER_CLIP_PLANES_ONLY
  user_clip_planes_only = 1,
};

/// Enhanced replacement type for VkPhysicalDevicePointClippingProperties.
class physical_device_point_clipping_properties
{
public:
  /// Default constructor.
  constexpr physical_device_point_clipping_properties() = default;

  /// Constructor.
  constexpr physical_device_point_clipping_properties(
    void* initial_next,
    vk::point_clipping_behavior initial_point_clipping_behavior) noexcept
  : _next(std::move(initial_next)),
    _point_clipping_behavior(std::move(initial_point_clipping_behavior))
  {
  }

  /// Copy constructor.
  constexpr physical_device_point_clipping_properties(
    const physical_device_point_clipping_properties& other) noexcept
  : _next(other._next), _point_clipping_behavior(other._point_clipping_behavior)
  {
  }

  /// Move constructor.
  constexpr physical_device_point_clipping_properties(
    physical_device_point_clipping_properties&& other) noexcept
  : _next(std::move(other._next)),
    _point_clipping_behavior(std::move(other._point_clipping_behavior))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_point_clipping_properties& operator=(
    const physical_device_point_clipping_properties& other) noexcept
  {
    _next = other._next;
    _point_clipping_behavior = other._point_clipping_behavior;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_point_clipping_properties& operator=(
    physical_device_point_clipping_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _point_clipping_behavior = std::move(other._point_clipping_behavior);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDevicePointClippingProperties&() const
  {
    return *reinterpret_cast<const VkPhysicalDevicePointClippingProperties*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::point_clipping_behavior& point_clipping_behavior()
  {
    return _point_clipping_behavior;
  }

  constexpr const vk::point_clipping_behavior& point_clipping_behavior() const
  {
    return _point_clipping_behavior;
  }

  void point_clipping_behavior(
    vk::point_clipping_behavior new_point_clipping_behavior)
  {
    _point_clipping_behavior = new_point_clipping_behavior;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_point_clipping_properties;
  void* _next = nullptr;
  vk::point_clipping_behavior _point_clipping_behavior =
    vk::point_clipping_behavior::all_clip_planes;
};
static_assert(sizeof(physical_device_point_clipping_properties) ==
                sizeof(::VkPhysicalDevicePointClippingProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkInputAttachmentAspectReference.
class input_attachment_aspect_reference
{
public:
  /// Default constructor.
  constexpr input_attachment_aspect_reference() = default;

  /// Constructor.
  constexpr input_attachment_aspect_reference(
    uint32_t initial_subpass, uint32_t initial_input_attachment_index,
    vk::image_aspect_flags initial_aspect_mask) noexcept
  : _subpass(std::move(initial_subpass)),
    _input_attachment_index(std::move(initial_input_attachment_index)),
    _aspect_mask(std::move(initial_aspect_mask))
  {
  }

  /// Copy constructor.
  constexpr input_attachment_aspect_reference(
    const input_attachment_aspect_reference& other) = default;

  /// Move constructor.
  constexpr input_attachment_aspect_reference(
    input_attachment_aspect_reference&& other) = default;

  /// Copy assignment operator.
  constexpr input_attachment_aspect_reference& operator=(
    const input_attachment_aspect_reference& other) = default;

  /// Move assignment operator.
  constexpr input_attachment_aspect_reference& operator=(
    input_attachment_aspect_reference&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkInputAttachmentAspectReference&() const
  {
    return *reinterpret_cast<const VkInputAttachmentAspectReference*>(this);
  }

  uint32_t& subpass()
  {
    return _subpass;
  }

  constexpr const uint32_t& subpass() const
  {
    return _subpass;
  }

  void subpass(uint32_t new_subpass)
  {
    _subpass = new_subpass;
  }

  uint32_t& input_attachment_index()
  {
    return _input_attachment_index;
  }

  constexpr const uint32_t& input_attachment_index() const
  {
    return _input_attachment_index;
  }

  void input_attachment_index(uint32_t new_input_attachment_index)
  {
    _input_attachment_index = new_input_attachment_index;
  }

  vk::image_aspect_flags& aspect_mask()
  {
    return _aspect_mask;
  }

  constexpr const vk::image_aspect_flags& aspect_mask() const
  {
    return _aspect_mask;
  }

  void aspect_mask(vk::image_aspect_flags new_aspect_mask)
  {
    _aspect_mask = new_aspect_mask;
  }

private:
  uint32_t _subpass = 0;
  uint32_t _input_attachment_index = 0;
  vk::image_aspect_flags _aspect_mask = vk::image_aspect_flag::none;
};
static_assert(sizeof(input_attachment_aspect_reference) ==
                sizeof(::VkInputAttachmentAspectReference),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkRenderPassInputAttachmentAspectCreateInfo.
class render_pass_input_attachment_aspect_create_info
{
public:
  /// Default constructor.
  constexpr render_pass_input_attachment_aspect_create_info() = default;

  /// Constructor.
  constexpr render_pass_input_attachment_aspect_create_info(
    const void* initial_next, uint32_t initial_aspect_reference_count,
    const vk::input_attachment_aspect_reference*
      initial_aspect_references) noexcept
  : _next(std::move(initial_next)),
    _aspect_reference_count(std::move(initial_aspect_reference_count)),
    _aspect_references(std::move(initial_aspect_references))
  {
  }

  /// Copy constructor.
  constexpr render_pass_input_attachment_aspect_create_info(
    const render_pass_input_attachment_aspect_create_info& other) noexcept
  : _next(other._next),
    _aspect_reference_count(other._aspect_reference_count),
    _aspect_references(other._aspect_references)
  {
  }

  /// Move constructor.
  constexpr render_pass_input_attachment_aspect_create_info(
    render_pass_input_attachment_aspect_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _aspect_reference_count(std::move(other._aspect_reference_count)),
    _aspect_references(std::move(other._aspect_references))
  {
  }

  /// Copy assignment operator.
  constexpr render_pass_input_attachment_aspect_create_info& operator=(
    const render_pass_input_attachment_aspect_create_info& other) noexcept
  {
    _next = other._next;
    _aspect_reference_count = other._aspect_reference_count;
    _aspect_references = other._aspect_references;
    return *this;
  }

  /// Move assignment operator.
  constexpr render_pass_input_attachment_aspect_create_info& operator=(
    render_pass_input_attachment_aspect_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _aspect_reference_count = std::move(other._aspect_reference_count);
    _aspect_references = std::move(other._aspect_references);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkRenderPassInputAttachmentAspectCreateInfo&() const
  {
    return *reinterpret_cast<
      const VkRenderPassInputAttachmentAspectCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& aspect_reference_count()
  {
    return _aspect_reference_count;
  }

  constexpr const uint32_t& aspect_reference_count() const
  {
    return _aspect_reference_count;
  }

  void aspect_reference_count(uint32_t new_aspect_reference_count)
  {
    _aspect_reference_count = new_aspect_reference_count;
  }

  const vk::input_attachment_aspect_reference* aspect_references()
  {
    return _aspect_references;
  }

  constexpr const vk::input_attachment_aspect_reference* aspect_references()
    const
  {
    return _aspect_references;
  }

  void aspect_references(
    const vk::input_attachment_aspect_reference* new_aspect_references)
  {
    _aspect_references = new_aspect_references;
  }

  template <std::size_t Count>
  void aspect_references(const std::array<vk::input_attachment_aspect_reference,
                                          Count>& new_aspect_references)
  {
    _aspect_reference_count =
      static_cast<uint32_t>(new_aspect_references.size());
    _aspect_references = new_aspect_references.data();
  }

  void aspect_references(
    const std::vector<vk::input_attachment_aspect_reference>&
      new_aspect_references)
  {
    _aspect_reference_count =
      static_cast<uint32_t>(new_aspect_references.size());
    _aspect_references = new_aspect_references.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::render_pass_input_attachment_aspect_create_info;
  const void* _next = nullptr;
  uint32_t _aspect_reference_count = 0;
  const vk::input_attachment_aspect_reference* _aspect_references = nullptr;
};
static_assert(sizeof(render_pass_input_attachment_aspect_create_info) ==
                sizeof(::VkRenderPassInputAttachmentAspectCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImageViewUsageCreateInfo.
class image_view_usage_create_info
{
public:
  /// Default constructor.
  constexpr image_view_usage_create_info() = default;

  /// Constructor.
  constexpr image_view_usage_create_info(
    const void* initial_next, vk::image_usage_flags initial_usage) noexcept
  : _next(std::move(initial_next)), _usage(std::move(initial_usage))
  {
  }

  /// Copy constructor.
  constexpr image_view_usage_create_info(
    const image_view_usage_create_info& other) noexcept
  : _next(other._next), _usage(other._usage)
  {
  }

  /// Move constructor.
  constexpr image_view_usage_create_info(
    image_view_usage_create_info&& other) noexcept
  : _next(std::move(other._next)), _usage(std::move(other._usage))
  {
  }

  /// Copy assignment operator.
  constexpr image_view_usage_create_info& operator=(
    const image_view_usage_create_info& other) noexcept
  {
    _next = other._next;
    _usage = other._usage;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_view_usage_create_info& operator=(
    image_view_usage_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _usage = std::move(other._usage);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageViewUsageCreateInfo&() const
  {
    return *reinterpret_cast<const VkImageViewUsageCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::image_usage_flags& usage()
  {
    return _usage;
  }

  constexpr const vk::image_usage_flags& usage() const
  {
    return _usage;
  }

  void usage(vk::image_usage_flags new_usage)
  {
    _usage = new_usage;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_view_usage_create_info;
  const void* _next = nullptr;
  vk::image_usage_flags _usage = vk::image_usage_flag::none;
};
static_assert(sizeof(image_view_usage_create_info) ==
                sizeof(::VkImageViewUsageCreateInfo),
              "struct and wrapper have different size!");

enum class tessellation_domain_origin
{
  /// @see VK_TESSELLATION_DOMAIN_ORIGIN_UPPER_LEFT
  upper_left = 0,
  /// @see VK_TESSELLATION_DOMAIN_ORIGIN_LOWER_LEFT
  lower_left = 1,
};

/// Enhanced replacement type for
/// VkPipelineTessellationDomainOriginStateCreateInfo.
class pipeline_tessellation_domain_origin_state_create_info
{
public:
  /// Default constructor.
  constexpr pipeline_tessellation_domain_origin_state_create_info() = default;

  /// Constructor.
  constexpr pipeline_tessellation_domain_origin_state_create_info(
    const void* initial_next,
    vk::tessellation_domain_origin initial_domain_origin) noexcept
  : _next(std::move(initial_next)),
    _domain_origin(std::move(initial_domain_origin))
  {
  }

  /// Copy constructor.
  constexpr pipeline_tessellation_domain_origin_state_create_info(
    const pipeline_tessellation_domain_origin_state_create_info& other) noexcept
  : _next(other._next), _domain_origin(other._domain_origin)
  {
  }

  /// Move constructor.
  constexpr pipeline_tessellation_domain_origin_state_create_info(
    pipeline_tessellation_domain_origin_state_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _domain_origin(std::move(other._domain_origin))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_tessellation_domain_origin_state_create_info& operator=(
    const pipeline_tessellation_domain_origin_state_create_info& other) noexcept
  {
    _next = other._next;
    _domain_origin = other._domain_origin;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_tessellation_domain_origin_state_create_info& operator=(
    pipeline_tessellation_domain_origin_state_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _domain_origin = std::move(other._domain_origin);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineTessellationDomainOriginStateCreateInfo&() const
  {
    return *reinterpret_cast<
      const VkPipelineTessellationDomainOriginStateCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::tessellation_domain_origin& domain_origin()
  {
    return _domain_origin;
  }

  constexpr const vk::tessellation_domain_origin& domain_origin() const
  {
    return _domain_origin;
  }

  void domain_origin(vk::tessellation_domain_origin new_domain_origin)
  {
    _domain_origin = new_domain_origin;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_tessellation_domain_origin_state_create_info;
  const void* _next = nullptr;
  vk::tessellation_domain_origin _domain_origin =
    vk::tessellation_domain_origin::upper_left;
};
static_assert(sizeof(pipeline_tessellation_domain_origin_state_create_info) ==
                sizeof(::VkPipelineTessellationDomainOriginStateCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkRenderPassMultiviewCreateInfo.
class render_pass_multiview_create_info
{
public:
  /// Default constructor.
  constexpr render_pass_multiview_create_info() = default;

  /// Constructor.
  constexpr render_pass_multiview_create_info(
    const void* initial_next, uint32_t initial_subpass_count,
    const uint32_t* initial_view_masks, uint32_t initial_dependency_count,
    const int32_t* initial_view_offsets,
    uint32_t initial_correlation_mask_count,
    const uint32_t* initial_correlation_masks) noexcept
  : _next(std::move(initial_next)),
    _subpass_count(std::move(initial_subpass_count)),
    _view_masks(std::move(initial_view_masks)),
    _dependency_count(std::move(initial_dependency_count)),
    _view_offsets(std::move(initial_view_offsets)),
    _correlation_mask_count(std::move(initial_correlation_mask_count)),
    _correlation_masks(std::move(initial_correlation_masks))
  {
  }

  /// Copy constructor.
  constexpr render_pass_multiview_create_info(
    const render_pass_multiview_create_info& other) noexcept
  : _next(other._next),
    _subpass_count(other._subpass_count),
    _view_masks(other._view_masks),
    _dependency_count(other._dependency_count),
    _view_offsets(other._view_offsets),
    _correlation_mask_count(other._correlation_mask_count),
    _correlation_masks(other._correlation_masks)
  {
  }

  /// Move constructor.
  constexpr render_pass_multiview_create_info(
    render_pass_multiview_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _subpass_count(std::move(other._subpass_count)),
    _view_masks(std::move(other._view_masks)),
    _dependency_count(std::move(other._dependency_count)),
    _view_offsets(std::move(other._view_offsets)),
    _correlation_mask_count(std::move(other._correlation_mask_count)),
    _correlation_masks(std::move(other._correlation_masks))
  {
  }

  /// Copy assignment operator.
  constexpr render_pass_multiview_create_info& operator=(
    const render_pass_multiview_create_info& other) noexcept
  {
    _next = other._next;
    _subpass_count = other._subpass_count;
    _view_masks = other._view_masks;
    _dependency_count = other._dependency_count;
    _view_offsets = other._view_offsets;
    _correlation_mask_count = other._correlation_mask_count;
    _correlation_masks = other._correlation_masks;
    return *this;
  }

  /// Move assignment operator.
  constexpr render_pass_multiview_create_info& operator=(
    render_pass_multiview_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _subpass_count = std::move(other._subpass_count);
    _view_masks = std::move(other._view_masks);
    _dependency_count = std::move(other._dependency_count);
    _view_offsets = std::move(other._view_offsets);
    _correlation_mask_count = std::move(other._correlation_mask_count);
    _correlation_masks = std::move(other._correlation_masks);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkRenderPassMultiviewCreateInfo&() const
  {
    return *reinterpret_cast<const VkRenderPassMultiviewCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& subpass_count()
  {
    return _subpass_count;
  }

  constexpr const uint32_t& subpass_count() const
  {
    return _subpass_count;
  }

  void subpass_count(uint32_t new_subpass_count)
  {
    _subpass_count = new_subpass_count;
  }

  const uint32_t* view_masks()
  {
    return _view_masks;
  }

  constexpr const uint32_t* view_masks() const
  {
    return _view_masks;
  }

  void view_masks(const uint32_t* new_view_masks)
  {
    _view_masks = new_view_masks;
  }

  template <std::size_t Count>
  void view_masks(const std::array<uint32_t, Count>& new_view_masks)
  {
    _subpass_count = static_cast<uint32_t>(new_view_masks.size());
    _view_masks = new_view_masks.data();
  }

  void view_masks(const std::vector<uint32_t>& new_view_masks)
  {
    _subpass_count = static_cast<uint32_t>(new_view_masks.size());
    _view_masks = new_view_masks.data();
  }

  uint32_t& dependency_count()
  {
    return _dependency_count;
  }

  constexpr const uint32_t& dependency_count() const
  {
    return _dependency_count;
  }

  void dependency_count(uint32_t new_dependency_count)
  {
    _dependency_count = new_dependency_count;
  }

  const int32_t* view_offsets()
  {
    return _view_offsets;
  }

  constexpr const int32_t* view_offsets() const
  {
    return _view_offsets;
  }

  void view_offsets(const int32_t* new_view_offsets)
  {
    _view_offsets = new_view_offsets;
  }

  template <std::size_t Count>
  void view_offsets(const std::array<int32_t, Count>& new_view_offsets)
  {
    _dependency_count = static_cast<uint32_t>(new_view_offsets.size());
    _view_offsets = new_view_offsets.data();
  }

  void view_offsets(const std::vector<int32_t>& new_view_offsets)
  {
    _dependency_count = static_cast<uint32_t>(new_view_offsets.size());
    _view_offsets = new_view_offsets.data();
  }

  uint32_t& correlation_mask_count()
  {
    return _correlation_mask_count;
  }

  constexpr const uint32_t& correlation_mask_count() const
  {
    return _correlation_mask_count;
  }

  void correlation_mask_count(uint32_t new_correlation_mask_count)
  {
    _correlation_mask_count = new_correlation_mask_count;
  }

  const uint32_t* correlation_masks()
  {
    return _correlation_masks;
  }

  constexpr const uint32_t* correlation_masks() const
  {
    return _correlation_masks;
  }

  void correlation_masks(const uint32_t* new_correlation_masks)
  {
    _correlation_masks = new_correlation_masks;
  }

  template <std::size_t Count>
  void correlation_masks(
    const std::array<uint32_t, Count>& new_correlation_masks)
  {
    _correlation_mask_count =
      static_cast<uint32_t>(new_correlation_masks.size());
    _correlation_masks = new_correlation_masks.data();
  }

  void correlation_masks(const std::vector<uint32_t>& new_correlation_masks)
  {
    _correlation_mask_count =
      static_cast<uint32_t>(new_correlation_masks.size());
    _correlation_masks = new_correlation_masks.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::render_pass_multiview_create_info;
  const void* _next = nullptr;
  uint32_t _subpass_count = 0;
  const uint32_t* _view_masks = nullptr;
  uint32_t _dependency_count = 0;
  const int32_t* _view_offsets = nullptr;
  uint32_t _correlation_mask_count = 0;
  const uint32_t* _correlation_masks = nullptr;
};
static_assert(sizeof(render_pass_multiview_create_info) ==
                sizeof(::VkRenderPassMultiviewCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceMultiviewFeatures.
class physical_device_multiview_features
{
public:
  /// Default constructor.
  constexpr physical_device_multiview_features() = default;

  /// Constructor.
  constexpr physical_device_multiview_features(
    void* initial_next, VkBool32 initial_multiview,
    VkBool32 initial_multiview_geometry_shader,
    VkBool32 initial_multiview_tessellation_shader) noexcept
  : _next(std::move(initial_next)),
    _multiview(std::move(initial_multiview)),
    _multiview_geometry_shader(std::move(initial_multiview_geometry_shader)),
    _multiview_tessellation_shader(
      std::move(initial_multiview_tessellation_shader))
  {
  }

  /// Copy constructor.
  constexpr physical_device_multiview_features(
    const physical_device_multiview_features& other) noexcept
  : _next(other._next),
    _multiview(other._multiview),
    _multiview_geometry_shader(other._multiview_geometry_shader),
    _multiview_tessellation_shader(other._multiview_tessellation_shader)
  {
  }

  /// Move constructor.
  constexpr physical_device_multiview_features(
    physical_device_multiview_features&& other) noexcept
  : _next(std::move(other._next)),
    _multiview(std::move(other._multiview)),
    _multiview_geometry_shader(std::move(other._multiview_geometry_shader)),
    _multiview_tessellation_shader(
      std::move(other._multiview_tessellation_shader))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_multiview_features& operator=(
    const physical_device_multiview_features& other) noexcept
  {
    _next = other._next;
    _multiview = other._multiview;
    _multiview_geometry_shader = other._multiview_geometry_shader;
    _multiview_tessellation_shader = other._multiview_tessellation_shader;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_multiview_features& operator=(
    physical_device_multiview_features&& other) noexcept
  {
    _next = std::move(other._next);
    _multiview = std::move(other._multiview);
    _multiview_geometry_shader = std::move(other._multiview_geometry_shader);
    _multiview_tessellation_shader =
      std::move(other._multiview_tessellation_shader);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceMultiviewFeatures&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceMultiviewFeatures*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& multiview()
  {
    return _multiview;
  }

  constexpr const VkBool32& multiview() const
  {
    return _multiview;
  }

  void multiview(VkBool32 new_multiview)
  {
    _multiview = new_multiview;
  }

  VkBool32& multiview_geometry_shader()
  {
    return _multiview_geometry_shader;
  }

  constexpr const VkBool32& multiview_geometry_shader() const
  {
    return _multiview_geometry_shader;
  }

  void multiview_geometry_shader(VkBool32 new_multiview_geometry_shader)
  {
    _multiview_geometry_shader = new_multiview_geometry_shader;
  }

  VkBool32& multiview_tessellation_shader()
  {
    return _multiview_tessellation_shader;
  }

  constexpr const VkBool32& multiview_tessellation_shader() const
  {
    return _multiview_tessellation_shader;
  }

  void multiview_tessellation_shader(VkBool32 new_multiview_tessellation_shader)
  {
    _multiview_tessellation_shader = new_multiview_tessellation_shader;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_multiview_features;
  void* _next = nullptr;
  /// Multiple views in a renderpass
  VkBool32 _multiview = VK_FALSE;
  /// Multiple views in a renderpass w/ geometry shader
  VkBool32 _multiview_geometry_shader = VK_FALSE;
  /// Multiple views in a renderpass w/ tessellation shader
  VkBool32 _multiview_tessellation_shader = VK_FALSE;
};
static_assert(sizeof(physical_device_multiview_features) ==
                sizeof(::VkPhysicalDeviceMultiviewFeatures),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceMultiviewProperties.
class physical_device_multiview_properties
{
public:
  /// Default constructor.
  constexpr physical_device_multiview_properties() = default;

  /// Constructor.
  constexpr physical_device_multiview_properties(
    void* initial_next, uint32_t initial_max_multiview_view_count,
    uint32_t initial_max_multiview_instance_index) noexcept
  : _next(std::move(initial_next)),
    _max_multiview_view_count(std::move(initial_max_multiview_view_count)),
    _max_multiview_instance_index(
      std::move(initial_max_multiview_instance_index))
  {
  }

  /// Copy constructor.
  constexpr physical_device_multiview_properties(
    const physical_device_multiview_properties& other) noexcept
  : _next(other._next),
    _max_multiview_view_count(other._max_multiview_view_count),
    _max_multiview_instance_index(other._max_multiview_instance_index)
  {
  }

  /// Move constructor.
  constexpr physical_device_multiview_properties(
    physical_device_multiview_properties&& other) noexcept
  : _next(std::move(other._next)),
    _max_multiview_view_count(std::move(other._max_multiview_view_count)),
    _max_multiview_instance_index(
      std::move(other._max_multiview_instance_index))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_multiview_properties& operator=(
    const physical_device_multiview_properties& other) noexcept
  {
    _next = other._next;
    _max_multiview_view_count = other._max_multiview_view_count;
    _max_multiview_instance_index = other._max_multiview_instance_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_multiview_properties& operator=(
    physical_device_multiview_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _max_multiview_view_count = std::move(other._max_multiview_view_count);
    _max_multiview_instance_index =
      std::move(other._max_multiview_instance_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceMultiviewProperties&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceMultiviewProperties*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_multiview_view_count()
  {
    return _max_multiview_view_count;
  }

  constexpr const uint32_t& max_multiview_view_count() const
  {
    return _max_multiview_view_count;
  }

  void max_multiview_view_count(uint32_t new_max_multiview_view_count)
  {
    _max_multiview_view_count = new_max_multiview_view_count;
  }

  uint32_t& max_multiview_instance_index()
  {
    return _max_multiview_instance_index;
  }

  constexpr const uint32_t& max_multiview_instance_index() const
  {
    return _max_multiview_instance_index;
  }

  void max_multiview_instance_index(uint32_t new_max_multiview_instance_index)
  {
    _max_multiview_instance_index = new_max_multiview_instance_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_multiview_properties;
  void* _next = nullptr;
  /// max number of views in a subpass
  uint32_t _max_multiview_view_count = 0;
  /// max instance index for a draw in a multiview subpass
  uint32_t _max_multiview_instance_index = 0;
};
static_assert(sizeof(physical_device_multiview_properties) ==
                sizeof(::VkPhysicalDeviceMultiviewProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceVariablePointerFeatures.
class physical_device_variable_pointer_features
{
public:
  /// Default constructor.
  constexpr physical_device_variable_pointer_features() = default;

  /// Constructor.
  constexpr physical_device_variable_pointer_features(
    void* initial_next, VkBool32 initial_variable_pointers_storage_buffer,
    VkBool32 initial_variable_pointers) noexcept
  : _next(std::move(initial_next)),
    _variable_pointers_storage_buffer(
      std::move(initial_variable_pointers_storage_buffer)),
    _variable_pointers(std::move(initial_variable_pointers))
  {
  }

  /// Copy constructor.
  constexpr physical_device_variable_pointer_features(
    const physical_device_variable_pointer_features& other) noexcept
  : _next(other._next),
    _variable_pointers_storage_buffer(other._variable_pointers_storage_buffer),
    _variable_pointers(other._variable_pointers)
  {
  }

  /// Move constructor.
  constexpr physical_device_variable_pointer_features(
    physical_device_variable_pointer_features&& other) noexcept
  : _next(std::move(other._next)),
    _variable_pointers_storage_buffer(
      std::move(other._variable_pointers_storage_buffer)),
    _variable_pointers(std::move(other._variable_pointers))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_variable_pointer_features& operator=(
    const physical_device_variable_pointer_features& other) noexcept
  {
    _next = other._next;
    _variable_pointers_storage_buffer = other._variable_pointers_storage_buffer;
    _variable_pointers = other._variable_pointers;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_variable_pointer_features& operator=(
    physical_device_variable_pointer_features&& other) noexcept
  {
    _next = std::move(other._next);
    _variable_pointers_storage_buffer =
      std::move(other._variable_pointers_storage_buffer);
    _variable_pointers = std::move(other._variable_pointers);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceVariablePointerFeatures&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceVariablePointerFeatures*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& variable_pointers_storage_buffer()
  {
    return _variable_pointers_storage_buffer;
  }

  constexpr const VkBool32& variable_pointers_storage_buffer() const
  {
    return _variable_pointers_storage_buffer;
  }

  void variable_pointers_storage_buffer(
    VkBool32 new_variable_pointers_storage_buffer)
  {
    _variable_pointers_storage_buffer = new_variable_pointers_storage_buffer;
  }

  VkBool32& variable_pointers()
  {
    return _variable_pointers;
  }

  constexpr const VkBool32& variable_pointers() const
  {
    return _variable_pointers;
  }

  void variable_pointers(VkBool32 new_variable_pointers)
  {
    _variable_pointers = new_variable_pointers;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_variable_pointer_features;
  void* _next = nullptr;
  VkBool32 _variable_pointers_storage_buffer = VK_FALSE;
  VkBool32 _variable_pointers = VK_FALSE;
};
static_assert(sizeof(physical_device_variable_pointer_features) ==
                sizeof(::VkPhysicalDeviceVariablePointerFeatures),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceProtectedMemoryFeatures.
class physical_device_protected_memory_features
{
public:
  /// Default constructor.
  constexpr physical_device_protected_memory_features() = default;

  /// Constructor.
  constexpr physical_device_protected_memory_features(
    void* initial_next, VkBool32 initial_protected_memory) noexcept
  : _next(std::move(initial_next)),
    _protected_memory(std::move(initial_protected_memory))
  {
  }

  /// Copy constructor.
  constexpr physical_device_protected_memory_features(
    const physical_device_protected_memory_features& other) noexcept
  : _next(other._next), _protected_memory(other._protected_memory)
  {
  }

  /// Move constructor.
  constexpr physical_device_protected_memory_features(
    physical_device_protected_memory_features&& other) noexcept
  : _next(std::move(other._next)),
    _protected_memory(std::move(other._protected_memory))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_protected_memory_features& operator=(
    const physical_device_protected_memory_features& other) noexcept
  {
    _next = other._next;
    _protected_memory = other._protected_memory;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_protected_memory_features& operator=(
    physical_device_protected_memory_features&& other) noexcept
  {
    _next = std::move(other._next);
    _protected_memory = std::move(other._protected_memory);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceProtectedMemoryFeatures&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceProtectedMemoryFeatures*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& protected_memory()
  {
    return _protected_memory;
  }

  constexpr const VkBool32& protected_memory() const
  {
    return _protected_memory;
  }

  void protected_memory(VkBool32 new_protected_memory)
  {
    _protected_memory = new_protected_memory;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_protected_memory_features;
  void* _next = nullptr;
  VkBool32 _protected_memory = VK_FALSE;
};
static_assert(sizeof(physical_device_protected_memory_features) ==
                sizeof(::VkPhysicalDeviceProtectedMemoryFeatures),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceProtectedMemoryProperties.
class physical_device_protected_memory_properties
{
public:
  /// Default constructor.
  constexpr physical_device_protected_memory_properties() = default;

  /// Constructor.
  constexpr physical_device_protected_memory_properties(
    void* initial_next, VkBool32 initial_protected_no_fault) noexcept
  : _next(std::move(initial_next)),
    _protected_no_fault(std::move(initial_protected_no_fault))
  {
  }

  /// Copy constructor.
  constexpr physical_device_protected_memory_properties(
    const physical_device_protected_memory_properties& other) noexcept
  : _next(other._next), _protected_no_fault(other._protected_no_fault)
  {
  }

  /// Move constructor.
  constexpr physical_device_protected_memory_properties(
    physical_device_protected_memory_properties&& other) noexcept
  : _next(std::move(other._next)),
    _protected_no_fault(std::move(other._protected_no_fault))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_protected_memory_properties& operator=(
    const physical_device_protected_memory_properties& other) noexcept
  {
    _next = other._next;
    _protected_no_fault = other._protected_no_fault;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_protected_memory_properties& operator=(
    physical_device_protected_memory_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _protected_no_fault = std::move(other._protected_no_fault);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceProtectedMemoryProperties&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceProtectedMemoryProperties*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& protected_no_fault()
  {
    return _protected_no_fault;
  }

  constexpr const VkBool32& protected_no_fault() const
  {
    return _protected_no_fault;
  }

  void protected_no_fault(VkBool32 new_protected_no_fault)
  {
    _protected_no_fault = new_protected_no_fault;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_protected_memory_properties;
  void* _next = nullptr;
  VkBool32 _protected_no_fault = VK_FALSE;
};
static_assert(sizeof(physical_device_protected_memory_properties) ==
                sizeof(::VkPhysicalDeviceProtectedMemoryProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceQueueInfo2.
class device_queue_info_2
{
public:
  /// Default constructor.
  constexpr device_queue_info_2() = default;

  /// Constructor.
  constexpr device_queue_info_2(const void* initial_next,
                                vk::device_queue_create_flags initial_flags,
                                uint32_t initial_queue_family_index,
                                uint32_t initial_queue_index) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _queue_family_index(std::move(initial_queue_family_index)),
    _queue_index(std::move(initial_queue_index))
  {
  }

  /// Copy constructor.
  constexpr device_queue_info_2(const device_queue_info_2& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _queue_family_index(other._queue_family_index),
    _queue_index(other._queue_index)
  {
  }

  /// Move constructor.
  constexpr device_queue_info_2(device_queue_info_2&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _queue_family_index(std::move(other._queue_family_index)),
    _queue_index(std::move(other._queue_index))
  {
  }

  /// Copy assignment operator.
  constexpr device_queue_info_2& operator=(
    const device_queue_info_2& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _queue_family_index = other._queue_family_index;
    _queue_index = other._queue_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_queue_info_2& operator=(device_queue_info_2&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _queue_family_index = std::move(other._queue_family_index);
    _queue_index = std::move(other._queue_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceQueueInfo2&() const
  {
    return *reinterpret_cast<const VkDeviceQueueInfo2*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::device_queue_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::device_queue_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::device_queue_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& queue_family_index()
  {
    return _queue_family_index;
  }

  constexpr const uint32_t& queue_family_index() const
  {
    return _queue_family_index;
  }

  void queue_family_index(uint32_t new_queue_family_index)
  {
    _queue_family_index = new_queue_family_index;
  }

  uint32_t& queue_index()
  {
    return _queue_index;
  }

  constexpr const uint32_t& queue_index() const
  {
    return _queue_index;
  }

  void queue_index(uint32_t new_queue_index)
  {
    _queue_index = new_queue_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_queue_info_2;
  const void* _next = nullptr;
  vk::device_queue_create_flags _flags = vk::device_queue_create_flag::none;
  uint32_t _queue_family_index = 0;
  uint32_t _queue_index = 0;
};
static_assert(sizeof(device_queue_info_2) == sizeof(::VkDeviceQueueInfo2),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkProtectedSubmitInfo.
class protected_submit_info
{
public:
  /// Default constructor.
  constexpr protected_submit_info() = default;

  /// Constructor.
  constexpr protected_submit_info(const void* initial_next,
                                  VkBool32 initial_protected_submit) noexcept
  : _next(std::move(initial_next)),
    _protected_submit(std::move(initial_protected_submit))
  {
  }

  /// Copy constructor.
  constexpr protected_submit_info(const protected_submit_info& other) noexcept
  : _next(other._next), _protected_submit(other._protected_submit)
  {
  }

  /// Move constructor.
  constexpr protected_submit_info(protected_submit_info&& other) noexcept
  : _next(std::move(other._next)),
    _protected_submit(std::move(other._protected_submit))
  {
  }

  /// Copy assignment operator.
  constexpr protected_submit_info& operator=(
    const protected_submit_info& other) noexcept
  {
    _next = other._next;
    _protected_submit = other._protected_submit;
    return *this;
  }

  /// Move assignment operator.
  constexpr protected_submit_info& operator=(
    protected_submit_info&& other) noexcept
  {
    _next = std::move(other._next);
    _protected_submit = std::move(other._protected_submit);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkProtectedSubmitInfo&() const
  {
    return *reinterpret_cast<const VkProtectedSubmitInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& protected_submit()
  {
    return _protected_submit;
  }

  constexpr const VkBool32& protected_submit() const
  {
    return _protected_submit;
  }

  void protected_submit(VkBool32 new_protected_submit)
  {
    _protected_submit = new_protected_submit;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::protected_submit_info;
  const void* _next = nullptr;
  /// Submit protected command buffers
  VkBool32 _protected_submit = VK_FALSE;
};
static_assert(sizeof(protected_submit_info) == sizeof(::VkProtectedSubmitInfo),
              "struct and wrapper have different size!");

enum class sampler_ycbcr_model_conversion
{
  /// @see VK_SAMPLER_YCBCR_MODEL_CONVERSION_RGB_IDENTITY
  rgb_identity = 0,
  /// just range expansion
  /// @see VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_IDENTITY
  ycbcr_identity = 1,
  /// aka HD YUV
  /// @see VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_709
  ycbcr_709 = 2,
  /// aka SD YUV
  /// @see VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_601
  ycbcr_601 = 3,
  /// aka UHD YUV
  /// @see VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_2020
  ycbcr_2020 = 4,
};
enum class sampler_ycbcr_range
{
  /// Luma 0..1 maps to 0..255, chroma -0.5..0.5 to 1..255 (clamped)
  /// @see VK_SAMPLER_YCBCR_RANGE_ITU_FULL
  itu_full = 0,
  /// Luma 0..1 maps to 16..235, chroma -0.5..0.5 to 16..240
  /// @see VK_SAMPLER_YCBCR_RANGE_ITU_NARROW
  itu_narrow = 1,
};
enum class chroma_location
{
  /// @see VK_CHROMA_LOCATION_COSITED_EVEN
  cosited_even = 0,
  /// @see VK_CHROMA_LOCATION_MIDPOINT
  midpoint = 1,
};

/// Enhanced replacement type for VkSamplerYcbcrConversionCreateInfo.
class sampler_ycbcr_conversion_create_info
{
public:
  /// Default constructor.
  constexpr sampler_ycbcr_conversion_create_info() = default;

  /// Constructor.
  constexpr sampler_ycbcr_conversion_create_info(
    const void* initial_next, vk::format initial_format,
    vk::sampler_ycbcr_model_conversion initial_ycbcr_model,
    vk::sampler_ycbcr_range initial_ycbcr_range,
    vk::component_mapping initial_components,
    vk::chroma_location initial_x_chroma_offset,
    vk::chroma_location initial_y_chroma_offset,
    vk::filter initial_chroma_filter,
    VkBool32 initial_force_explicit_reconstruction) noexcept
  : _next(std::move(initial_next)),
    _format(std::move(initial_format)),
    _ycbcr_model(std::move(initial_ycbcr_model)),
    _ycbcr_range(std::move(initial_ycbcr_range)),
    _components(std::move(initial_components)),
    _x_chroma_offset(std::move(initial_x_chroma_offset)),
    _y_chroma_offset(std::move(initial_y_chroma_offset)),
    _chroma_filter(std::move(initial_chroma_filter)),
    _force_explicit_reconstruction(
      std::move(initial_force_explicit_reconstruction))
  {
  }

  /// Copy constructor.
  constexpr sampler_ycbcr_conversion_create_info(
    const sampler_ycbcr_conversion_create_info& other) noexcept
  : _next(other._next),
    _format(other._format),
    _ycbcr_model(other._ycbcr_model),
    _ycbcr_range(other._ycbcr_range),
    _components(other._components),
    _x_chroma_offset(other._x_chroma_offset),
    _y_chroma_offset(other._y_chroma_offset),
    _chroma_filter(other._chroma_filter),
    _force_explicit_reconstruction(other._force_explicit_reconstruction)
  {
  }

  /// Move constructor.
  constexpr sampler_ycbcr_conversion_create_info(
    sampler_ycbcr_conversion_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _format(std::move(other._format)),
    _ycbcr_model(std::move(other._ycbcr_model)),
    _ycbcr_range(std::move(other._ycbcr_range)),
    _components(std::move(other._components)),
    _x_chroma_offset(std::move(other._x_chroma_offset)),
    _y_chroma_offset(std::move(other._y_chroma_offset)),
    _chroma_filter(std::move(other._chroma_filter)),
    _force_explicit_reconstruction(
      std::move(other._force_explicit_reconstruction))
  {
  }

  /// Copy assignment operator.
  constexpr sampler_ycbcr_conversion_create_info& operator=(
    const sampler_ycbcr_conversion_create_info& other) noexcept
  {
    _next = other._next;
    _format = other._format;
    _ycbcr_model = other._ycbcr_model;
    _ycbcr_range = other._ycbcr_range;
    _components = other._components;
    _x_chroma_offset = other._x_chroma_offset;
    _y_chroma_offset = other._y_chroma_offset;
    _chroma_filter = other._chroma_filter;
    _force_explicit_reconstruction = other._force_explicit_reconstruction;
    return *this;
  }

  /// Move assignment operator.
  constexpr sampler_ycbcr_conversion_create_info& operator=(
    sampler_ycbcr_conversion_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _format = std::move(other._format);
    _ycbcr_model = std::move(other._ycbcr_model);
    _ycbcr_range = std::move(other._ycbcr_range);
    _components = std::move(other._components);
    _x_chroma_offset = std::move(other._x_chroma_offset);
    _y_chroma_offset = std::move(other._y_chroma_offset);
    _chroma_filter = std::move(other._chroma_filter);
    _force_explicit_reconstruction =
      std::move(other._force_explicit_reconstruction);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSamplerYcbcrConversionCreateInfo&() const
  {
    return *reinterpret_cast<const VkSamplerYcbcrConversionCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  vk::sampler_ycbcr_model_conversion& ycbcr_model()
  {
    return _ycbcr_model;
  }

  constexpr const vk::sampler_ycbcr_model_conversion& ycbcr_model() const
  {
    return _ycbcr_model;
  }

  void ycbcr_model(vk::sampler_ycbcr_model_conversion new_ycbcr_model)
  {
    _ycbcr_model = new_ycbcr_model;
  }

  vk::sampler_ycbcr_range& ycbcr_range()
  {
    return _ycbcr_range;
  }

  constexpr const vk::sampler_ycbcr_range& ycbcr_range() const
  {
    return _ycbcr_range;
  }

  void ycbcr_range(vk::sampler_ycbcr_range new_ycbcr_range)
  {
    _ycbcr_range = new_ycbcr_range;
  }

  vk::component_mapping& components()
  {
    return _components;
  }

  constexpr const vk::component_mapping& components() const
  {
    return _components;
  }

  void components(vk::component_mapping new_components)
  {
    _components = new_components;
  }

  vk::chroma_location& x_chroma_offset()
  {
    return _x_chroma_offset;
  }

  constexpr const vk::chroma_location& x_chroma_offset() const
  {
    return _x_chroma_offset;
  }

  void x_chroma_offset(vk::chroma_location new_x_chroma_offset)
  {
    _x_chroma_offset = new_x_chroma_offset;
  }

  vk::chroma_location& y_chroma_offset()
  {
    return _y_chroma_offset;
  }

  constexpr const vk::chroma_location& y_chroma_offset() const
  {
    return _y_chroma_offset;
  }

  void y_chroma_offset(vk::chroma_location new_y_chroma_offset)
  {
    _y_chroma_offset = new_y_chroma_offset;
  }

  vk::filter& chroma_filter()
  {
    return _chroma_filter;
  }

  constexpr const vk::filter& chroma_filter() const
  {
    return _chroma_filter;
  }

  void chroma_filter(vk::filter new_chroma_filter)
  {
    _chroma_filter = new_chroma_filter;
  }

  VkBool32& force_explicit_reconstruction()
  {
    return _force_explicit_reconstruction;
  }

  constexpr const VkBool32& force_explicit_reconstruction() const
  {
    return _force_explicit_reconstruction;
  }

  void force_explicit_reconstruction(VkBool32 new_force_explicit_reconstruction)
  {
    _force_explicit_reconstruction = new_force_explicit_reconstruction;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::sampler_ycbcr_conversion_create_info;
  const void* _next = nullptr;
  vk::format _format = vk::format::undefined;
  vk::sampler_ycbcr_model_conversion _ycbcr_model =
    vk::sampler_ycbcr_model_conversion::rgb_identity;
  vk::sampler_ycbcr_range _ycbcr_range = vk::sampler_ycbcr_range::itu_full;
  vk::component_mapping _components = vk::component_mapping{};
  vk::chroma_location _x_chroma_offset = vk::chroma_location::cosited_even;
  vk::chroma_location _y_chroma_offset = vk::chroma_location::cosited_even;
  vk::filter _chroma_filter = vk::filter::nearest;
  VkBool32 _force_explicit_reconstruction = VK_FALSE;
};
static_assert(sizeof(sampler_ycbcr_conversion_create_info) ==
                sizeof(::VkSamplerYcbcrConversionCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSamplerYcbcrConversionInfo.
class sampler_ycbcr_conversion_info
{
public:
  /// Default constructor.
  constexpr sampler_ycbcr_conversion_info() = default;

  /// Constructor.
  constexpr sampler_ycbcr_conversion_info(
    const void* initial_next,
    VkSamplerYcbcrConversion initial_conversion) noexcept
  : _next(std::move(initial_next)), _conversion(std::move(initial_conversion))
  {
  }

  /// Copy constructor.
  constexpr sampler_ycbcr_conversion_info(
    const sampler_ycbcr_conversion_info& other) noexcept
  : _next(other._next), _conversion(other._conversion)
  {
  }

  /// Move constructor.
  constexpr sampler_ycbcr_conversion_info(
    sampler_ycbcr_conversion_info&& other) noexcept
  : _next(std::move(other._next)), _conversion(std::move(other._conversion))
  {
  }

  /// Copy assignment operator.
  constexpr sampler_ycbcr_conversion_info& operator=(
    const sampler_ycbcr_conversion_info& other) noexcept
  {
    _next = other._next;
    _conversion = other._conversion;
    return *this;
  }

  /// Move assignment operator.
  constexpr sampler_ycbcr_conversion_info& operator=(
    sampler_ycbcr_conversion_info&& other) noexcept
  {
    _next = std::move(other._next);
    _conversion = std::move(other._conversion);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSamplerYcbcrConversionInfo&() const
  {
    return *reinterpret_cast<const VkSamplerYcbcrConversionInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkSamplerYcbcrConversion& conversion()
  {
    return _conversion;
  }

  constexpr const VkSamplerYcbcrConversion& conversion() const
  {
    return _conversion;
  }

  void conversion(VkSamplerYcbcrConversion new_conversion)
  {
    _conversion = new_conversion;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::sampler_ycbcr_conversion_info;
  const void* _next = nullptr;
  VkSamplerYcbcrConversion _conversion = nullptr;
};
static_assert(sizeof(sampler_ycbcr_conversion_info) ==
                sizeof(::VkSamplerYcbcrConversionInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkBindImagePlaneMemoryInfo.
class bind_image_plane_memory_info
{
public:
  /// Default constructor.
  constexpr bind_image_plane_memory_info() = default;

  /// Constructor.
  constexpr bind_image_plane_memory_info(
    const void* initial_next,
    vk::image_aspect_flag initial_plane_aspect) noexcept
  : _next(std::move(initial_next)),
    _plane_aspect(std::move(initial_plane_aspect))
  {
  }

  /// Copy constructor.
  constexpr bind_image_plane_memory_info(
    const bind_image_plane_memory_info& other) noexcept
  : _next(other._next), _plane_aspect(other._plane_aspect)
  {
  }

  /// Move constructor.
  constexpr bind_image_plane_memory_info(
    bind_image_plane_memory_info&& other) noexcept
  : _next(std::move(other._next)), _plane_aspect(std::move(other._plane_aspect))
  {
  }

  /// Copy assignment operator.
  constexpr bind_image_plane_memory_info& operator=(
    const bind_image_plane_memory_info& other) noexcept
  {
    _next = other._next;
    _plane_aspect = other._plane_aspect;
    return *this;
  }

  /// Move assignment operator.
  constexpr bind_image_plane_memory_info& operator=(
    bind_image_plane_memory_info&& other) noexcept
  {
    _next = std::move(other._next);
    _plane_aspect = std::move(other._plane_aspect);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBindImagePlaneMemoryInfo&() const
  {
    return *reinterpret_cast<const VkBindImagePlaneMemoryInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::image_aspect_flag& plane_aspect()
  {
    return _plane_aspect;
  }

  constexpr const vk::image_aspect_flag& plane_aspect() const
  {
    return _plane_aspect;
  }

  void plane_aspect(vk::image_aspect_flag new_plane_aspect)
  {
    _plane_aspect = new_plane_aspect;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::bind_image_plane_memory_info;
  const void* _next = nullptr;
  vk::image_aspect_flag _plane_aspect = vk::image_aspect_flag::none;
};
static_assert(sizeof(bind_image_plane_memory_info) ==
                sizeof(::VkBindImagePlaneMemoryInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImagePlaneMemoryRequirementsInfo.
class image_plane_memory_requirements_info
{
public:
  /// Default constructor.
  constexpr image_plane_memory_requirements_info() = default;

  /// Constructor.
  constexpr image_plane_memory_requirements_info(
    const void* initial_next,
    vk::image_aspect_flag initial_plane_aspect) noexcept
  : _next(std::move(initial_next)),
    _plane_aspect(std::move(initial_plane_aspect))
  {
  }

  /// Copy constructor.
  constexpr image_plane_memory_requirements_info(
    const image_plane_memory_requirements_info& other) noexcept
  : _next(other._next), _plane_aspect(other._plane_aspect)
  {
  }

  /// Move constructor.
  constexpr image_plane_memory_requirements_info(
    image_plane_memory_requirements_info&& other) noexcept
  : _next(std::move(other._next)), _plane_aspect(std::move(other._plane_aspect))
  {
  }

  /// Copy assignment operator.
  constexpr image_plane_memory_requirements_info& operator=(
    const image_plane_memory_requirements_info& other) noexcept
  {
    _next = other._next;
    _plane_aspect = other._plane_aspect;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_plane_memory_requirements_info& operator=(
    image_plane_memory_requirements_info&& other) noexcept
  {
    _next = std::move(other._next);
    _plane_aspect = std::move(other._plane_aspect);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImagePlaneMemoryRequirementsInfo&() const
  {
    return *reinterpret_cast<const VkImagePlaneMemoryRequirementsInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::image_aspect_flag& plane_aspect()
  {
    return _plane_aspect;
  }

  constexpr const vk::image_aspect_flag& plane_aspect() const
  {
    return _plane_aspect;
  }

  void plane_aspect(vk::image_aspect_flag new_plane_aspect)
  {
    _plane_aspect = new_plane_aspect;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_plane_memory_requirements_info;
  const void* _next = nullptr;
  vk::image_aspect_flag _plane_aspect = vk::image_aspect_flag::none;
};
static_assert(sizeof(image_plane_memory_requirements_info) ==
                sizeof(::VkImagePlaneMemoryRequirementsInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceSamplerYcbcrConversionFeatures.
class physical_device_sampler_ycbcr_conversion_features
{
public:
  /// Default constructor.
  constexpr physical_device_sampler_ycbcr_conversion_features() = default;

  /// Constructor.
  constexpr physical_device_sampler_ycbcr_conversion_features(
    void* initial_next, VkBool32 initial_sampler_ycbcr_conversion) noexcept
  : _next(std::move(initial_next)),
    _sampler_ycbcr_conversion(std::move(initial_sampler_ycbcr_conversion))
  {
  }

  /// Copy constructor.
  constexpr physical_device_sampler_ycbcr_conversion_features(
    const physical_device_sampler_ycbcr_conversion_features& other) noexcept
  : _next(other._next),
    _sampler_ycbcr_conversion(other._sampler_ycbcr_conversion)
  {
  }

  /// Move constructor.
  constexpr physical_device_sampler_ycbcr_conversion_features(
    physical_device_sampler_ycbcr_conversion_features&& other) noexcept
  : _next(std::move(other._next)),
    _sampler_ycbcr_conversion(std::move(other._sampler_ycbcr_conversion))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_sampler_ycbcr_conversion_features& operator=(
    const physical_device_sampler_ycbcr_conversion_features& other) noexcept
  {
    _next = other._next;
    _sampler_ycbcr_conversion = other._sampler_ycbcr_conversion;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_sampler_ycbcr_conversion_features& operator=(
    physical_device_sampler_ycbcr_conversion_features&& other) noexcept
  {
    _next = std::move(other._next);
    _sampler_ycbcr_conversion = std::move(other._sampler_ycbcr_conversion);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceSamplerYcbcrConversionFeatures&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceSamplerYcbcrConversionFeatures*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& sampler_ycbcr_conversion()
  {
    return _sampler_ycbcr_conversion;
  }

  constexpr const VkBool32& sampler_ycbcr_conversion() const
  {
    return _sampler_ycbcr_conversion;
  }

  void sampler_ycbcr_conversion(VkBool32 new_sampler_ycbcr_conversion)
  {
    _sampler_ycbcr_conversion = new_sampler_ycbcr_conversion;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_sampler_ycbcr_conversion_features;
  void* _next = nullptr;
  /// Sampler color conversion supported
  VkBool32 _sampler_ycbcr_conversion = VK_FALSE;
};
static_assert(sizeof(physical_device_sampler_ycbcr_conversion_features) ==
                sizeof(::VkPhysicalDeviceSamplerYcbcrConversionFeatures),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSamplerYcbcrConversionImageFormatProperties.
class sampler_ycbcr_conversion_image_format_properties
{
public:
  /// Default constructor.
  constexpr sampler_ycbcr_conversion_image_format_properties() = default;

  /// Constructor.
  constexpr sampler_ycbcr_conversion_image_format_properties(
    void* initial_next,
    uint32_t initial_combined_image_sampler_descriptor_count) noexcept
  : _next(std::move(initial_next)),
    _combined_image_sampler_descriptor_count(
      std::move(initial_combined_image_sampler_descriptor_count))
  {
  }

  /// Copy constructor.
  constexpr sampler_ycbcr_conversion_image_format_properties(
    const sampler_ycbcr_conversion_image_format_properties& other) noexcept
  : _next(other._next),
    _combined_image_sampler_descriptor_count(
      other._combined_image_sampler_descriptor_count)
  {
  }

  /// Move constructor.
  constexpr sampler_ycbcr_conversion_image_format_properties(
    sampler_ycbcr_conversion_image_format_properties&& other) noexcept
  : _next(std::move(other._next)),
    _combined_image_sampler_descriptor_count(
      std::move(other._combined_image_sampler_descriptor_count))
  {
  }

  /// Copy assignment operator.
  constexpr sampler_ycbcr_conversion_image_format_properties& operator=(
    const sampler_ycbcr_conversion_image_format_properties& other) noexcept
  {
    _next = other._next;
    _combined_image_sampler_descriptor_count =
      other._combined_image_sampler_descriptor_count;
    return *this;
  }

  /// Move assignment operator.
  constexpr sampler_ycbcr_conversion_image_format_properties& operator=(
    sampler_ycbcr_conversion_image_format_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _combined_image_sampler_descriptor_count =
      std::move(other._combined_image_sampler_descriptor_count);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSamplerYcbcrConversionImageFormatProperties&() const
  {
    return *reinterpret_cast<
      const VkSamplerYcbcrConversionImageFormatProperties*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& combined_image_sampler_descriptor_count()
  {
    return _combined_image_sampler_descriptor_count;
  }

  constexpr const uint32_t& combined_image_sampler_descriptor_count() const
  {
    return _combined_image_sampler_descriptor_count;
  }

  void combined_image_sampler_descriptor_count(
    uint32_t new_combined_image_sampler_descriptor_count)
  {
    _combined_image_sampler_descriptor_count =
      new_combined_image_sampler_descriptor_count;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::sampler_ycbcr_conversion_image_format_properties;
  void* _next = nullptr;
  uint32_t _combined_image_sampler_descriptor_count = 0;
};
static_assert(sizeof(sampler_ycbcr_conversion_image_format_properties) ==
                sizeof(::VkSamplerYcbcrConversionImageFormatProperties),
              "struct and wrapper have different size!");

using descriptor_update_template_create_flags = VkFlags;
enum class descriptor_update_template_type
{
  /// Create descriptor update template for descriptor set updates
  /// @see VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_DESCRIPTOR_SET
  descriptor_set = 0,
  /// Create descriptor update template for pushed descriptor updates
  /// @see VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_PUSH_DESCRIPTORS_KHR
  push_descriptors_khr = 1,
};

/// Enhanced replacement type for VkDescriptorUpdateTemplateEntry.
class descriptor_update_template_entry
{
public:
  /// Default constructor.
  constexpr descriptor_update_template_entry() = default;

  /// Constructor.
  constexpr descriptor_update_template_entry(
    uint32_t initial_dst_binding, uint32_t initial_dst_array_element,
    uint32_t initial_descriptor_count,
    vk::descriptor_type initial_descriptor_type, size_t initial_offset,
    size_t initial_stride) noexcept
  : _dst_binding(std::move(initial_dst_binding)),
    _dst_array_element(std::move(initial_dst_array_element)),
    _descriptor_count(std::move(initial_descriptor_count)),
    _descriptor_type(std::move(initial_descriptor_type)),
    _offset(std::move(initial_offset)),
    _stride(std::move(initial_stride))
  {
  }

  /// Copy constructor.
  constexpr descriptor_update_template_entry(
    const descriptor_update_template_entry& other) = default;

  /// Move constructor.
  constexpr descriptor_update_template_entry(
    descriptor_update_template_entry&& other) = default;

  /// Copy assignment operator.
  constexpr descriptor_update_template_entry& operator=(
    const descriptor_update_template_entry& other) = default;

  /// Move assignment operator.
  constexpr descriptor_update_template_entry& operator=(
    descriptor_update_template_entry&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorUpdateTemplateEntry&() const
  {
    return *reinterpret_cast<const VkDescriptorUpdateTemplateEntry*>(this);
  }

  uint32_t& dst_binding()
  {
    return _dst_binding;
  }

  constexpr const uint32_t& dst_binding() const
  {
    return _dst_binding;
  }

  void dst_binding(uint32_t new_dst_binding)
  {
    _dst_binding = new_dst_binding;
  }

  uint32_t& dst_array_element()
  {
    return _dst_array_element;
  }

  constexpr const uint32_t& dst_array_element() const
  {
    return _dst_array_element;
  }

  void dst_array_element(uint32_t new_dst_array_element)
  {
    _dst_array_element = new_dst_array_element;
  }

  uint32_t& descriptor_count()
  {
    return _descriptor_count;
  }

  constexpr const uint32_t& descriptor_count() const
  {
    return _descriptor_count;
  }

  void descriptor_count(uint32_t new_descriptor_count)
  {
    _descriptor_count = new_descriptor_count;
  }

  vk::descriptor_type& descriptor_type()
  {
    return _descriptor_type;
  }

  constexpr const vk::descriptor_type& descriptor_type() const
  {
    return _descriptor_type;
  }

  void descriptor_type(vk::descriptor_type new_descriptor_type)
  {
    _descriptor_type = new_descriptor_type;
  }

  size_t& offset()
  {
    return _offset;
  }

  constexpr const size_t& offset() const
  {
    return _offset;
  }

  void offset(size_t new_offset)
  {
    _offset = new_offset;
  }

  size_t& stride()
  {
    return _stride;
  }

  constexpr const size_t& stride() const
  {
    return _stride;
  }

  void stride(size_t new_stride)
  {
    _stride = new_stride;
  }

private:
  /// Binding within the destination descriptor set to write
  uint32_t _dst_binding = 0;
  /// Array element within the destination binding to write
  uint32_t _dst_array_element = 0;
  /// Number of descriptors to write
  uint32_t _descriptor_count = 0;
  /// Descriptor type to write
  vk::descriptor_type _descriptor_type = vk::descriptor_type::sampler;
  /// Offset into pData where the descriptors to update are stored
  size_t _offset = 0;
  /// Stride between two descriptors in pData when writing more than one
  /// descriptor
  size_t _stride = 0;
};
static_assert(sizeof(descriptor_update_template_entry) ==
                sizeof(::VkDescriptorUpdateTemplateEntry),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDescriptorUpdateTemplateCreateInfo.
class descriptor_update_template_create_info
{
public:
  /// Default constructor.
  constexpr descriptor_update_template_create_info() = default;

  /// Constructor.
  constexpr descriptor_update_template_create_info(
    void* initial_next,
    vk::descriptor_update_template_create_flags initial_flags,
    uint32_t initial_descriptor_update_entry_count,
    const vk::descriptor_update_template_entry*
      initial_descriptor_update_entries,
    vk::descriptor_update_template_type initial_template_type,
    VkDescriptorSetLayout initial_descriptor_set_layout,
    vk::pipeline_bind_point initial_pipeline_bind_point,
    VkPipelineLayout initial_pipeline_layout, uint32_t initial_set) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _descriptor_update_entry_count(
      std::move(initial_descriptor_update_entry_count)),
    _descriptor_update_entries(std::move(initial_descriptor_update_entries)),
    _template_type(std::move(initial_template_type)),
    _descriptor_set_layout(std::move(initial_descriptor_set_layout)),
    _pipeline_bind_point(std::move(initial_pipeline_bind_point)),
    _pipeline_layout(std::move(initial_pipeline_layout)),
    _set(std::move(initial_set))
  {
  }

  /// Copy constructor.
  constexpr descriptor_update_template_create_info(
    const descriptor_update_template_create_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _descriptor_update_entry_count(other._descriptor_update_entry_count),
    _descriptor_update_entries(other._descriptor_update_entries),
    _template_type(other._template_type),
    _descriptor_set_layout(other._descriptor_set_layout),
    _pipeline_bind_point(other._pipeline_bind_point),
    _pipeline_layout(other._pipeline_layout),
    _set(other._set)
  {
  }

  /// Move constructor.
  constexpr descriptor_update_template_create_info(
    descriptor_update_template_create_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _descriptor_update_entry_count(
      std::move(other._descriptor_update_entry_count)),
    _descriptor_update_entries(std::move(other._descriptor_update_entries)),
    _template_type(std::move(other._template_type)),
    _descriptor_set_layout(std::move(other._descriptor_set_layout)),
    _pipeline_bind_point(std::move(other._pipeline_bind_point)),
    _pipeline_layout(std::move(other._pipeline_layout)),
    _set(std::move(other._set))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_update_template_create_info& operator=(
    const descriptor_update_template_create_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _descriptor_update_entry_count = other._descriptor_update_entry_count;
    _descriptor_update_entries = other._descriptor_update_entries;
    _template_type = other._template_type;
    _descriptor_set_layout = other._descriptor_set_layout;
    _pipeline_bind_point = other._pipeline_bind_point;
    _pipeline_layout = other._pipeline_layout;
    _set = other._set;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_update_template_create_info& operator=(
    descriptor_update_template_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _descriptor_update_entry_count =
      std::move(other._descriptor_update_entry_count);
    _descriptor_update_entries = std::move(other._descriptor_update_entries);
    _template_type = std::move(other._template_type);
    _descriptor_set_layout = std::move(other._descriptor_set_layout);
    _pipeline_bind_point = std::move(other._pipeline_bind_point);
    _pipeline_layout = std::move(other._pipeline_layout);
    _set = std::move(other._set);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorUpdateTemplateCreateInfo&() const
  {
    return *reinterpret_cast<const VkDescriptorUpdateTemplateCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::descriptor_update_template_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::descriptor_update_template_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::descriptor_update_template_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& descriptor_update_entry_count()
  {
    return _descriptor_update_entry_count;
  }

  constexpr const uint32_t& descriptor_update_entry_count() const
  {
    return _descriptor_update_entry_count;
  }

  void descriptor_update_entry_count(uint32_t new_descriptor_update_entry_count)
  {
    _descriptor_update_entry_count = new_descriptor_update_entry_count;
  }

  const vk::descriptor_update_template_entry* descriptor_update_entries()
  {
    return _descriptor_update_entries;
  }

  constexpr const vk::descriptor_update_template_entry*
  descriptor_update_entries() const
  {
    return _descriptor_update_entries;
  }

  void descriptor_update_entries(
    const vk::descriptor_update_template_entry* new_descriptor_update_entries)
  {
    _descriptor_update_entries = new_descriptor_update_entries;
  }

  template <std::size_t Count>
  void descriptor_update_entries(
    const std::array<vk::descriptor_update_template_entry, Count>&
      new_descriptor_update_entries)
  {
    _descriptor_update_entry_count =
      static_cast<uint32_t>(new_descriptor_update_entries.size());
    _descriptor_update_entries = new_descriptor_update_entries.data();
  }

  void descriptor_update_entries(
    const std::vector<vk::descriptor_update_template_entry>&
      new_descriptor_update_entries)
  {
    _descriptor_update_entry_count =
      static_cast<uint32_t>(new_descriptor_update_entries.size());
    _descriptor_update_entries = new_descriptor_update_entries.data();
  }

  vk::descriptor_update_template_type& template_type()
  {
    return _template_type;
  }

  constexpr const vk::descriptor_update_template_type& template_type() const
  {
    return _template_type;
  }

  void template_type(vk::descriptor_update_template_type new_template_type)
  {
    _template_type = new_template_type;
  }

  VkDescriptorSetLayout& descriptor_set_layout()
  {
    return _descriptor_set_layout;
  }

  constexpr const VkDescriptorSetLayout& descriptor_set_layout() const
  {
    return _descriptor_set_layout;
  }

  void descriptor_set_layout(VkDescriptorSetLayout new_descriptor_set_layout)
  {
    _descriptor_set_layout = new_descriptor_set_layout;
  }

  vk::pipeline_bind_point& pipeline_bind_point()
  {
    return _pipeline_bind_point;
  }

  constexpr const vk::pipeline_bind_point& pipeline_bind_point() const
  {
    return _pipeline_bind_point;
  }

  void pipeline_bind_point(vk::pipeline_bind_point new_pipeline_bind_point)
  {
    _pipeline_bind_point = new_pipeline_bind_point;
  }

  VkPipelineLayout& pipeline_layout()
  {
    return _pipeline_layout;
  }

  constexpr const VkPipelineLayout& pipeline_layout() const
  {
    return _pipeline_layout;
  }

  void pipeline_layout(VkPipelineLayout new_pipeline_layout)
  {
    _pipeline_layout = new_pipeline_layout;
  }

  uint32_t& set()
  {
    return _set;
  }

  constexpr const uint32_t& set() const
  {
    return _set;
  }

  void set(uint32_t new_set)
  {
    _set = new_set;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::descriptor_update_template_create_info;
  void* _next = nullptr;
  vk::descriptor_update_template_create_flags _flags = 0;
  /// Number of descriptor update entries to use for the update template
  uint32_t _descriptor_update_entry_count = 0;
  /// Descriptor update entries for the template
  const vk::descriptor_update_template_entry* _descriptor_update_entries =
    nullptr;
  vk::descriptor_update_template_type _template_type =
    vk::descriptor_update_template_type::descriptor_set;
  VkDescriptorSetLayout _descriptor_set_layout = nullptr;
  vk::pipeline_bind_point _pipeline_bind_point =
    vk::pipeline_bind_point::graphics;
  /// If used for push descriptors, this is the only allowed layout
  VkPipelineLayout _pipeline_layout = nullptr;
  uint32_t _set = 0;
};
static_assert(sizeof(descriptor_update_template_create_info) ==
                sizeof(::VkDescriptorUpdateTemplateCreateInfo),
              "struct and wrapper have different size!");

enum class external_memory_handle_type_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT
  opaque_fd_bit = 1 << 0,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT
  opaque_win32_bit = 1 << 1,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT
  opaque_win32_kmt_bit = 1 << 2,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT
  d3d_11_texture_bit = 1 << 3,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT
  d3d_11_texture_kmt_bit = 1 << 4,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP_BIT
  d3d_12_heap_bit = 1 << 5,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE_BIT
  d3d_12_resource_bit = 1 << 6,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_DMA_BUF_BIT_EXT
  dma_buf_bit_ext = 1 << 9,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_ANDROID_HARDWARE_BUFFER_BIT_ANDROID
  android_hardware_buffer_bit_android = 1 << 10,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT
  host_allocation_bit_ext = 1 << 7,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_MAPPED_FOREIGN_MEMORY_BIT_EXT
  host_mapped_foreign_memory_bit_ext = 1 << 8,
};
using external_memory_handle_type_flags =
  shift::core::bit_field<external_memory_handle_type_flag,
                         VkExternalMemoryHandleTypeFlags>;
inline constexpr external_memory_handle_type_flags operator|(
  external_memory_handle_type_flag lhs, external_memory_handle_type_flag rhs)
{
  return external_memory_handle_type_flags{lhs} | rhs;
}
enum class external_memory_feature_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_EXTERNAL_MEMORY_FEATURE_DEDICATED_ONLY_BIT
  dedicated_only_bit = 1 << 0,
  /// @see VK_EXTERNAL_MEMORY_FEATURE_EXPORTABLE_BIT
  exportable_bit = 1 << 1,
  /// @see VK_EXTERNAL_MEMORY_FEATURE_IMPORTABLE_BIT
  importable_bit = 1 << 2,
};
using external_memory_feature_flags =
  shift::core::bit_field<external_memory_feature_flag,
                         VkExternalMemoryFeatureFlags>;
inline constexpr external_memory_feature_flags operator|(
  external_memory_feature_flag lhs, external_memory_feature_flag rhs)
{
  return external_memory_feature_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkExternalMemoryProperties.
class external_memory_properties
{
public:
  /// Default constructor.
  constexpr external_memory_properties() = default;

  /// Constructor.
  constexpr external_memory_properties(
    vk::external_memory_feature_flags initial_external_memory_features,
    vk::external_memory_handle_type_flags
      initial_export_from_imported_handle_types,
    vk::external_memory_handle_type_flags
      initial_compatible_handle_types) noexcept
  : _external_memory_features(std::move(initial_external_memory_features)),
    _export_from_imported_handle_types(
      std::move(initial_export_from_imported_handle_types)),
    _compatible_handle_types(std::move(initial_compatible_handle_types))
  {
  }

  /// Copy constructor.
  constexpr external_memory_properties(
    const external_memory_properties& other) = default;

  /// Move constructor.
  constexpr external_memory_properties(external_memory_properties&& other) =
    default;

  /// Copy assignment operator.
  constexpr external_memory_properties& operator=(
    const external_memory_properties& other) = default;

  /// Move assignment operator.
  constexpr external_memory_properties& operator=(
    external_memory_properties&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkExternalMemoryProperties&() const
  {
    return *reinterpret_cast<const VkExternalMemoryProperties*>(this);
  }

  vk::external_memory_feature_flags& external_memory_features()
  {
    return _external_memory_features;
  }

  constexpr const vk::external_memory_feature_flags& external_memory_features()
    const
  {
    return _external_memory_features;
  }

  void external_memory_features(
    vk::external_memory_feature_flags new_external_memory_features)
  {
    _external_memory_features = new_external_memory_features;
  }

  vk::external_memory_handle_type_flags& export_from_imported_handle_types()
  {
    return _export_from_imported_handle_types;
  }

  constexpr const vk::external_memory_handle_type_flags&
  export_from_imported_handle_types() const
  {
    return _export_from_imported_handle_types;
  }

  void export_from_imported_handle_types(
    vk::external_memory_handle_type_flags new_export_from_imported_handle_types)
  {
    _export_from_imported_handle_types = new_export_from_imported_handle_types;
  }

  vk::external_memory_handle_type_flags& compatible_handle_types()
  {
    return _compatible_handle_types;
  }

  constexpr const vk::external_memory_handle_type_flags&
  compatible_handle_types() const
  {
    return _compatible_handle_types;
  }

  void compatible_handle_types(
    vk::external_memory_handle_type_flags new_compatible_handle_types)
  {
    _compatible_handle_types = new_compatible_handle_types;
  }

private:
  vk::external_memory_feature_flags _external_memory_features =
    vk::external_memory_feature_flag::none;
  vk::external_memory_handle_type_flags _export_from_imported_handle_types =
    vk::external_memory_handle_type_flag::none;
  vk::external_memory_handle_type_flags _compatible_handle_types =
    vk::external_memory_handle_type_flag::none;
};
static_assert(sizeof(external_memory_properties) ==
                sizeof(::VkExternalMemoryProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceExternalImageFormatInfo.
class physical_device_external_image_format_info
{
public:
  /// Default constructor.
  constexpr physical_device_external_image_format_info() = default;

  /// Constructor.
  constexpr physical_device_external_image_format_info(
    const void* initial_next,
    vk::external_memory_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)), _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr physical_device_external_image_format_info(
    const physical_device_external_image_format_info& other) noexcept
  : _next(other._next), _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr physical_device_external_image_format_info(
    physical_device_external_image_format_info&& other) noexcept
  : _next(std::move(other._next)), _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_external_image_format_info& operator=(
    const physical_device_external_image_format_info& other) noexcept
  {
    _next = other._next;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_external_image_format_info& operator=(
    physical_device_external_image_format_info&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceExternalImageFormatInfo&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceExternalImageFormatInfo*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_memory_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_memory_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_external_image_format_info;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flag _handle_type =
    vk::external_memory_handle_type_flag::none;
};
static_assert(sizeof(physical_device_external_image_format_info) ==
                sizeof(::VkPhysicalDeviceExternalImageFormatInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkExternalImageFormatProperties.
class external_image_format_properties
{
public:
  /// Default constructor.
  constexpr external_image_format_properties() = default;

  /// Constructor.
  constexpr external_image_format_properties(
    void* initial_next,
    vk::external_memory_properties initial_external_memory_properties) noexcept
  : _next(std::move(initial_next)),
    _external_memory_properties(std::move(initial_external_memory_properties))
  {
  }

  /// Copy constructor.
  constexpr external_image_format_properties(
    const external_image_format_properties& other) noexcept
  : _next(other._next),
    _external_memory_properties(other._external_memory_properties)
  {
  }

  /// Move constructor.
  constexpr external_image_format_properties(
    external_image_format_properties&& other) noexcept
  : _next(std::move(other._next)),
    _external_memory_properties(std::move(other._external_memory_properties))
  {
  }

  /// Copy assignment operator.
  constexpr external_image_format_properties& operator=(
    const external_image_format_properties& other) noexcept
  {
    _next = other._next;
    _external_memory_properties = other._external_memory_properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr external_image_format_properties& operator=(
    external_image_format_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _external_memory_properties = std::move(other._external_memory_properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExternalImageFormatProperties&() const
  {
    return *reinterpret_cast<const VkExternalImageFormatProperties*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_properties& external_memory_properties()
  {
    return _external_memory_properties;
  }

  constexpr const vk::external_memory_properties& external_memory_properties()
    const
  {
    return _external_memory_properties;
  }

  void external_memory_properties(
    vk::external_memory_properties new_external_memory_properties)
  {
    _external_memory_properties = new_external_memory_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::external_image_format_properties;
  void* _next = nullptr;
  vk::external_memory_properties _external_memory_properties =
    vk::external_memory_properties{};
};
static_assert(sizeof(external_image_format_properties) ==
                sizeof(::VkExternalImageFormatProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceExternalBufferInfo.
class physical_device_external_buffer_info
{
public:
  /// Default constructor.
  constexpr physical_device_external_buffer_info() = default;

  /// Constructor.
  constexpr physical_device_external_buffer_info(
    const void* initial_next, vk::buffer_create_flags initial_flags,
    vk::buffer_usage_flags initial_usage,
    vk::external_memory_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _usage(std::move(initial_usage)),
    _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr physical_device_external_buffer_info(
    const physical_device_external_buffer_info& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _usage(other._usage),
    _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr physical_device_external_buffer_info(
    physical_device_external_buffer_info&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _usage(std::move(other._usage)),
    _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_external_buffer_info& operator=(
    const physical_device_external_buffer_info& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _usage = other._usage;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_external_buffer_info& operator=(
    physical_device_external_buffer_info&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _usage = std::move(other._usage);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceExternalBufferInfo&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceExternalBufferInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::buffer_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::buffer_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::buffer_create_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::buffer_usage_flags& usage()
  {
    return _usage;
  }

  constexpr const vk::buffer_usage_flags& usage() const
  {
    return _usage;
  }

  void usage(vk::buffer_usage_flags new_usage)
  {
    _usage = new_usage;
  }

  vk::external_memory_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_memory_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_memory_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_external_buffer_info;
  const void* _next = nullptr;
  vk::buffer_create_flags _flags = vk::buffer_create_flag::none;
  vk::buffer_usage_flags _usage = vk::buffer_usage_flag::none;
  vk::external_memory_handle_type_flag _handle_type =
    vk::external_memory_handle_type_flag::none;
};
static_assert(sizeof(physical_device_external_buffer_info) ==
                sizeof(::VkPhysicalDeviceExternalBufferInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkExternalBufferProperties.
class external_buffer_properties
{
public:
  /// Default constructor.
  constexpr external_buffer_properties() = default;

  /// Constructor.
  constexpr external_buffer_properties(
    void* initial_next,
    vk::external_memory_properties initial_external_memory_properties) noexcept
  : _next(std::move(initial_next)),
    _external_memory_properties(std::move(initial_external_memory_properties))
  {
  }

  /// Copy constructor.
  constexpr external_buffer_properties(
    const external_buffer_properties& other) noexcept
  : _next(other._next),
    _external_memory_properties(other._external_memory_properties)
  {
  }

  /// Move constructor.
  constexpr external_buffer_properties(
    external_buffer_properties&& other) noexcept
  : _next(std::move(other._next)),
    _external_memory_properties(std::move(other._external_memory_properties))
  {
  }

  /// Copy assignment operator.
  constexpr external_buffer_properties& operator=(
    const external_buffer_properties& other) noexcept
  {
    _next = other._next;
    _external_memory_properties = other._external_memory_properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr external_buffer_properties& operator=(
    external_buffer_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _external_memory_properties = std::move(other._external_memory_properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExternalBufferProperties&() const
  {
    return *reinterpret_cast<const VkExternalBufferProperties*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_properties& external_memory_properties()
  {
    return _external_memory_properties;
  }

  constexpr const vk::external_memory_properties& external_memory_properties()
    const
  {
    return _external_memory_properties;
  }

  void external_memory_properties(
    vk::external_memory_properties new_external_memory_properties)
  {
    _external_memory_properties = new_external_memory_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::external_buffer_properties;
  void* _next = nullptr;
  vk::external_memory_properties _external_memory_properties =
    vk::external_memory_properties{};
};
static_assert(sizeof(external_buffer_properties) ==
                sizeof(::VkExternalBufferProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceIDProperties.
class physical_device_idproperties
{
public:
  /// Default constructor.
  constexpr physical_device_idproperties() = default;

  /// Constructor.
  constexpr physical_device_idproperties(
    void* initial_next, std::array<uint8_t, VK_UUID_SIZE> initial_device_uuid,
    std::array<uint8_t, VK_UUID_SIZE> initial_driver_uuid,
    std::array<uint8_t, VK_LUID_SIZE> initial_device_luid,
    uint32_t initial_device_node_mask,
    VkBool32 initial_device_luidvalid) noexcept
  : _next(std::move(initial_next)),
    _device_uuid(std::move(initial_device_uuid)),
    _driver_uuid(std::move(initial_driver_uuid)),
    _device_luid(std::move(initial_device_luid)),
    _device_node_mask(std::move(initial_device_node_mask)),
    _device_luidvalid(std::move(initial_device_luidvalid))
  {
  }

  /// Copy constructor.
  constexpr physical_device_idproperties(
    const physical_device_idproperties& other) noexcept
  : _next(other._next),
    _device_uuid(other._device_uuid),
    _driver_uuid(other._driver_uuid),
    _device_luid(other._device_luid),
    _device_node_mask(other._device_node_mask),
    _device_luidvalid(other._device_luidvalid)
  {
  }

  /// Move constructor.
  constexpr physical_device_idproperties(
    physical_device_idproperties&& other) noexcept
  : _next(std::move(other._next)),
    _device_uuid(std::move(other._device_uuid)),
    _driver_uuid(std::move(other._driver_uuid)),
    _device_luid(std::move(other._device_luid)),
    _device_node_mask(std::move(other._device_node_mask)),
    _device_luidvalid(std::move(other._device_luidvalid))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_idproperties& operator=(
    const physical_device_idproperties& other) noexcept
  {
    _next = other._next;
    _device_uuid = other._device_uuid;
    _driver_uuid = other._driver_uuid;
    _device_luid = other._device_luid;
    _device_node_mask = other._device_node_mask;
    _device_luidvalid = other._device_luidvalid;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_idproperties& operator=(
    physical_device_idproperties&& other) noexcept
  {
    _next = std::move(other._next);
    _device_uuid = std::move(other._device_uuid);
    _driver_uuid = std::move(other._driver_uuid);
    _device_luid = std::move(other._device_luid);
    _device_node_mask = std::move(other._device_node_mask);
    _device_luidvalid = std::move(other._device_luidvalid);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceIDProperties&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceIDProperties*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  std::array<uint8_t, VK_UUID_SIZE>& device_uuid()
  {
    return _device_uuid;
  }

  constexpr const std::array<uint8_t, VK_UUID_SIZE>& device_uuid() const
  {
    return _device_uuid;
  }

  void device_uuid(std::array<uint8_t, VK_UUID_SIZE> new_device_uuid)
  {
    _device_uuid = new_device_uuid;
  }

  std::array<uint8_t, VK_UUID_SIZE>& driver_uuid()
  {
    return _driver_uuid;
  }

  constexpr const std::array<uint8_t, VK_UUID_SIZE>& driver_uuid() const
  {
    return _driver_uuid;
  }

  void driver_uuid(std::array<uint8_t, VK_UUID_SIZE> new_driver_uuid)
  {
    _driver_uuid = new_driver_uuid;
  }

  std::array<uint8_t, VK_LUID_SIZE>& device_luid()
  {
    return _device_luid;
  }

  constexpr const std::array<uint8_t, VK_LUID_SIZE>& device_luid() const
  {
    return _device_luid;
  }

  void device_luid(std::array<uint8_t, VK_LUID_SIZE> new_device_luid)
  {
    _device_luid = new_device_luid;
  }

  uint32_t& device_node_mask()
  {
    return _device_node_mask;
  }

  constexpr const uint32_t& device_node_mask() const
  {
    return _device_node_mask;
  }

  void device_node_mask(uint32_t new_device_node_mask)
  {
    _device_node_mask = new_device_node_mask;
  }

  VkBool32& device_luidvalid()
  {
    return _device_luidvalid;
  }

  constexpr const VkBool32& device_luidvalid() const
  {
    return _device_luidvalid;
  }

  void device_luidvalid(VkBool32 new_device_luidvalid)
  {
    _device_luidvalid = new_device_luidvalid;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_id_properties;
  void* _next = nullptr;
  std::array<uint8_t, VK_UUID_SIZE> _device_uuid = {};
  std::array<uint8_t, VK_UUID_SIZE> _driver_uuid = {};
  std::array<uint8_t, VK_LUID_SIZE> _device_luid = {};
  uint32_t _device_node_mask = 0;
  VkBool32 _device_luidvalid = VK_FALSE;
};
static_assert(sizeof(physical_device_idproperties) ==
                sizeof(::VkPhysicalDeviceIDProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkExternalMemoryImageCreateInfo.
class external_memory_image_create_info
{
public:
  /// Default constructor.
  constexpr external_memory_image_create_info() = default;

  /// Constructor.
  constexpr external_memory_image_create_info(
    const void* initial_next,
    vk::external_memory_handle_type_flags initial_handle_types) noexcept
  : _next(std::move(initial_next)),
    _handle_types(std::move(initial_handle_types))
  {
  }

  /// Copy constructor.
  constexpr external_memory_image_create_info(
    const external_memory_image_create_info& other) noexcept
  : _next(other._next), _handle_types(other._handle_types)
  {
  }

  /// Move constructor.
  constexpr external_memory_image_create_info(
    external_memory_image_create_info&& other) noexcept
  : _next(std::move(other._next)), _handle_types(std::move(other._handle_types))
  {
  }

  /// Copy assignment operator.
  constexpr external_memory_image_create_info& operator=(
    const external_memory_image_create_info& other) noexcept
  {
    _next = other._next;
    _handle_types = other._handle_types;
    return *this;
  }

  /// Move assignment operator.
  constexpr external_memory_image_create_info& operator=(
    external_memory_image_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_types = std::move(other._handle_types);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExternalMemoryImageCreateInfo&() const
  {
    return *reinterpret_cast<const VkExternalMemoryImageCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flags& handle_types()
  {
    return _handle_types;
  }

  constexpr const vk::external_memory_handle_type_flags& handle_types() const
  {
    return _handle_types;
  }

  void handle_types(vk::external_memory_handle_type_flags new_handle_types)
  {
    _handle_types = new_handle_types;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::external_memory_image_create_info;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flags _handle_types =
    vk::external_memory_handle_type_flag::none;
};
static_assert(sizeof(external_memory_image_create_info) ==
                sizeof(::VkExternalMemoryImageCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkExternalMemoryBufferCreateInfo.
class external_memory_buffer_create_info
{
public:
  /// Default constructor.
  constexpr external_memory_buffer_create_info() = default;

  /// Constructor.
  constexpr external_memory_buffer_create_info(
    const void* initial_next,
    vk::external_memory_handle_type_flags initial_handle_types) noexcept
  : _next(std::move(initial_next)),
    _handle_types(std::move(initial_handle_types))
  {
  }

  /// Copy constructor.
  constexpr external_memory_buffer_create_info(
    const external_memory_buffer_create_info& other) noexcept
  : _next(other._next), _handle_types(other._handle_types)
  {
  }

  /// Move constructor.
  constexpr external_memory_buffer_create_info(
    external_memory_buffer_create_info&& other) noexcept
  : _next(std::move(other._next)), _handle_types(std::move(other._handle_types))
  {
  }

  /// Copy assignment operator.
  constexpr external_memory_buffer_create_info& operator=(
    const external_memory_buffer_create_info& other) noexcept
  {
    _next = other._next;
    _handle_types = other._handle_types;
    return *this;
  }

  /// Move assignment operator.
  constexpr external_memory_buffer_create_info& operator=(
    external_memory_buffer_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_types = std::move(other._handle_types);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExternalMemoryBufferCreateInfo&() const
  {
    return *reinterpret_cast<const VkExternalMemoryBufferCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flags& handle_types()
  {
    return _handle_types;
  }

  constexpr const vk::external_memory_handle_type_flags& handle_types() const
  {
    return _handle_types;
  }

  void handle_types(vk::external_memory_handle_type_flags new_handle_types)
  {
    _handle_types = new_handle_types;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::external_memory_buffer_create_info;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flags _handle_types =
    vk::external_memory_handle_type_flag::none;
};
static_assert(sizeof(external_memory_buffer_create_info) ==
                sizeof(::VkExternalMemoryBufferCreateInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkExportMemoryAllocateInfo.
class export_memory_allocate_info
{
public:
  /// Default constructor.
  constexpr export_memory_allocate_info() = default;

  /// Constructor.
  constexpr export_memory_allocate_info(
    const void* initial_next,
    vk::external_memory_handle_type_flags initial_handle_types) noexcept
  : _next(std::move(initial_next)),
    _handle_types(std::move(initial_handle_types))
  {
  }

  /// Copy constructor.
  constexpr export_memory_allocate_info(
    const export_memory_allocate_info& other) noexcept
  : _next(other._next), _handle_types(other._handle_types)
  {
  }

  /// Move constructor.
  constexpr export_memory_allocate_info(
    export_memory_allocate_info&& other) noexcept
  : _next(std::move(other._next)), _handle_types(std::move(other._handle_types))
  {
  }

  /// Copy assignment operator.
  constexpr export_memory_allocate_info& operator=(
    const export_memory_allocate_info& other) noexcept
  {
    _next = other._next;
    _handle_types = other._handle_types;
    return *this;
  }

  /// Move assignment operator.
  constexpr export_memory_allocate_info& operator=(
    export_memory_allocate_info&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_types = std::move(other._handle_types);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExportMemoryAllocateInfo&() const
  {
    return *reinterpret_cast<const VkExportMemoryAllocateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flags& handle_types()
  {
    return _handle_types;
  }

  constexpr const vk::external_memory_handle_type_flags& handle_types() const
  {
    return _handle_types;
  }

  void handle_types(vk::external_memory_handle_type_flags new_handle_types)
  {
    _handle_types = new_handle_types;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::export_memory_allocate_info;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flags _handle_types =
    vk::external_memory_handle_type_flag::none;
};
static_assert(sizeof(export_memory_allocate_info) ==
                sizeof(::VkExportMemoryAllocateInfo),
              "struct and wrapper have different size!");

enum class external_fence_handle_type_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_FD_BIT
  opaque_fd_bit = 1 << 0,
  /// @see VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_BIT
  opaque_win32_bit = 1 << 1,
  /// @see VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT
  opaque_win32_kmt_bit = 1 << 2,
  /// @see VK_EXTERNAL_FENCE_HANDLE_TYPE_SYNC_FD_BIT
  sync_fd_bit = 1 << 3,
};
using external_fence_handle_type_flags =
  shift::core::bit_field<external_fence_handle_type_flag,
                         VkExternalFenceHandleTypeFlags>;
inline constexpr external_fence_handle_type_flags operator|(
  external_fence_handle_type_flag lhs, external_fence_handle_type_flag rhs)
{
  return external_fence_handle_type_flags{lhs} | rhs;
}
enum class external_fence_feature_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_EXTERNAL_FENCE_FEATURE_EXPORTABLE_BIT
  exportable_bit = 1 << 0,
  /// @see VK_EXTERNAL_FENCE_FEATURE_IMPORTABLE_BIT
  importable_bit = 1 << 1,
};
using external_fence_feature_flags =
  shift::core::bit_field<external_fence_feature_flag,
                         VkExternalFenceFeatureFlags>;
inline constexpr external_fence_feature_flags operator|(
  external_fence_feature_flag lhs, external_fence_feature_flag rhs)
{
  return external_fence_feature_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkPhysicalDeviceExternalFenceInfo.
class physical_device_external_fence_info
{
public:
  /// Default constructor.
  constexpr physical_device_external_fence_info() = default;

  /// Constructor.
  constexpr physical_device_external_fence_info(
    const void* initial_next,
    vk::external_fence_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)), _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr physical_device_external_fence_info(
    const physical_device_external_fence_info& other) noexcept
  : _next(other._next), _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr physical_device_external_fence_info(
    physical_device_external_fence_info&& other) noexcept
  : _next(std::move(other._next)), _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_external_fence_info& operator=(
    const physical_device_external_fence_info& other) noexcept
  {
    _next = other._next;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_external_fence_info& operator=(
    physical_device_external_fence_info&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceExternalFenceInfo&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceExternalFenceInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_fence_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_fence_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_fence_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_external_fence_info;
  const void* _next = nullptr;
  vk::external_fence_handle_type_flag _handle_type =
    vk::external_fence_handle_type_flag::none;
};
static_assert(sizeof(physical_device_external_fence_info) ==
                sizeof(::VkPhysicalDeviceExternalFenceInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkExternalFenceProperties.
class external_fence_properties
{
public:
  /// Default constructor.
  constexpr external_fence_properties() = default;

  /// Constructor.
  constexpr external_fence_properties(
    void* initial_next,
    vk::external_fence_handle_type_flags
      initial_export_from_imported_handle_types,
    vk::external_fence_handle_type_flags initial_compatible_handle_types,
    vk::external_fence_feature_flags initial_external_fence_features) noexcept
  : _next(std::move(initial_next)),
    _export_from_imported_handle_types(
      std::move(initial_export_from_imported_handle_types)),
    _compatible_handle_types(std::move(initial_compatible_handle_types)),
    _external_fence_features(std::move(initial_external_fence_features))
  {
  }

  /// Copy constructor.
  constexpr external_fence_properties(
    const external_fence_properties& other) noexcept
  : _next(other._next),
    _export_from_imported_handle_types(
      other._export_from_imported_handle_types),
    _compatible_handle_types(other._compatible_handle_types),
    _external_fence_features(other._external_fence_features)
  {
  }

  /// Move constructor.
  constexpr external_fence_properties(
    external_fence_properties&& other) noexcept
  : _next(std::move(other._next)),
    _export_from_imported_handle_types(
      std::move(other._export_from_imported_handle_types)),
    _compatible_handle_types(std::move(other._compatible_handle_types)),
    _external_fence_features(std::move(other._external_fence_features))
  {
  }

  /// Copy assignment operator.
  constexpr external_fence_properties& operator=(
    const external_fence_properties& other) noexcept
  {
    _next = other._next;
    _export_from_imported_handle_types =
      other._export_from_imported_handle_types;
    _compatible_handle_types = other._compatible_handle_types;
    _external_fence_features = other._external_fence_features;
    return *this;
  }

  /// Move assignment operator.
  constexpr external_fence_properties& operator=(
    external_fence_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _export_from_imported_handle_types =
      std::move(other._export_from_imported_handle_types);
    _compatible_handle_types = std::move(other._compatible_handle_types);
    _external_fence_features = std::move(other._external_fence_features);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExternalFenceProperties&() const
  {
    return *reinterpret_cast<const VkExternalFenceProperties*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::external_fence_handle_type_flags& export_from_imported_handle_types()
  {
    return _export_from_imported_handle_types;
  }

  constexpr const vk::external_fence_handle_type_flags&
  export_from_imported_handle_types() const
  {
    return _export_from_imported_handle_types;
  }

  void export_from_imported_handle_types(
    vk::external_fence_handle_type_flags new_export_from_imported_handle_types)
  {
    _export_from_imported_handle_types = new_export_from_imported_handle_types;
  }

  vk::external_fence_handle_type_flags& compatible_handle_types()
  {
    return _compatible_handle_types;
  }

  constexpr const vk::external_fence_handle_type_flags&
  compatible_handle_types() const
  {
    return _compatible_handle_types;
  }

  void compatible_handle_types(
    vk::external_fence_handle_type_flags new_compatible_handle_types)
  {
    _compatible_handle_types = new_compatible_handle_types;
  }

  vk::external_fence_feature_flags& external_fence_features()
  {
    return _external_fence_features;
  }

  constexpr const vk::external_fence_feature_flags& external_fence_features()
    const
  {
    return _external_fence_features;
  }

  void external_fence_features(
    vk::external_fence_feature_flags new_external_fence_features)
  {
    _external_fence_features = new_external_fence_features;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::external_fence_properties;
  void* _next = nullptr;
  vk::external_fence_handle_type_flags _export_from_imported_handle_types =
    vk::external_fence_handle_type_flag::none;
  vk::external_fence_handle_type_flags _compatible_handle_types =
    vk::external_fence_handle_type_flag::none;
  vk::external_fence_feature_flags _external_fence_features =
    vk::external_fence_feature_flag::none;
};
static_assert(sizeof(external_fence_properties) ==
                sizeof(::VkExternalFenceProperties),
              "struct and wrapper have different size!");

enum class fence_import_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_FENCE_IMPORT_TEMPORARY_BIT
  temporary_bit = 1 << 0,
};
using fence_import_flags =
  shift::core::bit_field<fence_import_flag, VkFenceImportFlags>;
inline constexpr fence_import_flags operator|(fence_import_flag lhs,
                                              fence_import_flag rhs)
{
  return fence_import_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkExportFenceCreateInfo.
class export_fence_create_info
{
public:
  /// Default constructor.
  constexpr export_fence_create_info() = default;

  /// Constructor.
  constexpr export_fence_create_info(
    const void* initial_next,
    vk::external_fence_handle_type_flags initial_handle_types) noexcept
  : _next(std::move(initial_next)),
    _handle_types(std::move(initial_handle_types))
  {
  }

  /// Copy constructor.
  constexpr export_fence_create_info(
    const export_fence_create_info& other) noexcept
  : _next(other._next), _handle_types(other._handle_types)
  {
  }

  /// Move constructor.
  constexpr export_fence_create_info(export_fence_create_info&& other) noexcept
  : _next(std::move(other._next)), _handle_types(std::move(other._handle_types))
  {
  }

  /// Copy assignment operator.
  constexpr export_fence_create_info& operator=(
    const export_fence_create_info& other) noexcept
  {
    _next = other._next;
    _handle_types = other._handle_types;
    return *this;
  }

  /// Move assignment operator.
  constexpr export_fence_create_info& operator=(
    export_fence_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_types = std::move(other._handle_types);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExportFenceCreateInfo&() const
  {
    return *reinterpret_cast<const VkExportFenceCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_fence_handle_type_flags& handle_types()
  {
    return _handle_types;
  }

  constexpr const vk::external_fence_handle_type_flags& handle_types() const
  {
    return _handle_types;
  }

  void handle_types(vk::external_fence_handle_type_flags new_handle_types)
  {
    _handle_types = new_handle_types;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::export_fence_create_info;
  const void* _next = nullptr;
  vk::external_fence_handle_type_flags _handle_types =
    vk::external_fence_handle_type_flag::none;
};
static_assert(sizeof(export_fence_create_info) ==
                sizeof(::VkExportFenceCreateInfo),
              "struct and wrapper have different size!");

enum class semaphore_import_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_SEMAPHORE_IMPORT_TEMPORARY_BIT
  temporary_bit = 1 << 0,
};
using semaphore_import_flags =
  shift::core::bit_field<semaphore_import_flag, VkSemaphoreImportFlags>;
inline constexpr semaphore_import_flags operator|(semaphore_import_flag lhs,
                                                  semaphore_import_flag rhs)
{
  return semaphore_import_flags{lhs} | rhs;
}
enum class external_semaphore_handle_type_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT
  opaque_fd_bit = 1 << 0,
  /// @see VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT
  opaque_win32_bit = 1 << 1,
  /// @see VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT
  opaque_win32_kmt_bit = 1 << 2,
  /// @see VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT
  d3d_12_fence_bit = 1 << 3,
  /// @see VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_SYNC_FD_BIT
  sync_fd_bit = 1 << 4,
};
using external_semaphore_handle_type_flags =
  shift::core::bit_field<external_semaphore_handle_type_flag,
                         VkExternalSemaphoreHandleTypeFlags>;
inline constexpr external_semaphore_handle_type_flags operator|(
  external_semaphore_handle_type_flag lhs,
  external_semaphore_handle_type_flag rhs)
{
  return external_semaphore_handle_type_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkExportSemaphoreCreateInfo.
class export_semaphore_create_info
{
public:
  /// Default constructor.
  constexpr export_semaphore_create_info() = default;

  /// Constructor.
  constexpr export_semaphore_create_info(
    const void* initial_next,
    vk::external_semaphore_handle_type_flags initial_handle_types) noexcept
  : _next(std::move(initial_next)),
    _handle_types(std::move(initial_handle_types))
  {
  }

  /// Copy constructor.
  constexpr export_semaphore_create_info(
    const export_semaphore_create_info& other) noexcept
  : _next(other._next), _handle_types(other._handle_types)
  {
  }

  /// Move constructor.
  constexpr export_semaphore_create_info(
    export_semaphore_create_info&& other) noexcept
  : _next(std::move(other._next)), _handle_types(std::move(other._handle_types))
  {
  }

  /// Copy assignment operator.
  constexpr export_semaphore_create_info& operator=(
    const export_semaphore_create_info& other) noexcept
  {
    _next = other._next;
    _handle_types = other._handle_types;
    return *this;
  }

  /// Move assignment operator.
  constexpr export_semaphore_create_info& operator=(
    export_semaphore_create_info&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_types = std::move(other._handle_types);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExportSemaphoreCreateInfo&() const
  {
    return *reinterpret_cast<const VkExportSemaphoreCreateInfo*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_semaphore_handle_type_flags& handle_types()
  {
    return _handle_types;
  }

  constexpr const vk::external_semaphore_handle_type_flags& handle_types() const
  {
    return _handle_types;
  }

  void handle_types(vk::external_semaphore_handle_type_flags new_handle_types)
  {
    _handle_types = new_handle_types;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::export_semaphore_create_info;
  const void* _next = nullptr;
  vk::external_semaphore_handle_type_flags _handle_types =
    vk::external_semaphore_handle_type_flag::none;
};
static_assert(sizeof(export_semaphore_create_info) ==
                sizeof(::VkExportSemaphoreCreateInfo),
              "struct and wrapper have different size!");

enum class external_semaphore_feature_flag
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_EXTERNAL_SEMAPHORE_FEATURE_EXPORTABLE_BIT
  exportable_bit = 1 << 0,
  /// @see VK_EXTERNAL_SEMAPHORE_FEATURE_IMPORTABLE_BIT
  importable_bit = 1 << 1,
};
using external_semaphore_feature_flags =
  shift::core::bit_field<external_semaphore_feature_flag,
                         VkExternalSemaphoreFeatureFlags>;
inline constexpr external_semaphore_feature_flags operator|(
  external_semaphore_feature_flag lhs, external_semaphore_feature_flag rhs)
{
  return external_semaphore_feature_flags{lhs} | rhs;
}
/// Enhanced replacement type for VkPhysicalDeviceExternalSemaphoreInfo.
class physical_device_external_semaphore_info
{
public:
  /// Default constructor.
  constexpr physical_device_external_semaphore_info() = default;

  /// Constructor.
  constexpr physical_device_external_semaphore_info(
    const void* initial_next,
    vk::external_semaphore_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)), _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr physical_device_external_semaphore_info(
    const physical_device_external_semaphore_info& other) noexcept
  : _next(other._next), _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr physical_device_external_semaphore_info(
    physical_device_external_semaphore_info&& other) noexcept
  : _next(std::move(other._next)), _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_external_semaphore_info& operator=(
    const physical_device_external_semaphore_info& other) noexcept
  {
    _next = other._next;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_external_semaphore_info& operator=(
    physical_device_external_semaphore_info&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceExternalSemaphoreInfo&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceExternalSemaphoreInfo*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_semaphore_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_semaphore_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_semaphore_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_external_semaphore_info;
  const void* _next = nullptr;
  vk::external_semaphore_handle_type_flag _handle_type =
    vk::external_semaphore_handle_type_flag::none;
};
static_assert(sizeof(physical_device_external_semaphore_info) ==
                sizeof(::VkPhysicalDeviceExternalSemaphoreInfo),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkExternalSemaphoreProperties.
class external_semaphore_properties
{
public:
  /// Default constructor.
  constexpr external_semaphore_properties() = default;

  /// Constructor.
  constexpr external_semaphore_properties(
    void* initial_next,
    vk::external_semaphore_handle_type_flags
      initial_export_from_imported_handle_types,
    vk::external_semaphore_handle_type_flags initial_compatible_handle_types,
    vk::external_semaphore_feature_flags
      initial_external_semaphore_features) noexcept
  : _next(std::move(initial_next)),
    _export_from_imported_handle_types(
      std::move(initial_export_from_imported_handle_types)),
    _compatible_handle_types(std::move(initial_compatible_handle_types)),
    _external_semaphore_features(std::move(initial_external_semaphore_features))
  {
  }

  /// Copy constructor.
  constexpr external_semaphore_properties(
    const external_semaphore_properties& other) noexcept
  : _next(other._next),
    _export_from_imported_handle_types(
      other._export_from_imported_handle_types),
    _compatible_handle_types(other._compatible_handle_types),
    _external_semaphore_features(other._external_semaphore_features)
  {
  }

  /// Move constructor.
  constexpr external_semaphore_properties(
    external_semaphore_properties&& other) noexcept
  : _next(std::move(other._next)),
    _export_from_imported_handle_types(
      std::move(other._export_from_imported_handle_types)),
    _compatible_handle_types(std::move(other._compatible_handle_types)),
    _external_semaphore_features(std::move(other._external_semaphore_features))
  {
  }

  /// Copy assignment operator.
  constexpr external_semaphore_properties& operator=(
    const external_semaphore_properties& other) noexcept
  {
    _next = other._next;
    _export_from_imported_handle_types =
      other._export_from_imported_handle_types;
    _compatible_handle_types = other._compatible_handle_types;
    _external_semaphore_features = other._external_semaphore_features;
    return *this;
  }

  /// Move assignment operator.
  constexpr external_semaphore_properties& operator=(
    external_semaphore_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _export_from_imported_handle_types =
      std::move(other._export_from_imported_handle_types);
    _compatible_handle_types = std::move(other._compatible_handle_types);
    _external_semaphore_features =
      std::move(other._external_semaphore_features);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExternalSemaphoreProperties&() const
  {
    return *reinterpret_cast<const VkExternalSemaphoreProperties*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::external_semaphore_handle_type_flags& export_from_imported_handle_types()
  {
    return _export_from_imported_handle_types;
  }

  constexpr const vk::external_semaphore_handle_type_flags&
  export_from_imported_handle_types() const
  {
    return _export_from_imported_handle_types;
  }

  void export_from_imported_handle_types(
    vk::external_semaphore_handle_type_flags
      new_export_from_imported_handle_types)
  {
    _export_from_imported_handle_types = new_export_from_imported_handle_types;
  }

  vk::external_semaphore_handle_type_flags& compatible_handle_types()
  {
    return _compatible_handle_types;
  }

  constexpr const vk::external_semaphore_handle_type_flags&
  compatible_handle_types() const
  {
    return _compatible_handle_types;
  }

  void compatible_handle_types(
    vk::external_semaphore_handle_type_flags new_compatible_handle_types)
  {
    _compatible_handle_types = new_compatible_handle_types;
  }

  vk::external_semaphore_feature_flags& external_semaphore_features()
  {
    return _external_semaphore_features;
  }

  constexpr const vk::external_semaphore_feature_flags&
  external_semaphore_features() const
  {
    return _external_semaphore_features;
  }

  void external_semaphore_features(
    vk::external_semaphore_feature_flags new_external_semaphore_features)
  {
    _external_semaphore_features = new_external_semaphore_features;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::external_semaphore_properties;
  void* _next = nullptr;
  vk::external_semaphore_handle_type_flags _export_from_imported_handle_types =
    vk::external_semaphore_handle_type_flag::none;
  vk::external_semaphore_handle_type_flags _compatible_handle_types =
    vk::external_semaphore_handle_type_flag::none;
  vk::external_semaphore_feature_flags _external_semaphore_features =
    vk::external_semaphore_feature_flag::none;
};
static_assert(sizeof(external_semaphore_properties) ==
                sizeof(::VkExternalSemaphoreProperties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceMaintenance3Properties.
class physical_device_maintenance_3_properties
{
public:
  /// Default constructor.
  constexpr physical_device_maintenance_3_properties() = default;

  /// Constructor.
  constexpr physical_device_maintenance_3_properties(
    void* initial_next, uint32_t initial_max_per_set_descriptors,
    VkDeviceSize initial_max_memory_allocation_size) noexcept
  : _next(std::move(initial_next)),
    _max_per_set_descriptors(std::move(initial_max_per_set_descriptors)),
    _max_memory_allocation_size(std::move(initial_max_memory_allocation_size))
  {
  }

  /// Copy constructor.
  constexpr physical_device_maintenance_3_properties(
    const physical_device_maintenance_3_properties& other) noexcept
  : _next(other._next),
    _max_per_set_descriptors(other._max_per_set_descriptors),
    _max_memory_allocation_size(other._max_memory_allocation_size)
  {
  }

  /// Move constructor.
  constexpr physical_device_maintenance_3_properties(
    physical_device_maintenance_3_properties&& other) noexcept
  : _next(std::move(other._next)),
    _max_per_set_descriptors(std::move(other._max_per_set_descriptors)),
    _max_memory_allocation_size(std::move(other._max_memory_allocation_size))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_maintenance_3_properties& operator=(
    const physical_device_maintenance_3_properties& other) noexcept
  {
    _next = other._next;
    _max_per_set_descriptors = other._max_per_set_descriptors;
    _max_memory_allocation_size = other._max_memory_allocation_size;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_maintenance_3_properties& operator=(
    physical_device_maintenance_3_properties&& other) noexcept
  {
    _next = std::move(other._next);
    _max_per_set_descriptors = std::move(other._max_per_set_descriptors);
    _max_memory_allocation_size = std::move(other._max_memory_allocation_size);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceMaintenance3Properties&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceMaintenance3Properties*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_per_set_descriptors()
  {
    return _max_per_set_descriptors;
  }

  constexpr const uint32_t& max_per_set_descriptors() const
  {
    return _max_per_set_descriptors;
  }

  void max_per_set_descriptors(uint32_t new_max_per_set_descriptors)
  {
    _max_per_set_descriptors = new_max_per_set_descriptors;
  }

  VkDeviceSize& max_memory_allocation_size()
  {
    return _max_memory_allocation_size;
  }

  constexpr const VkDeviceSize& max_memory_allocation_size() const
  {
    return _max_memory_allocation_size;
  }

  void max_memory_allocation_size(VkDeviceSize new_max_memory_allocation_size)
  {
    _max_memory_allocation_size = new_max_memory_allocation_size;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_maintenance_3_properties;
  void* _next = nullptr;
  uint32_t _max_per_set_descriptors = 0;
  VkDeviceSize _max_memory_allocation_size = 0;
};
static_assert(sizeof(physical_device_maintenance_3_properties) ==
                sizeof(::VkPhysicalDeviceMaintenance3Properties),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDescriptorSetLayoutSupport.
class descriptor_set_layout_support
{
public:
  /// Default constructor.
  constexpr descriptor_set_layout_support() = default;

  /// Constructor.
  constexpr descriptor_set_layout_support(void* initial_next,
                                          VkBool32 initial_supported) noexcept
  : _next(std::move(initial_next)), _supported(std::move(initial_supported))
  {
  }

  /// Copy constructor.
  constexpr descriptor_set_layout_support(
    const descriptor_set_layout_support& other) noexcept
  : _next(other._next), _supported(other._supported)
  {
  }

  /// Move constructor.
  constexpr descriptor_set_layout_support(
    descriptor_set_layout_support&& other) noexcept
  : _next(std::move(other._next)), _supported(std::move(other._supported))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_set_layout_support& operator=(
    const descriptor_set_layout_support& other) noexcept
  {
    _next = other._next;
    _supported = other._supported;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_set_layout_support& operator=(
    descriptor_set_layout_support&& other) noexcept
  {
    _next = std::move(other._next);
    _supported = std::move(other._supported);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorSetLayoutSupport&() const
  {
    return *reinterpret_cast<const VkDescriptorSetLayoutSupport*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& supported()
  {
    return _supported;
  }

  constexpr const VkBool32& supported() const
  {
    return _supported;
  }

  void supported(VkBool32 new_supported)
  {
    _supported = new_supported;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::descriptor_set_layout_support;
  void* _next = nullptr;
  VkBool32 _supported = VK_FALSE;
};
static_assert(sizeof(descriptor_set_layout_support) ==
                sizeof(::VkDescriptorSetLayoutSupport),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceShaderDrawParameterFeatures.
class physical_device_shader_draw_parameter_features
{
public:
  /// Default constructor.
  constexpr physical_device_shader_draw_parameter_features() = default;

  /// Constructor.
  constexpr physical_device_shader_draw_parameter_features(
    void* initial_next, VkBool32 initial_shader_draw_parameters) noexcept
  : _next(std::move(initial_next)),
    _shader_draw_parameters(std::move(initial_shader_draw_parameters))
  {
  }

  /// Copy constructor.
  constexpr physical_device_shader_draw_parameter_features(
    const physical_device_shader_draw_parameter_features& other) noexcept
  : _next(other._next), _shader_draw_parameters(other._shader_draw_parameters)
  {
  }

  /// Move constructor.
  constexpr physical_device_shader_draw_parameter_features(
    physical_device_shader_draw_parameter_features&& other) noexcept
  : _next(std::move(other._next)),
    _shader_draw_parameters(std::move(other._shader_draw_parameters))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_shader_draw_parameter_features& operator=(
    const physical_device_shader_draw_parameter_features& other) noexcept
  {
    _next = other._next;
    _shader_draw_parameters = other._shader_draw_parameters;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_shader_draw_parameter_features& operator=(
    physical_device_shader_draw_parameter_features&& other) noexcept
  {
    _next = std::move(other._next);
    _shader_draw_parameters = std::move(other._shader_draw_parameters);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceShaderDrawParameterFeatures&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceShaderDrawParameterFeatures*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& shader_draw_parameters()
  {
    return _shader_draw_parameters;
  }

  constexpr const VkBool32& shader_draw_parameters() const
  {
    return _shader_draw_parameters;
  }

  void shader_draw_parameters(VkBool32 new_shader_draw_parameters)
  {
    _shader_draw_parameters = new_shader_draw_parameters;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_shader_draw_parameter_features;
  void* _next = nullptr;
  VkBool32 _shader_draw_parameters = VK_FALSE;
};
static_assert(sizeof(physical_device_shader_draw_parameter_features) ==
                sizeof(::VkPhysicalDeviceShaderDrawParameterFeatures),
              "struct and wrapper have different size!");

inline vk::result enumerate_instance_version(uint32_t* api_version)
{
  return static_cast<vk::result>(
    vkEnumerateInstanceVersion(reinterpret_cast<uint32_t*>(api_version)));
}
inline vk::result bind_buffer_memory_2(
  VkDevice device, uint32_t bind_info_count,
  const vk::bind_buffer_memory_info* bind_infos)
{
  return static_cast<vk::result>(vkBindBufferMemory2(
    static_cast<VkDevice>(device), static_cast<uint32_t>(bind_info_count),
    reinterpret_cast<const VkBindBufferMemoryInfo*>(bind_infos)));
}
inline vk::result bind_image_memory_2(
  VkDevice device, uint32_t bind_info_count,
  const vk::bind_image_memory_info* bind_infos)
{
  return static_cast<vk::result>(vkBindImageMemory2(
    static_cast<VkDevice>(device), static_cast<uint32_t>(bind_info_count),
    reinterpret_cast<const VkBindImageMemoryInfo*>(bind_infos)));
}
inline void get_device_group_peer_memory_features(
  VkDevice device, uint32_t heap_index, uint32_t local_device_index,
  uint32_t remote_device_index,
  vk::peer_memory_feature_flags* peer_memory_features)
{
  vkGetDeviceGroupPeerMemoryFeatures(
    static_cast<VkDevice>(device), static_cast<uint32_t>(heap_index),
    static_cast<uint32_t>(local_device_index),
    static_cast<uint32_t>(remote_device_index),
    reinterpret_cast<VkPeerMemoryFeatureFlags*>(peer_memory_features));
}
inline void cmd_set_device_mask(VkCommandBuffer command_buffer,
                                uint32_t device_mask)
{
  vkCmdSetDeviceMask(static_cast<VkCommandBuffer>(command_buffer),
                     static_cast<uint32_t>(device_mask));
}
inline void cmd_dispatch_base(VkCommandBuffer command_buffer,
                              uint32_t base_group_x, uint32_t base_group_y,
                              uint32_t base_group_z, uint32_t group_count_x,
                              uint32_t group_count_y, uint32_t group_count_z)
{
  vkCmdDispatchBase(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<uint32_t>(base_group_x), static_cast<uint32_t>(base_group_y),
    static_cast<uint32_t>(base_group_z), static_cast<uint32_t>(group_count_x),
    static_cast<uint32_t>(group_count_y), static_cast<uint32_t>(group_count_z));
}
inline vk::result enumerate_physical_device_groups(
  VkInstance instance, uint32_t* physical_device_group_count,
  vk::physical_device_group_properties* physical_device_group_properties)
{
  return static_cast<vk::result>(vkEnumeratePhysicalDeviceGroups(
    static_cast<VkInstance>(instance),
    reinterpret_cast<uint32_t*>(physical_device_group_count),
    reinterpret_cast<VkPhysicalDeviceGroupProperties*>(
      physical_device_group_properties)));
}
inline void get_image_memory_requirements_2(
  VkDevice device, const vk::image_memory_requirements_info_2* info,
  vk::memory_requirements_2* memory_requirements)
{
  vkGetImageMemoryRequirements2(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkImageMemoryRequirementsInfo2*>(info),
    reinterpret_cast<VkMemoryRequirements2*>(memory_requirements));
}
inline void get_buffer_memory_requirements_2(
  VkDevice device, const vk::buffer_memory_requirements_info_2* info,
  vk::memory_requirements_2* memory_requirements)
{
  vkGetBufferMemoryRequirements2(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkBufferMemoryRequirementsInfo2*>(info),
    reinterpret_cast<VkMemoryRequirements2*>(memory_requirements));
}
inline void get_image_sparse_memory_requirements_2(
  VkDevice device, const vk::image_sparse_memory_requirements_info_2* info,
  uint32_t* sparse_memory_requirement_count,
  vk::sparse_image_memory_requirements_2* sparse_memory_requirements)
{
  vkGetImageSparseMemoryRequirements2(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>(info),
    reinterpret_cast<uint32_t*>(sparse_memory_requirement_count),
    reinterpret_cast<VkSparseImageMemoryRequirements2*>(
      sparse_memory_requirements));
}
inline void get_physical_device_features_2(
  VkPhysicalDevice physical_device, vk::physical_device_features_2* features)
{
  vkGetPhysicalDeviceFeatures2(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<VkPhysicalDeviceFeatures2*>(features));
}
inline void get_physical_device_properties_2(
  VkPhysicalDevice physical_device,
  vk::physical_device_properties_2* properties)
{
  vkGetPhysicalDeviceProperties2(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<VkPhysicalDeviceProperties2*>(properties));
}
inline void get_physical_device_format_properties_2(
  VkPhysicalDevice physical_device, vk::format format,
  vk::format_properties_2* format_properties)
{
  vkGetPhysicalDeviceFormatProperties2(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkFormat>(format),
    reinterpret_cast<VkFormatProperties2*>(format_properties));
}
inline vk::result get_physical_device_image_format_properties_2(
  VkPhysicalDevice physical_device,
  const vk::physical_device_image_format_info_2* image_format_info,
  vk::image_format_properties_2* image_format_properties)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceImageFormatProperties2(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<const VkPhysicalDeviceImageFormatInfo2*>(
      image_format_info),
    reinterpret_cast<VkImageFormatProperties2*>(image_format_properties)));
}
inline void get_physical_device_queue_family_properties_2(
  VkPhysicalDevice physical_device, uint32_t* queue_family_property_count,
  vk::queue_family_properties_2* queue_family_properties)
{
  vkGetPhysicalDeviceQueueFamilyProperties2(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<uint32_t*>(queue_family_property_count),
    reinterpret_cast<VkQueueFamilyProperties2*>(queue_family_properties));
}
inline void get_physical_device_memory_properties_2(
  VkPhysicalDevice physical_device,
  vk::physical_device_memory_properties_2* memory_properties)
{
  vkGetPhysicalDeviceMemoryProperties2(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>(memory_properties));
}
inline void get_physical_device_sparse_image_format_properties_2(
  VkPhysicalDevice physical_device,
  const vk::physical_device_sparse_image_format_info_2* format_info,
  uint32_t* property_count, vk::sparse_image_format_properties_2* properties)
{
  vkGetPhysicalDeviceSparseImageFormatProperties2(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>(
      format_info),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkSparseImageFormatProperties2*>(properties));
}
inline void trim_command_pool(VkDevice device, VkCommandPool command_pool,
                              vk::command_pool_trim_flags flags)
{
  vkTrimCommandPool(static_cast<VkDevice>(device),
                    static_cast<VkCommandPool>(command_pool),
                    static_cast<VkCommandPoolTrimFlags>(flags));
}
inline void get_device_queue_2(VkDevice device,
                               const vk::device_queue_info_2* queue_info,
                               VkQueue* queue)
{
  vkGetDeviceQueue2(static_cast<VkDevice>(device),
                    reinterpret_cast<const VkDeviceQueueInfo2*>(queue_info),
                    reinterpret_cast<VkQueue*>(queue));
}
inline vk::result create_sampler_ycbcr_conversion(
  VkDevice device, const vk::sampler_ycbcr_conversion_create_info* create_info,
  const vk::allocation_callbacks* allocator,
  VkSamplerYcbcrConversion* ycbcr_conversion)
{
  return static_cast<vk::result>(vkCreateSamplerYcbcrConversion(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkSamplerYcbcrConversionCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSamplerYcbcrConversion*>(ycbcr_conversion)));
}
inline void destroy_sampler_ycbcr_conversion(
  VkDevice device, VkSamplerYcbcrConversion ycbcr_conversion,
  const vk::allocation_callbacks* allocator)
{
  vkDestroySamplerYcbcrConversion(
    static_cast<VkDevice>(device),
    static_cast<VkSamplerYcbcrConversion>(ycbcr_conversion),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result create_descriptor_update_template(
  VkDevice device,
  const vk::descriptor_update_template_create_info* create_info,
  const vk::allocation_callbacks* allocator,
  VkDescriptorUpdateTemplate* descriptor_update_template)
{
  return static_cast<vk::result>(vkCreateDescriptorUpdateTemplate(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDescriptorUpdateTemplateCreateInfo*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkDescriptorUpdateTemplate*>(descriptor_update_template)));
}
inline void destroy_descriptor_update_template(
  VkDevice device, VkDescriptorUpdateTemplate descriptor_update_template,
  const vk::allocation_callbacks* allocator)
{
  vkDestroyDescriptorUpdateTemplate(
    static_cast<VkDevice>(device),
    static_cast<VkDescriptorUpdateTemplate>(descriptor_update_template),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline void update_descriptor_set_with_template(
  VkDevice device, VkDescriptorSet descriptor_set,
  VkDescriptorUpdateTemplate descriptor_update_template, const void* data)
{
  vkUpdateDescriptorSetWithTemplate(
    static_cast<VkDevice>(device), static_cast<VkDescriptorSet>(descriptor_set),
    static_cast<VkDescriptorUpdateTemplate>(descriptor_update_template),
    reinterpret_cast<const void*>(data));
}
inline void get_physical_device_external_buffer_properties(
  VkPhysicalDevice physical_device,
  const vk::physical_device_external_buffer_info* external_buffer_info,
  vk::external_buffer_properties* external_buffer_properties)
{
  vkGetPhysicalDeviceExternalBufferProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<const VkPhysicalDeviceExternalBufferInfo*>(
      external_buffer_info),
    reinterpret_cast<VkExternalBufferProperties*>(external_buffer_properties));
}
inline void get_physical_device_external_fence_properties(
  VkPhysicalDevice physical_device,
  const vk::physical_device_external_fence_info* external_fence_info,
  vk::external_fence_properties* external_fence_properties)
{
  vkGetPhysicalDeviceExternalFenceProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<const VkPhysicalDeviceExternalFenceInfo*>(
      external_fence_info),
    reinterpret_cast<VkExternalFenceProperties*>(external_fence_properties));
}
inline void get_physical_device_external_semaphore_properties(
  VkPhysicalDevice physical_device,
  const vk::physical_device_external_semaphore_info* external_semaphore_info,
  vk::external_semaphore_properties* external_semaphore_properties)
{
  vkGetPhysicalDeviceExternalSemaphoreProperties(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<const VkPhysicalDeviceExternalSemaphoreInfo*>(
      external_semaphore_info),
    reinterpret_cast<VkExternalSemaphoreProperties*>(
      external_semaphore_properties));
}
inline void get_descriptor_set_layout_support(
  VkDevice device, const vk::descriptor_set_layout_create_info* create_info,
  vk::descriptor_set_layout_support* support)
{
  vkGetDescriptorSetLayoutSupport(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>(create_info),
    reinterpret_cast<VkDescriptorSetLayoutSupport*>(support));
}
inline void destroy_surface_khr(VkInstance instance, VkSurfaceKHR surface,
                                const vk::allocation_callbacks* allocator)
{
  vkDestroySurfaceKHR(
    static_cast<VkInstance>(instance), static_cast<VkSurfaceKHR>(surface),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result get_physical_device_surface_support_khr(
  VkPhysicalDevice physical_device, uint32_t queue_family_index,
  VkSurfaceKHR surface, VkBool32* supported)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceSurfaceSupportKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<uint32_t>(queue_family_index),
    static_cast<VkSurfaceKHR>(surface),
    reinterpret_cast<VkBool32*>(supported)));
}
enum class surface_transform_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_SURFACE_TRANSFORM_IDENTITY_BIT_KHR
  identity_bit_khr = 1 << 0,
  /// @see VK_SURFACE_TRANSFORM_ROTATE_90_BIT_KHR
  rotate_90_bit_khr = 1 << 1,
  /// @see VK_SURFACE_TRANSFORM_ROTATE_180_BIT_KHR
  rotate_180_bit_khr = 1 << 2,
  /// @see VK_SURFACE_TRANSFORM_ROTATE_270_BIT_KHR
  rotate_270_bit_khr = 1 << 3,
  /// @see VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_BIT_KHR
  horizontal_mirror_bit_khr = 1 << 4,
  /// @see VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_90_BIT_KHR
  horizontal_mirror_rotate_90_bit_khr = 1 << 5,
  /// @see VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_180_BIT_KHR
  horizontal_mirror_rotate_180_bit_khr = 1 << 6,
  /// @see VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_270_BIT_KHR
  horizontal_mirror_rotate_270_bit_khr = 1 << 7,
  /// @see VK_SURFACE_TRANSFORM_INHERIT_BIT_KHR
  inherit_bit_khr = 1 << 8,
};
using surface_transform_flags_khr =
  shift::core::bit_field<surface_transform_flag_khr,
                         VkSurfaceTransformFlagsKHR>;
inline constexpr surface_transform_flags_khr operator|(
  surface_transform_flag_khr lhs, surface_transform_flag_khr rhs)
{
  return surface_transform_flags_khr{lhs} | rhs;
}
enum class composite_alpha_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR
  opaque_bit_khr = 1 << 0,
  /// @see VK_COMPOSITE_ALPHA_PRE_MULTIPLIED_BIT_KHR
  pre_multiplied_bit_khr = 1 << 1,
  /// @see VK_COMPOSITE_ALPHA_POST_MULTIPLIED_BIT_KHR
  post_multiplied_bit_khr = 1 << 2,
  /// @see VK_COMPOSITE_ALPHA_INHERIT_BIT_KHR
  inherit_bit_khr = 1 << 3,
};
using composite_alpha_flags_khr =
  shift::core::bit_field<composite_alpha_flag_khr, VkCompositeAlphaFlagsKHR>;
inline constexpr composite_alpha_flags_khr operator|(
  composite_alpha_flag_khr lhs, composite_alpha_flag_khr rhs)
{
  return composite_alpha_flags_khr{lhs} | rhs;
}
/// Enhanced replacement type for VkSurfaceCapabilitiesKHR.
class surface_capabilities_khr
{
public:
  /// Default constructor.
  constexpr surface_capabilities_khr() = default;

  /// Constructor.
  constexpr surface_capabilities_khr(
    uint32_t initial_min_image_count, uint32_t initial_max_image_count,
    vk::extent_2d initial_current_extent,
    vk::extent_2d initial_min_image_extent,
    vk::extent_2d initial_max_image_extent,
    uint32_t initial_max_image_array_layers,
    vk::surface_transform_flags_khr initial_supported_transforms,
    vk::surface_transform_flag_khr initial_current_transform,
    vk::composite_alpha_flags_khr initial_supported_composite_alpha,
    vk::image_usage_flags initial_supported_usage_flags) noexcept
  : _min_image_count(std::move(initial_min_image_count)),
    _max_image_count(std::move(initial_max_image_count)),
    _current_extent(std::move(initial_current_extent)),
    _min_image_extent(std::move(initial_min_image_extent)),
    _max_image_extent(std::move(initial_max_image_extent)),
    _max_image_array_layers(std::move(initial_max_image_array_layers)),
    _supported_transforms(std::move(initial_supported_transforms)),
    _current_transform(std::move(initial_current_transform)),
    _supported_composite_alpha(std::move(initial_supported_composite_alpha)),
    _supported_usage_flags(std::move(initial_supported_usage_flags))
  {
  }

  /// Copy constructor.
  constexpr surface_capabilities_khr(const surface_capabilities_khr& other) =
    default;

  /// Move constructor.
  constexpr surface_capabilities_khr(surface_capabilities_khr&& other) =
    default;

  /// Copy assignment operator.
  constexpr surface_capabilities_khr& operator=(
    const surface_capabilities_khr& other) = default;

  /// Move assignment operator.
  constexpr surface_capabilities_khr& operator=(
    surface_capabilities_khr&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSurfaceCapabilitiesKHR&() const
  {
    return *reinterpret_cast<const VkSurfaceCapabilitiesKHR*>(this);
  }

  uint32_t& min_image_count()
  {
    return _min_image_count;
  }

  constexpr const uint32_t& min_image_count() const
  {
    return _min_image_count;
  }

  void min_image_count(uint32_t new_min_image_count)
  {
    _min_image_count = new_min_image_count;
  }

  uint32_t& max_image_count()
  {
    return _max_image_count;
  }

  constexpr const uint32_t& max_image_count() const
  {
    return _max_image_count;
  }

  void max_image_count(uint32_t new_max_image_count)
  {
    _max_image_count = new_max_image_count;
  }

  vk::extent_2d& current_extent()
  {
    return _current_extent;
  }

  constexpr const vk::extent_2d& current_extent() const
  {
    return _current_extent;
  }

  void current_extent(vk::extent_2d new_current_extent)
  {
    _current_extent = new_current_extent;
  }

  vk::extent_2d& min_image_extent()
  {
    return _min_image_extent;
  }

  constexpr const vk::extent_2d& min_image_extent() const
  {
    return _min_image_extent;
  }

  void min_image_extent(vk::extent_2d new_min_image_extent)
  {
    _min_image_extent = new_min_image_extent;
  }

  vk::extent_2d& max_image_extent()
  {
    return _max_image_extent;
  }

  constexpr const vk::extent_2d& max_image_extent() const
  {
    return _max_image_extent;
  }

  void max_image_extent(vk::extent_2d new_max_image_extent)
  {
    _max_image_extent = new_max_image_extent;
  }

  uint32_t& max_image_array_layers()
  {
    return _max_image_array_layers;
  }

  constexpr const uint32_t& max_image_array_layers() const
  {
    return _max_image_array_layers;
  }

  void max_image_array_layers(uint32_t new_max_image_array_layers)
  {
    _max_image_array_layers = new_max_image_array_layers;
  }

  vk::surface_transform_flags_khr& supported_transforms()
  {
    return _supported_transforms;
  }

  constexpr const vk::surface_transform_flags_khr& supported_transforms() const
  {
    return _supported_transforms;
  }

  void supported_transforms(
    vk::surface_transform_flags_khr new_supported_transforms)
  {
    _supported_transforms = new_supported_transforms;
  }

  vk::surface_transform_flag_khr& current_transform()
  {
    return _current_transform;
  }

  constexpr const vk::surface_transform_flag_khr& current_transform() const
  {
    return _current_transform;
  }

  void current_transform(vk::surface_transform_flag_khr new_current_transform)
  {
    _current_transform = new_current_transform;
  }

  vk::composite_alpha_flags_khr& supported_composite_alpha()
  {
    return _supported_composite_alpha;
  }

  constexpr const vk::composite_alpha_flags_khr& supported_composite_alpha()
    const
  {
    return _supported_composite_alpha;
  }

  void supported_composite_alpha(
    vk::composite_alpha_flags_khr new_supported_composite_alpha)
  {
    _supported_composite_alpha = new_supported_composite_alpha;
  }

  vk::image_usage_flags& supported_usage_flags()
  {
    return _supported_usage_flags;
  }

  constexpr const vk::image_usage_flags& supported_usage_flags() const
  {
    return _supported_usage_flags;
  }

  void supported_usage_flags(vk::image_usage_flags new_supported_usage_flags)
  {
    _supported_usage_flags = new_supported_usage_flags;
  }

private:
  /// Supported minimum number of images for the surface
  uint32_t _min_image_count = 0;
  /// Supported maximum number of images for the surface, 0 for unlimited
  uint32_t _max_image_count = 0;
  /// Current image width and height for the surface, (0, 0) if undefined
  vk::extent_2d _current_extent = vk::extent_2d{};
  /// Supported minimum image width and height for the surface
  vk::extent_2d _min_image_extent = vk::extent_2d{};
  /// Supported maximum image width and height for the surface
  vk::extent_2d _max_image_extent = vk::extent_2d{};
  /// Supported maximum number of image layers for the surface
  uint32_t _max_image_array_layers = 0;
  /// 1 or more bits representing the transforms supported
  vk::surface_transform_flags_khr _supported_transforms =
    vk::surface_transform_flag_khr::none;
  /// The surface's current transform relative to the device's natural
  /// orientation
  vk::surface_transform_flag_khr _current_transform =
    vk::surface_transform_flag_khr::none;
  /// 1 or more bits representing the alpha compositing modes supported
  vk::composite_alpha_flags_khr _supported_composite_alpha =
    vk::composite_alpha_flag_khr::none;
  /// Supported image usage flags for the surface
  vk::image_usage_flags _supported_usage_flags = vk::image_usage_flag::none;
};
static_assert(sizeof(surface_capabilities_khr) ==
                sizeof(::VkSurfaceCapabilitiesKHR),
              "struct and wrapper have different size!");

inline vk::result get_physical_device_surface_capabilities_khr(
  VkPhysicalDevice physical_device, VkSurfaceKHR surface,
  vk::surface_capabilities_khr* surface_capabilities)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceSurfaceCapabilitiesKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkSurfaceKHR>(surface),
    reinterpret_cast<VkSurfaceCapabilitiesKHR*>(surface_capabilities)));
}
enum class color_space_khr
{
  /// @see VK_COLOR_SPACE_SRGB_NONLINEAR_KHR
  color_space_srgb_nonlinear_khr = 0,
  /// Backwards-compatible alias containing a typo
  /// @see VK_COLORSPACE_SRGB_NONLINEAR_KHR
  colorspace_srgb_nonlinear_khr = color_space_srgb_nonlinear_khr,
  /// @see VK_COLOR_SPACE_DISPLAY_P3_NONLINEAR_EXT
  color_space_display_p_3_nonlinear_ext = 1000104001,
  /// @see VK_COLOR_SPACE_EXTENDED_SRGB_LINEAR_EXT
  color_space_extended_srgb_linear_ext = 1000104002,
  /// @see VK_COLOR_SPACE_DCI_P3_LINEAR_EXT
  color_space_dci_p_3_linear_ext = 1000104003,
  /// @see VK_COLOR_SPACE_DCI_P3_NONLINEAR_EXT
  color_space_dci_p_3_nonlinear_ext = 1000104004,
  /// @see VK_COLOR_SPACE_BT709_LINEAR_EXT
  color_space_bt_709_linear_ext = 1000104005,
  /// @see VK_COLOR_SPACE_BT709_NONLINEAR_EXT
  color_space_bt_709_nonlinear_ext = 1000104006,
  /// @see VK_COLOR_SPACE_BT2020_LINEAR_EXT
  color_space_bt_2020_linear_ext = 1000104007,
  /// @see VK_COLOR_SPACE_HDR10_ST2084_EXT
  color_space_hdr10_st_2084_ext = 1000104008,
  /// @see VK_COLOR_SPACE_DOLBYVISION_EXT
  color_space_dolbyvision_ext = 1000104009,
  /// @see VK_COLOR_SPACE_HDR10_HLG_EXT
  color_space_hdr10_hlg_ext = 1000104010,
  /// @see VK_COLOR_SPACE_ADOBERGB_LINEAR_EXT
  color_space_adobergb_linear_ext = 1000104011,
  /// @see VK_COLOR_SPACE_ADOBERGB_NONLINEAR_EXT
  color_space_adobergb_nonlinear_ext = 1000104012,
  /// @see VK_COLOR_SPACE_PASS_THROUGH_EXT
  color_space_pass_through_ext = 1000104013,
  /// @see VK_COLOR_SPACE_EXTENDED_SRGB_NONLINEAR_EXT
  color_space_extended_srgb_nonlinear_ext = 1000104014,
};

/// Enhanced replacement type for VkSurfaceFormatKHR.
class surface_format_khr
{
public:
  /// Default constructor.
  constexpr surface_format_khr() = default;

  /// Constructor.
  constexpr surface_format_khr(vk::format initial_format,
                               vk::color_space_khr initial_color_space) noexcept
  : _format(std::move(initial_format)),
    _color_space(std::move(initial_color_space))
  {
  }

  /// Copy constructor.
  constexpr surface_format_khr(const surface_format_khr& other) = default;

  /// Move constructor.
  constexpr surface_format_khr(surface_format_khr&& other) = default;

  /// Copy assignment operator.
  constexpr surface_format_khr& operator=(const surface_format_khr& other) =
    default;

  /// Move assignment operator.
  constexpr surface_format_khr& operator=(surface_format_khr&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSurfaceFormatKHR&() const
  {
    return *reinterpret_cast<const VkSurfaceFormatKHR*>(this);
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  vk::color_space_khr& color_space()
  {
    return _color_space;
  }

  constexpr const vk::color_space_khr& color_space() const
  {
    return _color_space;
  }

  void color_space(vk::color_space_khr new_color_space)
  {
    _color_space = new_color_space;
  }

private:
  /// Supported pair of rendering format
  vk::format _format = vk::format::undefined;
  /// and color space for the surface
  vk::color_space_khr _color_space =
    vk::color_space_khr::color_space_srgb_nonlinear_khr;
};
static_assert(sizeof(surface_format_khr) == sizeof(::VkSurfaceFormatKHR),
              "struct and wrapper have different size!");

inline vk::result get_physical_device_surface_formats_khr(
  VkPhysicalDevice physical_device, VkSurfaceKHR surface,
  uint32_t* surface_format_count, vk::surface_format_khr* surface_formats)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceSurfaceFormatsKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkSurfaceKHR>(surface),
    reinterpret_cast<uint32_t*>(surface_format_count),
    reinterpret_cast<VkSurfaceFormatKHR*>(surface_formats)));
}
enum class present_mode_khr
{
  /// @see VK_PRESENT_MODE_IMMEDIATE_KHR
  present_mode_immediate_khr = 0,
  /// @see VK_PRESENT_MODE_MAILBOX_KHR
  present_mode_mailbox_khr = 1,
  /// @see VK_PRESENT_MODE_FIFO_KHR
  present_mode_fifo_khr = 2,
  /// @see VK_PRESENT_MODE_FIFO_RELAXED_KHR
  present_mode_fifo_relaxed_khr = 3,
  /// @see VK_PRESENT_MODE_SHARED_DEMAND_REFRESH_KHR
  present_mode_shared_demand_refresh_khr = 1000111000,
  /// @see VK_PRESENT_MODE_SHARED_CONTINUOUS_REFRESH_KHR
  present_mode_shared_continuous_refresh_khr = 1000111001,
};
inline vk::result get_physical_device_surface_present_modes_khr(
  VkPhysicalDevice physical_device, VkSurfaceKHR surface,
  uint32_t* present_mode_count, vk::present_mode_khr* present_modes)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceSurfacePresentModesKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkSurfaceKHR>(surface),
    reinterpret_cast<uint32_t*>(present_mode_count),
    reinterpret_cast<VkPresentModeKHR*>(present_modes)));
}

/// Enhanced replacement type for VkImageSwapchainCreateInfoKHR.
class image_swapchain_create_info_khr
{
public:
  /// Default constructor.
  constexpr image_swapchain_create_info_khr() = default;

  /// Constructor.
  constexpr image_swapchain_create_info_khr(
    const void* initial_next, VkSwapchainKHR initial_swapchain) noexcept
  : _next(std::move(initial_next)), _swapchain(std::move(initial_swapchain))
  {
  }

  /// Copy constructor.
  constexpr image_swapchain_create_info_khr(
    const image_swapchain_create_info_khr& other) noexcept
  : _next(other._next), _swapchain(other._swapchain)
  {
  }

  /// Move constructor.
  constexpr image_swapchain_create_info_khr(
    image_swapchain_create_info_khr&& other) noexcept
  : _next(std::move(other._next)), _swapchain(std::move(other._swapchain))
  {
  }

  /// Copy assignment operator.
  constexpr image_swapchain_create_info_khr& operator=(
    const image_swapchain_create_info_khr& other) noexcept
  {
    _next = other._next;
    _swapchain = other._swapchain;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_swapchain_create_info_khr& operator=(
    image_swapchain_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _swapchain = std::move(other._swapchain);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageSwapchainCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkImageSwapchainCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkSwapchainKHR& swapchain()
  {
    return _swapchain;
  }

  constexpr const VkSwapchainKHR& swapchain() const
  {
    return _swapchain;
  }

  void swapchain(VkSwapchainKHR new_swapchain)
  {
    _swapchain = new_swapchain;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_swapchain_create_info_khr;
  const void* _next = nullptr;
  VkSwapchainKHR _swapchain = nullptr;
};
static_assert(sizeof(image_swapchain_create_info_khr) ==
                sizeof(::VkImageSwapchainCreateInfoKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkBindImageMemorySwapchainInfoKHR.
class bind_image_memory_swapchain_info_khr
{
public:
  /// Default constructor.
  constexpr bind_image_memory_swapchain_info_khr() = default;

  /// Constructor.
  constexpr bind_image_memory_swapchain_info_khr(
    const void* initial_next, VkSwapchainKHR initial_swapchain,
    uint32_t initial_image_index) noexcept
  : _next(std::move(initial_next)),
    _swapchain(std::move(initial_swapchain)),
    _image_index(std::move(initial_image_index))
  {
  }

  /// Copy constructor.
  constexpr bind_image_memory_swapchain_info_khr(
    const bind_image_memory_swapchain_info_khr& other) noexcept
  : _next(other._next),
    _swapchain(other._swapchain),
    _image_index(other._image_index)
  {
  }

  /// Move constructor.
  constexpr bind_image_memory_swapchain_info_khr(
    bind_image_memory_swapchain_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _swapchain(std::move(other._swapchain)),
    _image_index(std::move(other._image_index))
  {
  }

  /// Copy assignment operator.
  constexpr bind_image_memory_swapchain_info_khr& operator=(
    const bind_image_memory_swapchain_info_khr& other) noexcept
  {
    _next = other._next;
    _swapchain = other._swapchain;
    _image_index = other._image_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr bind_image_memory_swapchain_info_khr& operator=(
    bind_image_memory_swapchain_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _swapchain = std::move(other._swapchain);
    _image_index = std::move(other._image_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBindImageMemorySwapchainInfoKHR&() const
  {
    return *reinterpret_cast<const VkBindImageMemorySwapchainInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkSwapchainKHR& swapchain()
  {
    return _swapchain;
  }

  constexpr const VkSwapchainKHR& swapchain() const
  {
    return _swapchain;
  }

  void swapchain(VkSwapchainKHR new_swapchain)
  {
    _swapchain = new_swapchain;
  }

  uint32_t& image_index()
  {
    return _image_index;
  }

  constexpr const uint32_t& image_index() const
  {
    return _image_index;
  }

  void image_index(uint32_t new_image_index)
  {
    _image_index = new_image_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::bind_image_memory_swapchain_info_khr;
  const void* _next = nullptr;
  VkSwapchainKHR _swapchain = nullptr;
  uint32_t _image_index = 0;
};
static_assert(sizeof(bind_image_memory_swapchain_info_khr) ==
                sizeof(::VkBindImageMemorySwapchainInfoKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkAcquireNextImageInfoKHR.
class acquire_next_image_info_khr
{
public:
  /// Default constructor.
  constexpr acquire_next_image_info_khr() = default;

  /// Constructor.
  constexpr acquire_next_image_info_khr(const void* initial_next,
                                        VkSwapchainKHR initial_swapchain,
                                        uint64_t initial_timeout,
                                        VkSemaphore initial_semaphore,
                                        VkFence initial_fence,
                                        uint32_t initial_device_mask) noexcept
  : _next(std::move(initial_next)),
    _swapchain(std::move(initial_swapchain)),
    _timeout(std::move(initial_timeout)),
    _semaphore(std::move(initial_semaphore)),
    _fence(std::move(initial_fence)),
    _device_mask(std::move(initial_device_mask))
  {
  }

  /// Copy constructor.
  constexpr acquire_next_image_info_khr(
    const acquire_next_image_info_khr& other) noexcept
  : _next(other._next),
    _swapchain(other._swapchain),
    _timeout(other._timeout),
    _semaphore(other._semaphore),
    _fence(other._fence),
    _device_mask(other._device_mask)
  {
  }

  /// Move constructor.
  constexpr acquire_next_image_info_khr(
    acquire_next_image_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _swapchain(std::move(other._swapchain)),
    _timeout(std::move(other._timeout)),
    _semaphore(std::move(other._semaphore)),
    _fence(std::move(other._fence)),
    _device_mask(std::move(other._device_mask))
  {
  }

  /// Copy assignment operator.
  constexpr acquire_next_image_info_khr& operator=(
    const acquire_next_image_info_khr& other) noexcept
  {
    _next = other._next;
    _swapchain = other._swapchain;
    _timeout = other._timeout;
    _semaphore = other._semaphore;
    _fence = other._fence;
    _device_mask = other._device_mask;
    return *this;
  }

  /// Move assignment operator.
  constexpr acquire_next_image_info_khr& operator=(
    acquire_next_image_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _swapchain = std::move(other._swapchain);
    _timeout = std::move(other._timeout);
    _semaphore = std::move(other._semaphore);
    _fence = std::move(other._fence);
    _device_mask = std::move(other._device_mask);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkAcquireNextImageInfoKHR&() const
  {
    return *reinterpret_cast<const VkAcquireNextImageInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkSwapchainKHR& swapchain()
  {
    return _swapchain;
  }

  constexpr const VkSwapchainKHR& swapchain() const
  {
    return _swapchain;
  }

  void swapchain(VkSwapchainKHR new_swapchain)
  {
    _swapchain = new_swapchain;
  }

  uint64_t& timeout()
  {
    return _timeout;
  }

  constexpr const uint64_t& timeout() const
  {
    return _timeout;
  }

  void timeout(uint64_t new_timeout)
  {
    _timeout = new_timeout;
  }

  VkSemaphore& semaphore()
  {
    return _semaphore;
  }

  constexpr const VkSemaphore& semaphore() const
  {
    return _semaphore;
  }

  void semaphore(VkSemaphore new_semaphore)
  {
    _semaphore = new_semaphore;
  }

  VkFence& fence()
  {
    return _fence;
  }

  constexpr const VkFence& fence() const
  {
    return _fence;
  }

  void fence(VkFence new_fence)
  {
    _fence = new_fence;
  }

  uint32_t& device_mask()
  {
    return _device_mask;
  }

  constexpr const uint32_t& device_mask() const
  {
    return _device_mask;
  }

  void device_mask(uint32_t new_device_mask)
  {
    _device_mask = new_device_mask;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::acquire_next_image_info_khr;
  const void* _next = nullptr;
  VkSwapchainKHR _swapchain = nullptr;
  uint64_t _timeout = 0;
  VkSemaphore _semaphore = nullptr;
  VkFence _fence = nullptr;
  uint32_t _device_mask = 0;
};
static_assert(sizeof(acquire_next_image_info_khr) ==
                sizeof(::VkAcquireNextImageInfoKHR),
              "struct and wrapper have different size!");

enum class device_group_present_mode_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Present from local memory
  /// @see VK_DEVICE_GROUP_PRESENT_MODE_LOCAL_BIT_KHR
  local_bit_khr = 1 << 0,
  /// Present from remote memory
  /// @see VK_DEVICE_GROUP_PRESENT_MODE_REMOTE_BIT_KHR
  remote_bit_khr = 1 << 1,
  /// Present sum of local and/or remote memory
  /// @see VK_DEVICE_GROUP_PRESENT_MODE_SUM_BIT_KHR
  sum_bit_khr = 1 << 2,
  /// Each physical device presents from local memory
  /// @see VK_DEVICE_GROUP_PRESENT_MODE_LOCAL_MULTI_DEVICE_BIT_KHR
  local_multi_device_bit_khr = 1 << 3,
};
using device_group_present_mode_flags_khr =
  shift::core::bit_field<device_group_present_mode_flag_khr,
                         VkDeviceGroupPresentModeFlagsKHR>;
inline constexpr device_group_present_mode_flags_khr operator|(
  device_group_present_mode_flag_khr lhs,
  device_group_present_mode_flag_khr rhs)
{
  return device_group_present_mode_flags_khr{lhs} | rhs;
}
/// Enhanced replacement type for VkDeviceGroupPresentCapabilitiesKHR.
class device_group_present_capabilities_khr
{
public:
  /// Default constructor.
  constexpr device_group_present_capabilities_khr() = default;

  /// Constructor.
  constexpr device_group_present_capabilities_khr(
    const void* initial_next,
    std::array<uint32_t, VK_MAX_DEVICE_GROUP_SIZE> initial_present_mask,
    vk::device_group_present_mode_flags_khr initial_modes) noexcept
  : _next(std::move(initial_next)),
    _present_mask(std::move(initial_present_mask)),
    _modes(std::move(initial_modes))
  {
  }

  /// Copy constructor.
  constexpr device_group_present_capabilities_khr(
    const device_group_present_capabilities_khr& other) noexcept
  : _next(other._next), _present_mask(other._present_mask), _modes(other._modes)
  {
  }

  /// Move constructor.
  constexpr device_group_present_capabilities_khr(
    device_group_present_capabilities_khr&& other) noexcept
  : _next(std::move(other._next)),
    _present_mask(std::move(other._present_mask)),
    _modes(std::move(other._modes))
  {
  }

  /// Copy assignment operator.
  constexpr device_group_present_capabilities_khr& operator=(
    const device_group_present_capabilities_khr& other) noexcept
  {
    _next = other._next;
    _present_mask = other._present_mask;
    _modes = other._modes;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_group_present_capabilities_khr& operator=(
    device_group_present_capabilities_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _present_mask = std::move(other._present_mask);
    _modes = std::move(other._modes);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGroupPresentCapabilitiesKHR&() const
  {
    return *reinterpret_cast<const VkDeviceGroupPresentCapabilitiesKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  std::array<uint32_t, VK_MAX_DEVICE_GROUP_SIZE>& present_mask()
  {
    return _present_mask;
  }

  constexpr const std::array<uint32_t, VK_MAX_DEVICE_GROUP_SIZE>& present_mask()
    const
  {
    return _present_mask;
  }

  void present_mask(
    std::array<uint32_t, VK_MAX_DEVICE_GROUP_SIZE> new_present_mask)
  {
    _present_mask = new_present_mask;
  }

  vk::device_group_present_mode_flags_khr& modes()
  {
    return _modes;
  }

  constexpr const vk::device_group_present_mode_flags_khr& modes() const
  {
    return _modes;
  }

  void modes(vk::device_group_present_mode_flags_khr new_modes)
  {
    _modes = new_modes;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_group_present_capabilities_khr;
  const void* _next = nullptr;
  std::array<uint32_t, VK_MAX_DEVICE_GROUP_SIZE> _present_mask = {};
  vk::device_group_present_mode_flags_khr _modes =
    vk::device_group_present_mode_flag_khr::none;
};
static_assert(sizeof(device_group_present_capabilities_khr) ==
                sizeof(::VkDeviceGroupPresentCapabilitiesKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceGroupPresentInfoKHR.
class device_group_present_info_khr
{
public:
  /// Default constructor.
  constexpr device_group_present_info_khr() = default;

  /// Constructor.
  constexpr device_group_present_info_khr(
    const void* initial_next, uint32_t initial_swapchain_count,
    const uint32_t* initial_device_masks,
    vk::device_group_present_mode_flag_khr initial_mode) noexcept
  : _next(std::move(initial_next)),
    _swapchain_count(std::move(initial_swapchain_count)),
    _device_masks(std::move(initial_device_masks)),
    _mode(std::move(initial_mode))
  {
  }

  /// Copy constructor.
  constexpr device_group_present_info_khr(
    const device_group_present_info_khr& other) noexcept
  : _next(other._next),
    _swapchain_count(other._swapchain_count),
    _device_masks(other._device_masks),
    _mode(other._mode)
  {
  }

  /// Move constructor.
  constexpr device_group_present_info_khr(
    device_group_present_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _swapchain_count(std::move(other._swapchain_count)),
    _device_masks(std::move(other._device_masks)),
    _mode(std::move(other._mode))
  {
  }

  /// Copy assignment operator.
  constexpr device_group_present_info_khr& operator=(
    const device_group_present_info_khr& other) noexcept
  {
    _next = other._next;
    _swapchain_count = other._swapchain_count;
    _device_masks = other._device_masks;
    _mode = other._mode;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_group_present_info_khr& operator=(
    device_group_present_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _swapchain_count = std::move(other._swapchain_count);
    _device_masks = std::move(other._device_masks);
    _mode = std::move(other._mode);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGroupPresentInfoKHR&() const
  {
    return *reinterpret_cast<const VkDeviceGroupPresentInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& swapchain_count()
  {
    return _swapchain_count;
  }

  constexpr const uint32_t& swapchain_count() const
  {
    return _swapchain_count;
  }

  void swapchain_count(uint32_t new_swapchain_count)
  {
    _swapchain_count = new_swapchain_count;
  }

  const uint32_t* device_masks()
  {
    return _device_masks;
  }

  constexpr const uint32_t* device_masks() const
  {
    return _device_masks;
  }

  void device_masks(const uint32_t* new_device_masks)
  {
    _device_masks = new_device_masks;
  }

  template <std::size_t Count>
  void device_masks(const std::array<uint32_t, Count>& new_device_masks)
  {
    _swapchain_count = static_cast<uint32_t>(new_device_masks.size());
    _device_masks = new_device_masks.data();
  }

  void device_masks(const std::vector<uint32_t>& new_device_masks)
  {
    _swapchain_count = static_cast<uint32_t>(new_device_masks.size());
    _device_masks = new_device_masks.data();
  }

  vk::device_group_present_mode_flag_khr& mode()
  {
    return _mode;
  }

  constexpr const vk::device_group_present_mode_flag_khr& mode() const
  {
    return _mode;
  }

  void mode(vk::device_group_present_mode_flag_khr new_mode)
  {
    _mode = new_mode;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_group_present_info_khr;
  const void* _next = nullptr;
  uint32_t _swapchain_count = 0;
  const uint32_t* _device_masks = nullptr;
  vk::device_group_present_mode_flag_khr _mode =
    vk::device_group_present_mode_flag_khr::none;
};
static_assert(sizeof(device_group_present_info_khr) ==
                sizeof(::VkDeviceGroupPresentInfoKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceGroupSwapchainCreateInfoKHR.
class device_group_swapchain_create_info_khr
{
public:
  /// Default constructor.
  constexpr device_group_swapchain_create_info_khr() = default;

  /// Constructor.
  constexpr device_group_swapchain_create_info_khr(
    const void* initial_next,
    vk::device_group_present_mode_flags_khr initial_modes) noexcept
  : _next(std::move(initial_next)), _modes(std::move(initial_modes))
  {
  }

  /// Copy constructor.
  constexpr device_group_swapchain_create_info_khr(
    const device_group_swapchain_create_info_khr& other) noexcept
  : _next(other._next), _modes(other._modes)
  {
  }

  /// Move constructor.
  constexpr device_group_swapchain_create_info_khr(
    device_group_swapchain_create_info_khr&& other) noexcept
  : _next(std::move(other._next)), _modes(std::move(other._modes))
  {
  }

  /// Copy assignment operator.
  constexpr device_group_swapchain_create_info_khr& operator=(
    const device_group_swapchain_create_info_khr& other) noexcept
  {
    _next = other._next;
    _modes = other._modes;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_group_swapchain_create_info_khr& operator=(
    device_group_swapchain_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _modes = std::move(other._modes);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGroupSwapchainCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkDeviceGroupSwapchainCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::device_group_present_mode_flags_khr& modes()
  {
    return _modes;
  }

  constexpr const vk::device_group_present_mode_flags_khr& modes() const
  {
    return _modes;
  }

  void modes(vk::device_group_present_mode_flags_khr new_modes)
  {
    _modes = new_modes;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_group_swapchain_create_info_khr;
  const void* _next = nullptr;
  vk::device_group_present_mode_flags_khr _modes =
    vk::device_group_present_mode_flag_khr::none;
};
static_assert(sizeof(device_group_swapchain_create_info_khr) ==
                sizeof(::VkDeviceGroupSwapchainCreateInfoKHR),
              "struct and wrapper have different size!");

enum class swapchain_create_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// Allow images with VK_IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT
  /// @see VK_SWAPCHAIN_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT_KHR
  split_instance_bind_regions_bit_khr = 1 << 0,
  /// Swapchain is protected
  /// @see VK_SWAPCHAIN_CREATE_PROTECTED_BIT_KHR
  protected_bit_khr = 1 << 1,
};
using swapchain_create_flags_khr =
  shift::core::bit_field<swapchain_create_flag_khr, VkSwapchainCreateFlagsKHR>;
inline constexpr swapchain_create_flags_khr operator|(
  swapchain_create_flag_khr lhs, swapchain_create_flag_khr rhs)
{
  return swapchain_create_flags_khr{lhs} | rhs;
}
/// Enhanced replacement type for VkSwapchainCreateInfoKHR.
class swapchain_create_info_khr
{
public:
  /// Default constructor.
  constexpr swapchain_create_info_khr() = default;

  /// Constructor.
  constexpr swapchain_create_info_khr(
    const void* initial_next, vk::swapchain_create_flags_khr initial_flags,
    VkSurfaceKHR initial_surface, uint32_t initial_min_image_count,
    vk::format initial_image_format,
    vk::color_space_khr initial_image_color_space,
    vk::extent_2d initial_image_extent, uint32_t initial_image_array_layers,
    vk::image_usage_flags initial_image_usage,
    vk::sharing_mode initial_image_sharing_mode,
    uint32_t initial_queue_family_index_count,
    const uint32_t* initial_queue_family_indices,
    vk::surface_transform_flag_khr initial_pre_transform,
    vk::composite_alpha_flag_khr initial_composite_alpha,
    vk::present_mode_khr initial_present_mode, VkBool32 initial_clipped,
    VkSwapchainKHR initial_old_swapchain) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _surface(std::move(initial_surface)),
    _min_image_count(std::move(initial_min_image_count)),
    _image_format(std::move(initial_image_format)),
    _image_color_space(std::move(initial_image_color_space)),
    _image_extent(std::move(initial_image_extent)),
    _image_array_layers(std::move(initial_image_array_layers)),
    _image_usage(std::move(initial_image_usage)),
    _image_sharing_mode(std::move(initial_image_sharing_mode)),
    _queue_family_index_count(std::move(initial_queue_family_index_count)),
    _queue_family_indices(std::move(initial_queue_family_indices)),
    _pre_transform(std::move(initial_pre_transform)),
    _composite_alpha(std::move(initial_composite_alpha)),
    _present_mode(std::move(initial_present_mode)),
    _clipped(std::move(initial_clipped)),
    _old_swapchain(std::move(initial_old_swapchain))
  {
  }

  /// Copy constructor.
  constexpr swapchain_create_info_khr(
    const swapchain_create_info_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _surface(other._surface),
    _min_image_count(other._min_image_count),
    _image_format(other._image_format),
    _image_color_space(other._image_color_space),
    _image_extent(other._image_extent),
    _image_array_layers(other._image_array_layers),
    _image_usage(other._image_usage),
    _image_sharing_mode(other._image_sharing_mode),
    _queue_family_index_count(other._queue_family_index_count),
    _queue_family_indices(other._queue_family_indices),
    _pre_transform(other._pre_transform),
    _composite_alpha(other._composite_alpha),
    _present_mode(other._present_mode),
    _clipped(other._clipped),
    _old_swapchain(other._old_swapchain)
  {
  }

  /// Move constructor.
  constexpr swapchain_create_info_khr(
    swapchain_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _surface(std::move(other._surface)),
    _min_image_count(std::move(other._min_image_count)),
    _image_format(std::move(other._image_format)),
    _image_color_space(std::move(other._image_color_space)),
    _image_extent(std::move(other._image_extent)),
    _image_array_layers(std::move(other._image_array_layers)),
    _image_usage(std::move(other._image_usage)),
    _image_sharing_mode(std::move(other._image_sharing_mode)),
    _queue_family_index_count(std::move(other._queue_family_index_count)),
    _queue_family_indices(std::move(other._queue_family_indices)),
    _pre_transform(std::move(other._pre_transform)),
    _composite_alpha(std::move(other._composite_alpha)),
    _present_mode(std::move(other._present_mode)),
    _clipped(std::move(other._clipped)),
    _old_swapchain(std::move(other._old_swapchain))
  {
  }

  /// Copy assignment operator.
  constexpr swapchain_create_info_khr& operator=(
    const swapchain_create_info_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _surface = other._surface;
    _min_image_count = other._min_image_count;
    _image_format = other._image_format;
    _image_color_space = other._image_color_space;
    _image_extent = other._image_extent;
    _image_array_layers = other._image_array_layers;
    _image_usage = other._image_usage;
    _image_sharing_mode = other._image_sharing_mode;
    _queue_family_index_count = other._queue_family_index_count;
    _queue_family_indices = other._queue_family_indices;
    _pre_transform = other._pre_transform;
    _composite_alpha = other._composite_alpha;
    _present_mode = other._present_mode;
    _clipped = other._clipped;
    _old_swapchain = other._old_swapchain;
    return *this;
  }

  /// Move assignment operator.
  constexpr swapchain_create_info_khr& operator=(
    swapchain_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _surface = std::move(other._surface);
    _min_image_count = std::move(other._min_image_count);
    _image_format = std::move(other._image_format);
    _image_color_space = std::move(other._image_color_space);
    _image_extent = std::move(other._image_extent);
    _image_array_layers = std::move(other._image_array_layers);
    _image_usage = std::move(other._image_usage);
    _image_sharing_mode = std::move(other._image_sharing_mode);
    _queue_family_index_count = std::move(other._queue_family_index_count);
    _queue_family_indices = std::move(other._queue_family_indices);
    _pre_transform = std::move(other._pre_transform);
    _composite_alpha = std::move(other._composite_alpha);
    _present_mode = std::move(other._present_mode);
    _clipped = std::move(other._clipped);
    _old_swapchain = std::move(other._old_swapchain);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSwapchainCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkSwapchainCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::swapchain_create_flags_khr& flags()
  {
    return _flags;
  }

  constexpr const vk::swapchain_create_flags_khr& flags() const
  {
    return _flags;
  }

  void flags(vk::swapchain_create_flags_khr new_flags)
  {
    _flags = new_flags;
  }

  VkSurfaceKHR& surface()
  {
    return _surface;
  }

  constexpr const VkSurfaceKHR& surface() const
  {
    return _surface;
  }

  void surface(VkSurfaceKHR new_surface)
  {
    _surface = new_surface;
  }

  uint32_t& min_image_count()
  {
    return _min_image_count;
  }

  constexpr const uint32_t& min_image_count() const
  {
    return _min_image_count;
  }

  void min_image_count(uint32_t new_min_image_count)
  {
    _min_image_count = new_min_image_count;
  }

  vk::format& image_format()
  {
    return _image_format;
  }

  constexpr const vk::format& image_format() const
  {
    return _image_format;
  }

  void image_format(vk::format new_image_format)
  {
    _image_format = new_image_format;
  }

  vk::color_space_khr& image_color_space()
  {
    return _image_color_space;
  }

  constexpr const vk::color_space_khr& image_color_space() const
  {
    return _image_color_space;
  }

  void image_color_space(vk::color_space_khr new_image_color_space)
  {
    _image_color_space = new_image_color_space;
  }

  vk::extent_2d& image_extent()
  {
    return _image_extent;
  }

  constexpr const vk::extent_2d& image_extent() const
  {
    return _image_extent;
  }

  void image_extent(vk::extent_2d new_image_extent)
  {
    _image_extent = new_image_extent;
  }

  uint32_t& image_array_layers()
  {
    return _image_array_layers;
  }

  constexpr const uint32_t& image_array_layers() const
  {
    return _image_array_layers;
  }

  void image_array_layers(uint32_t new_image_array_layers)
  {
    _image_array_layers = new_image_array_layers;
  }

  vk::image_usage_flags& image_usage()
  {
    return _image_usage;
  }

  constexpr const vk::image_usage_flags& image_usage() const
  {
    return _image_usage;
  }

  void image_usage(vk::image_usage_flags new_image_usage)
  {
    _image_usage = new_image_usage;
  }

  vk::sharing_mode& image_sharing_mode()
  {
    return _image_sharing_mode;
  }

  constexpr const vk::sharing_mode& image_sharing_mode() const
  {
    return _image_sharing_mode;
  }

  void image_sharing_mode(vk::sharing_mode new_image_sharing_mode)
  {
    _image_sharing_mode = new_image_sharing_mode;
  }

  uint32_t& queue_family_index_count()
  {
    return _queue_family_index_count;
  }

  constexpr const uint32_t& queue_family_index_count() const
  {
    return _queue_family_index_count;
  }

  void queue_family_index_count(uint32_t new_queue_family_index_count)
  {
    _queue_family_index_count = new_queue_family_index_count;
  }

  const uint32_t* queue_family_indices()
  {
    return _queue_family_indices;
  }

  constexpr const uint32_t* queue_family_indices() const
  {
    return _queue_family_indices;
  }

  void queue_family_indices(const uint32_t* new_queue_family_indices)
  {
    _queue_family_indices = new_queue_family_indices;
  }

  template <std::size_t Count>
  void queue_family_indices(
    const std::array<uint32_t, Count>& new_queue_family_indices)
  {
    _queue_family_index_count =
      static_cast<uint32_t>(new_queue_family_indices.size());
    _queue_family_indices = new_queue_family_indices.data();
  }

  void queue_family_indices(
    const std::vector<uint32_t>& new_queue_family_indices)
  {
    _queue_family_index_count =
      static_cast<uint32_t>(new_queue_family_indices.size());
    _queue_family_indices = new_queue_family_indices.data();
  }

  vk::surface_transform_flag_khr& pre_transform()
  {
    return _pre_transform;
  }

  constexpr const vk::surface_transform_flag_khr& pre_transform() const
  {
    return _pre_transform;
  }

  void pre_transform(vk::surface_transform_flag_khr new_pre_transform)
  {
    _pre_transform = new_pre_transform;
  }

  vk::composite_alpha_flag_khr& composite_alpha()
  {
    return _composite_alpha;
  }

  constexpr const vk::composite_alpha_flag_khr& composite_alpha() const
  {
    return _composite_alpha;
  }

  void composite_alpha(vk::composite_alpha_flag_khr new_composite_alpha)
  {
    _composite_alpha = new_composite_alpha;
  }

  vk::present_mode_khr& present_mode()
  {
    return _present_mode;
  }

  constexpr const vk::present_mode_khr& present_mode() const
  {
    return _present_mode;
  }

  void present_mode(vk::present_mode_khr new_present_mode)
  {
    _present_mode = new_present_mode;
  }

  VkBool32& clipped()
  {
    return _clipped;
  }

  constexpr const VkBool32& clipped() const
  {
    return _clipped;
  }

  void clipped(VkBool32 new_clipped)
  {
    _clipped = new_clipped;
  }

  VkSwapchainKHR& old_swapchain()
  {
    return _old_swapchain;
  }

  constexpr const VkSwapchainKHR& old_swapchain() const
  {
    return _old_swapchain;
  }

  void old_swapchain(VkSwapchainKHR new_old_swapchain)
  {
    _old_swapchain = new_old_swapchain;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::swapchain_create_info_khr;
  const void* _next = nullptr;
  vk::swapchain_create_flags_khr _flags = vk::swapchain_create_flag_khr::none;
  /// The swapchain's target surface
  VkSurfaceKHR _surface = nullptr;
  /// Minimum number of presentation images the application needs
  uint32_t _min_image_count = 0;
  /// Format of the presentation images
  vk::format _image_format = vk::format::undefined;
  /// Colorspace of the presentation images
  vk::color_space_khr _image_color_space =
    vk::color_space_khr::color_space_srgb_nonlinear_khr;
  /// Dimensions of the presentation images
  vk::extent_2d _image_extent = vk::extent_2d{};
  /// Determines the number of views for multiview/stereo presentation
  uint32_t _image_array_layers = 0;
  /// Bits indicating how the presentation images will be used
  vk::image_usage_flags _image_usage = vk::image_usage_flag::none;
  /// Sharing mode used for the presentation images
  vk::sharing_mode _image_sharing_mode = vk::sharing_mode::exclusive;
  /// Number of queue families having access to the images in case of concurrent
  /// sharing mode
  uint32_t _queue_family_index_count = 0;
  /// Array of queue family indices having access to the images in case of
  /// concurrent sharing mode
  const uint32_t* _queue_family_indices = nullptr;
  /// The transform, relative to the device's natural orientation, applied to
  /// the image content prior to presentation
  vk::surface_transform_flag_khr _pre_transform =
    vk::surface_transform_flag_khr::none;
  /// The alpha blending mode used when compositing this surface with other
  /// surfaces in the window system
  vk::composite_alpha_flag_khr _composite_alpha =
    vk::composite_alpha_flag_khr::none;
  /// Which presentation mode to use for presents on this swap chain
  vk::present_mode_khr _present_mode =
    vk::present_mode_khr::present_mode_immediate_khr;
  /// Specifies whether presentable images may be affected by window clip
  /// regions
  VkBool32 _clipped = VK_FALSE;
  /// Existing swap chain to replace, if any
  VkSwapchainKHR _old_swapchain = nullptr;
};
static_assert(sizeof(swapchain_create_info_khr) ==
                sizeof(::VkSwapchainCreateInfoKHR),
              "struct and wrapper have different size!");

inline vk::result create_swapchain_khr(
  VkDevice device, const vk::swapchain_create_info_khr* create_info,
  const vk::allocation_callbacks* allocator, VkSwapchainKHR* swapchain)
{
  return static_cast<vk::result>(vkCreateSwapchainKHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkSwapchainCreateInfoKHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSwapchainKHR*>(swapchain)));
}
inline void destroy_swapchain_khr(VkDevice device, VkSwapchainKHR swapchain,
                                  const vk::allocation_callbacks* allocator)
{
  vkDestroySwapchainKHR(
    static_cast<VkDevice>(device), static_cast<VkSwapchainKHR>(swapchain),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result get_swapchain_images_khr(VkDevice device,
                                           VkSwapchainKHR swapchain,
                                           uint32_t* swapchain_image_count,
                                           VkImage* swapchain_images)
{
  return static_cast<vk::result>(vkGetSwapchainImagesKHR(
    static_cast<VkDevice>(device), static_cast<VkSwapchainKHR>(swapchain),
    reinterpret_cast<uint32_t*>(swapchain_image_count),
    reinterpret_cast<VkImage*>(swapchain_images)));
}
inline vk::result acquire_next_image_khr(VkDevice device,
                                         VkSwapchainKHR swapchain,
                                         uint64_t timeout,
                                         VkSemaphore semaphore, VkFence fence,
                                         uint32_t* image_index)
{
  return static_cast<vk::result>(vkAcquireNextImageKHR(
    static_cast<VkDevice>(device), static_cast<VkSwapchainKHR>(swapchain),
    static_cast<uint64_t>(timeout), static_cast<VkSemaphore>(semaphore),
    static_cast<VkFence>(fence), reinterpret_cast<uint32_t*>(image_index)));
}

/// Enhanced replacement type for VkPresentInfoKHR.
class present_info_khr
{
public:
  /// Default constructor.
  constexpr present_info_khr() = default;

  /// Constructor.
  constexpr present_info_khr(const void* initial_next,
                             uint32_t initial_wait_semaphore_count,
                             const VkSemaphore* initial_wait_semaphores,
                             uint32_t initial_swapchain_count,
                             const VkSwapchainKHR* initial_swapchains,
                             const uint32_t* initial_image_indices,
                             vk::result* initial_results) noexcept
  : _next(std::move(initial_next)),
    _wait_semaphore_count(std::move(initial_wait_semaphore_count)),
    _wait_semaphores(std::move(initial_wait_semaphores)),
    _swapchain_count(std::move(initial_swapchain_count)),
    _swapchains(std::move(initial_swapchains)),
    _image_indices(std::move(initial_image_indices)),
    _results(std::move(initial_results))
  {
  }

  /// Copy constructor.
  constexpr present_info_khr(const present_info_khr& other) noexcept
  : _next(other._next),
    _wait_semaphore_count(other._wait_semaphore_count),
    _wait_semaphores(other._wait_semaphores),
    _swapchain_count(other._swapchain_count),
    _swapchains(other._swapchains),
    _image_indices(other._image_indices),
    _results(other._results)
  {
  }

  /// Move constructor.
  constexpr present_info_khr(present_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _wait_semaphore_count(std::move(other._wait_semaphore_count)),
    _wait_semaphores(std::move(other._wait_semaphores)),
    _swapchain_count(std::move(other._swapchain_count)),
    _swapchains(std::move(other._swapchains)),
    _image_indices(std::move(other._image_indices)),
    _results(std::move(other._results))
  {
  }

  /// Copy assignment operator.
  constexpr present_info_khr& operator=(const present_info_khr& other) noexcept
  {
    _next = other._next;
    _wait_semaphore_count = other._wait_semaphore_count;
    _wait_semaphores = other._wait_semaphores;
    _swapchain_count = other._swapchain_count;
    _swapchains = other._swapchains;
    _image_indices = other._image_indices;
    _results = other._results;
    return *this;
  }

  /// Move assignment operator.
  constexpr present_info_khr& operator=(present_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _wait_semaphore_count = std::move(other._wait_semaphore_count);
    _wait_semaphores = std::move(other._wait_semaphores);
    _swapchain_count = std::move(other._swapchain_count);
    _swapchains = std::move(other._swapchains);
    _image_indices = std::move(other._image_indices);
    _results = std::move(other._results);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPresentInfoKHR&() const
  {
    return *reinterpret_cast<const VkPresentInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& wait_semaphore_count()
  {
    return _wait_semaphore_count;
  }

  constexpr const uint32_t& wait_semaphore_count() const
  {
    return _wait_semaphore_count;
  }

  void wait_semaphore_count(uint32_t new_wait_semaphore_count)
  {
    _wait_semaphore_count = new_wait_semaphore_count;
  }

  const VkSemaphore* wait_semaphores()
  {
    return _wait_semaphores;
  }

  constexpr const VkSemaphore* wait_semaphores() const
  {
    return _wait_semaphores;
  }

  void wait_semaphores(const VkSemaphore* new_wait_semaphores)
  {
    _wait_semaphores = new_wait_semaphores;
  }

  template <std::size_t Count>
  void wait_semaphores(
    const std::array<VkSemaphore, Count>& new_wait_semaphores)
  {
    _wait_semaphore_count = static_cast<uint32_t>(new_wait_semaphores.size());
    _wait_semaphores = new_wait_semaphores.data();
  }

  void wait_semaphores(const std::vector<VkSemaphore>& new_wait_semaphores)
  {
    _wait_semaphore_count = static_cast<uint32_t>(new_wait_semaphores.size());
    _wait_semaphores = new_wait_semaphores.data();
  }

  uint32_t& swapchain_count()
  {
    return _swapchain_count;
  }

  constexpr const uint32_t& swapchain_count() const
  {
    return _swapchain_count;
  }

  void swapchain_count(uint32_t new_swapchain_count)
  {
    _swapchain_count = new_swapchain_count;
  }

  const VkSwapchainKHR* swapchains()
  {
    return _swapchains;
  }

  constexpr const VkSwapchainKHR* swapchains() const
  {
    return _swapchains;
  }

  void swapchains(const VkSwapchainKHR* new_swapchains)
  {
    _swapchains = new_swapchains;
  }

  template <std::size_t Count>
  void swapchains(const std::array<VkSwapchainKHR, Count>& new_swapchains)
  {
    _swapchain_count = static_cast<uint32_t>(new_swapchains.size());
    _swapchains = new_swapchains.data();
  }

  void swapchains(const std::vector<VkSwapchainKHR>& new_swapchains)
  {
    _swapchain_count = static_cast<uint32_t>(new_swapchains.size());
    _swapchains = new_swapchains.data();
  }

  const uint32_t* image_indices()
  {
    return _image_indices;
  }

  constexpr const uint32_t* image_indices() const
  {
    return _image_indices;
  }

  void image_indices(const uint32_t* new_image_indices)
  {
    _image_indices = new_image_indices;
  }

  template <std::size_t Count>
  void image_indices(const std::array<uint32_t, Count>& new_image_indices)
  {
    _swapchain_count = static_cast<uint32_t>(new_image_indices.size());
    _image_indices = new_image_indices.data();
  }

  void image_indices(const std::vector<uint32_t>& new_image_indices)
  {
    _swapchain_count = static_cast<uint32_t>(new_image_indices.size());
    _image_indices = new_image_indices.data();
  }

  vk::result* results()
  {
    return _results;
  }

  constexpr vk::result* results() const
  {
    return _results;
  }

  void results(vk::result* new_results)
  {
    _results = new_results;
  }

  template <std::size_t Count>
  void results(std::array<vk::result, Count>& new_results)
  {
    _swapchain_count = static_cast<uint32_t>(new_results.size());
    _results = new_results.data();
  }

  void results(std::vector<vk::result>& new_results)
  {
    _swapchain_count = static_cast<uint32_t>(new_results.size());
    _results = new_results.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::present_info_khr;
  const void* _next = nullptr;
  /// Number of semaphores to wait for before presenting
  uint32_t _wait_semaphore_count = 0;
  /// Semaphores to wait for before presenting
  const VkSemaphore* _wait_semaphores = nullptr;
  /// Number of swapchains to present in this call
  uint32_t _swapchain_count = 0;
  /// Swapchains to present an image from
  const VkSwapchainKHR* _swapchains = nullptr;
  /// Indices of which presentable images to present
  const uint32_t* _image_indices = nullptr;
  /// Optional (i.e. if non-NULL) VkResult for each swapchain
  vk::result* _results = nullptr;
};
static_assert(sizeof(present_info_khr) == sizeof(::VkPresentInfoKHR),
              "struct and wrapper have different size!");

inline vk::result queue_present_khr(VkQueue queue,
                                    const vk::present_info_khr* present_info)
{
  return static_cast<vk::result>(
    vkQueuePresentKHR(static_cast<VkQueue>(queue),
                      reinterpret_cast<const VkPresentInfoKHR*>(present_info)));
}
inline vk::result get_device_group_present_capabilities_khr(
  VkDevice device,
  vk::device_group_present_capabilities_khr* device_group_present_capabilities)
{
  return static_cast<vk::result>(vkGetDeviceGroupPresentCapabilitiesKHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<VkDeviceGroupPresentCapabilitiesKHR*>(
      device_group_present_capabilities)));
}
inline vk::result get_device_group_surface_present_modes_khr(
  VkDevice device, VkSurfaceKHR surface,
  vk::device_group_present_mode_flags_khr* modes)
{
  return static_cast<vk::result>(vkGetDeviceGroupSurfacePresentModesKHR(
    static_cast<VkDevice>(device), static_cast<VkSurfaceKHR>(surface),
    reinterpret_cast<VkDeviceGroupPresentModeFlagsKHR*>(modes)));
}
inline vk::result get_physical_device_present_rectangles_khr(
  VkPhysicalDevice physical_device, VkSurfaceKHR surface, uint32_t* rect_count,
  vk::rect_2d* rects)
{
  return static_cast<vk::result>(vkGetPhysicalDevicePresentRectanglesKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkSurfaceKHR>(surface), reinterpret_cast<uint32_t*>(rect_count),
    reinterpret_cast<VkRect2D*>(rects)));
}
inline vk::result acquire_next_image_2_khr(
  VkDevice device, const vk::acquire_next_image_info_khr* acquire_info,
  uint32_t* image_index)
{
  return static_cast<vk::result>(vkAcquireNextImage2KHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkAcquireNextImageInfoKHR*>(acquire_info),
    reinterpret_cast<uint32_t*>(image_index)));
}
enum class display_plane_alpha_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_DISPLAY_PLANE_ALPHA_OPAQUE_BIT_KHR
  opaque_bit_khr = 1 << 0,
  /// @see VK_DISPLAY_PLANE_ALPHA_GLOBAL_BIT_KHR
  global_bit_khr = 1 << 1,
  /// @see VK_DISPLAY_PLANE_ALPHA_PER_PIXEL_BIT_KHR
  per_pixel_bit_khr = 1 << 2,
  /// @see VK_DISPLAY_PLANE_ALPHA_PER_PIXEL_PREMULTIPLIED_BIT_KHR
  per_pixel_premultiplied_bit_khr = 1 << 3,
};
using display_plane_alpha_flags_khr =
  shift::core::bit_field<display_plane_alpha_flag_khr,
                         VkDisplayPlaneAlphaFlagsKHR>;
inline constexpr display_plane_alpha_flags_khr operator|(
  display_plane_alpha_flag_khr lhs, display_plane_alpha_flag_khr rhs)
{
  return display_plane_alpha_flags_khr{lhs} | rhs;
}
/// Enhanced replacement type for VkDisplayPropertiesKHR.
class display_properties_khr
{
public:
  /// Default constructor.
  constexpr display_properties_khr() = default;

  /// Constructor.
  constexpr display_properties_khr(
    VkDisplayKHR initial_display, const char* initial_display_name,
    vk::extent_2d initial_physical_dimensions,
    vk::extent_2d initial_physical_resolution,
    vk::surface_transform_flags_khr initial_supported_transforms,
    VkBool32 initial_plane_reorder_possible,
    VkBool32 initial_persistent_content) noexcept
  : _display(std::move(initial_display)),
    _display_name(std::move(initial_display_name)),
    _physical_dimensions(std::move(initial_physical_dimensions)),
    _physical_resolution(std::move(initial_physical_resolution)),
    _supported_transforms(std::move(initial_supported_transforms)),
    _plane_reorder_possible(std::move(initial_plane_reorder_possible)),
    _persistent_content(std::move(initial_persistent_content))
  {
  }

  /// Copy constructor.
  constexpr display_properties_khr(const display_properties_khr& other) =
    default;

  /// Move constructor.
  constexpr display_properties_khr(display_properties_khr&& other) = default;

  /// Copy assignment operator.
  constexpr display_properties_khr& operator=(
    const display_properties_khr& other) = default;

  /// Move assignment operator.
  constexpr display_properties_khr& operator=(display_properties_khr&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayPropertiesKHR&() const
  {
    return *reinterpret_cast<const VkDisplayPropertiesKHR*>(this);
  }

  VkDisplayKHR& display()
  {
    return _display;
  }

  constexpr const VkDisplayKHR& display() const
  {
    return _display;
  }

  void display(VkDisplayKHR new_display)
  {
    _display = new_display;
  }

  const char* display_name()
  {
    return _display_name;
  }

  constexpr const char* display_name() const
  {
    return _display_name;
  }

  void display_name(const char* new_display_name)
  {
    _display_name = new_display_name;
  }

  vk::extent_2d& physical_dimensions()
  {
    return _physical_dimensions;
  }

  constexpr const vk::extent_2d& physical_dimensions() const
  {
    return _physical_dimensions;
  }

  void physical_dimensions(vk::extent_2d new_physical_dimensions)
  {
    _physical_dimensions = new_physical_dimensions;
  }

  vk::extent_2d& physical_resolution()
  {
    return _physical_resolution;
  }

  constexpr const vk::extent_2d& physical_resolution() const
  {
    return _physical_resolution;
  }

  void physical_resolution(vk::extent_2d new_physical_resolution)
  {
    _physical_resolution = new_physical_resolution;
  }

  vk::surface_transform_flags_khr& supported_transforms()
  {
    return _supported_transforms;
  }

  constexpr const vk::surface_transform_flags_khr& supported_transforms() const
  {
    return _supported_transforms;
  }

  void supported_transforms(
    vk::surface_transform_flags_khr new_supported_transforms)
  {
    _supported_transforms = new_supported_transforms;
  }

  VkBool32& plane_reorder_possible()
  {
    return _plane_reorder_possible;
  }

  constexpr const VkBool32& plane_reorder_possible() const
  {
    return _plane_reorder_possible;
  }

  void plane_reorder_possible(VkBool32 new_plane_reorder_possible)
  {
    _plane_reorder_possible = new_plane_reorder_possible;
  }

  VkBool32& persistent_content()
  {
    return _persistent_content;
  }

  constexpr const VkBool32& persistent_content() const
  {
    return _persistent_content;
  }

  void persistent_content(VkBool32 new_persistent_content)
  {
    _persistent_content = new_persistent_content;
  }

private:
  /// Handle of the display object
  VkDisplayKHR _display = nullptr;
  /// Name of the display
  const char* _display_name = nullptr;
  /// In millimeters?
  vk::extent_2d _physical_dimensions = vk::extent_2d{};
  /// Max resolution for CRT?
  vk::extent_2d _physical_resolution = vk::extent_2d{};
  /// one or more bits from VkSurfaceTransformFlagsKHR
  vk::surface_transform_flags_khr _supported_transforms =
    vk::surface_transform_flag_khr::none;
  /// VK_TRUE if the overlay plane's z-order can be changed on this display.
  VkBool32 _plane_reorder_possible = VK_FALSE;
  /// VK_TRUE if this is a "smart" display that supports self-refresh/internal
  /// buffering.
  VkBool32 _persistent_content = VK_FALSE;
};
static_assert(sizeof(display_properties_khr) ==
                sizeof(::VkDisplayPropertiesKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDisplayModeParametersKHR.
class display_mode_parameters_khr
{
public:
  /// Default constructor.
  constexpr display_mode_parameters_khr() = default;

  /// Constructor.
  constexpr display_mode_parameters_khr(vk::extent_2d initial_visible_region,
                                        uint32_t initial_refresh_rate) noexcept
  : _visible_region(std::move(initial_visible_region)),
    _refresh_rate(std::move(initial_refresh_rate))
  {
  }

  /// Copy constructor.
  constexpr display_mode_parameters_khr(
    const display_mode_parameters_khr& other) = default;

  /// Move constructor.
  constexpr display_mode_parameters_khr(display_mode_parameters_khr&& other) =
    default;

  /// Copy assignment operator.
  constexpr display_mode_parameters_khr& operator=(
    const display_mode_parameters_khr& other) = default;

  /// Move assignment operator.
  constexpr display_mode_parameters_khr& operator=(
    display_mode_parameters_khr&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayModeParametersKHR&() const
  {
    return *reinterpret_cast<const VkDisplayModeParametersKHR*>(this);
  }

  vk::extent_2d& visible_region()
  {
    return _visible_region;
  }

  constexpr const vk::extent_2d& visible_region() const
  {
    return _visible_region;
  }

  void visible_region(vk::extent_2d new_visible_region)
  {
    _visible_region = new_visible_region;
  }

  uint32_t& refresh_rate()
  {
    return _refresh_rate;
  }

  constexpr const uint32_t& refresh_rate() const
  {
    return _refresh_rate;
  }

  void refresh_rate(uint32_t new_refresh_rate)
  {
    _refresh_rate = new_refresh_rate;
  }

private:
  /// Visible scanout region.
  vk::extent_2d _visible_region = vk::extent_2d{};
  /// Number of times per second the display is updated.
  uint32_t _refresh_rate = 0;
};
static_assert(sizeof(display_mode_parameters_khr) ==
                sizeof(::VkDisplayModeParametersKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDisplayModePropertiesKHR.
class display_mode_properties_khr
{
public:
  /// Default constructor.
  constexpr display_mode_properties_khr() = default;

  /// Constructor.
  constexpr display_mode_properties_khr(
    VkDisplayModeKHR initial_display_mode,
    vk::display_mode_parameters_khr initial_parameters) noexcept
  : _display_mode(std::move(initial_display_mode)),
    _parameters(std::move(initial_parameters))
  {
  }

  /// Copy constructor.
  constexpr display_mode_properties_khr(
    const display_mode_properties_khr& other) = default;

  /// Move constructor.
  constexpr display_mode_properties_khr(display_mode_properties_khr&& other) =
    default;

  /// Copy assignment operator.
  constexpr display_mode_properties_khr& operator=(
    const display_mode_properties_khr& other) = default;

  /// Move assignment operator.
  constexpr display_mode_properties_khr& operator=(
    display_mode_properties_khr&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayModePropertiesKHR&() const
  {
    return *reinterpret_cast<const VkDisplayModePropertiesKHR*>(this);
  }

  VkDisplayModeKHR& display_mode()
  {
    return _display_mode;
  }

  constexpr const VkDisplayModeKHR& display_mode() const
  {
    return _display_mode;
  }

  void display_mode(VkDisplayModeKHR new_display_mode)
  {
    _display_mode = new_display_mode;
  }

  vk::display_mode_parameters_khr& parameters()
  {
    return _parameters;
  }

  constexpr const vk::display_mode_parameters_khr& parameters() const
  {
    return _parameters;
  }

  void parameters(vk::display_mode_parameters_khr new_parameters)
  {
    _parameters = new_parameters;
  }

private:
  /// Handle of this display mode.
  VkDisplayModeKHR _display_mode = nullptr;
  /// The parameters this mode uses.
  vk::display_mode_parameters_khr _parameters =
    vk::display_mode_parameters_khr{};
};
static_assert(sizeof(display_mode_properties_khr) ==
                sizeof(::VkDisplayModePropertiesKHR),
              "struct and wrapper have different size!");

using display_mode_create_flags_khr = VkFlags;

/// Enhanced replacement type for VkDisplayModeCreateInfoKHR.
class display_mode_create_info_khr
{
public:
  /// Default constructor.
  constexpr display_mode_create_info_khr() = default;

  /// Constructor.
  constexpr display_mode_create_info_khr(
    const void* initial_next, vk::display_mode_create_flags_khr initial_flags,
    vk::display_mode_parameters_khr initial_parameters) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _parameters(std::move(initial_parameters))
  {
  }

  /// Copy constructor.
  constexpr display_mode_create_info_khr(
    const display_mode_create_info_khr& other) noexcept
  : _next(other._next), _flags(other._flags), _parameters(other._parameters)
  {
  }

  /// Move constructor.
  constexpr display_mode_create_info_khr(
    display_mode_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _parameters(std::move(other._parameters))
  {
  }

  /// Copy assignment operator.
  constexpr display_mode_create_info_khr& operator=(
    const display_mode_create_info_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _parameters = other._parameters;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_mode_create_info_khr& operator=(
    display_mode_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _parameters = std::move(other._parameters);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayModeCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkDisplayModeCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::display_mode_create_flags_khr& flags()
  {
    return _flags;
  }

  constexpr const vk::display_mode_create_flags_khr& flags() const
  {
    return _flags;
  }

  void flags(vk::display_mode_create_flags_khr new_flags)
  {
    _flags = new_flags;
  }

  vk::display_mode_parameters_khr& parameters()
  {
    return _parameters;
  }

  constexpr const vk::display_mode_parameters_khr& parameters() const
  {
    return _parameters;
  }

  void parameters(vk::display_mode_parameters_khr new_parameters)
  {
    _parameters = new_parameters;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_mode_create_info_khr;
  const void* _next = nullptr;
  vk::display_mode_create_flags_khr _flags = 0;
  /// The parameters this mode uses.
  vk::display_mode_parameters_khr _parameters =
    vk::display_mode_parameters_khr{};
};
static_assert(sizeof(display_mode_create_info_khr) ==
                sizeof(::VkDisplayModeCreateInfoKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDisplayPlaneCapabilitiesKHR.
class display_plane_capabilities_khr
{
public:
  /// Default constructor.
  constexpr display_plane_capabilities_khr() = default;

  /// Constructor.
  constexpr display_plane_capabilities_khr(
    vk::display_plane_alpha_flags_khr initial_supported_alpha,
    vk::offset_2d initial_min_src_position,
    vk::offset_2d initial_max_src_position,
    vk::extent_2d initial_min_src_extent, vk::extent_2d initial_max_src_extent,
    vk::offset_2d initial_min_dst_position,
    vk::offset_2d initial_max_dst_position,
    vk::extent_2d initial_min_dst_extent,
    vk::extent_2d initial_max_dst_extent) noexcept
  : _supported_alpha(std::move(initial_supported_alpha)),
    _min_src_position(std::move(initial_min_src_position)),
    _max_src_position(std::move(initial_max_src_position)),
    _min_src_extent(std::move(initial_min_src_extent)),
    _max_src_extent(std::move(initial_max_src_extent)),
    _min_dst_position(std::move(initial_min_dst_position)),
    _max_dst_position(std::move(initial_max_dst_position)),
    _min_dst_extent(std::move(initial_min_dst_extent)),
    _max_dst_extent(std::move(initial_max_dst_extent))
  {
  }

  /// Copy constructor.
  constexpr display_plane_capabilities_khr(
    const display_plane_capabilities_khr& other) = default;

  /// Move constructor.
  constexpr display_plane_capabilities_khr(
    display_plane_capabilities_khr&& other) = default;

  /// Copy assignment operator.
  constexpr display_plane_capabilities_khr& operator=(
    const display_plane_capabilities_khr& other) = default;

  /// Move assignment operator.
  constexpr display_plane_capabilities_khr& operator=(
    display_plane_capabilities_khr&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayPlaneCapabilitiesKHR&() const
  {
    return *reinterpret_cast<const VkDisplayPlaneCapabilitiesKHR*>(this);
  }

  vk::display_plane_alpha_flags_khr& supported_alpha()
  {
    return _supported_alpha;
  }

  constexpr const vk::display_plane_alpha_flags_khr& supported_alpha() const
  {
    return _supported_alpha;
  }

  void supported_alpha(vk::display_plane_alpha_flags_khr new_supported_alpha)
  {
    _supported_alpha = new_supported_alpha;
  }

  vk::offset_2d& min_src_position()
  {
    return _min_src_position;
  }

  constexpr const vk::offset_2d& min_src_position() const
  {
    return _min_src_position;
  }

  void min_src_position(vk::offset_2d new_min_src_position)
  {
    _min_src_position = new_min_src_position;
  }

  vk::offset_2d& max_src_position()
  {
    return _max_src_position;
  }

  constexpr const vk::offset_2d& max_src_position() const
  {
    return _max_src_position;
  }

  void max_src_position(vk::offset_2d new_max_src_position)
  {
    _max_src_position = new_max_src_position;
  }

  vk::extent_2d& min_src_extent()
  {
    return _min_src_extent;
  }

  constexpr const vk::extent_2d& min_src_extent() const
  {
    return _min_src_extent;
  }

  void min_src_extent(vk::extent_2d new_min_src_extent)
  {
    _min_src_extent = new_min_src_extent;
  }

  vk::extent_2d& max_src_extent()
  {
    return _max_src_extent;
  }

  constexpr const vk::extent_2d& max_src_extent() const
  {
    return _max_src_extent;
  }

  void max_src_extent(vk::extent_2d new_max_src_extent)
  {
    _max_src_extent = new_max_src_extent;
  }

  vk::offset_2d& min_dst_position()
  {
    return _min_dst_position;
  }

  constexpr const vk::offset_2d& min_dst_position() const
  {
    return _min_dst_position;
  }

  void min_dst_position(vk::offset_2d new_min_dst_position)
  {
    _min_dst_position = new_min_dst_position;
  }

  vk::offset_2d& max_dst_position()
  {
    return _max_dst_position;
  }

  constexpr const vk::offset_2d& max_dst_position() const
  {
    return _max_dst_position;
  }

  void max_dst_position(vk::offset_2d new_max_dst_position)
  {
    _max_dst_position = new_max_dst_position;
  }

  vk::extent_2d& min_dst_extent()
  {
    return _min_dst_extent;
  }

  constexpr const vk::extent_2d& min_dst_extent() const
  {
    return _min_dst_extent;
  }

  void min_dst_extent(vk::extent_2d new_min_dst_extent)
  {
    _min_dst_extent = new_min_dst_extent;
  }

  vk::extent_2d& max_dst_extent()
  {
    return _max_dst_extent;
  }

  constexpr const vk::extent_2d& max_dst_extent() const
  {
    return _max_dst_extent;
  }

  void max_dst_extent(vk::extent_2d new_max_dst_extent)
  {
    _max_dst_extent = new_max_dst_extent;
  }

private:
  /// Types of alpha blending supported, if any.
  vk::display_plane_alpha_flags_khr _supported_alpha =
    vk::display_plane_alpha_flag_khr::none;
  /// Does the plane have any position and extent restrictions?
  vk::offset_2d _min_src_position = vk::offset_2d{};
  vk::offset_2d _max_src_position = vk::offset_2d{};
  vk::extent_2d _min_src_extent = vk::extent_2d{};
  vk::extent_2d _max_src_extent = vk::extent_2d{};
  vk::offset_2d _min_dst_position = vk::offset_2d{};
  vk::offset_2d _max_dst_position = vk::offset_2d{};
  vk::extent_2d _min_dst_extent = vk::extent_2d{};
  vk::extent_2d _max_dst_extent = vk::extent_2d{};
};
static_assert(sizeof(display_plane_capabilities_khr) ==
                sizeof(::VkDisplayPlaneCapabilitiesKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDisplayPlanePropertiesKHR.
class display_plane_properties_khr
{
public:
  /// Default constructor.
  constexpr display_plane_properties_khr() = default;

  /// Constructor.
  constexpr display_plane_properties_khr(
    VkDisplayKHR initial_current_display,
    uint32_t initial_current_stack_index) noexcept
  : _current_display(std::move(initial_current_display)),
    _current_stack_index(std::move(initial_current_stack_index))
  {
  }

  /// Copy constructor.
  constexpr display_plane_properties_khr(
    const display_plane_properties_khr& other) = default;

  /// Move constructor.
  constexpr display_plane_properties_khr(display_plane_properties_khr&& other) =
    default;

  /// Copy assignment operator.
  constexpr display_plane_properties_khr& operator=(
    const display_plane_properties_khr& other) = default;

  /// Move assignment operator.
  constexpr display_plane_properties_khr& operator=(
    display_plane_properties_khr&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayPlanePropertiesKHR&() const
  {
    return *reinterpret_cast<const VkDisplayPlanePropertiesKHR*>(this);
  }

  VkDisplayKHR& current_display()
  {
    return _current_display;
  }

  constexpr const VkDisplayKHR& current_display() const
  {
    return _current_display;
  }

  void current_display(VkDisplayKHR new_current_display)
  {
    _current_display = new_current_display;
  }

  uint32_t& current_stack_index()
  {
    return _current_stack_index;
  }

  constexpr const uint32_t& current_stack_index() const
  {
    return _current_stack_index;
  }

  void current_stack_index(uint32_t new_current_stack_index)
  {
    _current_stack_index = new_current_stack_index;
  }

private:
  /// Display the plane is currently associated with.  Will be VK_NULL_HANDLE if
  /// the plane is not in use.
  VkDisplayKHR _current_display = nullptr;
  /// Current z-order of the plane.
  uint32_t _current_stack_index = 0;
};
static_assert(sizeof(display_plane_properties_khr) ==
                sizeof(::VkDisplayPlanePropertiesKHR),
              "struct and wrapper have different size!");

using display_surface_create_flags_khr = VkFlags;

/// Enhanced replacement type for VkDisplaySurfaceCreateInfoKHR.
class display_surface_create_info_khr
{
public:
  /// Default constructor.
  constexpr display_surface_create_info_khr() = default;

  /// Constructor.
  constexpr display_surface_create_info_khr(
    const void* initial_next,
    vk::display_surface_create_flags_khr initial_flags,
    VkDisplayModeKHR initial_display_mode, uint32_t initial_plane_index,
    uint32_t initial_plane_stack_index,
    vk::surface_transform_flag_khr initial_transform,
    float initial_global_alpha,
    vk::display_plane_alpha_flag_khr initial_alpha_mode,
    vk::extent_2d initial_image_extent) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _display_mode(std::move(initial_display_mode)),
    _plane_index(std::move(initial_plane_index)),
    _plane_stack_index(std::move(initial_plane_stack_index)),
    _transform(std::move(initial_transform)),
    _global_alpha(std::move(initial_global_alpha)),
    _alpha_mode(std::move(initial_alpha_mode)),
    _image_extent(std::move(initial_image_extent))
  {
  }

  /// Copy constructor.
  constexpr display_surface_create_info_khr(
    const display_surface_create_info_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _display_mode(other._display_mode),
    _plane_index(other._plane_index),
    _plane_stack_index(other._plane_stack_index),
    _transform(other._transform),
    _global_alpha(other._global_alpha),
    _alpha_mode(other._alpha_mode),
    _image_extent(other._image_extent)
  {
  }

  /// Move constructor.
  constexpr display_surface_create_info_khr(
    display_surface_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _display_mode(std::move(other._display_mode)),
    _plane_index(std::move(other._plane_index)),
    _plane_stack_index(std::move(other._plane_stack_index)),
    _transform(std::move(other._transform)),
    _global_alpha(std::move(other._global_alpha)),
    _alpha_mode(std::move(other._alpha_mode)),
    _image_extent(std::move(other._image_extent))
  {
  }

  /// Copy assignment operator.
  constexpr display_surface_create_info_khr& operator=(
    const display_surface_create_info_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _display_mode = other._display_mode;
    _plane_index = other._plane_index;
    _plane_stack_index = other._plane_stack_index;
    _transform = other._transform;
    _global_alpha = other._global_alpha;
    _alpha_mode = other._alpha_mode;
    _image_extent = other._image_extent;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_surface_create_info_khr& operator=(
    display_surface_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _display_mode = std::move(other._display_mode);
    _plane_index = std::move(other._plane_index);
    _plane_stack_index = std::move(other._plane_stack_index);
    _transform = std::move(other._transform);
    _global_alpha = std::move(other._global_alpha);
    _alpha_mode = std::move(other._alpha_mode);
    _image_extent = std::move(other._image_extent);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplaySurfaceCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkDisplaySurfaceCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::display_surface_create_flags_khr& flags()
  {
    return _flags;
  }

  constexpr const vk::display_surface_create_flags_khr& flags() const
  {
    return _flags;
  }

  void flags(vk::display_surface_create_flags_khr new_flags)
  {
    _flags = new_flags;
  }

  VkDisplayModeKHR& display_mode()
  {
    return _display_mode;
  }

  constexpr const VkDisplayModeKHR& display_mode() const
  {
    return _display_mode;
  }

  void display_mode(VkDisplayModeKHR new_display_mode)
  {
    _display_mode = new_display_mode;
  }

  uint32_t& plane_index()
  {
    return _plane_index;
  }

  constexpr const uint32_t& plane_index() const
  {
    return _plane_index;
  }

  void plane_index(uint32_t new_plane_index)
  {
    _plane_index = new_plane_index;
  }

  uint32_t& plane_stack_index()
  {
    return _plane_stack_index;
  }

  constexpr const uint32_t& plane_stack_index() const
  {
    return _plane_stack_index;
  }

  void plane_stack_index(uint32_t new_plane_stack_index)
  {
    _plane_stack_index = new_plane_stack_index;
  }

  vk::surface_transform_flag_khr& transform()
  {
    return _transform;
  }

  constexpr const vk::surface_transform_flag_khr& transform() const
  {
    return _transform;
  }

  void transform(vk::surface_transform_flag_khr new_transform)
  {
    _transform = new_transform;
  }

  float& global_alpha()
  {
    return _global_alpha;
  }

  constexpr const float& global_alpha() const
  {
    return _global_alpha;
  }

  void global_alpha(float new_global_alpha)
  {
    _global_alpha = new_global_alpha;
  }

  vk::display_plane_alpha_flag_khr& alpha_mode()
  {
    return _alpha_mode;
  }

  constexpr const vk::display_plane_alpha_flag_khr& alpha_mode() const
  {
    return _alpha_mode;
  }

  void alpha_mode(vk::display_plane_alpha_flag_khr new_alpha_mode)
  {
    _alpha_mode = new_alpha_mode;
  }

  vk::extent_2d& image_extent()
  {
    return _image_extent;
  }

  constexpr const vk::extent_2d& image_extent() const
  {
    return _image_extent;
  }

  void image_extent(vk::extent_2d new_image_extent)
  {
    _image_extent = new_image_extent;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_surface_create_info_khr;
  const void* _next = nullptr;
  vk::display_surface_create_flags_khr _flags = 0;
  /// The mode to use when displaying this surface
  VkDisplayModeKHR _display_mode = nullptr;
  /// The plane on which this surface appears.  Must be between 0 and the value
  /// returned by vkGetPhysicalDeviceDisplayPlanePropertiesKHR() in
  /// pPropertyCount.
  uint32_t _plane_index = 0;
  /// The z-order of the plane.
  uint32_t _plane_stack_index = 0;
  /// Transform to apply to the images as part of the scanout operation
  vk::surface_transform_flag_khr _transform =
    vk::surface_transform_flag_khr::none;
  /// Global alpha value.  Must be between 0 and 1, inclusive.  Ignored if
  /// alphaMode is not VK_DISPLAY_PLANE_ALPHA_GLOBAL_BIT_KHR
  float _global_alpha = 0.0f;
  /// What type of alpha blending to use.  Must be a bit from
  /// vkGetDisplayPlanePropertiesKHR::supportedAlpha.
  vk::display_plane_alpha_flag_khr _alpha_mode =
    vk::display_plane_alpha_flag_khr::none;
  /// size of the images to use with this surface
  vk::extent_2d _image_extent = vk::extent_2d{};
};
static_assert(sizeof(display_surface_create_info_khr) ==
                sizeof(::VkDisplaySurfaceCreateInfoKHR),
              "struct and wrapper have different size!");

inline vk::result get_physical_device_display_properties_khr(
  VkPhysicalDevice physical_device, uint32_t* property_count,
  vk::display_properties_khr* properties)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceDisplayPropertiesKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkDisplayPropertiesKHR*>(properties)));
}
inline vk::result get_physical_device_display_plane_properties_khr(
  VkPhysicalDevice physical_device, uint32_t* property_count,
  vk::display_plane_properties_khr* properties)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceDisplayPlanePropertiesKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkDisplayPlanePropertiesKHR*>(properties)));
}
inline vk::result get_display_plane_supported_displays_khr(
  VkPhysicalDevice physical_device, uint32_t plane_index,
  uint32_t* display_count, VkDisplayKHR* displays)
{
  return static_cast<vk::result>(vkGetDisplayPlaneSupportedDisplaysKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<uint32_t>(plane_index),
    reinterpret_cast<uint32_t*>(display_count),
    reinterpret_cast<VkDisplayKHR*>(displays)));
}
inline vk::result get_display_mode_properties_khr(
  VkPhysicalDevice physical_device, VkDisplayKHR display,
  uint32_t* property_count, vk::display_mode_properties_khr* properties)
{
  return static_cast<vk::result>(vkGetDisplayModePropertiesKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkDisplayKHR>(display),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkDisplayModePropertiesKHR*>(properties)));
}
inline vk::result create_display_mode_khr(
  VkPhysicalDevice physical_device, VkDisplayKHR display,
  const vk::display_mode_create_info_khr* create_info,
  const vk::allocation_callbacks* allocator, VkDisplayModeKHR* mode)
{
  return static_cast<vk::result>(vkCreateDisplayModeKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkDisplayKHR>(display),
    reinterpret_cast<const VkDisplayModeCreateInfoKHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkDisplayModeKHR*>(mode)));
}
inline vk::result get_display_plane_capabilities_khr(
  VkPhysicalDevice physical_device, VkDisplayModeKHR mode, uint32_t plane_index,
  vk::display_plane_capabilities_khr* capabilities)
{
  return static_cast<vk::result>(vkGetDisplayPlaneCapabilitiesKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkDisplayModeKHR>(mode), static_cast<uint32_t>(plane_index),
    reinterpret_cast<VkDisplayPlaneCapabilitiesKHR*>(capabilities)));
}
inline vk::result create_display_plane_surface_khr(
  VkInstance instance, const vk::display_surface_create_info_khr* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateDisplayPlaneSurfaceKHR(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkDisplaySurfaceCreateInfoKHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}

/// Enhanced replacement type for VkDisplayPresentInfoKHR.
class display_present_info_khr
{
public:
  /// Default constructor.
  constexpr display_present_info_khr() = default;

  /// Constructor.
  constexpr display_present_info_khr(const void* initial_next,
                                     vk::rect_2d initial_src_rect,
                                     vk::rect_2d initial_dst_rect,
                                     VkBool32 initial_persistent) noexcept
  : _next(std::move(initial_next)),
    _src_rect(std::move(initial_src_rect)),
    _dst_rect(std::move(initial_dst_rect)),
    _persistent(std::move(initial_persistent))
  {
  }

  /// Copy constructor.
  constexpr display_present_info_khr(
    const display_present_info_khr& other) noexcept
  : _next(other._next),
    _src_rect(other._src_rect),
    _dst_rect(other._dst_rect),
    _persistent(other._persistent)
  {
  }

  /// Move constructor.
  constexpr display_present_info_khr(display_present_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _src_rect(std::move(other._src_rect)),
    _dst_rect(std::move(other._dst_rect)),
    _persistent(std::move(other._persistent))
  {
  }

  /// Copy assignment operator.
  constexpr display_present_info_khr& operator=(
    const display_present_info_khr& other) noexcept
  {
    _next = other._next;
    _src_rect = other._src_rect;
    _dst_rect = other._dst_rect;
    _persistent = other._persistent;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_present_info_khr& operator=(
    display_present_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _src_rect = std::move(other._src_rect);
    _dst_rect = std::move(other._dst_rect);
    _persistent = std::move(other._persistent);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayPresentInfoKHR&() const
  {
    return *reinterpret_cast<const VkDisplayPresentInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::rect_2d& src_rect()
  {
    return _src_rect;
  }

  constexpr const vk::rect_2d& src_rect() const
  {
    return _src_rect;
  }

  void src_rect(vk::rect_2d new_src_rect)
  {
    _src_rect = new_src_rect;
  }

  vk::rect_2d& dst_rect()
  {
    return _dst_rect;
  }

  constexpr const vk::rect_2d& dst_rect() const
  {
    return _dst_rect;
  }

  void dst_rect(vk::rect_2d new_dst_rect)
  {
    _dst_rect = new_dst_rect;
  }

  VkBool32& persistent()
  {
    return _persistent;
  }

  constexpr const VkBool32& persistent() const
  {
    return _persistent;
  }

  void persistent(VkBool32 new_persistent)
  {
    _persistent = new_persistent;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_present_info_khr;
  const void* _next = nullptr;
  /// Rectangle within the presentable image to read pixel data from when
  /// presenting to the display.
  vk::rect_2d _src_rect = vk::rect_2d{};
  /// Rectangle within the current display mode's visible region to display
  /// srcRectangle in.
  vk::rect_2d _dst_rect = vk::rect_2d{};
  /// For smart displays, use buffered mode.  If the display properties member
  /// "persistentMode" is VK_FALSE, this member must always be VK_FALSE.
  VkBool32 _persistent = VK_FALSE;
};
static_assert(sizeof(display_present_info_khr) ==
                sizeof(::VkDisplayPresentInfoKHR),
              "struct and wrapper have different size!");

inline vk::result create_shared_swapchains_khr(
  VkDevice device, uint32_t swapchain_count,
  const vk::swapchain_create_info_khr* create_infos,
  const vk::allocation_callbacks* allocator, VkSwapchainKHR* swapchains)
{
  return static_cast<vk::result>(vkCreateSharedSwapchainsKHR(
    static_cast<VkDevice>(device), static_cast<uint32_t>(swapchain_count),
    reinterpret_cast<const VkSwapchainCreateInfoKHR*>(create_infos),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSwapchainKHR*>(swapchains)));
}
enum class rasterization_order_amd
{
  /// @see VK_RASTERIZATION_ORDER_STRICT_AMD
  rasterization_order_strict_amd = 0,
  /// @see VK_RASTERIZATION_ORDER_RELAXED_AMD
  rasterization_order_relaxed_amd = 1,
};

/// Enhanced replacement type for
/// VkPipelineRasterizationStateRasterizationOrderAMD.
class pipeline_rasterization_state_rasterization_order_amd
{
public:
  /// Default constructor.
  constexpr pipeline_rasterization_state_rasterization_order_amd() = default;

  /// Constructor.
  constexpr pipeline_rasterization_state_rasterization_order_amd(
    const void* initial_next,
    vk::rasterization_order_amd initial_rasterization_order) noexcept
  : _next(std::move(initial_next)),
    _rasterization_order(std::move(initial_rasterization_order))
  {
  }

  /// Copy constructor.
  constexpr pipeline_rasterization_state_rasterization_order_amd(
    const pipeline_rasterization_state_rasterization_order_amd& other) noexcept
  : _next(other._next), _rasterization_order(other._rasterization_order)
  {
  }

  /// Move constructor.
  constexpr pipeline_rasterization_state_rasterization_order_amd(
    pipeline_rasterization_state_rasterization_order_amd&& other) noexcept
  : _next(std::move(other._next)),
    _rasterization_order(std::move(other._rasterization_order))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_rasterization_state_rasterization_order_amd& operator=(
    const pipeline_rasterization_state_rasterization_order_amd& other) noexcept
  {
    _next = other._next;
    _rasterization_order = other._rasterization_order;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_rasterization_state_rasterization_order_amd& operator=(
    pipeline_rasterization_state_rasterization_order_amd&& other) noexcept
  {
    _next = std::move(other._next);
    _rasterization_order = std::move(other._rasterization_order);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineRasterizationStateRasterizationOrderAMD&() const
  {
    return *reinterpret_cast<
      const VkPipelineRasterizationStateRasterizationOrderAMD*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::rasterization_order_amd& rasterization_order()
  {
    return _rasterization_order;
  }

  constexpr const vk::rasterization_order_amd& rasterization_order() const
  {
    return _rasterization_order;
  }

  void rasterization_order(vk::rasterization_order_amd new_rasterization_order)
  {
    _rasterization_order = new_rasterization_order;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_rasterization_state_rasterization_order_amd;
  const void* _next = nullptr;
  /// Rasterization order to use for the pipeline
  vk::rasterization_order_amd _rasterization_order =
    vk::rasterization_order_amd::rasterization_order_strict_amd;
};
static_assert(sizeof(pipeline_rasterization_state_rasterization_order_amd) ==
                sizeof(::VkPipelineRasterizationStateRasterizationOrderAMD),
              "struct and wrapper have different size!");

enum class debug_report_object_type_ext
{
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_UNKNOWN_EXT
  debug_report_object_type_unknown_ext = 0,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_INSTANCE_EXT
  debug_report_object_type_instance_ext = 1,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_PHYSICAL_DEVICE_EXT
  debug_report_object_type_physical_device_ext = 2,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT
  debug_report_object_type_device_ext = 3,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_QUEUE_EXT
  debug_report_object_type_queue_ext = 4,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_SEMAPHORE_EXT
  debug_report_object_type_semaphore_ext = 5,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_COMMAND_BUFFER_EXT
  debug_report_object_type_command_buffer_ext = 6,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_FENCE_EXT
  debug_report_object_type_fence_ext = 7,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_MEMORY_EXT
  debug_report_object_type_device_memory_ext = 8,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_EXT
  debug_report_object_type_buffer_ext = 9,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_IMAGE_EXT
  debug_report_object_type_image_ext = 10,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_EVENT_EXT
  debug_report_object_type_event_ext = 11,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_QUERY_POOL_EXT
  debug_report_object_type_query_pool_ext = 12,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_VIEW_EXT
  debug_report_object_type_buffer_view_ext = 13,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_IMAGE_VIEW_EXT
  debug_report_object_type_image_view_ext = 14,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_SHADER_MODULE_EXT
  debug_report_object_type_shader_module_ext = 15,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_CACHE_EXT
  debug_report_object_type_pipeline_cache_ext = 16,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_LAYOUT_EXT
  debug_report_object_type_pipeline_layout_ext = 17,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_RENDER_PASS_EXT
  debug_report_object_type_render_pass_ext = 18,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_EXT
  debug_report_object_type_pipeline_ext = 19,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_SET_LAYOUT_EXT
  debug_report_object_type_descriptor_set_layout_ext = 20,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_EXT
  debug_report_object_type_sampler_ext = 21,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_POOL_EXT
  debug_report_object_type_descriptor_pool_ext = 22,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_SET_EXT
  debug_report_object_type_descriptor_set_ext = 23,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_FRAMEBUFFER_EXT
  debug_report_object_type_framebuffer_ext = 24,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_COMMAND_POOL_EXT
  debug_report_object_type_command_pool_ext = 25,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_SURFACE_KHR_EXT
  debug_report_object_type_surface_khr_ext = 26,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_SWAPCHAIN_KHR_EXT
  debug_report_object_type_swapchain_khr_ext = 27,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_DEBUG_REPORT_CALLBACK_EXT_EXT
  debug_report_object_type_debug_report_callback_ext_ext = 28,
  /// Backwards-compatible alias containing a typo
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_DEBUG_REPORT_EXT
  debug_report_object_type_debug_report_ext =
    debug_report_object_type_debug_report_callback_ext_ext,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_DISPLAY_KHR_EXT
  debug_report_object_type_display_khr_ext = 29,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_DISPLAY_MODE_KHR_EXT
  debug_report_object_type_display_mode_khr_ext = 30,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_OBJECT_TABLE_NVX_EXT
  debug_report_object_type_object_table_nvx_ext = 31,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_INDIRECT_COMMANDS_LAYOUT_NVX_EXT
  debug_report_object_type_indirect_commands_layout_nvx_ext = 32,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_VALIDATION_CACHE_EXT_EXT
  debug_report_object_type_validation_cache_ext_ext = 33,
  /// Backwards-compatible alias containing a typo
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_VALIDATION_CACHE_EXT
  debug_report_object_type_validation_cache_ext =
    debug_report_object_type_validation_cache_ext_ext,
  /// @see VK_DEBUG_REPORT_OBJECT_TYPE_ACCELERATION_STRUCTURE_NVX_EXT
  debug_report_object_type_acceleration_structure_nvx_ext = 1000165000,
};

/// Enhanced replacement type for VkDebugMarkerObjectNameInfoEXT.
class debug_marker_object_name_info_ext
{
public:
  /// Default constructor.
  constexpr debug_marker_object_name_info_ext() = default;

  /// Constructor.
  constexpr debug_marker_object_name_info_ext(
    const void* initial_next,
    vk::debug_report_object_type_ext initial_object_type,
    uint64_t initial_object, const char* initial_object_name) noexcept
  : _next(std::move(initial_next)),
    _object_type(std::move(initial_object_type)),
    _object(std::move(initial_object)),
    _object_name(std::move(initial_object_name))
  {
  }

  /// Copy constructor.
  constexpr debug_marker_object_name_info_ext(
    const debug_marker_object_name_info_ext& other) noexcept
  : _next(other._next),
    _object_type(other._object_type),
    _object(other._object),
    _object_name(other._object_name)
  {
  }

  /// Move constructor.
  constexpr debug_marker_object_name_info_ext(
    debug_marker_object_name_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _object_type(std::move(other._object_type)),
    _object(std::move(other._object)),
    _object_name(std::move(other._object_name))
  {
  }

  /// Copy assignment operator.
  constexpr debug_marker_object_name_info_ext& operator=(
    const debug_marker_object_name_info_ext& other) noexcept
  {
    _next = other._next;
    _object_type = other._object_type;
    _object = other._object;
    _object_name = other._object_name;
    return *this;
  }

  /// Move assignment operator.
  constexpr debug_marker_object_name_info_ext& operator=(
    debug_marker_object_name_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _object_type = std::move(other._object_type);
    _object = std::move(other._object);
    _object_name = std::move(other._object_name);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDebugMarkerObjectNameInfoEXT&() const
  {
    return *reinterpret_cast<const VkDebugMarkerObjectNameInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::debug_report_object_type_ext& object_type()
  {
    return _object_type;
  }

  constexpr const vk::debug_report_object_type_ext& object_type() const
  {
    return _object_type;
  }

  void object_type(vk::debug_report_object_type_ext new_object_type)
  {
    _object_type = new_object_type;
  }

  uint64_t& object()
  {
    return _object;
  }

  constexpr const uint64_t& object() const
  {
    return _object;
  }

  void object(uint64_t new_object)
  {
    _object = new_object;
  }

  const char* object_name()
  {
    return _object_name;
  }

  constexpr const char* object_name() const
  {
    return _object_name;
  }

  void object_name(const char* new_object_name)
  {
    _object_name = new_object_name;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::debug_marker_object_name_info_ext;
  const void* _next = nullptr;
  /// The type of the object
  vk::debug_report_object_type_ext _object_type =
    vk::debug_report_object_type_ext::debug_report_object_type_unknown_ext;
  /// The handle of the object, cast to uint64_t
  uint64_t _object = 0;
  /// Name to apply to the object
  const char* _object_name = nullptr;
};
static_assert(sizeof(debug_marker_object_name_info_ext) ==
                sizeof(::VkDebugMarkerObjectNameInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDebugMarkerObjectTagInfoEXT.
class debug_marker_object_tag_info_ext
{
public:
  /// Default constructor.
  constexpr debug_marker_object_tag_info_ext() = default;

  /// Constructor.
  constexpr debug_marker_object_tag_info_ext(
    const void* initial_next,
    vk::debug_report_object_type_ext initial_object_type,
    uint64_t initial_object, uint64_t initial_tag_name, size_t initial_tag_size,
    const void* initial_tag) noexcept
  : _next(std::move(initial_next)),
    _object_type(std::move(initial_object_type)),
    _object(std::move(initial_object)),
    _tag_name(std::move(initial_tag_name)),
    _tag_size(std::move(initial_tag_size)),
    _tag(std::move(initial_tag))
  {
  }

  /// Copy constructor.
  constexpr debug_marker_object_tag_info_ext(
    const debug_marker_object_tag_info_ext& other) noexcept
  : _next(other._next),
    _object_type(other._object_type),
    _object(other._object),
    _tag_name(other._tag_name),
    _tag_size(other._tag_size),
    _tag(other._tag)
  {
  }

  /// Move constructor.
  constexpr debug_marker_object_tag_info_ext(
    debug_marker_object_tag_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _object_type(std::move(other._object_type)),
    _object(std::move(other._object)),
    _tag_name(std::move(other._tag_name)),
    _tag_size(std::move(other._tag_size)),
    _tag(std::move(other._tag))
  {
  }

  /// Copy assignment operator.
  constexpr debug_marker_object_tag_info_ext& operator=(
    const debug_marker_object_tag_info_ext& other) noexcept
  {
    _next = other._next;
    _object_type = other._object_type;
    _object = other._object;
    _tag_name = other._tag_name;
    _tag_size = other._tag_size;
    _tag = other._tag;
    return *this;
  }

  /// Move assignment operator.
  constexpr debug_marker_object_tag_info_ext& operator=(
    debug_marker_object_tag_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _object_type = std::move(other._object_type);
    _object = std::move(other._object);
    _tag_name = std::move(other._tag_name);
    _tag_size = std::move(other._tag_size);
    _tag = std::move(other._tag);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDebugMarkerObjectTagInfoEXT&() const
  {
    return *reinterpret_cast<const VkDebugMarkerObjectTagInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::debug_report_object_type_ext& object_type()
  {
    return _object_type;
  }

  constexpr const vk::debug_report_object_type_ext& object_type() const
  {
    return _object_type;
  }

  void object_type(vk::debug_report_object_type_ext new_object_type)
  {
    _object_type = new_object_type;
  }

  uint64_t& object()
  {
    return _object;
  }

  constexpr const uint64_t& object() const
  {
    return _object;
  }

  void object(uint64_t new_object)
  {
    _object = new_object;
  }

  uint64_t& tag_name()
  {
    return _tag_name;
  }

  constexpr const uint64_t& tag_name() const
  {
    return _tag_name;
  }

  void tag_name(uint64_t new_tag_name)
  {
    _tag_name = new_tag_name;
  }

  size_t& tag_size()
  {
    return _tag_size;
  }

  constexpr const size_t& tag_size() const
  {
    return _tag_size;
  }

  void tag_size(size_t new_tag_size)
  {
    _tag_size = new_tag_size;
  }

  const void* tag()
  {
    return _tag;
  }

  constexpr const void* tag() const
  {
    return _tag;
  }

  void tag(const void* new_tag)
  {
    _tag = new_tag;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::debug_marker_object_tag_info_ext;
  const void* _next = nullptr;
  /// The type of the object
  vk::debug_report_object_type_ext _object_type =
    vk::debug_report_object_type_ext::debug_report_object_type_unknown_ext;
  /// The handle of the object, cast to uint64_t
  uint64_t _object = 0;
  /// The name of the tag to set on the object
  uint64_t _tag_name = 0;
  /// The length in bytes of the tag data
  size_t _tag_size = 0;
  /// Tag data to attach to the object
  const void* _tag = nullptr;
};
static_assert(sizeof(debug_marker_object_tag_info_ext) ==
                sizeof(::VkDebugMarkerObjectTagInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDebugMarkerMarkerInfoEXT.
class debug_marker_marker_info_ext
{
public:
  /// Default constructor.
  constexpr debug_marker_marker_info_ext() = default;

  /// Constructor.
  constexpr debug_marker_marker_info_ext(
    const void* initial_next, const char* initial_marker_name,
    std::array<float, 4> initial_color) noexcept
  : _next(std::move(initial_next)),
    _marker_name(std::move(initial_marker_name)),
    _color(std::move(initial_color))
  {
  }

  /// Copy constructor.
  constexpr debug_marker_marker_info_ext(
    const debug_marker_marker_info_ext& other) noexcept
  : _next(other._next), _marker_name(other._marker_name), _color(other._color)
  {
  }

  /// Move constructor.
  constexpr debug_marker_marker_info_ext(
    debug_marker_marker_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _marker_name(std::move(other._marker_name)),
    _color(std::move(other._color))
  {
  }

  /// Copy assignment operator.
  constexpr debug_marker_marker_info_ext& operator=(
    const debug_marker_marker_info_ext& other) noexcept
  {
    _next = other._next;
    _marker_name = other._marker_name;
    _color = other._color;
    return *this;
  }

  /// Move assignment operator.
  constexpr debug_marker_marker_info_ext& operator=(
    debug_marker_marker_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _marker_name = std::move(other._marker_name);
    _color = std::move(other._color);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDebugMarkerMarkerInfoEXT&() const
  {
    return *reinterpret_cast<const VkDebugMarkerMarkerInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  const char* marker_name()
  {
    return _marker_name;
  }

  constexpr const char* marker_name() const
  {
    return _marker_name;
  }

  void marker_name(const char* new_marker_name)
  {
    _marker_name = new_marker_name;
  }

  std::array<float, 4>& color()
  {
    return _color;
  }

  constexpr const std::array<float, 4>& color() const
  {
    return _color;
  }

  void color(std::array<float, 4> new_color)
  {
    _color = new_color;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::debug_marker_marker_info_ext;
  const void* _next = nullptr;
  /// Name of the debug marker
  const char* _marker_name = nullptr;
  /// Optional color for debug marker
  std::array<float, 4> _color = {};
};
static_assert(sizeof(debug_marker_marker_info_ext) ==
                sizeof(::VkDebugMarkerMarkerInfoEXT),
              "struct and wrapper have different size!");

inline vk::result debug_marker_set_object_tag_ext(
  VkDevice device, const vk::debug_marker_object_tag_info_ext* tag_info)
{
  return static_cast<vk::result>(vkDebugMarkerSetObjectTagEXT(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDebugMarkerObjectTagInfoEXT*>(tag_info)));
}
inline vk::result debug_marker_set_object_name_ext(
  VkDevice device, const vk::debug_marker_object_name_info_ext* name_info)
{
  return static_cast<vk::result>(vkDebugMarkerSetObjectNameEXT(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDebugMarkerObjectNameInfoEXT*>(name_info)));
}
inline void cmd_debug_marker_begin_ext(
  VkCommandBuffer command_buffer,
  const vk::debug_marker_marker_info_ext* marker_info)
{
  vkCmdDebugMarkerBeginEXT(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkDebugMarkerMarkerInfoEXT*>(marker_info));
}
inline void cmd_debug_marker_end_ext(VkCommandBuffer command_buffer)
{
  vkCmdDebugMarkerEndEXT(static_cast<VkCommandBuffer>(command_buffer));
}
inline void cmd_debug_marker_insert_ext(
  VkCommandBuffer command_buffer,
  const vk::debug_marker_marker_info_ext* marker_info)
{
  vkCmdDebugMarkerInsertEXT(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkDebugMarkerMarkerInfoEXT*>(marker_info));
}

/// Enhanced replacement type for VkDedicatedAllocationImageCreateInfoNV.
class dedicated_allocation_image_create_info_nv
{
public:
  /// Default constructor.
  constexpr dedicated_allocation_image_create_info_nv() = default;

  /// Constructor.
  constexpr dedicated_allocation_image_create_info_nv(
    const void* initial_next, VkBool32 initial_dedicated_allocation) noexcept
  : _next(std::move(initial_next)),
    _dedicated_allocation(std::move(initial_dedicated_allocation))
  {
  }

  /// Copy constructor.
  constexpr dedicated_allocation_image_create_info_nv(
    const dedicated_allocation_image_create_info_nv& other) noexcept
  : _next(other._next), _dedicated_allocation(other._dedicated_allocation)
  {
  }

  /// Move constructor.
  constexpr dedicated_allocation_image_create_info_nv(
    dedicated_allocation_image_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _dedicated_allocation(std::move(other._dedicated_allocation))
  {
  }

  /// Copy assignment operator.
  constexpr dedicated_allocation_image_create_info_nv& operator=(
    const dedicated_allocation_image_create_info_nv& other) noexcept
  {
    _next = other._next;
    _dedicated_allocation = other._dedicated_allocation;
    return *this;
  }

  /// Move assignment operator.
  constexpr dedicated_allocation_image_create_info_nv& operator=(
    dedicated_allocation_image_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _dedicated_allocation = std::move(other._dedicated_allocation);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDedicatedAllocationImageCreateInfoNV&() const
  {
    return *reinterpret_cast<const VkDedicatedAllocationImageCreateInfoNV*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& dedicated_allocation()
  {
    return _dedicated_allocation;
  }

  constexpr const VkBool32& dedicated_allocation() const
  {
    return _dedicated_allocation;
  }

  void dedicated_allocation(VkBool32 new_dedicated_allocation)
  {
    _dedicated_allocation = new_dedicated_allocation;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::dedicated_allocation_image_create_info_nv;
  const void* _next = nullptr;
  /// Whether this image uses a dedicated allocation
  VkBool32 _dedicated_allocation = VK_FALSE;
};
static_assert(sizeof(dedicated_allocation_image_create_info_nv) ==
                sizeof(::VkDedicatedAllocationImageCreateInfoNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDedicatedAllocationBufferCreateInfoNV.
class dedicated_allocation_buffer_create_info_nv
{
public:
  /// Default constructor.
  constexpr dedicated_allocation_buffer_create_info_nv() = default;

  /// Constructor.
  constexpr dedicated_allocation_buffer_create_info_nv(
    const void* initial_next, VkBool32 initial_dedicated_allocation) noexcept
  : _next(std::move(initial_next)),
    _dedicated_allocation(std::move(initial_dedicated_allocation))
  {
  }

  /// Copy constructor.
  constexpr dedicated_allocation_buffer_create_info_nv(
    const dedicated_allocation_buffer_create_info_nv& other) noexcept
  : _next(other._next), _dedicated_allocation(other._dedicated_allocation)
  {
  }

  /// Move constructor.
  constexpr dedicated_allocation_buffer_create_info_nv(
    dedicated_allocation_buffer_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _dedicated_allocation(std::move(other._dedicated_allocation))
  {
  }

  /// Copy assignment operator.
  constexpr dedicated_allocation_buffer_create_info_nv& operator=(
    const dedicated_allocation_buffer_create_info_nv& other) noexcept
  {
    _next = other._next;
    _dedicated_allocation = other._dedicated_allocation;
    return *this;
  }

  /// Move assignment operator.
  constexpr dedicated_allocation_buffer_create_info_nv& operator=(
    dedicated_allocation_buffer_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _dedicated_allocation = std::move(other._dedicated_allocation);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDedicatedAllocationBufferCreateInfoNV&() const
  {
    return *reinterpret_cast<const VkDedicatedAllocationBufferCreateInfoNV*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& dedicated_allocation()
  {
    return _dedicated_allocation;
  }

  constexpr const VkBool32& dedicated_allocation() const
  {
    return _dedicated_allocation;
  }

  void dedicated_allocation(VkBool32 new_dedicated_allocation)
  {
    _dedicated_allocation = new_dedicated_allocation;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::dedicated_allocation_buffer_create_info_nv;
  const void* _next = nullptr;
  /// Whether this buffer uses a dedicated allocation
  VkBool32 _dedicated_allocation = VK_FALSE;
};
static_assert(sizeof(dedicated_allocation_buffer_create_info_nv) ==
                sizeof(::VkDedicatedAllocationBufferCreateInfoNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDedicatedAllocationMemoryAllocateInfoNV.
class dedicated_allocation_memory_allocate_info_nv
{
public:
  /// Default constructor.
  constexpr dedicated_allocation_memory_allocate_info_nv() = default;

  /// Constructor.
  constexpr dedicated_allocation_memory_allocate_info_nv(
    const void* initial_next, VkImage initial_image,
    VkBuffer initial_buffer) noexcept
  : _next(std::move(initial_next)),
    _image(std::move(initial_image)),
    _buffer(std::move(initial_buffer))
  {
  }

  /// Copy constructor.
  constexpr dedicated_allocation_memory_allocate_info_nv(
    const dedicated_allocation_memory_allocate_info_nv& other) noexcept
  : _next(other._next), _image(other._image), _buffer(other._buffer)
  {
  }

  /// Move constructor.
  constexpr dedicated_allocation_memory_allocate_info_nv(
    dedicated_allocation_memory_allocate_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _image(std::move(other._image)),
    _buffer(std::move(other._buffer))
  {
  }

  /// Copy assignment operator.
  constexpr dedicated_allocation_memory_allocate_info_nv& operator=(
    const dedicated_allocation_memory_allocate_info_nv& other) noexcept
  {
    _next = other._next;
    _image = other._image;
    _buffer = other._buffer;
    return *this;
  }

  /// Move assignment operator.
  constexpr dedicated_allocation_memory_allocate_info_nv& operator=(
    dedicated_allocation_memory_allocate_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _image = std::move(other._image);
    _buffer = std::move(other._buffer);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDedicatedAllocationMemoryAllocateInfoNV&() const
  {
    return *reinterpret_cast<const VkDedicatedAllocationMemoryAllocateInfoNV*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkImage& image()
  {
    return _image;
  }

  constexpr const VkImage& image() const
  {
    return _image;
  }

  void image(VkImage new_image)
  {
    _image = new_image;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::dedicated_allocation_memory_allocate_info_nv;
  const void* _next = nullptr;
  /// Image that this allocation will be bound to
  VkImage _image = nullptr;
  /// Buffer that this allocation will be bound to
  VkBuffer _buffer = nullptr;
};
static_assert(sizeof(dedicated_allocation_memory_allocate_info_nv) ==
                sizeof(::VkDedicatedAllocationMemoryAllocateInfoNV),
              "struct and wrapper have different size!");

inline void cmd_draw_indirect_count_amd(VkCommandBuffer command_buffer,
                                        VkBuffer buffer, VkDeviceSize offset,
                                        VkBuffer count_buffer,
                                        VkDeviceSize count_buffer_offset,
                                        uint32_t max_draw_count,
                                        uint32_t stride)
{
  vkCmdDrawIndirectCountAMD(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceSize>(offset), static_cast<VkBuffer>(count_buffer),
    static_cast<VkDeviceSize>(count_buffer_offset),
    static_cast<uint32_t>(max_draw_count), static_cast<uint32_t>(stride));
}
inline void cmd_draw_indexed_indirect_count_amd(
  VkCommandBuffer command_buffer, VkBuffer buffer, VkDeviceSize offset,
  VkBuffer count_buffer, VkDeviceSize count_buffer_offset,
  uint32_t max_draw_count, uint32_t stride)
{
  vkCmdDrawIndexedIndirectCountAMD(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceSize>(offset), static_cast<VkBuffer>(count_buffer),
    static_cast<VkDeviceSize>(count_buffer_offset),
    static_cast<uint32_t>(max_draw_count), static_cast<uint32_t>(stride));
}

/// Enhanced replacement type for VkTextureLODGatherFormatPropertiesAMD.
class texture_lodgather_format_properties_amd
{
public:
  /// Default constructor.
  constexpr texture_lodgather_format_properties_amd() = default;

  /// Constructor.
  constexpr texture_lodgather_format_properties_amd(
    void* initial_next,
    VkBool32 initial_supports_texture_gather_lodbias_amd) noexcept
  : _next(std::move(initial_next)),
    _supports_texture_gather_lodbias_amd(
      std::move(initial_supports_texture_gather_lodbias_amd))
  {
  }

  /// Copy constructor.
  constexpr texture_lodgather_format_properties_amd(
    const texture_lodgather_format_properties_amd& other) noexcept
  : _next(other._next),
    _supports_texture_gather_lodbias_amd(
      other._supports_texture_gather_lodbias_amd)
  {
  }

  /// Move constructor.
  constexpr texture_lodgather_format_properties_amd(
    texture_lodgather_format_properties_amd&& other) noexcept
  : _next(std::move(other._next)),
    _supports_texture_gather_lodbias_amd(
      std::move(other._supports_texture_gather_lodbias_amd))
  {
  }

  /// Copy assignment operator.
  constexpr texture_lodgather_format_properties_amd& operator=(
    const texture_lodgather_format_properties_amd& other) noexcept
  {
    _next = other._next;
    _supports_texture_gather_lodbias_amd =
      other._supports_texture_gather_lodbias_amd;
    return *this;
  }

  /// Move assignment operator.
  constexpr texture_lodgather_format_properties_amd& operator=(
    texture_lodgather_format_properties_amd&& other) noexcept
  {
    _next = std::move(other._next);
    _supports_texture_gather_lodbias_amd =
      std::move(other._supports_texture_gather_lodbias_amd);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkTextureLODGatherFormatPropertiesAMD&() const
  {
    return *reinterpret_cast<const VkTextureLODGatherFormatPropertiesAMD*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& supports_texture_gather_lodbias_amd()
  {
    return _supports_texture_gather_lodbias_amd;
  }

  constexpr const VkBool32& supports_texture_gather_lodbias_amd() const
  {
    return _supports_texture_gather_lodbias_amd;
  }

  void supports_texture_gather_lodbias_amd(
    VkBool32 new_supports_texture_gather_lodbias_amd)
  {
    _supports_texture_gather_lodbias_amd =
      new_supports_texture_gather_lodbias_amd;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::texture_lod_gather_format_properties_amd;
  void* _next = nullptr;
  VkBool32 _supports_texture_gather_lodbias_amd = VK_FALSE;
};
static_assert(sizeof(texture_lodgather_format_properties_amd) ==
                sizeof(::VkTextureLODGatherFormatPropertiesAMD),
              "struct and wrapper have different size!");

enum class shader_info_type_amd
{
  /// @see VK_SHADER_INFO_TYPE_STATISTICS_AMD
  shader_info_type_statistics_amd = 0,
  /// @see VK_SHADER_INFO_TYPE_BINARY_AMD
  shader_info_type_binary_amd = 1,
  /// @see VK_SHADER_INFO_TYPE_DISASSEMBLY_AMD
  shader_info_type_disassembly_amd = 2,
};

/// Enhanced replacement type for VkShaderResourceUsageAMD.
class shader_resource_usage_amd
{
public:
  /// Default constructor.
  constexpr shader_resource_usage_amd() = default;

  /// Constructor.
  constexpr shader_resource_usage_amd(
    uint32_t initial_num_used_vgprs, uint32_t initial_num_used_sgprs,
    uint32_t initial_lds_size_per_local_work_group,
    size_t initial_lds_usage_size_in_bytes,
    size_t initial_scratch_mem_usage_in_bytes) noexcept
  : _num_used_vgprs(std::move(initial_num_used_vgprs)),
    _num_used_sgprs(std::move(initial_num_used_sgprs)),
    _lds_size_per_local_work_group(
      std::move(initial_lds_size_per_local_work_group)),
    _lds_usage_size_in_bytes(std::move(initial_lds_usage_size_in_bytes)),
    _scratch_mem_usage_in_bytes(std::move(initial_scratch_mem_usage_in_bytes))
  {
  }

  /// Copy constructor.
  constexpr shader_resource_usage_amd(const shader_resource_usage_amd& other) =
    default;

  /// Move constructor.
  constexpr shader_resource_usage_amd(shader_resource_usage_amd&& other) =
    default;

  /// Copy assignment operator.
  constexpr shader_resource_usage_amd& operator=(
    const shader_resource_usage_amd& other) = default;

  /// Move assignment operator.
  constexpr shader_resource_usage_amd& operator=(
    shader_resource_usage_amd&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkShaderResourceUsageAMD&() const
  {
    return *reinterpret_cast<const VkShaderResourceUsageAMD*>(this);
  }

  uint32_t& num_used_vgprs()
  {
    return _num_used_vgprs;
  }

  constexpr const uint32_t& num_used_vgprs() const
  {
    return _num_used_vgprs;
  }

  void num_used_vgprs(uint32_t new_num_used_vgprs)
  {
    _num_used_vgprs = new_num_used_vgprs;
  }

  uint32_t& num_used_sgprs()
  {
    return _num_used_sgprs;
  }

  constexpr const uint32_t& num_used_sgprs() const
  {
    return _num_used_sgprs;
  }

  void num_used_sgprs(uint32_t new_num_used_sgprs)
  {
    _num_used_sgprs = new_num_used_sgprs;
  }

  uint32_t& lds_size_per_local_work_group()
  {
    return _lds_size_per_local_work_group;
  }

  constexpr const uint32_t& lds_size_per_local_work_group() const
  {
    return _lds_size_per_local_work_group;
  }

  void lds_size_per_local_work_group(uint32_t new_lds_size_per_local_work_group)
  {
    _lds_size_per_local_work_group = new_lds_size_per_local_work_group;
  }

  size_t& lds_usage_size_in_bytes()
  {
    return _lds_usage_size_in_bytes;
  }

  constexpr const size_t& lds_usage_size_in_bytes() const
  {
    return _lds_usage_size_in_bytes;
  }

  void lds_usage_size_in_bytes(size_t new_lds_usage_size_in_bytes)
  {
    _lds_usage_size_in_bytes = new_lds_usage_size_in_bytes;
  }

  size_t& scratch_mem_usage_in_bytes()
  {
    return _scratch_mem_usage_in_bytes;
  }

  constexpr const size_t& scratch_mem_usage_in_bytes() const
  {
    return _scratch_mem_usage_in_bytes;
  }

  void scratch_mem_usage_in_bytes(size_t new_scratch_mem_usage_in_bytes)
  {
    _scratch_mem_usage_in_bytes = new_scratch_mem_usage_in_bytes;
  }

private:
  uint32_t _num_used_vgprs = 0;
  uint32_t _num_used_sgprs = 0;
  uint32_t _lds_size_per_local_work_group = 0;
  size_t _lds_usage_size_in_bytes = 0;
  size_t _scratch_mem_usage_in_bytes = 0;
};
static_assert(sizeof(shader_resource_usage_amd) ==
                sizeof(::VkShaderResourceUsageAMD),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkShaderStatisticsInfoAMD.
class shader_statistics_info_amd
{
public:
  /// Default constructor.
  constexpr shader_statistics_info_amd() = default;

  /// Constructor.
  constexpr shader_statistics_info_amd(
    vk::shader_stage_flags initial_shader_stage_mask,
    vk::shader_resource_usage_amd initial_resource_usage,
    uint32_t initial_num_physical_vgprs, uint32_t initial_num_physical_sgprs,
    uint32_t initial_num_available_vgprs, uint32_t initial_num_available_sgprs,
    std::array<uint32_t, 3> initial_compute_work_group_size) noexcept
  : _shader_stage_mask(std::move(initial_shader_stage_mask)),
    _resource_usage(std::move(initial_resource_usage)),
    _num_physical_vgprs(std::move(initial_num_physical_vgprs)),
    _num_physical_sgprs(std::move(initial_num_physical_sgprs)),
    _num_available_vgprs(std::move(initial_num_available_vgprs)),
    _num_available_sgprs(std::move(initial_num_available_sgprs)),
    _compute_work_group_size(std::move(initial_compute_work_group_size))
  {
  }

  /// Copy constructor.
  constexpr shader_statistics_info_amd(
    const shader_statistics_info_amd& other) = default;

  /// Move constructor.
  constexpr shader_statistics_info_amd(shader_statistics_info_amd&& other) =
    default;

  /// Copy assignment operator.
  constexpr shader_statistics_info_amd& operator=(
    const shader_statistics_info_amd& other) = default;

  /// Move assignment operator.
  constexpr shader_statistics_info_amd& operator=(
    shader_statistics_info_amd&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkShaderStatisticsInfoAMD&() const
  {
    return *reinterpret_cast<const VkShaderStatisticsInfoAMD*>(this);
  }

  vk::shader_stage_flags& shader_stage_mask()
  {
    return _shader_stage_mask;
  }

  constexpr const vk::shader_stage_flags& shader_stage_mask() const
  {
    return _shader_stage_mask;
  }

  void shader_stage_mask(vk::shader_stage_flags new_shader_stage_mask)
  {
    _shader_stage_mask = new_shader_stage_mask;
  }

  vk::shader_resource_usage_amd& resource_usage()
  {
    return _resource_usage;
  }

  constexpr const vk::shader_resource_usage_amd& resource_usage() const
  {
    return _resource_usage;
  }

  void resource_usage(vk::shader_resource_usage_amd new_resource_usage)
  {
    _resource_usage = new_resource_usage;
  }

  uint32_t& num_physical_vgprs()
  {
    return _num_physical_vgprs;
  }

  constexpr const uint32_t& num_physical_vgprs() const
  {
    return _num_physical_vgprs;
  }

  void num_physical_vgprs(uint32_t new_num_physical_vgprs)
  {
    _num_physical_vgprs = new_num_physical_vgprs;
  }

  uint32_t& num_physical_sgprs()
  {
    return _num_physical_sgprs;
  }

  constexpr const uint32_t& num_physical_sgprs() const
  {
    return _num_physical_sgprs;
  }

  void num_physical_sgprs(uint32_t new_num_physical_sgprs)
  {
    _num_physical_sgprs = new_num_physical_sgprs;
  }

  uint32_t& num_available_vgprs()
  {
    return _num_available_vgprs;
  }

  constexpr const uint32_t& num_available_vgprs() const
  {
    return _num_available_vgprs;
  }

  void num_available_vgprs(uint32_t new_num_available_vgprs)
  {
    _num_available_vgprs = new_num_available_vgprs;
  }

  uint32_t& num_available_sgprs()
  {
    return _num_available_sgprs;
  }

  constexpr const uint32_t& num_available_sgprs() const
  {
    return _num_available_sgprs;
  }

  void num_available_sgprs(uint32_t new_num_available_sgprs)
  {
    _num_available_sgprs = new_num_available_sgprs;
  }

  std::array<uint32_t, 3>& compute_work_group_size()
  {
    return _compute_work_group_size;
  }

  constexpr const std::array<uint32_t, 3>& compute_work_group_size() const
  {
    return _compute_work_group_size;
  }

  void compute_work_group_size(
    std::array<uint32_t, 3> new_compute_work_group_size)
  {
    _compute_work_group_size = new_compute_work_group_size;
  }

private:
  vk::shader_stage_flags _shader_stage_mask = vk::shader_stage_flag::none;
  vk::shader_resource_usage_amd _resource_usage =
    vk::shader_resource_usage_amd{};
  uint32_t _num_physical_vgprs = 0;
  uint32_t _num_physical_sgprs = 0;
  uint32_t _num_available_vgprs = 0;
  uint32_t _num_available_sgprs = 0;
  std::array<uint32_t, 3> _compute_work_group_size = {};
};
static_assert(sizeof(shader_statistics_info_amd) ==
                sizeof(::VkShaderStatisticsInfoAMD),
              "struct and wrapper have different size!");

inline vk::result get_shader_info_amd(VkDevice device, VkPipeline pipeline,
                                      vk::shader_stage_flag shader_stage,
                                      vk::shader_info_type_amd info_type,
                                      size_t* info_size, void* info)
{
  return static_cast<vk::result>(vkGetShaderInfoAMD(
    static_cast<VkDevice>(device), static_cast<VkPipeline>(pipeline),
    static_cast<VkShaderStageFlagBits>(shader_stage),
    static_cast<VkShaderInfoTypeAMD>(info_type),
    reinterpret_cast<size_t*>(info_size), reinterpret_cast<void*>(info)));
}

/// Enhanced replacement type for VkPhysicalDeviceCornerSampledImageFeaturesNV.
class physical_device_corner_sampled_image_features_nv
{
public:
  /// Default constructor.
  constexpr physical_device_corner_sampled_image_features_nv() = default;

  /// Constructor.
  constexpr physical_device_corner_sampled_image_features_nv(
    void* initial_next, VkBool32 initial_corner_sampled_image) noexcept
  : _next(std::move(initial_next)),
    _corner_sampled_image(std::move(initial_corner_sampled_image))
  {
  }

  /// Copy constructor.
  constexpr physical_device_corner_sampled_image_features_nv(
    const physical_device_corner_sampled_image_features_nv& other) noexcept
  : _next(other._next), _corner_sampled_image(other._corner_sampled_image)
  {
  }

  /// Move constructor.
  constexpr physical_device_corner_sampled_image_features_nv(
    physical_device_corner_sampled_image_features_nv&& other) noexcept
  : _next(std::move(other._next)),
    _corner_sampled_image(std::move(other._corner_sampled_image))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_corner_sampled_image_features_nv& operator=(
    const physical_device_corner_sampled_image_features_nv& other) noexcept
  {
    _next = other._next;
    _corner_sampled_image = other._corner_sampled_image;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_corner_sampled_image_features_nv& operator=(
    physical_device_corner_sampled_image_features_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _corner_sampled_image = std::move(other._corner_sampled_image);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceCornerSampledImageFeaturesNV&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceCornerSampledImageFeaturesNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& corner_sampled_image()
  {
    return _corner_sampled_image;
  }

  constexpr const VkBool32& corner_sampled_image() const
  {
    return _corner_sampled_image;
  }

  void corner_sampled_image(VkBool32 new_corner_sampled_image)
  {
    _corner_sampled_image = new_corner_sampled_image;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_corner_sampled_image_features_nv;
  void* _next = nullptr;
  VkBool32 _corner_sampled_image = VK_FALSE;
};
static_assert(sizeof(physical_device_corner_sampled_image_features_nv) ==
                sizeof(::VkPhysicalDeviceCornerSampledImageFeaturesNV),
              "struct and wrapper have different size!");

enum class external_memory_handle_type_flag_nv
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT_NV
  opaque_win32_bit_nv = 1 << 0,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT_NV
  opaque_win32_kmt_bit_nv = 1 << 1,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_IMAGE_BIT_NV
  d3d_11_image_bit_nv = 1 << 2,
  /// @see VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_IMAGE_KMT_BIT_NV
  d3d_11_image_kmt_bit_nv = 1 << 3,
};
using external_memory_handle_type_flags_nv =
  shift::core::bit_field<external_memory_handle_type_flag_nv,
                         VkExternalMemoryHandleTypeFlagsNV>;
inline constexpr external_memory_handle_type_flags_nv operator|(
  external_memory_handle_type_flag_nv lhs,
  external_memory_handle_type_flag_nv rhs)
{
  return external_memory_handle_type_flags_nv{lhs} | rhs;
}
enum class external_memory_feature_flag_nv
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_EXTERNAL_MEMORY_FEATURE_DEDICATED_ONLY_BIT_NV
  dedicated_only_bit_nv = 1 << 0,
  /// @see VK_EXTERNAL_MEMORY_FEATURE_EXPORTABLE_BIT_NV
  exportable_bit_nv = 1 << 1,
  /// @see VK_EXTERNAL_MEMORY_FEATURE_IMPORTABLE_BIT_NV
  importable_bit_nv = 1 << 2,
};
using external_memory_feature_flags_nv =
  shift::core::bit_field<external_memory_feature_flag_nv,
                         VkExternalMemoryFeatureFlagsNV>;
inline constexpr external_memory_feature_flags_nv operator|(
  external_memory_feature_flag_nv lhs, external_memory_feature_flag_nv rhs)
{
  return external_memory_feature_flags_nv{lhs} | rhs;
}
/// Enhanced replacement type for VkExternalImageFormatPropertiesNV.
class external_image_format_properties_nv
{
public:
  /// Default constructor.
  constexpr external_image_format_properties_nv() = default;

  /// Constructor.
  constexpr external_image_format_properties_nv(
    vk::image_format_properties initial_image_format_properties,
    vk::external_memory_feature_flags_nv initial_external_memory_features,
    vk::external_memory_handle_type_flags_nv
      initial_export_from_imported_handle_types,
    vk::external_memory_handle_type_flags_nv
      initial_compatible_handle_types) noexcept
  : _image_format_properties(std::move(initial_image_format_properties)),
    _external_memory_features(std::move(initial_external_memory_features)),
    _export_from_imported_handle_types(
      std::move(initial_export_from_imported_handle_types)),
    _compatible_handle_types(std::move(initial_compatible_handle_types))
  {
  }

  /// Copy constructor.
  constexpr external_image_format_properties_nv(
    const external_image_format_properties_nv& other) = default;

  /// Move constructor.
  constexpr external_image_format_properties_nv(
    external_image_format_properties_nv&& other) = default;

  /// Copy assignment operator.
  constexpr external_image_format_properties_nv& operator=(
    const external_image_format_properties_nv& other) = default;

  /// Move assignment operator.
  constexpr external_image_format_properties_nv& operator=(
    external_image_format_properties_nv&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkExternalImageFormatPropertiesNV&() const
  {
    return *reinterpret_cast<const VkExternalImageFormatPropertiesNV*>(this);
  }

  vk::image_format_properties& image_format_properties()
  {
    return _image_format_properties;
  }

  constexpr const vk::image_format_properties& image_format_properties() const
  {
    return _image_format_properties;
  }

  void image_format_properties(
    vk::image_format_properties new_image_format_properties)
  {
    _image_format_properties = new_image_format_properties;
  }

  vk::external_memory_feature_flags_nv& external_memory_features()
  {
    return _external_memory_features;
  }

  constexpr const vk::external_memory_feature_flags_nv&
  external_memory_features() const
  {
    return _external_memory_features;
  }

  void external_memory_features(
    vk::external_memory_feature_flags_nv new_external_memory_features)
  {
    _external_memory_features = new_external_memory_features;
  }

  vk::external_memory_handle_type_flags_nv& export_from_imported_handle_types()
  {
    return _export_from_imported_handle_types;
  }

  constexpr const vk::external_memory_handle_type_flags_nv&
  export_from_imported_handle_types() const
  {
    return _export_from_imported_handle_types;
  }

  void export_from_imported_handle_types(
    vk::external_memory_handle_type_flags_nv
      new_export_from_imported_handle_types)
  {
    _export_from_imported_handle_types = new_export_from_imported_handle_types;
  }

  vk::external_memory_handle_type_flags_nv& compatible_handle_types()
  {
    return _compatible_handle_types;
  }

  constexpr const vk::external_memory_handle_type_flags_nv&
  compatible_handle_types() const
  {
    return _compatible_handle_types;
  }

  void compatible_handle_types(
    vk::external_memory_handle_type_flags_nv new_compatible_handle_types)
  {
    _compatible_handle_types = new_compatible_handle_types;
  }

private:
  vk::image_format_properties _image_format_properties =
    vk::image_format_properties{};
  vk::external_memory_feature_flags_nv _external_memory_features =
    vk::external_memory_feature_flag_nv::none;
  vk::external_memory_handle_type_flags_nv _export_from_imported_handle_types =
    vk::external_memory_handle_type_flag_nv::none;
  vk::external_memory_handle_type_flags_nv _compatible_handle_types =
    vk::external_memory_handle_type_flag_nv::none;
};
static_assert(sizeof(external_image_format_properties_nv) ==
                sizeof(::VkExternalImageFormatPropertiesNV),
              "struct and wrapper have different size!");

inline vk::result get_physical_device_external_image_format_properties_nv(
  VkPhysicalDevice physical_device, vk::format format, vk::image_type type,
  vk::image_tiling tiling, vk::image_usage_flags usage,
  vk::image_create_flags flags,
  vk::external_memory_handle_type_flags_nv external_handle_type,
  vk::external_image_format_properties_nv* external_image_format_properties)
{
  return static_cast<vk::result>(
    vkGetPhysicalDeviceExternalImageFormatPropertiesNV(
      static_cast<VkPhysicalDevice>(physical_device),
      static_cast<VkFormat>(format), static_cast<VkImageType>(type),
      static_cast<VkImageTiling>(tiling), static_cast<VkImageUsageFlags>(usage),
      static_cast<VkImageCreateFlags>(flags),
      static_cast<VkExternalMemoryHandleTypeFlagsNV>(external_handle_type),
      reinterpret_cast<VkExternalImageFormatPropertiesNV*>(
        external_image_format_properties)));
}

/// Enhanced replacement type for VkExternalMemoryImageCreateInfoNV.
class external_memory_image_create_info_nv
{
public:
  /// Default constructor.
  constexpr external_memory_image_create_info_nv() = default;

  /// Constructor.
  constexpr external_memory_image_create_info_nv(
    const void* initial_next,
    vk::external_memory_handle_type_flags_nv initial_handle_types) noexcept
  : _next(std::move(initial_next)),
    _handle_types(std::move(initial_handle_types))
  {
  }

  /// Copy constructor.
  constexpr external_memory_image_create_info_nv(
    const external_memory_image_create_info_nv& other) noexcept
  : _next(other._next), _handle_types(other._handle_types)
  {
  }

  /// Move constructor.
  constexpr external_memory_image_create_info_nv(
    external_memory_image_create_info_nv&& other) noexcept
  : _next(std::move(other._next)), _handle_types(std::move(other._handle_types))
  {
  }

  /// Copy assignment operator.
  constexpr external_memory_image_create_info_nv& operator=(
    const external_memory_image_create_info_nv& other) noexcept
  {
    _next = other._next;
    _handle_types = other._handle_types;
    return *this;
  }

  /// Move assignment operator.
  constexpr external_memory_image_create_info_nv& operator=(
    external_memory_image_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_types = std::move(other._handle_types);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExternalMemoryImageCreateInfoNV&() const
  {
    return *reinterpret_cast<const VkExternalMemoryImageCreateInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flags_nv& handle_types()
  {
    return _handle_types;
  }

  constexpr const vk::external_memory_handle_type_flags_nv& handle_types() const
  {
    return _handle_types;
  }

  void handle_types(vk::external_memory_handle_type_flags_nv new_handle_types)
  {
    _handle_types = new_handle_types;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::external_memory_image_create_info_nv;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flags_nv _handle_types =
    vk::external_memory_handle_type_flag_nv::none;
};
static_assert(sizeof(external_memory_image_create_info_nv) ==
                sizeof(::VkExternalMemoryImageCreateInfoNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkExportMemoryAllocateInfoNV.
class export_memory_allocate_info_nv
{
public:
  /// Default constructor.
  constexpr export_memory_allocate_info_nv() = default;

  /// Constructor.
  constexpr export_memory_allocate_info_nv(
    const void* initial_next,
    vk::external_memory_handle_type_flags_nv initial_handle_types) noexcept
  : _next(std::move(initial_next)),
    _handle_types(std::move(initial_handle_types))
  {
  }

  /// Copy constructor.
  constexpr export_memory_allocate_info_nv(
    const export_memory_allocate_info_nv& other) noexcept
  : _next(other._next), _handle_types(other._handle_types)
  {
  }

  /// Move constructor.
  constexpr export_memory_allocate_info_nv(
    export_memory_allocate_info_nv&& other) noexcept
  : _next(std::move(other._next)), _handle_types(std::move(other._handle_types))
  {
  }

  /// Copy assignment operator.
  constexpr export_memory_allocate_info_nv& operator=(
    const export_memory_allocate_info_nv& other) noexcept
  {
    _next = other._next;
    _handle_types = other._handle_types;
    return *this;
  }

  /// Move assignment operator.
  constexpr export_memory_allocate_info_nv& operator=(
    export_memory_allocate_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_types = std::move(other._handle_types);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExportMemoryAllocateInfoNV&() const
  {
    return *reinterpret_cast<const VkExportMemoryAllocateInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flags_nv& handle_types()
  {
    return _handle_types;
  }

  constexpr const vk::external_memory_handle_type_flags_nv& handle_types() const
  {
    return _handle_types;
  }

  void handle_types(vk::external_memory_handle_type_flags_nv new_handle_types)
  {
    _handle_types = new_handle_types;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::export_memory_allocate_info_nv;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flags_nv _handle_types =
    vk::external_memory_handle_type_flag_nv::none;
};
static_assert(sizeof(export_memory_allocate_info_nv) ==
                sizeof(::VkExportMemoryAllocateInfoNV),
              "struct and wrapper have different size!");

enum class validation_check_ext
{
  /// @see VK_VALIDATION_CHECK_ALL_EXT
  validation_check_all_ext = 0,
  /// @see VK_VALIDATION_CHECK_SHADERS_EXT
  validation_check_shaders_ext = 1,
};

/// Enhanced replacement type for VkValidationFlagsEXT.
class validation_flags_ext
{
public:
  /// Default constructor.
  constexpr validation_flags_ext() = default;

  /// Constructor.
  constexpr validation_flags_ext(
    const void* initial_next, uint32_t initial_disabled_validation_check_count,
    const vk::validation_check_ext* initial_disabled_validation_checks) noexcept
  : _next(std::move(initial_next)),
    _disabled_validation_check_count(
      std::move(initial_disabled_validation_check_count)),
    _disabled_validation_checks(std::move(initial_disabled_validation_checks))
  {
  }

  /// Copy constructor.
  constexpr validation_flags_ext(const validation_flags_ext& other) noexcept
  : _next(other._next),
    _disabled_validation_check_count(other._disabled_validation_check_count),
    _disabled_validation_checks(other._disabled_validation_checks)
  {
  }

  /// Move constructor.
  constexpr validation_flags_ext(validation_flags_ext&& other) noexcept
  : _next(std::move(other._next)),
    _disabled_validation_check_count(
      std::move(other._disabled_validation_check_count)),
    _disabled_validation_checks(std::move(other._disabled_validation_checks))
  {
  }

  /// Copy assignment operator.
  constexpr validation_flags_ext& operator=(
    const validation_flags_ext& other) noexcept
  {
    _next = other._next;
    _disabled_validation_check_count = other._disabled_validation_check_count;
    _disabled_validation_checks = other._disabled_validation_checks;
    return *this;
  }

  /// Move assignment operator.
  constexpr validation_flags_ext& operator=(
    validation_flags_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _disabled_validation_check_count =
      std::move(other._disabled_validation_check_count);
    _disabled_validation_checks = std::move(other._disabled_validation_checks);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkValidationFlagsEXT&() const
  {
    return *reinterpret_cast<const VkValidationFlagsEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& disabled_validation_check_count()
  {
    return _disabled_validation_check_count;
  }

  constexpr const uint32_t& disabled_validation_check_count() const
  {
    return _disabled_validation_check_count;
  }

  void disabled_validation_check_count(
    uint32_t new_disabled_validation_check_count)
  {
    _disabled_validation_check_count = new_disabled_validation_check_count;
  }

  const vk::validation_check_ext* disabled_validation_checks()
  {
    return _disabled_validation_checks;
  }

  constexpr const vk::validation_check_ext* disabled_validation_checks() const
  {
    return _disabled_validation_checks;
  }

  void disabled_validation_checks(
    const vk::validation_check_ext* new_disabled_validation_checks)
  {
    _disabled_validation_checks = new_disabled_validation_checks;
  }

  template <std::size_t Count>
  void disabled_validation_checks(
    const std::array<vk::validation_check_ext, Count>&
      new_disabled_validation_checks)
  {
    _disabled_validation_check_count =
      static_cast<uint32_t>(new_disabled_validation_checks.size());
    _disabled_validation_checks = new_disabled_validation_checks.data();
  }

  void disabled_validation_checks(
    const std::vector<vk::validation_check_ext>& new_disabled_validation_checks)
  {
    _disabled_validation_check_count =
      static_cast<uint32_t>(new_disabled_validation_checks.size());
    _disabled_validation_checks = new_disabled_validation_checks.data();
  }

private:
  /// Must be VK_STRUCTURE_TYPE_VALIDATION_FLAGS_EXT
  const vk::structure_type _structure_type =
    vk::structure_type::validation_flags_ext;
  const void* _next = nullptr;
  /// Number of validation checks to disable
  uint32_t _disabled_validation_check_count = 0;
  /// Validation checks to disable
  const vk::validation_check_ext* _disabled_validation_checks = nullptr;
};
static_assert(sizeof(validation_flags_ext) == sizeof(::VkValidationFlagsEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImageViewASTCDecodeModeEXT.
class image_view_astcdecode_mode_ext
{
public:
  /// Default constructor.
  constexpr image_view_astcdecode_mode_ext() = default;

  /// Constructor.
  constexpr image_view_astcdecode_mode_ext(
    const void* initial_next, vk::format initial_decode_mode) noexcept
  : _next(std::move(initial_next)), _decode_mode(std::move(initial_decode_mode))
  {
  }

  /// Copy constructor.
  constexpr image_view_astcdecode_mode_ext(
    const image_view_astcdecode_mode_ext& other) noexcept
  : _next(other._next), _decode_mode(other._decode_mode)
  {
  }

  /// Move constructor.
  constexpr image_view_astcdecode_mode_ext(
    image_view_astcdecode_mode_ext&& other) noexcept
  : _next(std::move(other._next)), _decode_mode(std::move(other._decode_mode))
  {
  }

  /// Copy assignment operator.
  constexpr image_view_astcdecode_mode_ext& operator=(
    const image_view_astcdecode_mode_ext& other) noexcept
  {
    _next = other._next;
    _decode_mode = other._decode_mode;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_view_astcdecode_mode_ext& operator=(
    image_view_astcdecode_mode_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _decode_mode = std::move(other._decode_mode);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageViewASTCDecodeModeEXT&() const
  {
    return *reinterpret_cast<const VkImageViewASTCDecodeModeEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::format& decode_mode()
  {
    return _decode_mode;
  }

  constexpr const vk::format& decode_mode() const
  {
    return _decode_mode;
  }

  void decode_mode(vk::format new_decode_mode)
  {
    _decode_mode = new_decode_mode;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_view_astc_decode_mode_ext;
  const void* _next = nullptr;
  vk::format _decode_mode = vk::format::undefined;
};
static_assert(sizeof(image_view_astcdecode_mode_ext) ==
                sizeof(::VkImageViewASTCDecodeModeEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceASTCDecodeFeaturesEXT.
class physical_device_astcdecode_features_ext
{
public:
  /// Default constructor.
  constexpr physical_device_astcdecode_features_ext() = default;

  /// Constructor.
  constexpr physical_device_astcdecode_features_ext(
    void* initial_next, VkBool32 initial_decode_mode_shared_exponent) noexcept
  : _next(std::move(initial_next)),
    _decode_mode_shared_exponent(std::move(initial_decode_mode_shared_exponent))
  {
  }

  /// Copy constructor.
  constexpr physical_device_astcdecode_features_ext(
    const physical_device_astcdecode_features_ext& other) noexcept
  : _next(other._next),
    _decode_mode_shared_exponent(other._decode_mode_shared_exponent)
  {
  }

  /// Move constructor.
  constexpr physical_device_astcdecode_features_ext(
    physical_device_astcdecode_features_ext&& other) noexcept
  : _next(std::move(other._next)),
    _decode_mode_shared_exponent(std::move(other._decode_mode_shared_exponent))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_astcdecode_features_ext& operator=(
    const physical_device_astcdecode_features_ext& other) noexcept
  {
    _next = other._next;
    _decode_mode_shared_exponent = other._decode_mode_shared_exponent;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_astcdecode_features_ext& operator=(
    physical_device_astcdecode_features_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _decode_mode_shared_exponent =
      std::move(other._decode_mode_shared_exponent);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceASTCDecodeFeaturesEXT&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceASTCDecodeFeaturesEXT*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& decode_mode_shared_exponent()
  {
    return _decode_mode_shared_exponent;
  }

  constexpr const VkBool32& decode_mode_shared_exponent() const
  {
    return _decode_mode_shared_exponent;
  }

  void decode_mode_shared_exponent(VkBool32 new_decode_mode_shared_exponent)
  {
    _decode_mode_shared_exponent = new_decode_mode_shared_exponent;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_astc_decode_features_ext;
  void* _next = nullptr;
  VkBool32 _decode_mode_shared_exponent = VK_FALSE;
};
static_assert(sizeof(physical_device_astcdecode_features_ext) ==
                sizeof(::VkPhysicalDeviceASTCDecodeFeaturesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkImportMemoryFdInfoKHR.
class import_memory_fd_info_khr
{
public:
  /// Default constructor.
  constexpr import_memory_fd_info_khr() = default;

  /// Constructor.
  constexpr import_memory_fd_info_khr(
    const void* initial_next,
    vk::external_memory_handle_type_flag initial_handle_type,
    int initial_fd) noexcept
  : _next(std::move(initial_next)),
    _handle_type(std::move(initial_handle_type)),
    _fd(std::move(initial_fd))
  {
  }

  /// Copy constructor.
  constexpr import_memory_fd_info_khr(
    const import_memory_fd_info_khr& other) noexcept
  : _next(other._next), _handle_type(other._handle_type), _fd(other._fd)
  {
  }

  /// Move constructor.
  constexpr import_memory_fd_info_khr(
    import_memory_fd_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _handle_type(std::move(other._handle_type)),
    _fd(std::move(other._fd))
  {
  }

  /// Copy assignment operator.
  constexpr import_memory_fd_info_khr& operator=(
    const import_memory_fd_info_khr& other) noexcept
  {
    _next = other._next;
    _handle_type = other._handle_type;
    _fd = other._fd;
    return *this;
  }

  /// Move assignment operator.
  constexpr import_memory_fd_info_khr& operator=(
    import_memory_fd_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_type = std::move(other._handle_type);
    _fd = std::move(other._fd);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImportMemoryFdInfoKHR&() const
  {
    return *reinterpret_cast<const VkImportMemoryFdInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_memory_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_memory_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

  int& fd()
  {
    return _fd;
  }

  constexpr const int& fd() const
  {
    return _fd;
  }

  void fd(int new_fd)
  {
    _fd = new_fd;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::import_memory_fd_info_khr;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flag _handle_type =
    vk::external_memory_handle_type_flag::none;
  int _fd = 0;
};
static_assert(sizeof(import_memory_fd_info_khr) ==
                sizeof(::VkImportMemoryFdInfoKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkMemoryFdPropertiesKHR.
class memory_fd_properties_khr
{
public:
  /// Default constructor.
  constexpr memory_fd_properties_khr() = default;

  /// Constructor.
  constexpr memory_fd_properties_khr(void* initial_next,
                                     uint32_t initial_memory_type_bits) noexcept
  : _next(std::move(initial_next)),
    _memory_type_bits(std::move(initial_memory_type_bits))
  {
  }

  /// Copy constructor.
  constexpr memory_fd_properties_khr(
    const memory_fd_properties_khr& other) noexcept
  : _next(other._next), _memory_type_bits(other._memory_type_bits)
  {
  }

  /// Move constructor.
  constexpr memory_fd_properties_khr(memory_fd_properties_khr&& other) noexcept
  : _next(std::move(other._next)),
    _memory_type_bits(std::move(other._memory_type_bits))
  {
  }

  /// Copy assignment operator.
  constexpr memory_fd_properties_khr& operator=(
    const memory_fd_properties_khr& other) noexcept
  {
    _next = other._next;
    _memory_type_bits = other._memory_type_bits;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_fd_properties_khr& operator=(
    memory_fd_properties_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _memory_type_bits = std::move(other._memory_type_bits);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryFdPropertiesKHR&() const
  {
    return *reinterpret_cast<const VkMemoryFdPropertiesKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& memory_type_bits()
  {
    return _memory_type_bits;
  }

  constexpr const uint32_t& memory_type_bits() const
  {
    return _memory_type_bits;
  }

  void memory_type_bits(uint32_t new_memory_type_bits)
  {
    _memory_type_bits = new_memory_type_bits;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_fd_properties_khr;
  void* _next = nullptr;
  uint32_t _memory_type_bits = 0;
};
static_assert(sizeof(memory_fd_properties_khr) ==
                sizeof(::VkMemoryFdPropertiesKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkMemoryGetFdInfoKHR.
class memory_get_fd_info_khr
{
public:
  /// Default constructor.
  constexpr memory_get_fd_info_khr() = default;

  /// Constructor.
  constexpr memory_get_fd_info_khr(
    const void* initial_next, VkDeviceMemory initial_memory,
    vk::external_memory_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)),
    _memory(std::move(initial_memory)),
    _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr memory_get_fd_info_khr(const memory_get_fd_info_khr& other) noexcept
  : _next(other._next), _memory(other._memory), _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr memory_get_fd_info_khr(memory_get_fd_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _memory(std::move(other._memory)),
    _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr memory_get_fd_info_khr& operator=(
    const memory_get_fd_info_khr& other) noexcept
  {
    _next = other._next;
    _memory = other._memory;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_get_fd_info_khr& operator=(
    memory_get_fd_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _memory = std::move(other._memory);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryGetFdInfoKHR&() const
  {
    return *reinterpret_cast<const VkMemoryGetFdInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkDeviceMemory& memory()
  {
    return _memory;
  }

  constexpr const VkDeviceMemory& memory() const
  {
    return _memory;
  }

  void memory(VkDeviceMemory new_memory)
  {
    _memory = new_memory;
  }

  vk::external_memory_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_memory_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_memory_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_get_fd_info_khr;
  const void* _next = nullptr;
  VkDeviceMemory _memory = nullptr;
  vk::external_memory_handle_type_flag _handle_type =
    vk::external_memory_handle_type_flag::none;
};
static_assert(sizeof(memory_get_fd_info_khr) == sizeof(::VkMemoryGetFdInfoKHR),
              "struct and wrapper have different size!");

inline vk::result get_memory_fd_khr(
  VkDevice device, const vk::memory_get_fd_info_khr* get_fd_info, int* fd)
{
  return static_cast<vk::result>(
    vkGetMemoryFdKHR(static_cast<VkDevice>(device),
                     reinterpret_cast<const VkMemoryGetFdInfoKHR*>(get_fd_info),
                     reinterpret_cast<int*>(fd)));
}
inline vk::result get_memory_fd_properties_khr(
  VkDevice device, vk::external_memory_handle_type_flag handle_type, int fd,
  vk::memory_fd_properties_khr* memory_fd_properties)
{
  return static_cast<vk::result>(vkGetMemoryFdPropertiesKHR(
    static_cast<VkDevice>(device),
    static_cast<VkExternalMemoryHandleTypeFlagBits>(handle_type),
    static_cast<int>(fd),
    reinterpret_cast<VkMemoryFdPropertiesKHR*>(memory_fd_properties)));
}

/// Enhanced replacement type for VkImportSemaphoreFdInfoKHR.
class import_semaphore_fd_info_khr
{
public:
  /// Default constructor.
  constexpr import_semaphore_fd_info_khr() = default;

  /// Constructor.
  constexpr import_semaphore_fd_info_khr(
    const void* initial_next, VkSemaphore initial_semaphore,
    vk::semaphore_import_flags initial_flags,
    vk::external_semaphore_handle_type_flag initial_handle_type,
    int initial_fd) noexcept
  : _next(std::move(initial_next)),
    _semaphore(std::move(initial_semaphore)),
    _flags(std::move(initial_flags)),
    _handle_type(std::move(initial_handle_type)),
    _fd(std::move(initial_fd))
  {
  }

  /// Copy constructor.
  constexpr import_semaphore_fd_info_khr(
    const import_semaphore_fd_info_khr& other) noexcept
  : _next(other._next),
    _semaphore(other._semaphore),
    _flags(other._flags),
    _handle_type(other._handle_type),
    _fd(other._fd)
  {
  }

  /// Move constructor.
  constexpr import_semaphore_fd_info_khr(
    import_semaphore_fd_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _semaphore(std::move(other._semaphore)),
    _flags(std::move(other._flags)),
    _handle_type(std::move(other._handle_type)),
    _fd(std::move(other._fd))
  {
  }

  /// Copy assignment operator.
  constexpr import_semaphore_fd_info_khr& operator=(
    const import_semaphore_fd_info_khr& other) noexcept
  {
    _next = other._next;
    _semaphore = other._semaphore;
    _flags = other._flags;
    _handle_type = other._handle_type;
    _fd = other._fd;
    return *this;
  }

  /// Move assignment operator.
  constexpr import_semaphore_fd_info_khr& operator=(
    import_semaphore_fd_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _semaphore = std::move(other._semaphore);
    _flags = std::move(other._flags);
    _handle_type = std::move(other._handle_type);
    _fd = std::move(other._fd);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImportSemaphoreFdInfoKHR&() const
  {
    return *reinterpret_cast<const VkImportSemaphoreFdInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkSemaphore& semaphore()
  {
    return _semaphore;
  }

  constexpr const VkSemaphore& semaphore() const
  {
    return _semaphore;
  }

  void semaphore(VkSemaphore new_semaphore)
  {
    _semaphore = new_semaphore;
  }

  vk::semaphore_import_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::semaphore_import_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::semaphore_import_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::external_semaphore_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_semaphore_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_semaphore_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

  int& fd()
  {
    return _fd;
  }

  constexpr const int& fd() const
  {
    return _fd;
  }

  void fd(int new_fd)
  {
    _fd = new_fd;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::import_semaphore_fd_info_khr;
  const void* _next = nullptr;
  VkSemaphore _semaphore = nullptr;
  vk::semaphore_import_flags _flags = vk::semaphore_import_flag::none;
  vk::external_semaphore_handle_type_flag _handle_type =
    vk::external_semaphore_handle_type_flag::none;
  int _fd = 0;
};
static_assert(sizeof(import_semaphore_fd_info_khr) ==
                sizeof(::VkImportSemaphoreFdInfoKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSemaphoreGetFdInfoKHR.
class semaphore_get_fd_info_khr
{
public:
  /// Default constructor.
  constexpr semaphore_get_fd_info_khr() = default;

  /// Constructor.
  constexpr semaphore_get_fd_info_khr(
    const void* initial_next, VkSemaphore initial_semaphore,
    vk::external_semaphore_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)),
    _semaphore(std::move(initial_semaphore)),
    _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr semaphore_get_fd_info_khr(
    const semaphore_get_fd_info_khr& other) noexcept
  : _next(other._next),
    _semaphore(other._semaphore),
    _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr semaphore_get_fd_info_khr(
    semaphore_get_fd_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _semaphore(std::move(other._semaphore)),
    _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr semaphore_get_fd_info_khr& operator=(
    const semaphore_get_fd_info_khr& other) noexcept
  {
    _next = other._next;
    _semaphore = other._semaphore;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr semaphore_get_fd_info_khr& operator=(
    semaphore_get_fd_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _semaphore = std::move(other._semaphore);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSemaphoreGetFdInfoKHR&() const
  {
    return *reinterpret_cast<const VkSemaphoreGetFdInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkSemaphore& semaphore()
  {
    return _semaphore;
  }

  constexpr const VkSemaphore& semaphore() const
  {
    return _semaphore;
  }

  void semaphore(VkSemaphore new_semaphore)
  {
    _semaphore = new_semaphore;
  }

  vk::external_semaphore_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_semaphore_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_semaphore_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::semaphore_get_fd_info_khr;
  const void* _next = nullptr;
  VkSemaphore _semaphore = nullptr;
  vk::external_semaphore_handle_type_flag _handle_type =
    vk::external_semaphore_handle_type_flag::none;
};
static_assert(sizeof(semaphore_get_fd_info_khr) ==
                sizeof(::VkSemaphoreGetFdInfoKHR),
              "struct and wrapper have different size!");

inline vk::result import_semaphore_fd_khr(
  VkDevice device,
  const vk::import_semaphore_fd_info_khr* import_semaphore_fd_info)
{
  return static_cast<vk::result>(
    vkImportSemaphoreFdKHR(static_cast<VkDevice>(device),
                           reinterpret_cast<const VkImportSemaphoreFdInfoKHR*>(
                             import_semaphore_fd_info)));
}
inline vk::result get_semaphore_fd_khr(
  VkDevice device, const vk::semaphore_get_fd_info_khr* get_fd_info, int* fd)
{
  return static_cast<vk::result>(vkGetSemaphoreFdKHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkSemaphoreGetFdInfoKHR*>(get_fd_info),
    reinterpret_cast<int*>(fd)));
}

/// Enhanced replacement type for VkPhysicalDevicePushDescriptorPropertiesKHR.
class physical_device_push_descriptor_properties_khr
{
public:
  /// Default constructor.
  constexpr physical_device_push_descriptor_properties_khr() = default;

  /// Constructor.
  constexpr physical_device_push_descriptor_properties_khr(
    void* initial_next, uint32_t initial_max_push_descriptors) noexcept
  : _next(std::move(initial_next)),
    _max_push_descriptors(std::move(initial_max_push_descriptors))
  {
  }

  /// Copy constructor.
  constexpr physical_device_push_descriptor_properties_khr(
    const physical_device_push_descriptor_properties_khr& other) noexcept
  : _next(other._next), _max_push_descriptors(other._max_push_descriptors)
  {
  }

  /// Move constructor.
  constexpr physical_device_push_descriptor_properties_khr(
    physical_device_push_descriptor_properties_khr&& other) noexcept
  : _next(std::move(other._next)),
    _max_push_descriptors(std::move(other._max_push_descriptors))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_push_descriptor_properties_khr& operator=(
    const physical_device_push_descriptor_properties_khr& other) noexcept
  {
    _next = other._next;
    _max_push_descriptors = other._max_push_descriptors;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_push_descriptor_properties_khr& operator=(
    physical_device_push_descriptor_properties_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _max_push_descriptors = std::move(other._max_push_descriptors);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDevicePushDescriptorPropertiesKHR&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDevicePushDescriptorPropertiesKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_push_descriptors()
  {
    return _max_push_descriptors;
  }

  constexpr const uint32_t& max_push_descriptors() const
  {
    return _max_push_descriptors;
  }

  void max_push_descriptors(uint32_t new_max_push_descriptors)
  {
    _max_push_descriptors = new_max_push_descriptors;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_push_descriptor_properties_khr;
  void* _next = nullptr;
  uint32_t _max_push_descriptors = 0;
};
static_assert(sizeof(physical_device_push_descriptor_properties_khr) ==
                sizeof(::VkPhysicalDevicePushDescriptorPropertiesKHR),
              "struct and wrapper have different size!");

inline void cmd_push_descriptor_set_khr(
  VkCommandBuffer command_buffer, vk::pipeline_bind_point pipeline_bind_point,
  VkPipelineLayout layout, uint32_t set, uint32_t descriptor_write_count,
  const vk::write_descriptor_set* descriptor_writes)
{
  vkCmdPushDescriptorSetKHR(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<VkPipelineBindPoint>(pipeline_bind_point),
    static_cast<VkPipelineLayout>(layout), static_cast<uint32_t>(set),
    static_cast<uint32_t>(descriptor_write_count),
    reinterpret_cast<const VkWriteDescriptorSet*>(descriptor_writes));
}
inline void cmd_push_descriptor_set_with_template_khr(
  VkCommandBuffer command_buffer,
  VkDescriptorUpdateTemplate descriptor_update_template,
  VkPipelineLayout layout, uint32_t set, const void* data)
{
  vkCmdPushDescriptorSetWithTemplateKHR(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<VkDescriptorUpdateTemplate>(descriptor_update_template),
    static_cast<VkPipelineLayout>(layout), static_cast<uint32_t>(set),
    reinterpret_cast<const void*>(data));
}
enum class conditional_rendering_flag_ext
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_CONDITIONAL_RENDERING_INVERTED_BIT_EXT
  inverted_bit_ext = 1 << 0,
};
using conditional_rendering_flags_ext =
  shift::core::bit_field<conditional_rendering_flag_ext,
                         VkConditionalRenderingFlagsEXT>;
inline constexpr conditional_rendering_flags_ext operator|(
  conditional_rendering_flag_ext lhs, conditional_rendering_flag_ext rhs)
{
  return conditional_rendering_flags_ext{lhs} | rhs;
}
/// Enhanced replacement type for VkConditionalRenderingBeginInfoEXT.
class conditional_rendering_begin_info_ext
{
public:
  /// Default constructor.
  constexpr conditional_rendering_begin_info_ext() = default;

  /// Constructor.
  constexpr conditional_rendering_begin_info_ext(
    const void* initial_next, VkBuffer initial_buffer,
    VkDeviceSize initial_offset,
    vk::conditional_rendering_flags_ext initial_flags) noexcept
  : _next(std::move(initial_next)),
    _buffer(std::move(initial_buffer)),
    _offset(std::move(initial_offset)),
    _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr conditional_rendering_begin_info_ext(
    const conditional_rendering_begin_info_ext& other) noexcept
  : _next(other._next),
    _buffer(other._buffer),
    _offset(other._offset),
    _flags(other._flags)
  {
  }

  /// Move constructor.
  constexpr conditional_rendering_begin_info_ext(
    conditional_rendering_begin_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _buffer(std::move(other._buffer)),
    _offset(std::move(other._offset)),
    _flags(std::move(other._flags))
  {
  }

  /// Copy assignment operator.
  constexpr conditional_rendering_begin_info_ext& operator=(
    const conditional_rendering_begin_info_ext& other) noexcept
  {
    _next = other._next;
    _buffer = other._buffer;
    _offset = other._offset;
    _flags = other._flags;
    return *this;
  }

  /// Move assignment operator.
  constexpr conditional_rendering_begin_info_ext& operator=(
    conditional_rendering_begin_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _buffer = std::move(other._buffer);
    _offset = std::move(other._offset);
    _flags = std::move(other._flags);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkConditionalRenderingBeginInfoEXT&() const
  {
    return *reinterpret_cast<const VkConditionalRenderingBeginInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

  VkDeviceSize& offset()
  {
    return _offset;
  }

  constexpr const VkDeviceSize& offset() const
  {
    return _offset;
  }

  void offset(VkDeviceSize new_offset)
  {
    _offset = new_offset;
  }

  vk::conditional_rendering_flags_ext& flags()
  {
    return _flags;
  }

  constexpr const vk::conditional_rendering_flags_ext& flags() const
  {
    return _flags;
  }

  void flags(vk::conditional_rendering_flags_ext new_flags)
  {
    _flags = new_flags;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::conditional_rendering_begin_info_ext;
  const void* _next = nullptr;
  VkBuffer _buffer = nullptr;
  VkDeviceSize _offset = 0;
  vk::conditional_rendering_flags_ext _flags =
    vk::conditional_rendering_flag_ext::none;
};
static_assert(sizeof(conditional_rendering_begin_info_ext) ==
                sizeof(::VkConditionalRenderingBeginInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceConditionalRenderingFeaturesEXT.
class physical_device_conditional_rendering_features_ext
{
public:
  /// Default constructor.
  constexpr physical_device_conditional_rendering_features_ext() = default;

  /// Constructor.
  constexpr physical_device_conditional_rendering_features_ext(
    void* initial_next, VkBool32 initial_conditional_rendering,
    VkBool32 initial_inherited_conditional_rendering) noexcept
  : _next(std::move(initial_next)),
    _conditional_rendering(std::move(initial_conditional_rendering)),
    _inherited_conditional_rendering(
      std::move(initial_inherited_conditional_rendering))
  {
  }

  /// Copy constructor.
  constexpr physical_device_conditional_rendering_features_ext(
    const physical_device_conditional_rendering_features_ext& other) noexcept
  : _next(other._next),
    _conditional_rendering(other._conditional_rendering),
    _inherited_conditional_rendering(other._inherited_conditional_rendering)
  {
  }

  /// Move constructor.
  constexpr physical_device_conditional_rendering_features_ext(
    physical_device_conditional_rendering_features_ext&& other) noexcept
  : _next(std::move(other._next)),
    _conditional_rendering(std::move(other._conditional_rendering)),
    _inherited_conditional_rendering(
      std::move(other._inherited_conditional_rendering))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_conditional_rendering_features_ext& operator=(
    const physical_device_conditional_rendering_features_ext& other) noexcept
  {
    _next = other._next;
    _conditional_rendering = other._conditional_rendering;
    _inherited_conditional_rendering = other._inherited_conditional_rendering;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_conditional_rendering_features_ext& operator=(
    physical_device_conditional_rendering_features_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _conditional_rendering = std::move(other._conditional_rendering);
    _inherited_conditional_rendering =
      std::move(other._inherited_conditional_rendering);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceConditionalRenderingFeaturesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceConditionalRenderingFeaturesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& conditional_rendering()
  {
    return _conditional_rendering;
  }

  constexpr const VkBool32& conditional_rendering() const
  {
    return _conditional_rendering;
  }

  void conditional_rendering(VkBool32 new_conditional_rendering)
  {
    _conditional_rendering = new_conditional_rendering;
  }

  VkBool32& inherited_conditional_rendering()
  {
    return _inherited_conditional_rendering;
  }

  constexpr const VkBool32& inherited_conditional_rendering() const
  {
    return _inherited_conditional_rendering;
  }

  void inherited_conditional_rendering(
    VkBool32 new_inherited_conditional_rendering)
  {
    _inherited_conditional_rendering = new_inherited_conditional_rendering;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_conditional_rendering_features_ext;
  void* _next = nullptr;
  VkBool32 _conditional_rendering = VK_FALSE;
  VkBool32 _inherited_conditional_rendering = VK_FALSE;
};
static_assert(sizeof(physical_device_conditional_rendering_features_ext) ==
                sizeof(::VkPhysicalDeviceConditionalRenderingFeaturesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkCommandBufferInheritanceConditionalRenderingInfoEXT.
class command_buffer_inheritance_conditional_rendering_info_ext
{
public:
  /// Default constructor.
  constexpr command_buffer_inheritance_conditional_rendering_info_ext() =
    default;

  /// Constructor.
  constexpr command_buffer_inheritance_conditional_rendering_info_ext(
    const void* initial_next,
    VkBool32 initial_conditional_rendering_enable) noexcept
  : _next(std::move(initial_next)),
    _conditional_rendering_enable(
      std::move(initial_conditional_rendering_enable))
  {
  }

  /// Copy constructor.
  constexpr command_buffer_inheritance_conditional_rendering_info_ext(
    const command_buffer_inheritance_conditional_rendering_info_ext&
      other) noexcept
  : _next(other._next),
    _conditional_rendering_enable(other._conditional_rendering_enable)
  {
  }

  /// Move constructor.
  constexpr command_buffer_inheritance_conditional_rendering_info_ext(
    command_buffer_inheritance_conditional_rendering_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _conditional_rendering_enable(
      std::move(other._conditional_rendering_enable))
  {
  }

  /// Copy assignment operator.
  constexpr command_buffer_inheritance_conditional_rendering_info_ext&
  operator=(const command_buffer_inheritance_conditional_rendering_info_ext&
              other) noexcept
  {
    _next = other._next;
    _conditional_rendering_enable = other._conditional_rendering_enable;
    return *this;
  }

  /// Move assignment operator.
  constexpr command_buffer_inheritance_conditional_rendering_info_ext&
  operator=(
    command_buffer_inheritance_conditional_rendering_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _conditional_rendering_enable =
      std::move(other._conditional_rendering_enable);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkCommandBufferInheritanceConditionalRenderingInfoEXT&() const
  {
    return *reinterpret_cast<
      const VkCommandBufferInheritanceConditionalRenderingInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& conditional_rendering_enable()
  {
    return _conditional_rendering_enable;
  }

  constexpr const VkBool32& conditional_rendering_enable() const
  {
    return _conditional_rendering_enable;
  }

  void conditional_rendering_enable(VkBool32 new_conditional_rendering_enable)
  {
    _conditional_rendering_enable = new_conditional_rendering_enable;
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    command_buffer_inheritance_conditional_rendering_info_ext;
  const void* _next = nullptr;
  /// Whether this secondary command buffer may be executed during an active
  /// conditional rendering
  VkBool32 _conditional_rendering_enable = VK_FALSE;
};
static_assert(
  sizeof(command_buffer_inheritance_conditional_rendering_info_ext) ==
    sizeof(::VkCommandBufferInheritanceConditionalRenderingInfoEXT),
  "struct and wrapper have different size!");

inline void cmd_begin_conditional_rendering_ext(
  VkCommandBuffer command_buffer,
  const vk::conditional_rendering_begin_info_ext* conditional_rendering_begin)
{
  vkCmdBeginConditionalRenderingEXT(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkConditionalRenderingBeginInfoEXT*>(
      conditional_rendering_begin));
}
inline void cmd_end_conditional_rendering_ext(VkCommandBuffer command_buffer)
{
  vkCmdEndConditionalRenderingEXT(static_cast<VkCommandBuffer>(command_buffer));
}

/// Enhanced replacement type for VkRectLayerKHR.
class rect_layer_khr
{
public:
  /// Default constructor.
  constexpr rect_layer_khr() = default;

  /// Constructor.
  constexpr rect_layer_khr(vk::offset_2d initial_offset,
                           vk::extent_2d initial_extent,
                           uint32_t initial_layer) noexcept
  : _offset(std::move(initial_offset)),
    _extent(std::move(initial_extent)),
    _layer(std::move(initial_layer))
  {
  }

  /// Copy constructor.
  constexpr rect_layer_khr(const rect_layer_khr& other) = default;

  /// Move constructor.
  constexpr rect_layer_khr(rect_layer_khr&& other) = default;

  /// Copy assignment operator.
  constexpr rect_layer_khr& operator=(const rect_layer_khr& other) = default;

  /// Move assignment operator.
  constexpr rect_layer_khr& operator=(rect_layer_khr&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkRectLayerKHR&() const
  {
    return *reinterpret_cast<const VkRectLayerKHR*>(this);
  }

  vk::offset_2d& offset()
  {
    return _offset;
  }

  constexpr const vk::offset_2d& offset() const
  {
    return _offset;
  }

  void offset(vk::offset_2d new_offset)
  {
    _offset = new_offset;
  }

  vk::extent_2d& extent()
  {
    return _extent;
  }

  constexpr const vk::extent_2d& extent() const
  {
    return _extent;
  }

  void extent(vk::extent_2d new_extent)
  {
    _extent = new_extent;
  }

  uint32_t& layer()
  {
    return _layer;
  }

  constexpr const uint32_t& layer() const
  {
    return _layer;
  }

  void layer(uint32_t new_layer)
  {
    _layer = new_layer;
  }

private:
  /// upper-left corner of a rectangle that has not changed, in pixels of a
  /// presentation images
  vk::offset_2d _offset = vk::offset_2d{};
  /// Dimensions of a rectangle that has not changed, in pixels of a
  /// presentation images
  vk::extent_2d _extent = vk::extent_2d{};
  /// Layer of a swapchain's image(s), for stereoscopic-3D images
  uint32_t _layer = 0;
};
static_assert(sizeof(rect_layer_khr) == sizeof(::VkRectLayerKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPresentRegionKHR.
class present_region_khr
{
public:
  /// Default constructor.
  constexpr present_region_khr() = default;

  /// Constructor.
  constexpr present_region_khr(
    uint32_t initial_rectangle_count,
    const vk::rect_layer_khr* initial_rectangles) noexcept
  : _rectangle_count(std::move(initial_rectangle_count)),
    _rectangles(std::move(initial_rectangles))
  {
  }

  /// Copy constructor.
  constexpr present_region_khr(const present_region_khr& other) = default;

  /// Move constructor.
  constexpr present_region_khr(present_region_khr&& other) = default;

  /// Copy assignment operator.
  constexpr present_region_khr& operator=(const present_region_khr& other) =
    default;

  /// Move assignment operator.
  constexpr present_region_khr& operator=(present_region_khr&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkPresentRegionKHR&() const
  {
    return *reinterpret_cast<const VkPresentRegionKHR*>(this);
  }

  uint32_t& rectangle_count()
  {
    return _rectangle_count;
  }

  constexpr const uint32_t& rectangle_count() const
  {
    return _rectangle_count;
  }

  void rectangle_count(uint32_t new_rectangle_count)
  {
    _rectangle_count = new_rectangle_count;
  }

  const vk::rect_layer_khr* rectangles()
  {
    return _rectangles;
  }

  constexpr const vk::rect_layer_khr* rectangles() const
  {
    return _rectangles;
  }

  void rectangles(const vk::rect_layer_khr* new_rectangles)
  {
    _rectangles = new_rectangles;
  }

  template <std::size_t Count>
  void rectangles(const std::array<vk::rect_layer_khr, Count>& new_rectangles)
  {
    _rectangle_count = static_cast<uint32_t>(new_rectangles.size());
    _rectangles = new_rectangles.data();
  }

  void rectangles(const std::vector<vk::rect_layer_khr>& new_rectangles)
  {
    _rectangle_count = static_cast<uint32_t>(new_rectangles.size());
    _rectangles = new_rectangles.data();
  }

private:
  /// Number of rectangles in pRectangles
  uint32_t _rectangle_count = 0;
  /// Array of rectangles that have changed in a swapchain's image(s)
  const vk::rect_layer_khr* _rectangles = nullptr;
};
static_assert(sizeof(present_region_khr) == sizeof(::VkPresentRegionKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPresentRegionsKHR.
class present_regions_khr
{
public:
  /// Default constructor.
  constexpr present_regions_khr() = default;

  /// Constructor.
  constexpr present_regions_khr(
    const void* initial_next, uint32_t initial_swapchain_count,
    const vk::present_region_khr* initial_regions) noexcept
  : _next(std::move(initial_next)),
    _swapchain_count(std::move(initial_swapchain_count)),
    _regions(std::move(initial_regions))
  {
  }

  /// Copy constructor.
  constexpr present_regions_khr(const present_regions_khr& other) noexcept
  : _next(other._next),
    _swapchain_count(other._swapchain_count),
    _regions(other._regions)
  {
  }

  /// Move constructor.
  constexpr present_regions_khr(present_regions_khr&& other) noexcept
  : _next(std::move(other._next)),
    _swapchain_count(std::move(other._swapchain_count)),
    _regions(std::move(other._regions))
  {
  }

  /// Copy assignment operator.
  constexpr present_regions_khr& operator=(
    const present_regions_khr& other) noexcept
  {
    _next = other._next;
    _swapchain_count = other._swapchain_count;
    _regions = other._regions;
    return *this;
  }

  /// Move assignment operator.
  constexpr present_regions_khr& operator=(present_regions_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _swapchain_count = std::move(other._swapchain_count);
    _regions = std::move(other._regions);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPresentRegionsKHR&() const
  {
    return *reinterpret_cast<const VkPresentRegionsKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& swapchain_count()
  {
    return _swapchain_count;
  }

  constexpr const uint32_t& swapchain_count() const
  {
    return _swapchain_count;
  }

  void swapchain_count(uint32_t new_swapchain_count)
  {
    _swapchain_count = new_swapchain_count;
  }

  const vk::present_region_khr* regions()
  {
    return _regions;
  }

  constexpr const vk::present_region_khr* regions() const
  {
    return _regions;
  }

  void regions(const vk::present_region_khr* new_regions)
  {
    _regions = new_regions;
  }

  template <std::size_t Count>
  void regions(const std::array<vk::present_region_khr, Count>& new_regions)
  {
    _swapchain_count = static_cast<uint32_t>(new_regions.size());
    _regions = new_regions.data();
  }

  void regions(const std::vector<vk::present_region_khr>& new_regions)
  {
    _swapchain_count = static_cast<uint32_t>(new_regions.size());
    _regions = new_regions.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::present_regions_khr;
  const void* _next = nullptr;
  /// Copy of VkPresentInfoKHR::swapchainCount
  uint32_t _swapchain_count = 0;
  /// The regions that have changed
  const vk::present_region_khr* _regions = nullptr;
};
static_assert(sizeof(present_regions_khr) == sizeof(::VkPresentRegionsKHR),
              "struct and wrapper have different size!");

enum class indirect_commands_layout_usage_flag_nvx
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_INDIRECT_COMMANDS_LAYOUT_USAGE_UNORDERED_SEQUENCES_BIT_NVX
  unordered_sequences_bit_nvx = 1 << 0,
  /// @see VK_INDIRECT_COMMANDS_LAYOUT_USAGE_SPARSE_SEQUENCES_BIT_NVX
  sparse_sequences_bit_nvx = 1 << 1,
  /// @see VK_INDIRECT_COMMANDS_LAYOUT_USAGE_EMPTY_EXECUTIONS_BIT_NVX
  empty_executions_bit_nvx = 1 << 2,
  /// @see VK_INDIRECT_COMMANDS_LAYOUT_USAGE_INDEXED_SEQUENCES_BIT_NVX
  indexed_sequences_bit_nvx = 1 << 3,
};
using indirect_commands_layout_usage_flags_nvx =
  shift::core::bit_field<indirect_commands_layout_usage_flag_nvx,
                         VkIndirectCommandsLayoutUsageFlagsNVX>;
inline constexpr indirect_commands_layout_usage_flags_nvx operator|(
  indirect_commands_layout_usage_flag_nvx lhs,
  indirect_commands_layout_usage_flag_nvx rhs)
{
  return indirect_commands_layout_usage_flags_nvx{lhs} | rhs;
}
enum class object_entry_usage_flag_nvx
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_OBJECT_ENTRY_USAGE_GRAPHICS_BIT_NVX
  graphics_bit_nvx = 1 << 0,
  /// @see VK_OBJECT_ENTRY_USAGE_COMPUTE_BIT_NVX
  compute_bit_nvx = 1 << 1,
};
using object_entry_usage_flags_nvx =
  shift::core::bit_field<object_entry_usage_flag_nvx,
                         VkObjectEntryUsageFlagsNVX>;
inline constexpr object_entry_usage_flags_nvx operator|(
  object_entry_usage_flag_nvx lhs, object_entry_usage_flag_nvx rhs)
{
  return object_entry_usage_flags_nvx{lhs} | rhs;
}
enum class indirect_commands_token_type_nvx
{
  /// @see VK_INDIRECT_COMMANDS_TOKEN_TYPE_PIPELINE_NVX
  indirect_commands_token_type_pipeline_nvx = 0,
  /// @see VK_INDIRECT_COMMANDS_TOKEN_TYPE_DESCRIPTOR_SET_NVX
  indirect_commands_token_type_descriptor_set_nvx = 1,
  /// @see VK_INDIRECT_COMMANDS_TOKEN_TYPE_INDEX_BUFFER_NVX
  indirect_commands_token_type_index_buffer_nvx = 2,
  /// @see VK_INDIRECT_COMMANDS_TOKEN_TYPE_VERTEX_BUFFER_NVX
  indirect_commands_token_type_vertex_buffer_nvx = 3,
  /// @see VK_INDIRECT_COMMANDS_TOKEN_TYPE_PUSH_CONSTANT_NVX
  indirect_commands_token_type_push_constant_nvx = 4,
  /// @see VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_INDEXED_NVX
  indirect_commands_token_type_draw_indexed_nvx = 5,
  /// @see VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_NVX
  indirect_commands_token_type_draw_nvx = 6,
  /// @see VK_INDIRECT_COMMANDS_TOKEN_TYPE_DISPATCH_NVX
  indirect_commands_token_type_dispatch_nvx = 7,
};
enum class object_entry_type_nvx
{
  /// @see VK_OBJECT_ENTRY_TYPE_DESCRIPTOR_SET_NVX
  object_entry_type_descriptor_set_nvx = 0,
  /// @see VK_OBJECT_ENTRY_TYPE_PIPELINE_NVX
  object_entry_type_pipeline_nvx = 1,
  /// @see VK_OBJECT_ENTRY_TYPE_INDEX_BUFFER_NVX
  object_entry_type_index_buffer_nvx = 2,
  /// @see VK_OBJECT_ENTRY_TYPE_VERTEX_BUFFER_NVX
  object_entry_type_vertex_buffer_nvx = 3,
  /// @see VK_OBJECT_ENTRY_TYPE_PUSH_CONSTANT_NVX
  object_entry_type_push_constant_nvx = 4,
};

/// Enhanced replacement type for VkDeviceGeneratedCommandsFeaturesNVX.
class device_generated_commands_features_nvx
{
public:
  /// Default constructor.
  constexpr device_generated_commands_features_nvx() = default;

  /// Constructor.
  constexpr device_generated_commands_features_nvx(
    const void* initial_next,
    VkBool32 initial_compute_binding_point_support) noexcept
  : _next(std::move(initial_next)),
    _compute_binding_point_support(
      std::move(initial_compute_binding_point_support))
  {
  }

  /// Copy constructor.
  constexpr device_generated_commands_features_nvx(
    const device_generated_commands_features_nvx& other) noexcept
  : _next(other._next),
    _compute_binding_point_support(other._compute_binding_point_support)
  {
  }

  /// Move constructor.
  constexpr device_generated_commands_features_nvx(
    device_generated_commands_features_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _compute_binding_point_support(
      std::move(other._compute_binding_point_support))
  {
  }

  /// Copy assignment operator.
  constexpr device_generated_commands_features_nvx& operator=(
    const device_generated_commands_features_nvx& other) noexcept
  {
    _next = other._next;
    _compute_binding_point_support = other._compute_binding_point_support;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_generated_commands_features_nvx& operator=(
    device_generated_commands_features_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _compute_binding_point_support =
      std::move(other._compute_binding_point_support);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGeneratedCommandsFeaturesNVX&() const
  {
    return *reinterpret_cast<const VkDeviceGeneratedCommandsFeaturesNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& compute_binding_point_support()
  {
    return _compute_binding_point_support;
  }

  constexpr const VkBool32& compute_binding_point_support() const
  {
    return _compute_binding_point_support;
  }

  void compute_binding_point_support(VkBool32 new_compute_binding_point_support)
  {
    _compute_binding_point_support = new_compute_binding_point_support;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_generated_commands_features_nvx;
  const void* _next = nullptr;
  VkBool32 _compute_binding_point_support = VK_FALSE;
};
static_assert(sizeof(device_generated_commands_features_nvx) ==
                sizeof(::VkDeviceGeneratedCommandsFeaturesNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceGeneratedCommandsLimitsNVX.
class device_generated_commands_limits_nvx
{
public:
  /// Default constructor.
  constexpr device_generated_commands_limits_nvx() = default;

  /// Constructor.
  constexpr device_generated_commands_limits_nvx(
    const void* initial_next,
    uint32_t initial_max_indirect_commands_layout_token_count,
    uint32_t initial_max_object_entry_counts,
    uint32_t initial_min_sequence_count_buffer_offset_alignment,
    uint32_t initial_min_sequence_index_buffer_offset_alignment,
    uint32_t initial_min_commands_token_buffer_offset_alignment) noexcept
  : _next(std::move(initial_next)),
    _max_indirect_commands_layout_token_count(
      std::move(initial_max_indirect_commands_layout_token_count)),
    _max_object_entry_counts(std::move(initial_max_object_entry_counts)),
    _min_sequence_count_buffer_offset_alignment(
      std::move(initial_min_sequence_count_buffer_offset_alignment)),
    _min_sequence_index_buffer_offset_alignment(
      std::move(initial_min_sequence_index_buffer_offset_alignment)),
    _min_commands_token_buffer_offset_alignment(
      std::move(initial_min_commands_token_buffer_offset_alignment))
  {
  }

  /// Copy constructor.
  constexpr device_generated_commands_limits_nvx(
    const device_generated_commands_limits_nvx& other) noexcept
  : _next(other._next),
    _max_indirect_commands_layout_token_count(
      other._max_indirect_commands_layout_token_count),
    _max_object_entry_counts(other._max_object_entry_counts),
    _min_sequence_count_buffer_offset_alignment(
      other._min_sequence_count_buffer_offset_alignment),
    _min_sequence_index_buffer_offset_alignment(
      other._min_sequence_index_buffer_offset_alignment),
    _min_commands_token_buffer_offset_alignment(
      other._min_commands_token_buffer_offset_alignment)
  {
  }

  /// Move constructor.
  constexpr device_generated_commands_limits_nvx(
    device_generated_commands_limits_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _max_indirect_commands_layout_token_count(
      std::move(other._max_indirect_commands_layout_token_count)),
    _max_object_entry_counts(std::move(other._max_object_entry_counts)),
    _min_sequence_count_buffer_offset_alignment(
      std::move(other._min_sequence_count_buffer_offset_alignment)),
    _min_sequence_index_buffer_offset_alignment(
      std::move(other._min_sequence_index_buffer_offset_alignment)),
    _min_commands_token_buffer_offset_alignment(
      std::move(other._min_commands_token_buffer_offset_alignment))
  {
  }

  /// Copy assignment operator.
  constexpr device_generated_commands_limits_nvx& operator=(
    const device_generated_commands_limits_nvx& other) noexcept
  {
    _next = other._next;
    _max_indirect_commands_layout_token_count =
      other._max_indirect_commands_layout_token_count;
    _max_object_entry_counts = other._max_object_entry_counts;
    _min_sequence_count_buffer_offset_alignment =
      other._min_sequence_count_buffer_offset_alignment;
    _min_sequence_index_buffer_offset_alignment =
      other._min_sequence_index_buffer_offset_alignment;
    _min_commands_token_buffer_offset_alignment =
      other._min_commands_token_buffer_offset_alignment;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_generated_commands_limits_nvx& operator=(
    device_generated_commands_limits_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _max_indirect_commands_layout_token_count =
      std::move(other._max_indirect_commands_layout_token_count);
    _max_object_entry_counts = std::move(other._max_object_entry_counts);
    _min_sequence_count_buffer_offset_alignment =
      std::move(other._min_sequence_count_buffer_offset_alignment);
    _min_sequence_index_buffer_offset_alignment =
      std::move(other._min_sequence_index_buffer_offset_alignment);
    _min_commands_token_buffer_offset_alignment =
      std::move(other._min_commands_token_buffer_offset_alignment);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceGeneratedCommandsLimitsNVX&() const
  {
    return *reinterpret_cast<const VkDeviceGeneratedCommandsLimitsNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_indirect_commands_layout_token_count()
  {
    return _max_indirect_commands_layout_token_count;
  }

  constexpr const uint32_t& max_indirect_commands_layout_token_count() const
  {
    return _max_indirect_commands_layout_token_count;
  }

  void max_indirect_commands_layout_token_count(
    uint32_t new_max_indirect_commands_layout_token_count)
  {
    _max_indirect_commands_layout_token_count =
      new_max_indirect_commands_layout_token_count;
  }

  uint32_t& max_object_entry_counts()
  {
    return _max_object_entry_counts;
  }

  constexpr const uint32_t& max_object_entry_counts() const
  {
    return _max_object_entry_counts;
  }

  void max_object_entry_counts(uint32_t new_max_object_entry_counts)
  {
    _max_object_entry_counts = new_max_object_entry_counts;
  }

  uint32_t& min_sequence_count_buffer_offset_alignment()
  {
    return _min_sequence_count_buffer_offset_alignment;
  }

  constexpr const uint32_t& min_sequence_count_buffer_offset_alignment() const
  {
    return _min_sequence_count_buffer_offset_alignment;
  }

  void min_sequence_count_buffer_offset_alignment(
    uint32_t new_min_sequence_count_buffer_offset_alignment)
  {
    _min_sequence_count_buffer_offset_alignment =
      new_min_sequence_count_buffer_offset_alignment;
  }

  uint32_t& min_sequence_index_buffer_offset_alignment()
  {
    return _min_sequence_index_buffer_offset_alignment;
  }

  constexpr const uint32_t& min_sequence_index_buffer_offset_alignment() const
  {
    return _min_sequence_index_buffer_offset_alignment;
  }

  void min_sequence_index_buffer_offset_alignment(
    uint32_t new_min_sequence_index_buffer_offset_alignment)
  {
    _min_sequence_index_buffer_offset_alignment =
      new_min_sequence_index_buffer_offset_alignment;
  }

  uint32_t& min_commands_token_buffer_offset_alignment()
  {
    return _min_commands_token_buffer_offset_alignment;
  }

  constexpr const uint32_t& min_commands_token_buffer_offset_alignment() const
  {
    return _min_commands_token_buffer_offset_alignment;
  }

  void min_commands_token_buffer_offset_alignment(
    uint32_t new_min_commands_token_buffer_offset_alignment)
  {
    _min_commands_token_buffer_offset_alignment =
      new_min_commands_token_buffer_offset_alignment;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_generated_commands_limits_nvx;
  const void* _next = nullptr;
  uint32_t _max_indirect_commands_layout_token_count = 0;
  uint32_t _max_object_entry_counts = 0;
  uint32_t _min_sequence_count_buffer_offset_alignment = 0;
  uint32_t _min_sequence_index_buffer_offset_alignment = 0;
  uint32_t _min_commands_token_buffer_offset_alignment = 0;
};
static_assert(sizeof(device_generated_commands_limits_nvx) ==
                sizeof(::VkDeviceGeneratedCommandsLimitsNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkIndirectCommandsTokenNVX.
class indirect_commands_token_nvx
{
public:
  /// Default constructor.
  constexpr indirect_commands_token_nvx() = default;

  /// Constructor.
  constexpr indirect_commands_token_nvx(
    vk::indirect_commands_token_type_nvx initial_token_type,
    VkBuffer initial_buffer, VkDeviceSize initial_offset) noexcept
  : _token_type(std::move(initial_token_type)),
    _buffer(std::move(initial_buffer)),
    _offset(std::move(initial_offset))
  {
  }

  /// Copy constructor.
  constexpr indirect_commands_token_nvx(
    const indirect_commands_token_nvx& other) = default;

  /// Move constructor.
  constexpr indirect_commands_token_nvx(indirect_commands_token_nvx&& other) =
    default;

  /// Copy assignment operator.
  constexpr indirect_commands_token_nvx& operator=(
    const indirect_commands_token_nvx& other) = default;

  /// Move assignment operator.
  constexpr indirect_commands_token_nvx& operator=(
    indirect_commands_token_nvx&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkIndirectCommandsTokenNVX&() const
  {
    return *reinterpret_cast<const VkIndirectCommandsTokenNVX*>(this);
  }

  vk::indirect_commands_token_type_nvx& token_type()
  {
    return _token_type;
  }

  constexpr const vk::indirect_commands_token_type_nvx& token_type() const
  {
    return _token_type;
  }

  void token_type(vk::indirect_commands_token_type_nvx new_token_type)
  {
    _token_type = new_token_type;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

  VkDeviceSize& offset()
  {
    return _offset;
  }

  constexpr const VkDeviceSize& offset() const
  {
    return _offset;
  }

  void offset(VkDeviceSize new_offset)
  {
    _offset = new_offset;
  }

private:
  vk::indirect_commands_token_type_nvx _token_type = vk::
    indirect_commands_token_type_nvx::indirect_commands_token_type_pipeline_nvx;
  /// buffer containing tableEntries and additional data for indirectCommands
  VkBuffer _buffer = nullptr;
  /// offset from the base address of the buffer
  VkDeviceSize _offset = 0;
};
static_assert(sizeof(indirect_commands_token_nvx) ==
                sizeof(::VkIndirectCommandsTokenNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkIndirectCommandsLayoutTokenNVX.
class indirect_commands_layout_token_nvx
{
public:
  /// Default constructor.
  constexpr indirect_commands_layout_token_nvx() = default;

  /// Constructor.
  constexpr indirect_commands_layout_token_nvx(
    vk::indirect_commands_token_type_nvx initial_token_type,
    uint32_t initial_binding_unit, uint32_t initial_dynamic_count,
    uint32_t initial_divisor) noexcept
  : _token_type(std::move(initial_token_type)),
    _binding_unit(std::move(initial_binding_unit)),
    _dynamic_count(std::move(initial_dynamic_count)),
    _divisor(std::move(initial_divisor))
  {
  }

  /// Copy constructor.
  constexpr indirect_commands_layout_token_nvx(
    const indirect_commands_layout_token_nvx& other) = default;

  /// Move constructor.
  constexpr indirect_commands_layout_token_nvx(
    indirect_commands_layout_token_nvx&& other) = default;

  /// Copy assignment operator.
  constexpr indirect_commands_layout_token_nvx& operator=(
    const indirect_commands_layout_token_nvx& other) = default;

  /// Move assignment operator.
  constexpr indirect_commands_layout_token_nvx& operator=(
    indirect_commands_layout_token_nvx&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkIndirectCommandsLayoutTokenNVX&() const
  {
    return *reinterpret_cast<const VkIndirectCommandsLayoutTokenNVX*>(this);
  }

  vk::indirect_commands_token_type_nvx& token_type()
  {
    return _token_type;
  }

  constexpr const vk::indirect_commands_token_type_nvx& token_type() const
  {
    return _token_type;
  }

  void token_type(vk::indirect_commands_token_type_nvx new_token_type)
  {
    _token_type = new_token_type;
  }

  uint32_t& binding_unit()
  {
    return _binding_unit;
  }

  constexpr const uint32_t& binding_unit() const
  {
    return _binding_unit;
  }

  void binding_unit(uint32_t new_binding_unit)
  {
    _binding_unit = new_binding_unit;
  }

  uint32_t& dynamic_count()
  {
    return _dynamic_count;
  }

  constexpr const uint32_t& dynamic_count() const
  {
    return _dynamic_count;
  }

  void dynamic_count(uint32_t new_dynamic_count)
  {
    _dynamic_count = new_dynamic_count;
  }

  uint32_t& divisor()
  {
    return _divisor;
  }

  constexpr const uint32_t& divisor() const
  {
    return _divisor;
  }

  void divisor(uint32_t new_divisor)
  {
    _divisor = new_divisor;
  }

private:
  vk::indirect_commands_token_type_nvx _token_type = vk::
    indirect_commands_token_type_nvx::indirect_commands_token_type_pipeline_nvx;
  /// Binding unit for vertex attribute / descriptor set, offset for
  /// pushconstants
  uint32_t _binding_unit = 0;
  /// Number of variable dynamic values for descriptor set / push constants
  uint32_t _dynamic_count = 0;
  /// Rate the which the array is advanced per element (must be power of 2,
  /// minimum 1)
  uint32_t _divisor = 0;
};
static_assert(sizeof(indirect_commands_layout_token_nvx) ==
                sizeof(::VkIndirectCommandsLayoutTokenNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkIndirectCommandsLayoutCreateInfoNVX.
class indirect_commands_layout_create_info_nvx
{
public:
  /// Default constructor.
  constexpr indirect_commands_layout_create_info_nvx() = default;

  /// Constructor.
  constexpr indirect_commands_layout_create_info_nvx(
    const void* initial_next,
    vk::pipeline_bind_point initial_pipeline_bind_point,
    vk::indirect_commands_layout_usage_flags_nvx initial_flags,
    uint32_t initial_token_count,
    const vk::indirect_commands_layout_token_nvx* initial_tokens) noexcept
  : _next(std::move(initial_next)),
    _pipeline_bind_point(std::move(initial_pipeline_bind_point)),
    _flags(std::move(initial_flags)),
    _token_count(std::move(initial_token_count)),
    _tokens(std::move(initial_tokens))
  {
  }

  /// Copy constructor.
  constexpr indirect_commands_layout_create_info_nvx(
    const indirect_commands_layout_create_info_nvx& other) noexcept
  : _next(other._next),
    _pipeline_bind_point(other._pipeline_bind_point),
    _flags(other._flags),
    _token_count(other._token_count),
    _tokens(other._tokens)
  {
  }

  /// Move constructor.
  constexpr indirect_commands_layout_create_info_nvx(
    indirect_commands_layout_create_info_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _pipeline_bind_point(std::move(other._pipeline_bind_point)),
    _flags(std::move(other._flags)),
    _token_count(std::move(other._token_count)),
    _tokens(std::move(other._tokens))
  {
  }

  /// Copy assignment operator.
  constexpr indirect_commands_layout_create_info_nvx& operator=(
    const indirect_commands_layout_create_info_nvx& other) noexcept
  {
    _next = other._next;
    _pipeline_bind_point = other._pipeline_bind_point;
    _flags = other._flags;
    _token_count = other._token_count;
    _tokens = other._tokens;
    return *this;
  }

  /// Move assignment operator.
  constexpr indirect_commands_layout_create_info_nvx& operator=(
    indirect_commands_layout_create_info_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _pipeline_bind_point = std::move(other._pipeline_bind_point);
    _flags = std::move(other._flags);
    _token_count = std::move(other._token_count);
    _tokens = std::move(other._tokens);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkIndirectCommandsLayoutCreateInfoNVX&() const
  {
    return *reinterpret_cast<const VkIndirectCommandsLayoutCreateInfoNVX*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_bind_point& pipeline_bind_point()
  {
    return _pipeline_bind_point;
  }

  constexpr const vk::pipeline_bind_point& pipeline_bind_point() const
  {
    return _pipeline_bind_point;
  }

  void pipeline_bind_point(vk::pipeline_bind_point new_pipeline_bind_point)
  {
    _pipeline_bind_point = new_pipeline_bind_point;
  }

  vk::indirect_commands_layout_usage_flags_nvx& flags()
  {
    return _flags;
  }

  constexpr const vk::indirect_commands_layout_usage_flags_nvx& flags() const
  {
    return _flags;
  }

  void flags(vk::indirect_commands_layout_usage_flags_nvx new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& token_count()
  {
    return _token_count;
  }

  constexpr const uint32_t& token_count() const
  {
    return _token_count;
  }

  void token_count(uint32_t new_token_count)
  {
    _token_count = new_token_count;
  }

  const vk::indirect_commands_layout_token_nvx* tokens()
  {
    return _tokens;
  }

  constexpr const vk::indirect_commands_layout_token_nvx* tokens() const
  {
    return _tokens;
  }

  void tokens(const vk::indirect_commands_layout_token_nvx* new_tokens)
  {
    _tokens = new_tokens;
  }

  template <std::size_t Count>
  void tokens(
    const std::array<vk::indirect_commands_layout_token_nvx, Count>& new_tokens)
  {
    _token_count = static_cast<uint32_t>(new_tokens.size());
    _tokens = new_tokens.data();
  }

  void tokens(
    const std::vector<vk::indirect_commands_layout_token_nvx>& new_tokens)
  {
    _token_count = static_cast<uint32_t>(new_tokens.size());
    _tokens = new_tokens.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::indirect_commands_layout_create_info_nvx;
  const void* _next = nullptr;
  vk::pipeline_bind_point _pipeline_bind_point =
    vk::pipeline_bind_point::graphics;
  vk::indirect_commands_layout_usage_flags_nvx _flags =
    vk::indirect_commands_layout_usage_flag_nvx::none;
  uint32_t _token_count = 0;
  const vk::indirect_commands_layout_token_nvx* _tokens = nullptr;
};
static_assert(sizeof(indirect_commands_layout_create_info_nvx) ==
                sizeof(::VkIndirectCommandsLayoutCreateInfoNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkCmdProcessCommandsInfoNVX.
class cmd_process_commands_info_nvx
{
public:
  /// Default constructor.
  constexpr cmd_process_commands_info_nvx() = default;

  /// Constructor.
  constexpr cmd_process_commands_info_nvx(
    const void* initial_next, VkObjectTableNVX initial_object_table,
    VkIndirectCommandsLayoutNVX initial_indirect_commands_layout,
    uint32_t initial_indirect_commands_token_count,
    const vk::indirect_commands_token_nvx* initial_indirect_commands_tokens,
    uint32_t initial_max_sequences_count,
    VkCommandBuffer initial_target_command_buffer,
    VkBuffer initial_sequences_count_buffer,
    VkDeviceSize initial_sequences_count_offset,
    VkBuffer initial_sequences_index_buffer,
    VkDeviceSize initial_sequences_index_offset) noexcept
  : _next(std::move(initial_next)),
    _object_table(std::move(initial_object_table)),
    _indirect_commands_layout(std::move(initial_indirect_commands_layout)),
    _indirect_commands_token_count(
      std::move(initial_indirect_commands_token_count)),
    _indirect_commands_tokens(std::move(initial_indirect_commands_tokens)),
    _max_sequences_count(std::move(initial_max_sequences_count)),
    _target_command_buffer(std::move(initial_target_command_buffer)),
    _sequences_count_buffer(std::move(initial_sequences_count_buffer)),
    _sequences_count_offset(std::move(initial_sequences_count_offset)),
    _sequences_index_buffer(std::move(initial_sequences_index_buffer)),
    _sequences_index_offset(std::move(initial_sequences_index_offset))
  {
  }

  /// Copy constructor.
  constexpr cmd_process_commands_info_nvx(
    const cmd_process_commands_info_nvx& other) noexcept
  : _next(other._next),
    _object_table(other._object_table),
    _indirect_commands_layout(other._indirect_commands_layout),
    _indirect_commands_token_count(other._indirect_commands_token_count),
    _indirect_commands_tokens(other._indirect_commands_tokens),
    _max_sequences_count(other._max_sequences_count),
    _target_command_buffer(other._target_command_buffer),
    _sequences_count_buffer(other._sequences_count_buffer),
    _sequences_count_offset(other._sequences_count_offset),
    _sequences_index_buffer(other._sequences_index_buffer),
    _sequences_index_offset(other._sequences_index_offset)
  {
  }

  /// Move constructor.
  constexpr cmd_process_commands_info_nvx(
    cmd_process_commands_info_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _object_table(std::move(other._object_table)),
    _indirect_commands_layout(std::move(other._indirect_commands_layout)),
    _indirect_commands_token_count(
      std::move(other._indirect_commands_token_count)),
    _indirect_commands_tokens(std::move(other._indirect_commands_tokens)),
    _max_sequences_count(std::move(other._max_sequences_count)),
    _target_command_buffer(std::move(other._target_command_buffer)),
    _sequences_count_buffer(std::move(other._sequences_count_buffer)),
    _sequences_count_offset(std::move(other._sequences_count_offset)),
    _sequences_index_buffer(std::move(other._sequences_index_buffer)),
    _sequences_index_offset(std::move(other._sequences_index_offset))
  {
  }

  /// Copy assignment operator.
  constexpr cmd_process_commands_info_nvx& operator=(
    const cmd_process_commands_info_nvx& other) noexcept
  {
    _next = other._next;
    _object_table = other._object_table;
    _indirect_commands_layout = other._indirect_commands_layout;
    _indirect_commands_token_count = other._indirect_commands_token_count;
    _indirect_commands_tokens = other._indirect_commands_tokens;
    _max_sequences_count = other._max_sequences_count;
    _target_command_buffer = other._target_command_buffer;
    _sequences_count_buffer = other._sequences_count_buffer;
    _sequences_count_offset = other._sequences_count_offset;
    _sequences_index_buffer = other._sequences_index_buffer;
    _sequences_index_offset = other._sequences_index_offset;
    return *this;
  }

  /// Move assignment operator.
  constexpr cmd_process_commands_info_nvx& operator=(
    cmd_process_commands_info_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _object_table = std::move(other._object_table);
    _indirect_commands_layout = std::move(other._indirect_commands_layout);
    _indirect_commands_token_count =
      std::move(other._indirect_commands_token_count);
    _indirect_commands_tokens = std::move(other._indirect_commands_tokens);
    _max_sequences_count = std::move(other._max_sequences_count);
    _target_command_buffer = std::move(other._target_command_buffer);
    _sequences_count_buffer = std::move(other._sequences_count_buffer);
    _sequences_count_offset = std::move(other._sequences_count_offset);
    _sequences_index_buffer = std::move(other._sequences_index_buffer);
    _sequences_index_offset = std::move(other._sequences_index_offset);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkCmdProcessCommandsInfoNVX&() const
  {
    return *reinterpret_cast<const VkCmdProcessCommandsInfoNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkObjectTableNVX& object_table()
  {
    return _object_table;
  }

  constexpr const VkObjectTableNVX& object_table() const
  {
    return _object_table;
  }

  void object_table(VkObjectTableNVX new_object_table)
  {
    _object_table = new_object_table;
  }

  VkIndirectCommandsLayoutNVX& indirect_commands_layout()
  {
    return _indirect_commands_layout;
  }

  constexpr const VkIndirectCommandsLayoutNVX& indirect_commands_layout() const
  {
    return _indirect_commands_layout;
  }

  void indirect_commands_layout(
    VkIndirectCommandsLayoutNVX new_indirect_commands_layout)
  {
    _indirect_commands_layout = new_indirect_commands_layout;
  }

  uint32_t& indirect_commands_token_count()
  {
    return _indirect_commands_token_count;
  }

  constexpr const uint32_t& indirect_commands_token_count() const
  {
    return _indirect_commands_token_count;
  }

  void indirect_commands_token_count(uint32_t new_indirect_commands_token_count)
  {
    _indirect_commands_token_count = new_indirect_commands_token_count;
  }

  const vk::indirect_commands_token_nvx* indirect_commands_tokens()
  {
    return _indirect_commands_tokens;
  }

  constexpr const vk::indirect_commands_token_nvx* indirect_commands_tokens()
    const
  {
    return _indirect_commands_tokens;
  }

  void indirect_commands_tokens(
    const vk::indirect_commands_token_nvx* new_indirect_commands_tokens)
  {
    _indirect_commands_tokens = new_indirect_commands_tokens;
  }

  template <std::size_t Count>
  void indirect_commands_tokens(
    const std::array<vk::indirect_commands_token_nvx, Count>&
      new_indirect_commands_tokens)
  {
    _indirect_commands_token_count =
      static_cast<uint32_t>(new_indirect_commands_tokens.size());
    _indirect_commands_tokens = new_indirect_commands_tokens.data();
  }

  void indirect_commands_tokens(
    const std::vector<vk::indirect_commands_token_nvx>&
      new_indirect_commands_tokens)
  {
    _indirect_commands_token_count =
      static_cast<uint32_t>(new_indirect_commands_tokens.size());
    _indirect_commands_tokens = new_indirect_commands_tokens.data();
  }

  uint32_t& max_sequences_count()
  {
    return _max_sequences_count;
  }

  constexpr const uint32_t& max_sequences_count() const
  {
    return _max_sequences_count;
  }

  void max_sequences_count(uint32_t new_max_sequences_count)
  {
    _max_sequences_count = new_max_sequences_count;
  }

  VkCommandBuffer& target_command_buffer()
  {
    return _target_command_buffer;
  }

  constexpr const VkCommandBuffer& target_command_buffer() const
  {
    return _target_command_buffer;
  }

  void target_command_buffer(VkCommandBuffer new_target_command_buffer)
  {
    _target_command_buffer = new_target_command_buffer;
  }

  VkBuffer& sequences_count_buffer()
  {
    return _sequences_count_buffer;
  }

  constexpr const VkBuffer& sequences_count_buffer() const
  {
    return _sequences_count_buffer;
  }

  void sequences_count_buffer(VkBuffer new_sequences_count_buffer)
  {
    _sequences_count_buffer = new_sequences_count_buffer;
  }

  VkDeviceSize& sequences_count_offset()
  {
    return _sequences_count_offset;
  }

  constexpr const VkDeviceSize& sequences_count_offset() const
  {
    return _sequences_count_offset;
  }

  void sequences_count_offset(VkDeviceSize new_sequences_count_offset)
  {
    _sequences_count_offset = new_sequences_count_offset;
  }

  VkBuffer& sequences_index_buffer()
  {
    return _sequences_index_buffer;
  }

  constexpr const VkBuffer& sequences_index_buffer() const
  {
    return _sequences_index_buffer;
  }

  void sequences_index_buffer(VkBuffer new_sequences_index_buffer)
  {
    _sequences_index_buffer = new_sequences_index_buffer;
  }

  VkDeviceSize& sequences_index_offset()
  {
    return _sequences_index_offset;
  }

  constexpr const VkDeviceSize& sequences_index_offset() const
  {
    return _sequences_index_offset;
  }

  void sequences_index_offset(VkDeviceSize new_sequences_index_offset)
  {
    _sequences_index_offset = new_sequences_index_offset;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::cmd_process_commands_info_nvx;
  const void* _next = nullptr;
  VkObjectTableNVX _object_table = nullptr;
  VkIndirectCommandsLayoutNVX _indirect_commands_layout = nullptr;
  uint32_t _indirect_commands_token_count = 0;
  const vk::indirect_commands_token_nvx* _indirect_commands_tokens = nullptr;
  uint32_t _max_sequences_count = 0;
  VkCommandBuffer _target_command_buffer = nullptr;
  VkBuffer _sequences_count_buffer = nullptr;
  VkDeviceSize _sequences_count_offset = 0;
  VkBuffer _sequences_index_buffer = nullptr;
  VkDeviceSize _sequences_index_offset = 0;
};
static_assert(sizeof(cmd_process_commands_info_nvx) ==
                sizeof(::VkCmdProcessCommandsInfoNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkCmdReserveSpaceForCommandsInfoNVX.
class cmd_reserve_space_for_commands_info_nvx
{
public:
  /// Default constructor.
  constexpr cmd_reserve_space_for_commands_info_nvx() = default;

  /// Constructor.
  constexpr cmd_reserve_space_for_commands_info_nvx(
    const void* initial_next, VkObjectTableNVX initial_object_table,
    VkIndirectCommandsLayoutNVX initial_indirect_commands_layout,
    uint32_t initial_max_sequences_count) noexcept
  : _next(std::move(initial_next)),
    _object_table(std::move(initial_object_table)),
    _indirect_commands_layout(std::move(initial_indirect_commands_layout)),
    _max_sequences_count(std::move(initial_max_sequences_count))
  {
  }

  /// Copy constructor.
  constexpr cmd_reserve_space_for_commands_info_nvx(
    const cmd_reserve_space_for_commands_info_nvx& other) noexcept
  : _next(other._next),
    _object_table(other._object_table),
    _indirect_commands_layout(other._indirect_commands_layout),
    _max_sequences_count(other._max_sequences_count)
  {
  }

  /// Move constructor.
  constexpr cmd_reserve_space_for_commands_info_nvx(
    cmd_reserve_space_for_commands_info_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _object_table(std::move(other._object_table)),
    _indirect_commands_layout(std::move(other._indirect_commands_layout)),
    _max_sequences_count(std::move(other._max_sequences_count))
  {
  }

  /// Copy assignment operator.
  constexpr cmd_reserve_space_for_commands_info_nvx& operator=(
    const cmd_reserve_space_for_commands_info_nvx& other) noexcept
  {
    _next = other._next;
    _object_table = other._object_table;
    _indirect_commands_layout = other._indirect_commands_layout;
    _max_sequences_count = other._max_sequences_count;
    return *this;
  }

  /// Move assignment operator.
  constexpr cmd_reserve_space_for_commands_info_nvx& operator=(
    cmd_reserve_space_for_commands_info_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _object_table = std::move(other._object_table);
    _indirect_commands_layout = std::move(other._indirect_commands_layout);
    _max_sequences_count = std::move(other._max_sequences_count);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkCmdReserveSpaceForCommandsInfoNVX&() const
  {
    return *reinterpret_cast<const VkCmdReserveSpaceForCommandsInfoNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkObjectTableNVX& object_table()
  {
    return _object_table;
  }

  constexpr const VkObjectTableNVX& object_table() const
  {
    return _object_table;
  }

  void object_table(VkObjectTableNVX new_object_table)
  {
    _object_table = new_object_table;
  }

  VkIndirectCommandsLayoutNVX& indirect_commands_layout()
  {
    return _indirect_commands_layout;
  }

  constexpr const VkIndirectCommandsLayoutNVX& indirect_commands_layout() const
  {
    return _indirect_commands_layout;
  }

  void indirect_commands_layout(
    VkIndirectCommandsLayoutNVX new_indirect_commands_layout)
  {
    _indirect_commands_layout = new_indirect_commands_layout;
  }

  uint32_t& max_sequences_count()
  {
    return _max_sequences_count;
  }

  constexpr const uint32_t& max_sequences_count() const
  {
    return _max_sequences_count;
  }

  void max_sequences_count(uint32_t new_max_sequences_count)
  {
    _max_sequences_count = new_max_sequences_count;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::cmd_reserve_space_for_commands_info_nvx;
  const void* _next = nullptr;
  VkObjectTableNVX _object_table = nullptr;
  VkIndirectCommandsLayoutNVX _indirect_commands_layout = nullptr;
  uint32_t _max_sequences_count = 0;
};
static_assert(sizeof(cmd_reserve_space_for_commands_info_nvx) ==
                sizeof(::VkCmdReserveSpaceForCommandsInfoNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkObjectTableCreateInfoNVX.
class object_table_create_info_nvx
{
public:
  /// Default constructor.
  constexpr object_table_create_info_nvx() = default;

  /// Constructor.
  constexpr object_table_create_info_nvx(
    const void* initial_next, uint32_t initial_object_count,
    const vk::object_entry_type_nvx* initial_object_entry_types,
    const uint32_t* initial_object_entry_counts,
    const vk::object_entry_usage_flags_nvx* initial_object_entry_usage_flags,
    uint32_t initial_max_uniform_buffers_per_descriptor,
    uint32_t initial_max_storage_buffers_per_descriptor,
    uint32_t initial_max_storage_images_per_descriptor,
    uint32_t initial_max_sampled_images_per_descriptor,
    uint32_t initial_max_pipeline_layouts) noexcept
  : _next(std::move(initial_next)),
    _object_count(std::move(initial_object_count)),
    _object_entry_types(std::move(initial_object_entry_types)),
    _object_entry_counts(std::move(initial_object_entry_counts)),
    _object_entry_usage_flags(std::move(initial_object_entry_usage_flags)),
    _max_uniform_buffers_per_descriptor(
      std::move(initial_max_uniform_buffers_per_descriptor)),
    _max_storage_buffers_per_descriptor(
      std::move(initial_max_storage_buffers_per_descriptor)),
    _max_storage_images_per_descriptor(
      std::move(initial_max_storage_images_per_descriptor)),
    _max_sampled_images_per_descriptor(
      std::move(initial_max_sampled_images_per_descriptor)),
    _max_pipeline_layouts(std::move(initial_max_pipeline_layouts))
  {
  }

  /// Copy constructor.
  constexpr object_table_create_info_nvx(
    const object_table_create_info_nvx& other) noexcept
  : _next(other._next),
    _object_count(other._object_count),
    _object_entry_types(other._object_entry_types),
    _object_entry_counts(other._object_entry_counts),
    _object_entry_usage_flags(other._object_entry_usage_flags),
    _max_uniform_buffers_per_descriptor(
      other._max_uniform_buffers_per_descriptor),
    _max_storage_buffers_per_descriptor(
      other._max_storage_buffers_per_descriptor),
    _max_storage_images_per_descriptor(
      other._max_storage_images_per_descriptor),
    _max_sampled_images_per_descriptor(
      other._max_sampled_images_per_descriptor),
    _max_pipeline_layouts(other._max_pipeline_layouts)
  {
  }

  /// Move constructor.
  constexpr object_table_create_info_nvx(
    object_table_create_info_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _object_count(std::move(other._object_count)),
    _object_entry_types(std::move(other._object_entry_types)),
    _object_entry_counts(std::move(other._object_entry_counts)),
    _object_entry_usage_flags(std::move(other._object_entry_usage_flags)),
    _max_uniform_buffers_per_descriptor(
      std::move(other._max_uniform_buffers_per_descriptor)),
    _max_storage_buffers_per_descriptor(
      std::move(other._max_storage_buffers_per_descriptor)),
    _max_storage_images_per_descriptor(
      std::move(other._max_storage_images_per_descriptor)),
    _max_sampled_images_per_descriptor(
      std::move(other._max_sampled_images_per_descriptor)),
    _max_pipeline_layouts(std::move(other._max_pipeline_layouts))
  {
  }

  /// Copy assignment operator.
  constexpr object_table_create_info_nvx& operator=(
    const object_table_create_info_nvx& other) noexcept
  {
    _next = other._next;
    _object_count = other._object_count;
    _object_entry_types = other._object_entry_types;
    _object_entry_counts = other._object_entry_counts;
    _object_entry_usage_flags = other._object_entry_usage_flags;
    _max_uniform_buffers_per_descriptor =
      other._max_uniform_buffers_per_descriptor;
    _max_storage_buffers_per_descriptor =
      other._max_storage_buffers_per_descriptor;
    _max_storage_images_per_descriptor =
      other._max_storage_images_per_descriptor;
    _max_sampled_images_per_descriptor =
      other._max_sampled_images_per_descriptor;
    _max_pipeline_layouts = other._max_pipeline_layouts;
    return *this;
  }

  /// Move assignment operator.
  constexpr object_table_create_info_nvx& operator=(
    object_table_create_info_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _object_count = std::move(other._object_count);
    _object_entry_types = std::move(other._object_entry_types);
    _object_entry_counts = std::move(other._object_entry_counts);
    _object_entry_usage_flags = std::move(other._object_entry_usage_flags);
    _max_uniform_buffers_per_descriptor =
      std::move(other._max_uniform_buffers_per_descriptor);
    _max_storage_buffers_per_descriptor =
      std::move(other._max_storage_buffers_per_descriptor);
    _max_storage_images_per_descriptor =
      std::move(other._max_storage_images_per_descriptor);
    _max_sampled_images_per_descriptor =
      std::move(other._max_sampled_images_per_descriptor);
    _max_pipeline_layouts = std::move(other._max_pipeline_layouts);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkObjectTableCreateInfoNVX&() const
  {
    return *reinterpret_cast<const VkObjectTableCreateInfoNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& object_count()
  {
    return _object_count;
  }

  constexpr const uint32_t& object_count() const
  {
    return _object_count;
  }

  void object_count(uint32_t new_object_count)
  {
    _object_count = new_object_count;
  }

  const vk::object_entry_type_nvx* object_entry_types()
  {
    return _object_entry_types;
  }

  constexpr const vk::object_entry_type_nvx* object_entry_types() const
  {
    return _object_entry_types;
  }

  void object_entry_types(
    const vk::object_entry_type_nvx* new_object_entry_types)
  {
    _object_entry_types = new_object_entry_types;
  }

  template <std::size_t Count>
  void object_entry_types(
    const std::array<vk::object_entry_type_nvx, Count>& new_object_entry_types)
  {
    _object_count = static_cast<uint32_t>(new_object_entry_types.size());
    _object_entry_types = new_object_entry_types.data();
  }

  void object_entry_types(
    const std::vector<vk::object_entry_type_nvx>& new_object_entry_types)
  {
    _object_count = static_cast<uint32_t>(new_object_entry_types.size());
    _object_entry_types = new_object_entry_types.data();
  }

  const uint32_t* object_entry_counts()
  {
    return _object_entry_counts;
  }

  constexpr const uint32_t* object_entry_counts() const
  {
    return _object_entry_counts;
  }

  void object_entry_counts(const uint32_t* new_object_entry_counts)
  {
    _object_entry_counts = new_object_entry_counts;
  }

  template <std::size_t Count>
  void object_entry_counts(
    const std::array<uint32_t, Count>& new_object_entry_counts)
  {
    _object_count = static_cast<uint32_t>(new_object_entry_counts.size());
    _object_entry_counts = new_object_entry_counts.data();
  }

  void object_entry_counts(const std::vector<uint32_t>& new_object_entry_counts)
  {
    _object_count = static_cast<uint32_t>(new_object_entry_counts.size());
    _object_entry_counts = new_object_entry_counts.data();
  }

  const vk::object_entry_usage_flags_nvx* object_entry_usage_flags()
  {
    return _object_entry_usage_flags;
  }

  constexpr const vk::object_entry_usage_flags_nvx* object_entry_usage_flags()
    const
  {
    return _object_entry_usage_flags;
  }

  void object_entry_usage_flags(
    const vk::object_entry_usage_flags_nvx* new_object_entry_usage_flags)
  {
    _object_entry_usage_flags = new_object_entry_usage_flags;
  }

  template <std::size_t Count>
  void object_entry_usage_flags(
    const std::array<vk::object_entry_usage_flags_nvx, Count>&
      new_object_entry_usage_flags)
  {
    _object_count = static_cast<uint32_t>(new_object_entry_usage_flags.size());
    _object_entry_usage_flags = new_object_entry_usage_flags.data();
  }

  void object_entry_usage_flags(
    const std::vector<vk::object_entry_usage_flags_nvx>&
      new_object_entry_usage_flags)
  {
    _object_count = static_cast<uint32_t>(new_object_entry_usage_flags.size());
    _object_entry_usage_flags = new_object_entry_usage_flags.data();
  }

  uint32_t& max_uniform_buffers_per_descriptor()
  {
    return _max_uniform_buffers_per_descriptor;
  }

  constexpr const uint32_t& max_uniform_buffers_per_descriptor() const
  {
    return _max_uniform_buffers_per_descriptor;
  }

  void max_uniform_buffers_per_descriptor(
    uint32_t new_max_uniform_buffers_per_descriptor)
  {
    _max_uniform_buffers_per_descriptor =
      new_max_uniform_buffers_per_descriptor;
  }

  uint32_t& max_storage_buffers_per_descriptor()
  {
    return _max_storage_buffers_per_descriptor;
  }

  constexpr const uint32_t& max_storage_buffers_per_descriptor() const
  {
    return _max_storage_buffers_per_descriptor;
  }

  void max_storage_buffers_per_descriptor(
    uint32_t new_max_storage_buffers_per_descriptor)
  {
    _max_storage_buffers_per_descriptor =
      new_max_storage_buffers_per_descriptor;
  }

  uint32_t& max_storage_images_per_descriptor()
  {
    return _max_storage_images_per_descriptor;
  }

  constexpr const uint32_t& max_storage_images_per_descriptor() const
  {
    return _max_storage_images_per_descriptor;
  }

  void max_storage_images_per_descriptor(
    uint32_t new_max_storage_images_per_descriptor)
  {
    _max_storage_images_per_descriptor = new_max_storage_images_per_descriptor;
  }

  uint32_t& max_sampled_images_per_descriptor()
  {
    return _max_sampled_images_per_descriptor;
  }

  constexpr const uint32_t& max_sampled_images_per_descriptor() const
  {
    return _max_sampled_images_per_descriptor;
  }

  void max_sampled_images_per_descriptor(
    uint32_t new_max_sampled_images_per_descriptor)
  {
    _max_sampled_images_per_descriptor = new_max_sampled_images_per_descriptor;
  }

  uint32_t& max_pipeline_layouts()
  {
    return _max_pipeline_layouts;
  }

  constexpr const uint32_t& max_pipeline_layouts() const
  {
    return _max_pipeline_layouts;
  }

  void max_pipeline_layouts(uint32_t new_max_pipeline_layouts)
  {
    _max_pipeline_layouts = new_max_pipeline_layouts;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::object_table_create_info_nvx;
  const void* _next = nullptr;
  uint32_t _object_count = 0;
  const vk::object_entry_type_nvx* _object_entry_types = nullptr;
  const uint32_t* _object_entry_counts = nullptr;
  const vk::object_entry_usage_flags_nvx* _object_entry_usage_flags = nullptr;
  uint32_t _max_uniform_buffers_per_descriptor = 0;
  uint32_t _max_storage_buffers_per_descriptor = 0;
  uint32_t _max_storage_images_per_descriptor = 0;
  uint32_t _max_sampled_images_per_descriptor = 0;
  uint32_t _max_pipeline_layouts = 0;
};
static_assert(sizeof(object_table_create_info_nvx) ==
                sizeof(::VkObjectTableCreateInfoNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkObjectTableEntryNVX.
class object_table_entry_nvx
{
public:
  /// Default constructor.
  constexpr object_table_entry_nvx() = default;

  /// Constructor.
  constexpr object_table_entry_nvx(
    vk::object_entry_type_nvx initial_type,
    vk::object_entry_usage_flags_nvx initial_flags) noexcept
  : _type(std::move(initial_type)), _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr object_table_entry_nvx(const object_table_entry_nvx& other) =
    default;

  /// Move constructor.
  constexpr object_table_entry_nvx(object_table_entry_nvx&& other) = default;

  /// Copy assignment operator.
  constexpr object_table_entry_nvx& operator=(
    const object_table_entry_nvx& other) = default;

  /// Move assignment operator.
  constexpr object_table_entry_nvx& operator=(object_table_entry_nvx&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkObjectTableEntryNVX&() const
  {
    return *reinterpret_cast<const VkObjectTableEntryNVX*>(this);
  }

  vk::object_entry_type_nvx& type()
  {
    return _type;
  }

  constexpr const vk::object_entry_type_nvx& type() const
  {
    return _type;
  }

  void type(vk::object_entry_type_nvx new_type)
  {
    _type = new_type;
  }

  vk::object_entry_usage_flags_nvx& flags()
  {
    return _flags;
  }

  constexpr const vk::object_entry_usage_flags_nvx& flags() const
  {
    return _flags;
  }

  void flags(vk::object_entry_usage_flags_nvx new_flags)
  {
    _flags = new_flags;
  }

private:
  vk::object_entry_type_nvx _type =
    vk::object_entry_type_nvx::object_entry_type_descriptor_set_nvx;
  vk::object_entry_usage_flags_nvx _flags =
    vk::object_entry_usage_flag_nvx::none;
};
static_assert(sizeof(object_table_entry_nvx) == sizeof(::VkObjectTableEntryNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkObjectTablePipelineEntryNVX.
class object_table_pipeline_entry_nvx
{
public:
  /// Default constructor.
  constexpr object_table_pipeline_entry_nvx() = default;

  /// Constructor.
  constexpr object_table_pipeline_entry_nvx(
    vk::object_entry_type_nvx initial_type,
    vk::object_entry_usage_flags_nvx initial_flags,
    VkPipeline initial_pipeline) noexcept
  : _type(std::move(initial_type)),
    _flags(std::move(initial_flags)),
    _pipeline(std::move(initial_pipeline))
  {
  }

  /// Copy constructor.
  constexpr object_table_pipeline_entry_nvx(
    const object_table_pipeline_entry_nvx& other) = default;

  /// Move constructor.
  constexpr object_table_pipeline_entry_nvx(
    object_table_pipeline_entry_nvx&& other) = default;

  /// Copy assignment operator.
  constexpr object_table_pipeline_entry_nvx& operator=(
    const object_table_pipeline_entry_nvx& other) = default;

  /// Move assignment operator.
  constexpr object_table_pipeline_entry_nvx& operator=(
    object_table_pipeline_entry_nvx&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkObjectTablePipelineEntryNVX&() const
  {
    return *reinterpret_cast<const VkObjectTablePipelineEntryNVX*>(this);
  }

  vk::object_entry_type_nvx& type()
  {
    return _type;
  }

  constexpr const vk::object_entry_type_nvx& type() const
  {
    return _type;
  }

  void type(vk::object_entry_type_nvx new_type)
  {
    _type = new_type;
  }

  vk::object_entry_usage_flags_nvx& flags()
  {
    return _flags;
  }

  constexpr const vk::object_entry_usage_flags_nvx& flags() const
  {
    return _flags;
  }

  void flags(vk::object_entry_usage_flags_nvx new_flags)
  {
    _flags = new_flags;
  }

  VkPipeline& pipeline()
  {
    return _pipeline;
  }

  constexpr const VkPipeline& pipeline() const
  {
    return _pipeline;
  }

  void pipeline(VkPipeline new_pipeline)
  {
    _pipeline = new_pipeline;
  }

private:
  vk::object_entry_type_nvx _type =
    vk::object_entry_type_nvx::object_entry_type_descriptor_set_nvx;
  vk::object_entry_usage_flags_nvx _flags =
    vk::object_entry_usage_flag_nvx::none;
  VkPipeline _pipeline = nullptr;
};
static_assert(sizeof(object_table_pipeline_entry_nvx) ==
                sizeof(::VkObjectTablePipelineEntryNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkObjectTableDescriptorSetEntryNVX.
class object_table_descriptor_set_entry_nvx
{
public:
  /// Default constructor.
  constexpr object_table_descriptor_set_entry_nvx() = default;

  /// Constructor.
  constexpr object_table_descriptor_set_entry_nvx(
    vk::object_entry_type_nvx initial_type,
    vk::object_entry_usage_flags_nvx initial_flags,
    VkPipelineLayout initial_pipeline_layout,
    VkDescriptorSet initial_descriptor_set) noexcept
  : _type(std::move(initial_type)),
    _flags(std::move(initial_flags)),
    _pipeline_layout(std::move(initial_pipeline_layout)),
    _descriptor_set(std::move(initial_descriptor_set))
  {
  }

  /// Copy constructor.
  constexpr object_table_descriptor_set_entry_nvx(
    const object_table_descriptor_set_entry_nvx& other) = default;

  /// Move constructor.
  constexpr object_table_descriptor_set_entry_nvx(
    object_table_descriptor_set_entry_nvx&& other) = default;

  /// Copy assignment operator.
  constexpr object_table_descriptor_set_entry_nvx& operator=(
    const object_table_descriptor_set_entry_nvx& other) = default;

  /// Move assignment operator.
  constexpr object_table_descriptor_set_entry_nvx& operator=(
    object_table_descriptor_set_entry_nvx&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkObjectTableDescriptorSetEntryNVX&() const
  {
    return *reinterpret_cast<const VkObjectTableDescriptorSetEntryNVX*>(this);
  }

  vk::object_entry_type_nvx& type()
  {
    return _type;
  }

  constexpr const vk::object_entry_type_nvx& type() const
  {
    return _type;
  }

  void type(vk::object_entry_type_nvx new_type)
  {
    _type = new_type;
  }

  vk::object_entry_usage_flags_nvx& flags()
  {
    return _flags;
  }

  constexpr const vk::object_entry_usage_flags_nvx& flags() const
  {
    return _flags;
  }

  void flags(vk::object_entry_usage_flags_nvx new_flags)
  {
    _flags = new_flags;
  }

  VkPipelineLayout& pipeline_layout()
  {
    return _pipeline_layout;
  }

  constexpr const VkPipelineLayout& pipeline_layout() const
  {
    return _pipeline_layout;
  }

  void pipeline_layout(VkPipelineLayout new_pipeline_layout)
  {
    _pipeline_layout = new_pipeline_layout;
  }

  VkDescriptorSet& descriptor_set()
  {
    return _descriptor_set;
  }

  constexpr const VkDescriptorSet& descriptor_set() const
  {
    return _descriptor_set;
  }

  void descriptor_set(VkDescriptorSet new_descriptor_set)
  {
    _descriptor_set = new_descriptor_set;
  }

private:
  vk::object_entry_type_nvx _type =
    vk::object_entry_type_nvx::object_entry_type_descriptor_set_nvx;
  vk::object_entry_usage_flags_nvx _flags =
    vk::object_entry_usage_flag_nvx::none;
  VkPipelineLayout _pipeline_layout = nullptr;
  VkDescriptorSet _descriptor_set = nullptr;
};
static_assert(sizeof(object_table_descriptor_set_entry_nvx) ==
                sizeof(::VkObjectTableDescriptorSetEntryNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkObjectTableVertexBufferEntryNVX.
class object_table_vertex_buffer_entry_nvx
{
public:
  /// Default constructor.
  constexpr object_table_vertex_buffer_entry_nvx() = default;

  /// Constructor.
  constexpr object_table_vertex_buffer_entry_nvx(
    vk::object_entry_type_nvx initial_type,
    vk::object_entry_usage_flags_nvx initial_flags,
    VkBuffer initial_buffer) noexcept
  : _type(std::move(initial_type)),
    _flags(std::move(initial_flags)),
    _buffer(std::move(initial_buffer))
  {
  }

  /// Copy constructor.
  constexpr object_table_vertex_buffer_entry_nvx(
    const object_table_vertex_buffer_entry_nvx& other) = default;

  /// Move constructor.
  constexpr object_table_vertex_buffer_entry_nvx(
    object_table_vertex_buffer_entry_nvx&& other) = default;

  /// Copy assignment operator.
  constexpr object_table_vertex_buffer_entry_nvx& operator=(
    const object_table_vertex_buffer_entry_nvx& other) = default;

  /// Move assignment operator.
  constexpr object_table_vertex_buffer_entry_nvx& operator=(
    object_table_vertex_buffer_entry_nvx&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkObjectTableVertexBufferEntryNVX&() const
  {
    return *reinterpret_cast<const VkObjectTableVertexBufferEntryNVX*>(this);
  }

  vk::object_entry_type_nvx& type()
  {
    return _type;
  }

  constexpr const vk::object_entry_type_nvx& type() const
  {
    return _type;
  }

  void type(vk::object_entry_type_nvx new_type)
  {
    _type = new_type;
  }

  vk::object_entry_usage_flags_nvx& flags()
  {
    return _flags;
  }

  constexpr const vk::object_entry_usage_flags_nvx& flags() const
  {
    return _flags;
  }

  void flags(vk::object_entry_usage_flags_nvx new_flags)
  {
    _flags = new_flags;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

private:
  vk::object_entry_type_nvx _type =
    vk::object_entry_type_nvx::object_entry_type_descriptor_set_nvx;
  vk::object_entry_usage_flags_nvx _flags =
    vk::object_entry_usage_flag_nvx::none;
  VkBuffer _buffer = nullptr;
};
static_assert(sizeof(object_table_vertex_buffer_entry_nvx) ==
                sizeof(::VkObjectTableVertexBufferEntryNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkObjectTableIndexBufferEntryNVX.
class object_table_index_buffer_entry_nvx
{
public:
  /// Default constructor.
  constexpr object_table_index_buffer_entry_nvx() = default;

  /// Constructor.
  constexpr object_table_index_buffer_entry_nvx(
    vk::object_entry_type_nvx initial_type,
    vk::object_entry_usage_flags_nvx initial_flags, VkBuffer initial_buffer,
    vk::index_type initial_index_type) noexcept
  : _type(std::move(initial_type)),
    _flags(std::move(initial_flags)),
    _buffer(std::move(initial_buffer)),
    _index_type(std::move(initial_index_type))
  {
  }

  /// Copy constructor.
  constexpr object_table_index_buffer_entry_nvx(
    const object_table_index_buffer_entry_nvx& other) = default;

  /// Move constructor.
  constexpr object_table_index_buffer_entry_nvx(
    object_table_index_buffer_entry_nvx&& other) = default;

  /// Copy assignment operator.
  constexpr object_table_index_buffer_entry_nvx& operator=(
    const object_table_index_buffer_entry_nvx& other) = default;

  /// Move assignment operator.
  constexpr object_table_index_buffer_entry_nvx& operator=(
    object_table_index_buffer_entry_nvx&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkObjectTableIndexBufferEntryNVX&() const
  {
    return *reinterpret_cast<const VkObjectTableIndexBufferEntryNVX*>(this);
  }

  vk::object_entry_type_nvx& type()
  {
    return _type;
  }

  constexpr const vk::object_entry_type_nvx& type() const
  {
    return _type;
  }

  void type(vk::object_entry_type_nvx new_type)
  {
    _type = new_type;
  }

  vk::object_entry_usage_flags_nvx& flags()
  {
    return _flags;
  }

  constexpr const vk::object_entry_usage_flags_nvx& flags() const
  {
    return _flags;
  }

  void flags(vk::object_entry_usage_flags_nvx new_flags)
  {
    _flags = new_flags;
  }

  VkBuffer& buffer()
  {
    return _buffer;
  }

  constexpr const VkBuffer& buffer() const
  {
    return _buffer;
  }

  void buffer(VkBuffer new_buffer)
  {
    _buffer = new_buffer;
  }

  vk::index_type& index_type()
  {
    return _index_type;
  }

  constexpr const vk::index_type& index_type() const
  {
    return _index_type;
  }

  void index_type(vk::index_type new_index_type)
  {
    _index_type = new_index_type;
  }

private:
  vk::object_entry_type_nvx _type =
    vk::object_entry_type_nvx::object_entry_type_descriptor_set_nvx;
  vk::object_entry_usage_flags_nvx _flags =
    vk::object_entry_usage_flag_nvx::none;
  VkBuffer _buffer = nullptr;
  vk::index_type _index_type = vk::index_type::uint16;
};
static_assert(sizeof(object_table_index_buffer_entry_nvx) ==
                sizeof(::VkObjectTableIndexBufferEntryNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkObjectTablePushConstantEntryNVX.
class object_table_push_constant_entry_nvx
{
public:
  /// Default constructor.
  constexpr object_table_push_constant_entry_nvx() = default;

  /// Constructor.
  constexpr object_table_push_constant_entry_nvx(
    vk::object_entry_type_nvx initial_type,
    vk::object_entry_usage_flags_nvx initial_flags,
    VkPipelineLayout initial_pipeline_layout,
    vk::shader_stage_flags initial_stage_flags) noexcept
  : _type(std::move(initial_type)),
    _flags(std::move(initial_flags)),
    _pipeline_layout(std::move(initial_pipeline_layout)),
    _stage_flags(std::move(initial_stage_flags))
  {
  }

  /// Copy constructor.
  constexpr object_table_push_constant_entry_nvx(
    const object_table_push_constant_entry_nvx& other) = default;

  /// Move constructor.
  constexpr object_table_push_constant_entry_nvx(
    object_table_push_constant_entry_nvx&& other) = default;

  /// Copy assignment operator.
  constexpr object_table_push_constant_entry_nvx& operator=(
    const object_table_push_constant_entry_nvx& other) = default;

  /// Move assignment operator.
  constexpr object_table_push_constant_entry_nvx& operator=(
    object_table_push_constant_entry_nvx&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkObjectTablePushConstantEntryNVX&() const
  {
    return *reinterpret_cast<const VkObjectTablePushConstantEntryNVX*>(this);
  }

  vk::object_entry_type_nvx& type()
  {
    return _type;
  }

  constexpr const vk::object_entry_type_nvx& type() const
  {
    return _type;
  }

  void type(vk::object_entry_type_nvx new_type)
  {
    _type = new_type;
  }

  vk::object_entry_usage_flags_nvx& flags()
  {
    return _flags;
  }

  constexpr const vk::object_entry_usage_flags_nvx& flags() const
  {
    return _flags;
  }

  void flags(vk::object_entry_usage_flags_nvx new_flags)
  {
    _flags = new_flags;
  }

  VkPipelineLayout& pipeline_layout()
  {
    return _pipeline_layout;
  }

  constexpr const VkPipelineLayout& pipeline_layout() const
  {
    return _pipeline_layout;
  }

  void pipeline_layout(VkPipelineLayout new_pipeline_layout)
  {
    _pipeline_layout = new_pipeline_layout;
  }

  vk::shader_stage_flags& stage_flags()
  {
    return _stage_flags;
  }

  constexpr const vk::shader_stage_flags& stage_flags() const
  {
    return _stage_flags;
  }

  void stage_flags(vk::shader_stage_flags new_stage_flags)
  {
    _stage_flags = new_stage_flags;
  }

private:
  vk::object_entry_type_nvx _type =
    vk::object_entry_type_nvx::object_entry_type_descriptor_set_nvx;
  vk::object_entry_usage_flags_nvx _flags =
    vk::object_entry_usage_flag_nvx::none;
  VkPipelineLayout _pipeline_layout = nullptr;
  vk::shader_stage_flags _stage_flags = vk::shader_stage_flag::none;
};
static_assert(sizeof(object_table_push_constant_entry_nvx) ==
                sizeof(::VkObjectTablePushConstantEntryNVX),
              "struct and wrapper have different size!");

inline void cmd_process_commands_nvx(
  VkCommandBuffer command_buffer,
  const vk::cmd_process_commands_info_nvx* process_commands_info)
{
  vkCmdProcessCommandsNVX(static_cast<VkCommandBuffer>(command_buffer),
                          reinterpret_cast<const VkCmdProcessCommandsInfoNVX*>(
                            process_commands_info));
}
inline void cmd_reserve_space_for_commands_nvx(
  VkCommandBuffer command_buffer,
  const vk::cmd_reserve_space_for_commands_info_nvx* reserve_space_info)
{
  vkCmdReserveSpaceForCommandsNVX(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkCmdReserveSpaceForCommandsInfoNVX*>(
      reserve_space_info));
}
inline vk::result create_indirect_commands_layout_nvx(
  VkDevice device,
  const vk::indirect_commands_layout_create_info_nvx* create_info,
  const vk::allocation_callbacks* allocator,
  VkIndirectCommandsLayoutNVX* indirect_commands_layout)
{
  return static_cast<vk::result>(vkCreateIndirectCommandsLayoutNVX(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkIndirectCommandsLayoutCreateInfoNVX*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkIndirectCommandsLayoutNVX*>(indirect_commands_layout)));
}
inline void destroy_indirect_commands_layout_nvx(
  VkDevice device, VkIndirectCommandsLayoutNVX indirect_commands_layout,
  const vk::allocation_callbacks* allocator)
{
  vkDestroyIndirectCommandsLayoutNVX(
    static_cast<VkDevice>(device),
    static_cast<VkIndirectCommandsLayoutNVX>(indirect_commands_layout),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result create_object_table_nvx(
  VkDevice device, const vk::object_table_create_info_nvx* create_info,
  const vk::allocation_callbacks* allocator, VkObjectTableNVX* object_table)
{
  return static_cast<vk::result>(vkCreateObjectTableNVX(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkObjectTableCreateInfoNVX*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkObjectTableNVX*>(object_table)));
}
inline void destroy_object_table_nvx(VkDevice device,
                                     VkObjectTableNVX object_table,
                                     const vk::allocation_callbacks* allocator)
{
  vkDestroyObjectTableNVX(
    static_cast<VkDevice>(device), static_cast<VkObjectTableNVX>(object_table),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result register_objects_nvx(
  VkDevice device, VkObjectTableNVX object_table, uint32_t object_count,
  const vk::object_table_entry_nvx* const* object_table_entries,
  const uint32_t* object_indices)
{
  return static_cast<vk::result>(vkRegisterObjectsNVX(
    static_cast<VkDevice>(device), static_cast<VkObjectTableNVX>(object_table),
    static_cast<uint32_t>(object_count),
    reinterpret_cast<const VkObjectTableEntryNVX* const*>(object_table_entries),
    reinterpret_cast<const uint32_t*>(object_indices)));
}
inline vk::result unregister_objects_nvx(
  VkDevice device, VkObjectTableNVX object_table, uint32_t object_count,
  const vk::object_entry_type_nvx* object_entry_types,
  const uint32_t* object_indices)
{
  return static_cast<vk::result>(vkUnregisterObjectsNVX(
    static_cast<VkDevice>(device), static_cast<VkObjectTableNVX>(object_table),
    static_cast<uint32_t>(object_count),
    reinterpret_cast<const VkObjectEntryTypeNVX*>(object_entry_types),
    reinterpret_cast<const uint32_t*>(object_indices)));
}
inline void get_physical_device_generated_commands_properties_nvx(
  VkPhysicalDevice physical_device,
  vk::device_generated_commands_features_nvx* features,
  vk::device_generated_commands_limits_nvx* limits)
{
  vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<VkDeviceGeneratedCommandsFeaturesNVX*>(features),
    reinterpret_cast<VkDeviceGeneratedCommandsLimitsNVX*>(limits));
}

/// Enhanced replacement type for VkViewportWScalingNV.
class viewport_wscaling_nv
{
public:
  /// Default constructor.
  constexpr viewport_wscaling_nv() = default;

  /// Constructor.
  constexpr viewport_wscaling_nv(float initial_xcoeff,
                                 float initial_ycoeff) noexcept
  : _xcoeff(std::move(initial_xcoeff)), _ycoeff(std::move(initial_ycoeff))
  {
  }

  /// Copy constructor.
  constexpr viewport_wscaling_nv(const viewport_wscaling_nv& other) = default;

  /// Move constructor.
  constexpr viewport_wscaling_nv(viewport_wscaling_nv&& other) = default;

  /// Copy assignment operator.
  constexpr viewport_wscaling_nv& operator=(const viewport_wscaling_nv& other) =
    default;

  /// Move assignment operator.
  constexpr viewport_wscaling_nv& operator=(viewport_wscaling_nv&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkViewportWScalingNV&() const
  {
    return *reinterpret_cast<const VkViewportWScalingNV*>(this);
  }

  float& xcoeff()
  {
    return _xcoeff;
  }

  constexpr const float& xcoeff() const
  {
    return _xcoeff;
  }

  void xcoeff(float new_xcoeff)
  {
    _xcoeff = new_xcoeff;
  }

  float& ycoeff()
  {
    return _ycoeff;
  }

  constexpr const float& ycoeff() const
  {
    return _ycoeff;
  }

  void ycoeff(float new_ycoeff)
  {
    _ycoeff = new_ycoeff;
  }

private:
  float _xcoeff = 0.0f;
  float _ycoeff = 0.0f;
};
static_assert(sizeof(viewport_wscaling_nv) == sizeof(::VkViewportWScalingNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPipelineViewportWScalingStateCreateInfoNV.
class pipeline_viewport_wscaling_state_create_info_nv
{
public:
  /// Default constructor.
  constexpr pipeline_viewport_wscaling_state_create_info_nv() = default;

  /// Constructor.
  constexpr pipeline_viewport_wscaling_state_create_info_nv(
    const void* initial_next, VkBool32 initial_viewport_wscaling_enable,
    uint32_t initial_viewport_count,
    const vk::viewport_wscaling_nv* initial_viewport_wscalings) noexcept
  : _next(std::move(initial_next)),
    _viewport_wscaling_enable(std::move(initial_viewport_wscaling_enable)),
    _viewport_count(std::move(initial_viewport_count)),
    _viewport_wscalings(std::move(initial_viewport_wscalings))
  {
  }

  /// Copy constructor.
  constexpr pipeline_viewport_wscaling_state_create_info_nv(
    const pipeline_viewport_wscaling_state_create_info_nv& other) noexcept
  : _next(other._next),
    _viewport_wscaling_enable(other._viewport_wscaling_enable),
    _viewport_count(other._viewport_count),
    _viewport_wscalings(other._viewport_wscalings)
  {
  }

  /// Move constructor.
  constexpr pipeline_viewport_wscaling_state_create_info_nv(
    pipeline_viewport_wscaling_state_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _viewport_wscaling_enable(std::move(other._viewport_wscaling_enable)),
    _viewport_count(std::move(other._viewport_count)),
    _viewport_wscalings(std::move(other._viewport_wscalings))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_viewport_wscaling_state_create_info_nv& operator=(
    const pipeline_viewport_wscaling_state_create_info_nv& other) noexcept
  {
    _next = other._next;
    _viewport_wscaling_enable = other._viewport_wscaling_enable;
    _viewport_count = other._viewport_count;
    _viewport_wscalings = other._viewport_wscalings;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_viewport_wscaling_state_create_info_nv& operator=(
    pipeline_viewport_wscaling_state_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _viewport_wscaling_enable = std::move(other._viewport_wscaling_enable);
    _viewport_count = std::move(other._viewport_count);
    _viewport_wscalings = std::move(other._viewport_wscalings);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineViewportWScalingStateCreateInfoNV&() const
  {
    return *reinterpret_cast<
      const VkPipelineViewportWScalingStateCreateInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& viewport_wscaling_enable()
  {
    return _viewport_wscaling_enable;
  }

  constexpr const VkBool32& viewport_wscaling_enable() const
  {
    return _viewport_wscaling_enable;
  }

  void viewport_wscaling_enable(VkBool32 new_viewport_wscaling_enable)
  {
    _viewport_wscaling_enable = new_viewport_wscaling_enable;
  }

  uint32_t& viewport_count()
  {
    return _viewport_count;
  }

  constexpr const uint32_t& viewport_count() const
  {
    return _viewport_count;
  }

  void viewport_count(uint32_t new_viewport_count)
  {
    _viewport_count = new_viewport_count;
  }

  const vk::viewport_wscaling_nv* viewport_wscalings()
  {
    return _viewport_wscalings;
  }

  constexpr const vk::viewport_wscaling_nv* viewport_wscalings() const
  {
    return _viewport_wscalings;
  }

  void viewport_wscalings(
    const vk::viewport_wscaling_nv* new_viewport_wscalings)
  {
    _viewport_wscalings = new_viewport_wscalings;
  }

  template <std::size_t Count>
  void viewport_wscalings(
    const std::array<vk::viewport_wscaling_nv, Count>& new_viewport_wscalings)
  {
    _viewport_count = static_cast<uint32_t>(new_viewport_wscalings.size());
    _viewport_wscalings = new_viewport_wscalings.data();
  }

  void viewport_wscalings(
    const std::vector<vk::viewport_wscaling_nv>& new_viewport_wscalings)
  {
    _viewport_count = static_cast<uint32_t>(new_viewport_wscalings.size());
    _viewport_wscalings = new_viewport_wscalings.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_viewport_w_scaling_state_create_info_nv;
  const void* _next = nullptr;
  VkBool32 _viewport_wscaling_enable = VK_FALSE;
  uint32_t _viewport_count = 0;
  const vk::viewport_wscaling_nv* _viewport_wscalings = nullptr;
};
static_assert(sizeof(pipeline_viewport_wscaling_state_create_info_nv) ==
                sizeof(::VkPipelineViewportWScalingStateCreateInfoNV),
              "struct and wrapper have different size!");

inline void cmd_set_viewport_wscaling_nv(
  VkCommandBuffer command_buffer, uint32_t first_viewport,
  uint32_t viewport_count, const vk::viewport_wscaling_nv* viewport_wscalings)
{
  vkCmdSetViewportWScalingNV(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<uint32_t>(first_viewport),
    static_cast<uint32_t>(viewport_count),
    reinterpret_cast<const VkViewportWScalingNV*>(viewport_wscalings));
}
inline vk::result release_display_ext(VkPhysicalDevice physical_device,
                                      VkDisplayKHR display)
{
  return static_cast<vk::result>(
    vkReleaseDisplayEXT(static_cast<VkPhysicalDevice>(physical_device),
                        static_cast<VkDisplayKHR>(display)));
}
enum class display_power_state_ext
{
  /// @see VK_DISPLAY_POWER_STATE_OFF_EXT
  display_power_state_off_ext = 0,
  /// @see VK_DISPLAY_POWER_STATE_SUSPEND_EXT
  display_power_state_suspend_ext = 1,
  /// @see VK_DISPLAY_POWER_STATE_ON_EXT
  display_power_state_on_ext = 2,
};
enum class device_event_type_ext
{
  /// @see VK_DEVICE_EVENT_TYPE_DISPLAY_HOTPLUG_EXT
  device_event_type_display_hotplug_ext = 0,
};
enum class display_event_type_ext
{
  /// @see VK_DISPLAY_EVENT_TYPE_FIRST_PIXEL_OUT_EXT
  display_event_type_first_pixel_out_ext = 0,
};

/// Enhanced replacement type for VkDisplayPowerInfoEXT.
class display_power_info_ext
{
public:
  /// Default constructor.
  constexpr display_power_info_ext() = default;

  /// Constructor.
  constexpr display_power_info_ext(
    const void* initial_next,
    vk::display_power_state_ext initial_power_state) noexcept
  : _next(std::move(initial_next)), _power_state(std::move(initial_power_state))
  {
  }

  /// Copy constructor.
  constexpr display_power_info_ext(const display_power_info_ext& other) noexcept
  : _next(other._next), _power_state(other._power_state)
  {
  }

  /// Move constructor.
  constexpr display_power_info_ext(display_power_info_ext&& other) noexcept
  : _next(std::move(other._next)), _power_state(std::move(other._power_state))
  {
  }

  /// Copy assignment operator.
  constexpr display_power_info_ext& operator=(
    const display_power_info_ext& other) noexcept
  {
    _next = other._next;
    _power_state = other._power_state;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_power_info_ext& operator=(
    display_power_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _power_state = std::move(other._power_state);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayPowerInfoEXT&() const
  {
    return *reinterpret_cast<const VkDisplayPowerInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::display_power_state_ext& power_state()
  {
    return _power_state;
  }

  constexpr const vk::display_power_state_ext& power_state() const
  {
    return _power_state;
  }

  void power_state(vk::display_power_state_ext new_power_state)
  {
    _power_state = new_power_state;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_power_info_ext;
  const void* _next = nullptr;
  vk::display_power_state_ext _power_state =
    vk::display_power_state_ext::display_power_state_off_ext;
};
static_assert(sizeof(display_power_info_ext) == sizeof(::VkDisplayPowerInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDeviceEventInfoEXT.
class device_event_info_ext
{
public:
  /// Default constructor.
  constexpr device_event_info_ext() = default;

  /// Constructor.
  constexpr device_event_info_ext(
    const void* initial_next,
    vk::device_event_type_ext initial_device_event) noexcept
  : _next(std::move(initial_next)),
    _device_event(std::move(initial_device_event))
  {
  }

  /// Copy constructor.
  constexpr device_event_info_ext(const device_event_info_ext& other) noexcept
  : _next(other._next), _device_event(other._device_event)
  {
  }

  /// Move constructor.
  constexpr device_event_info_ext(device_event_info_ext&& other) noexcept
  : _next(std::move(other._next)), _device_event(std::move(other._device_event))
  {
  }

  /// Copy assignment operator.
  constexpr device_event_info_ext& operator=(
    const device_event_info_ext& other) noexcept
  {
    _next = other._next;
    _device_event = other._device_event;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_event_info_ext& operator=(
    device_event_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _device_event = std::move(other._device_event);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceEventInfoEXT&() const
  {
    return *reinterpret_cast<const VkDeviceEventInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::device_event_type_ext& device_event()
  {
    return _device_event;
  }

  constexpr const vk::device_event_type_ext& device_event() const
  {
    return _device_event;
  }

  void device_event(vk::device_event_type_ext new_device_event)
  {
    _device_event = new_device_event;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_event_info_ext;
  const void* _next = nullptr;
  vk::device_event_type_ext _device_event =
    vk::device_event_type_ext::device_event_type_display_hotplug_ext;
};
static_assert(sizeof(device_event_info_ext) == sizeof(::VkDeviceEventInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDisplayEventInfoEXT.
class display_event_info_ext
{
public:
  /// Default constructor.
  constexpr display_event_info_ext() = default;

  /// Constructor.
  constexpr display_event_info_ext(
    const void* initial_next,
    vk::display_event_type_ext initial_display_event) noexcept
  : _next(std::move(initial_next)),
    _display_event(std::move(initial_display_event))
  {
  }

  /// Copy constructor.
  constexpr display_event_info_ext(const display_event_info_ext& other) noexcept
  : _next(other._next), _display_event(other._display_event)
  {
  }

  /// Move constructor.
  constexpr display_event_info_ext(display_event_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _display_event(std::move(other._display_event))
  {
  }

  /// Copy assignment operator.
  constexpr display_event_info_ext& operator=(
    const display_event_info_ext& other) noexcept
  {
    _next = other._next;
    _display_event = other._display_event;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_event_info_ext& operator=(
    display_event_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _display_event = std::move(other._display_event);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayEventInfoEXT&() const
  {
    return *reinterpret_cast<const VkDisplayEventInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::display_event_type_ext& display_event()
  {
    return _display_event;
  }

  constexpr const vk::display_event_type_ext& display_event() const
  {
    return _display_event;
  }

  void display_event(vk::display_event_type_ext new_display_event)
  {
    _display_event = new_display_event;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_event_info_ext;
  const void* _next = nullptr;
  vk::display_event_type_ext _display_event =
    vk::display_event_type_ext::display_event_type_first_pixel_out_ext;
};
static_assert(sizeof(display_event_info_ext) == sizeof(::VkDisplayEventInfoEXT),
              "struct and wrapper have different size!");

enum class surface_counter_flag_ext
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_SURFACE_COUNTER_VBLANK_EXT
  vblank_ext = 1 << 0,
};
using surface_counter_flags_ext =
  shift::core::bit_field<surface_counter_flag_ext, VkSurfaceCounterFlagsEXT>;
inline constexpr surface_counter_flags_ext operator|(
  surface_counter_flag_ext lhs, surface_counter_flag_ext rhs)
{
  return surface_counter_flags_ext{lhs} | rhs;
}
/// Enhanced replacement type for VkSwapchainCounterCreateInfoEXT.
class swapchain_counter_create_info_ext
{
public:
  /// Default constructor.
  constexpr swapchain_counter_create_info_ext() = default;

  /// Constructor.
  constexpr swapchain_counter_create_info_ext(
    const void* initial_next,
    vk::surface_counter_flags_ext initial_surface_counters) noexcept
  : _next(std::move(initial_next)),
    _surface_counters(std::move(initial_surface_counters))
  {
  }

  /// Copy constructor.
  constexpr swapchain_counter_create_info_ext(
    const swapchain_counter_create_info_ext& other) noexcept
  : _next(other._next), _surface_counters(other._surface_counters)
  {
  }

  /// Move constructor.
  constexpr swapchain_counter_create_info_ext(
    swapchain_counter_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _surface_counters(std::move(other._surface_counters))
  {
  }

  /// Copy assignment operator.
  constexpr swapchain_counter_create_info_ext& operator=(
    const swapchain_counter_create_info_ext& other) noexcept
  {
    _next = other._next;
    _surface_counters = other._surface_counters;
    return *this;
  }

  /// Move assignment operator.
  constexpr swapchain_counter_create_info_ext& operator=(
    swapchain_counter_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _surface_counters = std::move(other._surface_counters);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSwapchainCounterCreateInfoEXT&() const
  {
    return *reinterpret_cast<const VkSwapchainCounterCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::surface_counter_flags_ext& surface_counters()
  {
    return _surface_counters;
  }

  constexpr const vk::surface_counter_flags_ext& surface_counters() const
  {
    return _surface_counters;
  }

  void surface_counters(vk::surface_counter_flags_ext new_surface_counters)
  {
    _surface_counters = new_surface_counters;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::swapchain_counter_create_info_ext;
  const void* _next = nullptr;
  vk::surface_counter_flags_ext _surface_counters =
    vk::surface_counter_flag_ext::none;
};
static_assert(sizeof(swapchain_counter_create_info_ext) ==
                sizeof(::VkSwapchainCounterCreateInfoEXT),
              "struct and wrapper have different size!");

inline vk::result display_power_control_ext(
  VkDevice device, VkDisplayKHR display,
  const vk::display_power_info_ext* display_power_info)
{
  return static_cast<vk::result>(vkDisplayPowerControlEXT(
    static_cast<VkDevice>(device), static_cast<VkDisplayKHR>(display),
    reinterpret_cast<const VkDisplayPowerInfoEXT*>(display_power_info)));
}
inline vk::result register_device_event_ext(
  VkDevice device, const vk::device_event_info_ext* device_event_info,
  const vk::allocation_callbacks* allocator, VkFence* fence)
{
  return static_cast<vk::result>(vkRegisterDeviceEventEXT(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDeviceEventInfoEXT*>(device_event_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkFence*>(fence)));
}
inline vk::result register_display_event_ext(
  VkDevice device, VkDisplayKHR display,
  const vk::display_event_info_ext* display_event_info,
  const vk::allocation_callbacks* allocator, VkFence* fence)
{
  return static_cast<vk::result>(vkRegisterDisplayEventEXT(
    static_cast<VkDevice>(device), static_cast<VkDisplayKHR>(display),
    reinterpret_cast<const VkDisplayEventInfoEXT*>(display_event_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkFence*>(fence)));
}
inline vk::result get_swapchain_counter_ext(
  VkDevice device, VkSwapchainKHR swapchain,
  vk::surface_counter_flag_ext counter, uint64_t* counter_value)
{
  return static_cast<vk::result>(vkGetSwapchainCounterEXT(
    static_cast<VkDevice>(device), static_cast<VkSwapchainKHR>(swapchain),
    static_cast<VkSurfaceCounterFlagBitsEXT>(counter),
    reinterpret_cast<uint64_t*>(counter_value)));
}

/// Enhanced replacement type for VkRefreshCycleDurationGOOGLE.
class refresh_cycle_duration_google
{
public:
  /// Default constructor.
  constexpr refresh_cycle_duration_google() = default;

  /// Constructor.
  constexpr refresh_cycle_duration_google(
    uint64_t initial_refresh_duration) noexcept
  : _refresh_duration(std::move(initial_refresh_duration))
  {
  }

  /// Copy constructor.
  constexpr refresh_cycle_duration_google(
    const refresh_cycle_duration_google& other) = default;

  /// Move constructor.
  constexpr refresh_cycle_duration_google(
    refresh_cycle_duration_google&& other) = default;

  /// Copy assignment operator.
  constexpr refresh_cycle_duration_google& operator=(
    const refresh_cycle_duration_google& other) = default;

  /// Move assignment operator.
  constexpr refresh_cycle_duration_google& operator=(
    refresh_cycle_duration_google&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkRefreshCycleDurationGOOGLE&() const
  {
    return *reinterpret_cast<const VkRefreshCycleDurationGOOGLE*>(this);
  }

  uint64_t& refresh_duration()
  {
    return _refresh_duration;
  }

  constexpr const uint64_t& refresh_duration() const
  {
    return _refresh_duration;
  }

  void refresh_duration(uint64_t new_refresh_duration)
  {
    _refresh_duration = new_refresh_duration;
  }

private:
  /// Number of nanoseconds from the start of one refresh cycle to the next
  uint64_t _refresh_duration = 0;
};
static_assert(sizeof(refresh_cycle_duration_google) ==
                sizeof(::VkRefreshCycleDurationGOOGLE),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPastPresentationTimingGOOGLE.
class past_presentation_timing_google
{
public:
  /// Default constructor.
  constexpr past_presentation_timing_google() = default;

  /// Constructor.
  constexpr past_presentation_timing_google(
    uint32_t initial_present_id, uint64_t initial_desired_present_time,
    uint64_t initial_actual_present_time,
    uint64_t initial_earliest_present_time,
    uint64_t initial_present_margin) noexcept
  : _present_id(std::move(initial_present_id)),
    _desired_present_time(std::move(initial_desired_present_time)),
    _actual_present_time(std::move(initial_actual_present_time)),
    _earliest_present_time(std::move(initial_earliest_present_time)),
    _present_margin(std::move(initial_present_margin))
  {
  }

  /// Copy constructor.
  constexpr past_presentation_timing_google(
    const past_presentation_timing_google& other) = default;

  /// Move constructor.
  constexpr past_presentation_timing_google(
    past_presentation_timing_google&& other) = default;

  /// Copy assignment operator.
  constexpr past_presentation_timing_google& operator=(
    const past_presentation_timing_google& other) = default;

  /// Move assignment operator.
  constexpr past_presentation_timing_google& operator=(
    past_presentation_timing_google&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkPastPresentationTimingGOOGLE&() const
  {
    return *reinterpret_cast<const VkPastPresentationTimingGOOGLE*>(this);
  }

  uint32_t& present_id()
  {
    return _present_id;
  }

  constexpr const uint32_t& present_id() const
  {
    return _present_id;
  }

  void present_id(uint32_t new_present_id)
  {
    _present_id = new_present_id;
  }

  uint64_t& desired_present_time()
  {
    return _desired_present_time;
  }

  constexpr const uint64_t& desired_present_time() const
  {
    return _desired_present_time;
  }

  void desired_present_time(uint64_t new_desired_present_time)
  {
    _desired_present_time = new_desired_present_time;
  }

  uint64_t& actual_present_time()
  {
    return _actual_present_time;
  }

  constexpr const uint64_t& actual_present_time() const
  {
    return _actual_present_time;
  }

  void actual_present_time(uint64_t new_actual_present_time)
  {
    _actual_present_time = new_actual_present_time;
  }

  uint64_t& earliest_present_time()
  {
    return _earliest_present_time;
  }

  constexpr const uint64_t& earliest_present_time() const
  {
    return _earliest_present_time;
  }

  void earliest_present_time(uint64_t new_earliest_present_time)
  {
    _earliest_present_time = new_earliest_present_time;
  }

  uint64_t& present_margin()
  {
    return _present_margin;
  }

  constexpr const uint64_t& present_margin() const
  {
    return _present_margin;
  }

  void present_margin(uint64_t new_present_margin)
  {
    _present_margin = new_present_margin;
  }

private:
  /// Application-provided identifier, previously given to vkQueuePresentKHR
  uint32_t _present_id = 0;
  /// Earliest time an image should have been presented, previously given to
  /// vkQueuePresentKHR
  uint64_t _desired_present_time = 0;
  /// Time the image was actually displayed
  uint64_t _actual_present_time = 0;
  /// Earliest time the image could have been displayed
  uint64_t _earliest_present_time = 0;
  /// How early vkQueuePresentKHR was processed vs. how soon it needed to be and
  /// make earliestPresentTime
  uint64_t _present_margin = 0;
};
static_assert(sizeof(past_presentation_timing_google) ==
                sizeof(::VkPastPresentationTimingGOOGLE),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPresentTimeGOOGLE.
class present_time_google
{
public:
  /// Default constructor.
  constexpr present_time_google() = default;

  /// Constructor.
  constexpr present_time_google(uint32_t initial_present_id,
                                uint64_t initial_desired_present_time) noexcept
  : _present_id(std::move(initial_present_id)),
    _desired_present_time(std::move(initial_desired_present_time))
  {
  }

  /// Copy constructor.
  constexpr present_time_google(const present_time_google& other) = default;

  /// Move constructor.
  constexpr present_time_google(present_time_google&& other) = default;

  /// Copy assignment operator.
  constexpr present_time_google& operator=(const present_time_google& other) =
    default;

  /// Move assignment operator.
  constexpr present_time_google& operator=(present_time_google&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkPresentTimeGOOGLE&() const
  {
    return *reinterpret_cast<const VkPresentTimeGOOGLE*>(this);
  }

  uint32_t& present_id()
  {
    return _present_id;
  }

  constexpr const uint32_t& present_id() const
  {
    return _present_id;
  }

  void present_id(uint32_t new_present_id)
  {
    _present_id = new_present_id;
  }

  uint64_t& desired_present_time()
  {
    return _desired_present_time;
  }

  constexpr const uint64_t& desired_present_time() const
  {
    return _desired_present_time;
  }

  void desired_present_time(uint64_t new_desired_present_time)
  {
    _desired_present_time = new_desired_present_time;
  }

private:
  /// Application-provided identifier
  uint32_t _present_id = 0;
  /// Earliest time an image should be presented
  uint64_t _desired_present_time = 0;
};
static_assert(sizeof(present_time_google) == sizeof(::VkPresentTimeGOOGLE),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPresentTimesInfoGOOGLE.
class present_times_info_google
{
public:
  /// Default constructor.
  constexpr present_times_info_google() = default;

  /// Constructor.
  constexpr present_times_info_google(
    const void* initial_next, uint32_t initial_swapchain_count,
    const vk::present_time_google* initial_times) noexcept
  : _next(std::move(initial_next)),
    _swapchain_count(std::move(initial_swapchain_count)),
    _times(std::move(initial_times))
  {
  }

  /// Copy constructor.
  constexpr present_times_info_google(
    const present_times_info_google& other) noexcept
  : _next(other._next),
    _swapchain_count(other._swapchain_count),
    _times(other._times)
  {
  }

  /// Move constructor.
  constexpr present_times_info_google(
    present_times_info_google&& other) noexcept
  : _next(std::move(other._next)),
    _swapchain_count(std::move(other._swapchain_count)),
    _times(std::move(other._times))
  {
  }

  /// Copy assignment operator.
  constexpr present_times_info_google& operator=(
    const present_times_info_google& other) noexcept
  {
    _next = other._next;
    _swapchain_count = other._swapchain_count;
    _times = other._times;
    return *this;
  }

  /// Move assignment operator.
  constexpr present_times_info_google& operator=(
    present_times_info_google&& other) noexcept
  {
    _next = std::move(other._next);
    _swapchain_count = std::move(other._swapchain_count);
    _times = std::move(other._times);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPresentTimesInfoGOOGLE&() const
  {
    return *reinterpret_cast<const VkPresentTimesInfoGOOGLE*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& swapchain_count()
  {
    return _swapchain_count;
  }

  constexpr const uint32_t& swapchain_count() const
  {
    return _swapchain_count;
  }

  void swapchain_count(uint32_t new_swapchain_count)
  {
    _swapchain_count = new_swapchain_count;
  }

  const vk::present_time_google* times()
  {
    return _times;
  }

  constexpr const vk::present_time_google* times() const
  {
    return _times;
  }

  void times(const vk::present_time_google* new_times)
  {
    _times = new_times;
  }

  template <std::size_t Count>
  void times(const std::array<vk::present_time_google, Count>& new_times)
  {
    _swapchain_count = static_cast<uint32_t>(new_times.size());
    _times = new_times.data();
  }

  void times(const std::vector<vk::present_time_google>& new_times)
  {
    _swapchain_count = static_cast<uint32_t>(new_times.size());
    _times = new_times.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::present_times_info_google;
  const void* _next = nullptr;
  /// Copy of VkPresentInfoKHR::swapchainCount
  uint32_t _swapchain_count = 0;
  /// The earliest times to present images
  const vk::present_time_google* _times = nullptr;
};
static_assert(sizeof(present_times_info_google) ==
                sizeof(::VkPresentTimesInfoGOOGLE),
              "struct and wrapper have different size!");

inline vk::result get_refresh_cycle_duration_google(
  VkDevice device, VkSwapchainKHR swapchain,
  vk::refresh_cycle_duration_google* display_timing_properties)
{
  return static_cast<vk::result>(vkGetRefreshCycleDurationGOOGLE(
    static_cast<VkDevice>(device), static_cast<VkSwapchainKHR>(swapchain),
    reinterpret_cast<VkRefreshCycleDurationGOOGLE*>(
      display_timing_properties)));
}
inline vk::result get_past_presentation_timing_google(
  VkDevice device, VkSwapchainKHR swapchain,
  uint32_t* presentation_timing_count,
  vk::past_presentation_timing_google* presentation_timings)
{
  return static_cast<vk::result>(vkGetPastPresentationTimingGOOGLE(
    static_cast<VkDevice>(device), static_cast<VkSwapchainKHR>(swapchain),
    reinterpret_cast<uint32_t*>(presentation_timing_count),
    reinterpret_cast<VkPastPresentationTimingGOOGLE*>(presentation_timings)));
}

/// Enhanced replacement type for
/// VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX.
class physical_device_multiview_per_view_attributes_properties_nvx
{
public:
  /// Default constructor.
  constexpr physical_device_multiview_per_view_attributes_properties_nvx() =
    default;

  /// Constructor.
  constexpr physical_device_multiview_per_view_attributes_properties_nvx(
    void* initial_next,
    VkBool32 initial_per_view_position_all_components) noexcept
  : _next(std::move(initial_next)),
    _per_view_position_all_components(
      std::move(initial_per_view_position_all_components))
  {
  }

  /// Copy constructor.
  constexpr physical_device_multiview_per_view_attributes_properties_nvx(
    const physical_device_multiview_per_view_attributes_properties_nvx&
      other) noexcept
  : _next(other._next),
    _per_view_position_all_components(other._per_view_position_all_components)
  {
  }

  /// Move constructor.
  constexpr physical_device_multiview_per_view_attributes_properties_nvx(
    physical_device_multiview_per_view_attributes_properties_nvx&&
      other) noexcept
  : _next(std::move(other._next)),
    _per_view_position_all_components(
      std::move(other._per_view_position_all_components))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_multiview_per_view_attributes_properties_nvx&
  operator=(const physical_device_multiview_per_view_attributes_properties_nvx&
              other) noexcept
  {
    _next = other._next;
    _per_view_position_all_components = other._per_view_position_all_components;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_multiview_per_view_attributes_properties_nvx&
  operator=(physical_device_multiview_per_view_attributes_properties_nvx&&
              other) noexcept
  {
    _next = std::move(other._next);
    _per_view_position_all_components =
      std::move(other._per_view_position_all_components);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX&()
    const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& per_view_position_all_components()
  {
    return _per_view_position_all_components;
  }

  constexpr const VkBool32& per_view_position_all_components() const
  {
    return _per_view_position_all_components;
  }

  void per_view_position_all_components(
    VkBool32 new_per_view_position_all_components)
  {
    _per_view_position_all_components = new_per_view_position_all_components;
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    physical_device_multiview_per_view_attributes_properties_nvx;
  void* _next = nullptr;
  VkBool32 _per_view_position_all_components = VK_FALSE;
};
static_assert(
  sizeof(physical_device_multiview_per_view_attributes_properties_nvx) ==
    sizeof(::VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX),
  "struct and wrapper have different size!");

enum class viewport_coordinate_swizzle_nv
{
  /// @see VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_X_NV
  viewport_coordinate_swizzle_positive_x_nv = 0,
  /// @see VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_X_NV
  viewport_coordinate_swizzle_negative_x_nv = 1,
  /// @see VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_Y_NV
  viewport_coordinate_swizzle_positive_y_nv = 2,
  /// @see VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_Y_NV
  viewport_coordinate_swizzle_negative_y_nv = 3,
  /// @see VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_Z_NV
  viewport_coordinate_swizzle_positive_z_nv = 4,
  /// @see VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_Z_NV
  viewport_coordinate_swizzle_negative_z_nv = 5,
  /// @see VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_W_NV
  viewport_coordinate_swizzle_positive_w_nv = 6,
  /// @see VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_W_NV
  viewport_coordinate_swizzle_negative_w_nv = 7,
};

/// Enhanced replacement type for VkViewportSwizzleNV.
class viewport_swizzle_nv
{
public:
  /// Default constructor.
  constexpr viewport_swizzle_nv() = default;

  /// Constructor.
  constexpr viewport_swizzle_nv(
    vk::viewport_coordinate_swizzle_nv initial_x,
    vk::viewport_coordinate_swizzle_nv initial_y,
    vk::viewport_coordinate_swizzle_nv initial_z,
    vk::viewport_coordinate_swizzle_nv initial_w) noexcept
  : _x(std::move(initial_x)),
    _y(std::move(initial_y)),
    _z(std::move(initial_z)),
    _w(std::move(initial_w))
  {
  }

  /// Copy constructor.
  constexpr viewport_swizzle_nv(const viewport_swizzle_nv& other) = default;

  /// Move constructor.
  constexpr viewport_swizzle_nv(viewport_swizzle_nv&& other) = default;

  /// Copy assignment operator.
  constexpr viewport_swizzle_nv& operator=(const viewport_swizzle_nv& other) =
    default;

  /// Move assignment operator.
  constexpr viewport_swizzle_nv& operator=(viewport_swizzle_nv&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkViewportSwizzleNV&() const
  {
    return *reinterpret_cast<const VkViewportSwizzleNV*>(this);
  }

  vk::viewport_coordinate_swizzle_nv& x()
  {
    return _x;
  }

  constexpr const vk::viewport_coordinate_swizzle_nv& x() const
  {
    return _x;
  }

  void x(vk::viewport_coordinate_swizzle_nv new_x)
  {
    _x = new_x;
  }

  vk::viewport_coordinate_swizzle_nv& y()
  {
    return _y;
  }

  constexpr const vk::viewport_coordinate_swizzle_nv& y() const
  {
    return _y;
  }

  void y(vk::viewport_coordinate_swizzle_nv new_y)
  {
    _y = new_y;
  }

  vk::viewport_coordinate_swizzle_nv& z()
  {
    return _z;
  }

  constexpr const vk::viewport_coordinate_swizzle_nv& z() const
  {
    return _z;
  }

  void z(vk::viewport_coordinate_swizzle_nv new_z)
  {
    _z = new_z;
  }

  vk::viewport_coordinate_swizzle_nv& w()
  {
    return _w;
  }

  constexpr const vk::viewport_coordinate_swizzle_nv& w() const
  {
    return _w;
  }

  void w(vk::viewport_coordinate_swizzle_nv new_w)
  {
    _w = new_w;
  }

private:
  vk::viewport_coordinate_swizzle_nv _x = vk::viewport_coordinate_swizzle_nv::
    viewport_coordinate_swizzle_positive_x_nv;
  vk::viewport_coordinate_swizzle_nv _y = vk::viewport_coordinate_swizzle_nv::
    viewport_coordinate_swizzle_positive_x_nv;
  vk::viewport_coordinate_swizzle_nv _z = vk::viewport_coordinate_swizzle_nv::
    viewport_coordinate_swizzle_positive_x_nv;
  vk::viewport_coordinate_swizzle_nv _w = vk::viewport_coordinate_swizzle_nv::
    viewport_coordinate_swizzle_positive_x_nv;
};
static_assert(sizeof(viewport_swizzle_nv) == sizeof(::VkViewportSwizzleNV),
              "struct and wrapper have different size!");

using pipeline_viewport_swizzle_state_create_flags_nv = VkFlags;

/// Enhanced replacement type for VkPipelineViewportSwizzleStateCreateInfoNV.
class pipeline_viewport_swizzle_state_create_info_nv
{
public:
  /// Default constructor.
  constexpr pipeline_viewport_swizzle_state_create_info_nv() = default;

  /// Constructor.
  constexpr pipeline_viewport_swizzle_state_create_info_nv(
    const void* initial_next,
    vk::pipeline_viewport_swizzle_state_create_flags_nv initial_flags,
    uint32_t initial_viewport_count,
    const vk::viewport_swizzle_nv* initial_viewport_swizzles) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _viewport_count(std::move(initial_viewport_count)),
    _viewport_swizzles(std::move(initial_viewport_swizzles))
  {
  }

  /// Copy constructor.
  constexpr pipeline_viewport_swizzle_state_create_info_nv(
    const pipeline_viewport_swizzle_state_create_info_nv& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _viewport_count(other._viewport_count),
    _viewport_swizzles(other._viewport_swizzles)
  {
  }

  /// Move constructor.
  constexpr pipeline_viewport_swizzle_state_create_info_nv(
    pipeline_viewport_swizzle_state_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _viewport_count(std::move(other._viewport_count)),
    _viewport_swizzles(std::move(other._viewport_swizzles))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_viewport_swizzle_state_create_info_nv& operator=(
    const pipeline_viewport_swizzle_state_create_info_nv& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _viewport_count = other._viewport_count;
    _viewport_swizzles = other._viewport_swizzles;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_viewport_swizzle_state_create_info_nv& operator=(
    pipeline_viewport_swizzle_state_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _viewport_count = std::move(other._viewport_count);
    _viewport_swizzles = std::move(other._viewport_swizzles);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineViewportSwizzleStateCreateInfoNV&() const
  {
    return *reinterpret_cast<const VkPipelineViewportSwizzleStateCreateInfoNV*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_viewport_swizzle_state_create_flags_nv& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_viewport_swizzle_state_create_flags_nv& flags()
    const
  {
    return _flags;
  }

  void flags(vk::pipeline_viewport_swizzle_state_create_flags_nv new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& viewport_count()
  {
    return _viewport_count;
  }

  constexpr const uint32_t& viewport_count() const
  {
    return _viewport_count;
  }

  void viewport_count(uint32_t new_viewport_count)
  {
    _viewport_count = new_viewport_count;
  }

  const vk::viewport_swizzle_nv* viewport_swizzles()
  {
    return _viewport_swizzles;
  }

  constexpr const vk::viewport_swizzle_nv* viewport_swizzles() const
  {
    return _viewport_swizzles;
  }

  void viewport_swizzles(const vk::viewport_swizzle_nv* new_viewport_swizzles)
  {
    _viewport_swizzles = new_viewport_swizzles;
  }

  template <std::size_t Count>
  void viewport_swizzles(
    const std::array<vk::viewport_swizzle_nv, Count>& new_viewport_swizzles)
  {
    _viewport_count = static_cast<uint32_t>(new_viewport_swizzles.size());
    _viewport_swizzles = new_viewport_swizzles.data();
  }

  void viewport_swizzles(
    const std::vector<vk::viewport_swizzle_nv>& new_viewport_swizzles)
  {
    _viewport_count = static_cast<uint32_t>(new_viewport_swizzles.size());
    _viewport_swizzles = new_viewport_swizzles.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_viewport_swizzle_state_create_info_nv;
  const void* _next = nullptr;
  vk::pipeline_viewport_swizzle_state_create_flags_nv _flags = 0;
  uint32_t _viewport_count = 0;
  const vk::viewport_swizzle_nv* _viewport_swizzles = nullptr;
};
static_assert(sizeof(pipeline_viewport_swizzle_state_create_info_nv) ==
                sizeof(::VkPipelineViewportSwizzleStateCreateInfoNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceDiscardRectanglePropertiesEXT.
class physical_device_discard_rectangle_properties_ext
{
public:
  /// Default constructor.
  constexpr physical_device_discard_rectangle_properties_ext() = default;

  /// Constructor.
  constexpr physical_device_discard_rectangle_properties_ext(
    void* initial_next, uint32_t initial_max_discard_rectangles) noexcept
  : _next(std::move(initial_next)),
    _max_discard_rectangles(std::move(initial_max_discard_rectangles))
  {
  }

  /// Copy constructor.
  constexpr physical_device_discard_rectangle_properties_ext(
    const physical_device_discard_rectangle_properties_ext& other) noexcept
  : _next(other._next), _max_discard_rectangles(other._max_discard_rectangles)
  {
  }

  /// Move constructor.
  constexpr physical_device_discard_rectangle_properties_ext(
    physical_device_discard_rectangle_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _max_discard_rectangles(std::move(other._max_discard_rectangles))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_discard_rectangle_properties_ext& operator=(
    const physical_device_discard_rectangle_properties_ext& other) noexcept
  {
    _next = other._next;
    _max_discard_rectangles = other._max_discard_rectangles;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_discard_rectangle_properties_ext& operator=(
    physical_device_discard_rectangle_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _max_discard_rectangles = std::move(other._max_discard_rectangles);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceDiscardRectanglePropertiesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceDiscardRectanglePropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_discard_rectangles()
  {
    return _max_discard_rectangles;
  }

  constexpr const uint32_t& max_discard_rectangles() const
  {
    return _max_discard_rectangles;
  }

  void max_discard_rectangles(uint32_t new_max_discard_rectangles)
  {
    _max_discard_rectangles = new_max_discard_rectangles;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_discard_rectangle_properties_ext;
  void* _next = nullptr;
  /// max number of active discard rectangles
  uint32_t _max_discard_rectangles = 0;
};
static_assert(sizeof(physical_device_discard_rectangle_properties_ext) ==
                sizeof(::VkPhysicalDeviceDiscardRectanglePropertiesEXT),
              "struct and wrapper have different size!");

using pipeline_discard_rectangle_state_create_flags_ext = VkFlags;
enum class discard_rectangle_mode_ext
{
  /// @see VK_DISCARD_RECTANGLE_MODE_INCLUSIVE_EXT
  discard_rectangle_mode_inclusive_ext = 0,
  /// @see VK_DISCARD_RECTANGLE_MODE_EXCLUSIVE_EXT
  discard_rectangle_mode_exclusive_ext = 1,
};

/// Enhanced replacement type for VkPipelineDiscardRectangleStateCreateInfoEXT.
class pipeline_discard_rectangle_state_create_info_ext
{
public:
  /// Default constructor.
  constexpr pipeline_discard_rectangle_state_create_info_ext() = default;

  /// Constructor.
  constexpr pipeline_discard_rectangle_state_create_info_ext(
    const void* initial_next,
    vk::pipeline_discard_rectangle_state_create_flags_ext initial_flags,
    vk::discard_rectangle_mode_ext initial_discard_rectangle_mode,
    uint32_t initial_discard_rectangle_count,
    const vk::rect_2d* initial_discard_rectangles) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _discard_rectangle_mode(std::move(initial_discard_rectangle_mode)),
    _discard_rectangle_count(std::move(initial_discard_rectangle_count)),
    _discard_rectangles(std::move(initial_discard_rectangles))
  {
  }

  /// Copy constructor.
  constexpr pipeline_discard_rectangle_state_create_info_ext(
    const pipeline_discard_rectangle_state_create_info_ext& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _discard_rectangle_mode(other._discard_rectangle_mode),
    _discard_rectangle_count(other._discard_rectangle_count),
    _discard_rectangles(other._discard_rectangles)
  {
  }

  /// Move constructor.
  constexpr pipeline_discard_rectangle_state_create_info_ext(
    pipeline_discard_rectangle_state_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _discard_rectangle_mode(std::move(other._discard_rectangle_mode)),
    _discard_rectangle_count(std::move(other._discard_rectangle_count)),
    _discard_rectangles(std::move(other._discard_rectangles))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_discard_rectangle_state_create_info_ext& operator=(
    const pipeline_discard_rectangle_state_create_info_ext& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _discard_rectangle_mode = other._discard_rectangle_mode;
    _discard_rectangle_count = other._discard_rectangle_count;
    _discard_rectangles = other._discard_rectangles;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_discard_rectangle_state_create_info_ext& operator=(
    pipeline_discard_rectangle_state_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _discard_rectangle_mode = std::move(other._discard_rectangle_mode);
    _discard_rectangle_count = std::move(other._discard_rectangle_count);
    _discard_rectangles = std::move(other._discard_rectangles);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineDiscardRectangleStateCreateInfoEXT&() const
  {
    return *reinterpret_cast<
      const VkPipelineDiscardRectangleStateCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_discard_rectangle_state_create_flags_ext& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_discard_rectangle_state_create_flags_ext& flags()
    const
  {
    return _flags;
  }

  void flags(vk::pipeline_discard_rectangle_state_create_flags_ext new_flags)
  {
    _flags = new_flags;
  }

  vk::discard_rectangle_mode_ext& discard_rectangle_mode()
  {
    return _discard_rectangle_mode;
  }

  constexpr const vk::discard_rectangle_mode_ext& discard_rectangle_mode() const
  {
    return _discard_rectangle_mode;
  }

  void discard_rectangle_mode(
    vk::discard_rectangle_mode_ext new_discard_rectangle_mode)
  {
    _discard_rectangle_mode = new_discard_rectangle_mode;
  }

  uint32_t& discard_rectangle_count()
  {
    return _discard_rectangle_count;
  }

  constexpr const uint32_t& discard_rectangle_count() const
  {
    return _discard_rectangle_count;
  }

  void discard_rectangle_count(uint32_t new_discard_rectangle_count)
  {
    _discard_rectangle_count = new_discard_rectangle_count;
  }

  const vk::rect_2d* discard_rectangles()
  {
    return _discard_rectangles;
  }

  constexpr const vk::rect_2d* discard_rectangles() const
  {
    return _discard_rectangles;
  }

  void discard_rectangles(const vk::rect_2d* new_discard_rectangles)
  {
    _discard_rectangles = new_discard_rectangles;
  }

  template <std::size_t Count>
  void discard_rectangles(
    const std::array<vk::rect_2d, Count>& new_discard_rectangles)
  {
    _discard_rectangle_count =
      static_cast<uint32_t>(new_discard_rectangles.size());
    _discard_rectangles = new_discard_rectangles.data();
  }

  void discard_rectangles(
    const std::vector<vk::rect_2d>& new_discard_rectangles)
  {
    _discard_rectangle_count =
      static_cast<uint32_t>(new_discard_rectangles.size());
    _discard_rectangles = new_discard_rectangles.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_discard_rectangle_state_create_info_ext;
  const void* _next = nullptr;
  vk::pipeline_discard_rectangle_state_create_flags_ext _flags = 0;
  vk::discard_rectangle_mode_ext _discard_rectangle_mode =
    vk::discard_rectangle_mode_ext::discard_rectangle_mode_inclusive_ext;
  uint32_t _discard_rectangle_count = 0;
  const vk::rect_2d* _discard_rectangles = nullptr;
};
static_assert(sizeof(pipeline_discard_rectangle_state_create_info_ext) ==
                sizeof(::VkPipelineDiscardRectangleStateCreateInfoEXT),
              "struct and wrapper have different size!");

inline void cmd_set_discard_rectangle_ext(VkCommandBuffer command_buffer,
                                          uint32_t first_discard_rectangle,
                                          uint32_t discard_rectangle_count,
                                          const vk::rect_2d* discard_rectangles)
{
  vkCmdSetDiscardRectangleEXT(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<uint32_t>(first_discard_rectangle),
    static_cast<uint32_t>(discard_rectangle_count),
    reinterpret_cast<const VkRect2D*>(discard_rectangles));
}

/// Enhanced replacement type for
/// VkPhysicalDeviceConservativeRasterizationPropertiesEXT.
class physical_device_conservative_rasterization_properties_ext
{
public:
  /// Default constructor.
  constexpr physical_device_conservative_rasterization_properties_ext() =
    default;

  /// Constructor.
  constexpr physical_device_conservative_rasterization_properties_ext(
    void* initial_next, float initial_primitive_overestimation_size,
    float initial_max_extra_primitive_overestimation_size,
    float initial_extra_primitive_overestimation_size_granularity,
    VkBool32 initial_primitive_underestimation,
    VkBool32 initial_conservative_point_and_line_rasterization,
    VkBool32 initial_degenerate_triangles_rasterized,
    VkBool32 initial_degenerate_lines_rasterized,
    VkBool32 initial_fully_covered_fragment_shader_input_variable,
    VkBool32 initial_conservative_rasterization_post_depth_coverage) noexcept
  : _next(std::move(initial_next)),
    _primitive_overestimation_size(
      std::move(initial_primitive_overestimation_size)),
    _max_extra_primitive_overestimation_size(
      std::move(initial_max_extra_primitive_overestimation_size)),
    _extra_primitive_overestimation_size_granularity(
      std::move(initial_extra_primitive_overestimation_size_granularity)),
    _primitive_underestimation(std::move(initial_primitive_underestimation)),
    _conservative_point_and_line_rasterization(
      std::move(initial_conservative_point_and_line_rasterization)),
    _degenerate_triangles_rasterized(
      std::move(initial_degenerate_triangles_rasterized)),
    _degenerate_lines_rasterized(
      std::move(initial_degenerate_lines_rasterized)),
    _fully_covered_fragment_shader_input_variable(
      std::move(initial_fully_covered_fragment_shader_input_variable)),
    _conservative_rasterization_post_depth_coverage(
      std::move(initial_conservative_rasterization_post_depth_coverage))
  {
  }

  /// Copy constructor.
  constexpr physical_device_conservative_rasterization_properties_ext(
    const physical_device_conservative_rasterization_properties_ext&
      other) noexcept
  : _next(other._next),
    _primitive_overestimation_size(other._primitive_overestimation_size),
    _max_extra_primitive_overestimation_size(
      other._max_extra_primitive_overestimation_size),
    _extra_primitive_overestimation_size_granularity(
      other._extra_primitive_overestimation_size_granularity),
    _primitive_underestimation(other._primitive_underestimation),
    _conservative_point_and_line_rasterization(
      other._conservative_point_and_line_rasterization),
    _degenerate_triangles_rasterized(other._degenerate_triangles_rasterized),
    _degenerate_lines_rasterized(other._degenerate_lines_rasterized),
    _fully_covered_fragment_shader_input_variable(
      other._fully_covered_fragment_shader_input_variable),
    _conservative_rasterization_post_depth_coverage(
      other._conservative_rasterization_post_depth_coverage)
  {
  }

  /// Move constructor.
  constexpr physical_device_conservative_rasterization_properties_ext(
    physical_device_conservative_rasterization_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _primitive_overestimation_size(
      std::move(other._primitive_overestimation_size)),
    _max_extra_primitive_overestimation_size(
      std::move(other._max_extra_primitive_overestimation_size)),
    _extra_primitive_overestimation_size_granularity(
      std::move(other._extra_primitive_overestimation_size_granularity)),
    _primitive_underestimation(std::move(other._primitive_underestimation)),
    _conservative_point_and_line_rasterization(
      std::move(other._conservative_point_and_line_rasterization)),
    _degenerate_triangles_rasterized(
      std::move(other._degenerate_triangles_rasterized)),
    _degenerate_lines_rasterized(std::move(other._degenerate_lines_rasterized)),
    _fully_covered_fragment_shader_input_variable(
      std::move(other._fully_covered_fragment_shader_input_variable)),
    _conservative_rasterization_post_depth_coverage(
      std::move(other._conservative_rasterization_post_depth_coverage))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_conservative_rasterization_properties_ext&
  operator=(const physical_device_conservative_rasterization_properties_ext&
              other) noexcept
  {
    _next = other._next;
    _primitive_overestimation_size = other._primitive_overestimation_size;
    _max_extra_primitive_overestimation_size =
      other._max_extra_primitive_overestimation_size;
    _extra_primitive_overestimation_size_granularity =
      other._extra_primitive_overestimation_size_granularity;
    _primitive_underestimation = other._primitive_underestimation;
    _conservative_point_and_line_rasterization =
      other._conservative_point_and_line_rasterization;
    _degenerate_triangles_rasterized = other._degenerate_triangles_rasterized;
    _degenerate_lines_rasterized = other._degenerate_lines_rasterized;
    _fully_covered_fragment_shader_input_variable =
      other._fully_covered_fragment_shader_input_variable;
    _conservative_rasterization_post_depth_coverage =
      other._conservative_rasterization_post_depth_coverage;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_conservative_rasterization_properties_ext&
  operator=(
    physical_device_conservative_rasterization_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _primitive_overestimation_size =
      std::move(other._primitive_overestimation_size);
    _max_extra_primitive_overestimation_size =
      std::move(other._max_extra_primitive_overestimation_size);
    _extra_primitive_overestimation_size_granularity =
      std::move(other._extra_primitive_overestimation_size_granularity);
    _primitive_underestimation = std::move(other._primitive_underestimation);
    _conservative_point_and_line_rasterization =
      std::move(other._conservative_point_and_line_rasterization);
    _degenerate_triangles_rasterized =
      std::move(other._degenerate_triangles_rasterized);
    _degenerate_lines_rasterized =
      std::move(other._degenerate_lines_rasterized);
    _fully_covered_fragment_shader_input_variable =
      std::move(other._fully_covered_fragment_shader_input_variable);
    _conservative_rasterization_post_depth_coverage =
      std::move(other._conservative_rasterization_post_depth_coverage);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceConservativeRasterizationPropertiesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceConservativeRasterizationPropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  float& primitive_overestimation_size()
  {
    return _primitive_overestimation_size;
  }

  constexpr const float& primitive_overestimation_size() const
  {
    return _primitive_overestimation_size;
  }

  void primitive_overestimation_size(float new_primitive_overestimation_size)
  {
    _primitive_overestimation_size = new_primitive_overestimation_size;
  }

  float& max_extra_primitive_overestimation_size()
  {
    return _max_extra_primitive_overestimation_size;
  }

  constexpr const float& max_extra_primitive_overestimation_size() const
  {
    return _max_extra_primitive_overestimation_size;
  }

  void max_extra_primitive_overestimation_size(
    float new_max_extra_primitive_overestimation_size)
  {
    _max_extra_primitive_overestimation_size =
      new_max_extra_primitive_overestimation_size;
  }

  float& extra_primitive_overestimation_size_granularity()
  {
    return _extra_primitive_overestimation_size_granularity;
  }

  constexpr const float& extra_primitive_overestimation_size_granularity() const
  {
    return _extra_primitive_overestimation_size_granularity;
  }

  void extra_primitive_overestimation_size_granularity(
    float new_extra_primitive_overestimation_size_granularity)
  {
    _extra_primitive_overestimation_size_granularity =
      new_extra_primitive_overestimation_size_granularity;
  }

  VkBool32& primitive_underestimation()
  {
    return _primitive_underestimation;
  }

  constexpr const VkBool32& primitive_underestimation() const
  {
    return _primitive_underestimation;
  }

  void primitive_underestimation(VkBool32 new_primitive_underestimation)
  {
    _primitive_underestimation = new_primitive_underestimation;
  }

  VkBool32& conservative_point_and_line_rasterization()
  {
    return _conservative_point_and_line_rasterization;
  }

  constexpr const VkBool32& conservative_point_and_line_rasterization() const
  {
    return _conservative_point_and_line_rasterization;
  }

  void conservative_point_and_line_rasterization(
    VkBool32 new_conservative_point_and_line_rasterization)
  {
    _conservative_point_and_line_rasterization =
      new_conservative_point_and_line_rasterization;
  }

  VkBool32& degenerate_triangles_rasterized()
  {
    return _degenerate_triangles_rasterized;
  }

  constexpr const VkBool32& degenerate_triangles_rasterized() const
  {
    return _degenerate_triangles_rasterized;
  }

  void degenerate_triangles_rasterized(
    VkBool32 new_degenerate_triangles_rasterized)
  {
    _degenerate_triangles_rasterized = new_degenerate_triangles_rasterized;
  }

  VkBool32& degenerate_lines_rasterized()
  {
    return _degenerate_lines_rasterized;
  }

  constexpr const VkBool32& degenerate_lines_rasterized() const
  {
    return _degenerate_lines_rasterized;
  }

  void degenerate_lines_rasterized(VkBool32 new_degenerate_lines_rasterized)
  {
    _degenerate_lines_rasterized = new_degenerate_lines_rasterized;
  }

  VkBool32& fully_covered_fragment_shader_input_variable()
  {
    return _fully_covered_fragment_shader_input_variable;
  }

  constexpr const VkBool32& fully_covered_fragment_shader_input_variable() const
  {
    return _fully_covered_fragment_shader_input_variable;
  }

  void fully_covered_fragment_shader_input_variable(
    VkBool32 new_fully_covered_fragment_shader_input_variable)
  {
    _fully_covered_fragment_shader_input_variable =
      new_fully_covered_fragment_shader_input_variable;
  }

  VkBool32& conservative_rasterization_post_depth_coverage()
  {
    return _conservative_rasterization_post_depth_coverage;
  }

  constexpr const VkBool32& conservative_rasterization_post_depth_coverage()
    const
  {
    return _conservative_rasterization_post_depth_coverage;
  }

  void conservative_rasterization_post_depth_coverage(
    VkBool32 new_conservative_rasterization_post_depth_coverage)
  {
    _conservative_rasterization_post_depth_coverage =
      new_conservative_rasterization_post_depth_coverage;
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    physical_device_conservative_rasterization_properties_ext;
  /// Pointer to next structure
  void* _next = nullptr;
  /// The size in pixels the primitive is enlarged at each edge during
  /// conservative rasterization
  float _primitive_overestimation_size = 0.0f;
  /// The maximum additional overestimation the client can specify in the
  /// pipeline state
  float _max_extra_primitive_overestimation_size = 0.0f;
  /// The granularity of extra overestimation sizes the implementations supports
  /// between 0 and maxExtraOverestimationSize
  float _extra_primitive_overestimation_size_granularity = 0.0f;
  /// true if the implementation supports conservative rasterization
  /// underestimation mode
  VkBool32 _primitive_underestimation = VK_FALSE;
  /// true if conservative rasterization also applies to points and lines
  VkBool32 _conservative_point_and_line_rasterization = VK_FALSE;
  /// true if degenerate triangles (those with zero area after snap) are
  /// rasterized
  VkBool32 _degenerate_triangles_rasterized = VK_FALSE;
  /// true if degenerate lines (those with zero length after snap) are
  /// rasterized
  VkBool32 _degenerate_lines_rasterized = VK_FALSE;
  /// true if the implementation supports the FullyCoveredEXT SPIR-V builtin
  /// fragment shader input variable
  VkBool32 _fully_covered_fragment_shader_input_variable = VK_FALSE;
  /// true if the implementation supports both conservative rasterization and
  /// post depth coverage sample coverage mask
  VkBool32 _conservative_rasterization_post_depth_coverage = VK_FALSE;
};
static_assert(
  sizeof(physical_device_conservative_rasterization_properties_ext) ==
    sizeof(::VkPhysicalDeviceConservativeRasterizationPropertiesEXT),
  "struct and wrapper have different size!");

using pipeline_rasterization_conservative_state_create_flags_ext = VkFlags;
enum class conservative_rasterization_mode_ext
{
  /// @see VK_CONSERVATIVE_RASTERIZATION_MODE_DISABLED_EXT
  conservative_rasterization_mode_disabled_ext = 0,
  /// @see VK_CONSERVATIVE_RASTERIZATION_MODE_OVERESTIMATE_EXT
  conservative_rasterization_mode_overestimate_ext = 1,
  /// @see VK_CONSERVATIVE_RASTERIZATION_MODE_UNDERESTIMATE_EXT
  conservative_rasterization_mode_underestimate_ext = 2,
};

/// Enhanced replacement type for
/// VkPipelineRasterizationConservativeStateCreateInfoEXT.
class pipeline_rasterization_conservative_state_create_info_ext
{
public:
  /// Default constructor.
  constexpr pipeline_rasterization_conservative_state_create_info_ext() =
    default;

  /// Constructor.
  constexpr pipeline_rasterization_conservative_state_create_info_ext(
    const void* initial_next,
    vk::pipeline_rasterization_conservative_state_create_flags_ext
      initial_flags,
    vk::conservative_rasterization_mode_ext
      initial_conservative_rasterization_mode,
    float initial_extra_primitive_overestimation_size) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _conservative_rasterization_mode(
      std::move(initial_conservative_rasterization_mode)),
    _extra_primitive_overestimation_size(
      std::move(initial_extra_primitive_overestimation_size))
  {
  }

  /// Copy constructor.
  constexpr pipeline_rasterization_conservative_state_create_info_ext(
    const pipeline_rasterization_conservative_state_create_info_ext&
      other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _conservative_rasterization_mode(other._conservative_rasterization_mode),
    _extra_primitive_overestimation_size(
      other._extra_primitive_overestimation_size)
  {
  }

  /// Move constructor.
  constexpr pipeline_rasterization_conservative_state_create_info_ext(
    pipeline_rasterization_conservative_state_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _conservative_rasterization_mode(
      std::move(other._conservative_rasterization_mode)),
    _extra_primitive_overestimation_size(
      std::move(other._extra_primitive_overestimation_size))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_rasterization_conservative_state_create_info_ext&
  operator=(const pipeline_rasterization_conservative_state_create_info_ext&
              other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _conservative_rasterization_mode = other._conservative_rasterization_mode;
    _extra_primitive_overestimation_size =
      other._extra_primitive_overestimation_size;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_rasterization_conservative_state_create_info_ext&
  operator=(
    pipeline_rasterization_conservative_state_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _conservative_rasterization_mode =
      std::move(other._conservative_rasterization_mode);
    _extra_primitive_overestimation_size =
      std::move(other._extra_primitive_overestimation_size);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineRasterizationConservativeStateCreateInfoEXT&() const
  {
    return *reinterpret_cast<
      const VkPipelineRasterizationConservativeStateCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_rasterization_conservative_state_create_flags_ext& flags()
  {
    return _flags;
  }

  constexpr const vk::
    pipeline_rasterization_conservative_state_create_flags_ext&
    flags() const
  {
    return _flags;
  }

  void flags(
    vk::pipeline_rasterization_conservative_state_create_flags_ext new_flags)
  {
    _flags = new_flags;
  }

  vk::conservative_rasterization_mode_ext& conservative_rasterization_mode()
  {
    return _conservative_rasterization_mode;
  }

  constexpr const vk::conservative_rasterization_mode_ext&
  conservative_rasterization_mode() const
  {
    return _conservative_rasterization_mode;
  }

  void conservative_rasterization_mode(
    vk::conservative_rasterization_mode_ext new_conservative_rasterization_mode)
  {
    _conservative_rasterization_mode = new_conservative_rasterization_mode;
  }

  float& extra_primitive_overestimation_size()
  {
    return _extra_primitive_overestimation_size;
  }

  constexpr const float& extra_primitive_overestimation_size() const
  {
    return _extra_primitive_overestimation_size;
  }

  void extra_primitive_overestimation_size(
    float new_extra_primitive_overestimation_size)
  {
    _extra_primitive_overestimation_size =
      new_extra_primitive_overestimation_size;
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    pipeline_rasterization_conservative_state_create_info_ext;
  /// Pointer to next structure
  const void* _next = nullptr;
  /// Reserved
  vk::pipeline_rasterization_conservative_state_create_flags_ext _flags = 0;
  /// Conservative rasterization mode
  vk::conservative_rasterization_mode_ext _conservative_rasterization_mode =
    vk::conservative_rasterization_mode_ext::
      conservative_rasterization_mode_disabled_ext;
  /// Extra overestimation to add to the primitive
  float _extra_primitive_overestimation_size = 0.0f;
};
static_assert(
  sizeof(pipeline_rasterization_conservative_state_create_info_ext) ==
    sizeof(::VkPipelineRasterizationConservativeStateCreateInfoEXT),
  "struct and wrapper have different size!");

/// Enhanced replacement type for VkXYColorEXT.
class xycolor_ext
{
public:
  /// Default constructor.
  constexpr xycolor_ext() = default;

  /// Constructor.
  constexpr xycolor_ext(float initial_x, float initial_y) noexcept
  : _x(std::move(initial_x)), _y(std::move(initial_y))
  {
  }

  /// Copy constructor.
  constexpr xycolor_ext(const xycolor_ext& other) = default;

  /// Move constructor.
  constexpr xycolor_ext(xycolor_ext&& other) = default;

  /// Copy assignment operator.
  constexpr xycolor_ext& operator=(const xycolor_ext& other) = default;

  /// Move assignment operator.
  constexpr xycolor_ext& operator=(xycolor_ext&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkXYColorEXT&() const
  {
    return *reinterpret_cast<const VkXYColorEXT*>(this);
  }

  float& x()
  {
    return _x;
  }

  constexpr const float& x() const
  {
    return _x;
  }

  void x(float new_x)
  {
    _x = new_x;
  }

  float& y()
  {
    return _y;
  }

  constexpr const float& y() const
  {
    return _y;
  }

  void y(float new_y)
  {
    _y = new_y;
  }

private:
  float _x = 0.0f;
  float _y = 0.0f;
};
static_assert(sizeof(xycolor_ext) == sizeof(::VkXYColorEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkHdrMetadataEXT.
class hdr_metadata_ext
{
public:
  /// Default constructor.
  constexpr hdr_metadata_ext() = default;

  /// Constructor.
  constexpr hdr_metadata_ext(
    const void* initial_next, vk::xycolor_ext initial_display_primary_red,
    vk::xycolor_ext initial_display_primary_green,
    vk::xycolor_ext initial_display_primary_blue,
    vk::xycolor_ext initial_white_point, float initial_max_luminance,
    float initial_min_luminance, float initial_max_content_light_level,
    float initial_max_frame_average_light_level) noexcept
  : _next(std::move(initial_next)),
    _display_primary_red(std::move(initial_display_primary_red)),
    _display_primary_green(std::move(initial_display_primary_green)),
    _display_primary_blue(std::move(initial_display_primary_blue)),
    _white_point(std::move(initial_white_point)),
    _max_luminance(std::move(initial_max_luminance)),
    _min_luminance(std::move(initial_min_luminance)),
    _max_content_light_level(std::move(initial_max_content_light_level)),
    _max_frame_average_light_level(
      std::move(initial_max_frame_average_light_level))
  {
  }

  /// Copy constructor.
  constexpr hdr_metadata_ext(const hdr_metadata_ext& other) noexcept
  : _next(other._next),
    _display_primary_red(other._display_primary_red),
    _display_primary_green(other._display_primary_green),
    _display_primary_blue(other._display_primary_blue),
    _white_point(other._white_point),
    _max_luminance(other._max_luminance),
    _min_luminance(other._min_luminance),
    _max_content_light_level(other._max_content_light_level),
    _max_frame_average_light_level(other._max_frame_average_light_level)
  {
  }

  /// Move constructor.
  constexpr hdr_metadata_ext(hdr_metadata_ext&& other) noexcept
  : _next(std::move(other._next)),
    _display_primary_red(std::move(other._display_primary_red)),
    _display_primary_green(std::move(other._display_primary_green)),
    _display_primary_blue(std::move(other._display_primary_blue)),
    _white_point(std::move(other._white_point)),
    _max_luminance(std::move(other._max_luminance)),
    _min_luminance(std::move(other._min_luminance)),
    _max_content_light_level(std::move(other._max_content_light_level)),
    _max_frame_average_light_level(
      std::move(other._max_frame_average_light_level))
  {
  }

  /// Copy assignment operator.
  constexpr hdr_metadata_ext& operator=(const hdr_metadata_ext& other) noexcept
  {
    _next = other._next;
    _display_primary_red = other._display_primary_red;
    _display_primary_green = other._display_primary_green;
    _display_primary_blue = other._display_primary_blue;
    _white_point = other._white_point;
    _max_luminance = other._max_luminance;
    _min_luminance = other._min_luminance;
    _max_content_light_level = other._max_content_light_level;
    _max_frame_average_light_level = other._max_frame_average_light_level;
    return *this;
  }

  /// Move assignment operator.
  constexpr hdr_metadata_ext& operator=(hdr_metadata_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _display_primary_red = std::move(other._display_primary_red);
    _display_primary_green = std::move(other._display_primary_green);
    _display_primary_blue = std::move(other._display_primary_blue);
    _white_point = std::move(other._white_point);
    _max_luminance = std::move(other._max_luminance);
    _min_luminance = std::move(other._min_luminance);
    _max_content_light_level = std::move(other._max_content_light_level);
    _max_frame_average_light_level =
      std::move(other._max_frame_average_light_level);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkHdrMetadataEXT&() const
  {
    return *reinterpret_cast<const VkHdrMetadataEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::xycolor_ext& display_primary_red()
  {
    return _display_primary_red;
  }

  constexpr const vk::xycolor_ext& display_primary_red() const
  {
    return _display_primary_red;
  }

  void display_primary_red(vk::xycolor_ext new_display_primary_red)
  {
    _display_primary_red = new_display_primary_red;
  }

  vk::xycolor_ext& display_primary_green()
  {
    return _display_primary_green;
  }

  constexpr const vk::xycolor_ext& display_primary_green() const
  {
    return _display_primary_green;
  }

  void display_primary_green(vk::xycolor_ext new_display_primary_green)
  {
    _display_primary_green = new_display_primary_green;
  }

  vk::xycolor_ext& display_primary_blue()
  {
    return _display_primary_blue;
  }

  constexpr const vk::xycolor_ext& display_primary_blue() const
  {
    return _display_primary_blue;
  }

  void display_primary_blue(vk::xycolor_ext new_display_primary_blue)
  {
    _display_primary_blue = new_display_primary_blue;
  }

  vk::xycolor_ext& white_point()
  {
    return _white_point;
  }

  constexpr const vk::xycolor_ext& white_point() const
  {
    return _white_point;
  }

  void white_point(vk::xycolor_ext new_white_point)
  {
    _white_point = new_white_point;
  }

  float& max_luminance()
  {
    return _max_luminance;
  }

  constexpr const float& max_luminance() const
  {
    return _max_luminance;
  }

  void max_luminance(float new_max_luminance)
  {
    _max_luminance = new_max_luminance;
  }

  float& min_luminance()
  {
    return _min_luminance;
  }

  constexpr const float& min_luminance() const
  {
    return _min_luminance;
  }

  void min_luminance(float new_min_luminance)
  {
    _min_luminance = new_min_luminance;
  }

  float& max_content_light_level()
  {
    return _max_content_light_level;
  }

  constexpr const float& max_content_light_level() const
  {
    return _max_content_light_level;
  }

  void max_content_light_level(float new_max_content_light_level)
  {
    _max_content_light_level = new_max_content_light_level;
  }

  float& max_frame_average_light_level()
  {
    return _max_frame_average_light_level;
  }

  constexpr const float& max_frame_average_light_level() const
  {
    return _max_frame_average_light_level;
  }

  void max_frame_average_light_level(float new_max_frame_average_light_level)
  {
    _max_frame_average_light_level = new_max_frame_average_light_level;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::hdr_metadata_ext;
  const void* _next = nullptr;
  /// Display primary's Red
  vk::xycolor_ext _display_primary_red = vk::xycolor_ext{};
  /// Display primary's Green
  vk::xycolor_ext _display_primary_green = vk::xycolor_ext{};
  /// Display primary's Blue
  vk::xycolor_ext _display_primary_blue = vk::xycolor_ext{};
  /// Display primary's Blue
  vk::xycolor_ext _white_point = vk::xycolor_ext{};
  /// Display maximum luminance
  float _max_luminance = 0.0f;
  /// Display minimum luminance
  float _min_luminance = 0.0f;
  /// Content maximum luminance
  float _max_content_light_level = 0.0f;
  float _max_frame_average_light_level = 0.0f;
};
static_assert(sizeof(hdr_metadata_ext) == sizeof(::VkHdrMetadataEXT),
              "struct and wrapper have different size!");

inline void set_hdr_metadata_ext(VkDevice device, uint32_t swapchain_count,
                                 const VkSwapchainKHR* swapchains,
                                 const vk::hdr_metadata_ext* metadata)
{
  vkSetHdrMetadataEXT(static_cast<VkDevice>(device),
                      static_cast<uint32_t>(swapchain_count),
                      reinterpret_cast<const VkSwapchainKHR*>(swapchains),
                      reinterpret_cast<const VkHdrMetadataEXT*>(metadata));
}

/// Enhanced replacement type for VkAttachmentDescription2KHR.
class attachment_description_2_khr
{
public:
  /// Default constructor.
  constexpr attachment_description_2_khr() = default;

  /// Constructor.
  constexpr attachment_description_2_khr(
    const void* initial_next, vk::attachment_description_flags initial_flags,
    vk::format initial_format, vk::sample_count_flag initial_samples,
    vk::attachment_load_op initial_load_op,
    vk::attachment_store_op initial_store_op,
    vk::attachment_load_op initial_stencil_load_op,
    vk::attachment_store_op initial_stencil_store_op,
    vk::image_layout initial_initial_layout,
    vk::image_layout initial_final_layout) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _format(std::move(initial_format)),
    _samples(std::move(initial_samples)),
    _load_op(std::move(initial_load_op)),
    _store_op(std::move(initial_store_op)),
    _stencil_load_op(std::move(initial_stencil_load_op)),
    _stencil_store_op(std::move(initial_stencil_store_op)),
    _initial_layout(std::move(initial_initial_layout)),
    _final_layout(std::move(initial_final_layout))
  {
  }

  /// Copy constructor.
  constexpr attachment_description_2_khr(
    const attachment_description_2_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _format(other._format),
    _samples(other._samples),
    _load_op(other._load_op),
    _store_op(other._store_op),
    _stencil_load_op(other._stencil_load_op),
    _stencil_store_op(other._stencil_store_op),
    _initial_layout(other._initial_layout),
    _final_layout(other._final_layout)
  {
  }

  /// Move constructor.
  constexpr attachment_description_2_khr(
    attachment_description_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _format(std::move(other._format)),
    _samples(std::move(other._samples)),
    _load_op(std::move(other._load_op)),
    _store_op(std::move(other._store_op)),
    _stencil_load_op(std::move(other._stencil_load_op)),
    _stencil_store_op(std::move(other._stencil_store_op)),
    _initial_layout(std::move(other._initial_layout)),
    _final_layout(std::move(other._final_layout))
  {
  }

  /// Copy assignment operator.
  constexpr attachment_description_2_khr& operator=(
    const attachment_description_2_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _format = other._format;
    _samples = other._samples;
    _load_op = other._load_op;
    _store_op = other._store_op;
    _stencil_load_op = other._stencil_load_op;
    _stencil_store_op = other._stencil_store_op;
    _initial_layout = other._initial_layout;
    _final_layout = other._final_layout;
    return *this;
  }

  /// Move assignment operator.
  constexpr attachment_description_2_khr& operator=(
    attachment_description_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _format = std::move(other._format);
    _samples = std::move(other._samples);
    _load_op = std::move(other._load_op);
    _store_op = std::move(other._store_op);
    _stencil_load_op = std::move(other._stencil_load_op);
    _stencil_store_op = std::move(other._stencil_store_op);
    _initial_layout = std::move(other._initial_layout);
    _final_layout = std::move(other._final_layout);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkAttachmentDescription2KHR&() const
  {
    return *reinterpret_cast<const VkAttachmentDescription2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::attachment_description_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::attachment_description_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::attachment_description_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  vk::sample_count_flag& samples()
  {
    return _samples;
  }

  constexpr const vk::sample_count_flag& samples() const
  {
    return _samples;
  }

  void samples(vk::sample_count_flag new_samples)
  {
    _samples = new_samples;
  }

  vk::attachment_load_op& load_op()
  {
    return _load_op;
  }

  constexpr const vk::attachment_load_op& load_op() const
  {
    return _load_op;
  }

  void load_op(vk::attachment_load_op new_load_op)
  {
    _load_op = new_load_op;
  }

  vk::attachment_store_op& store_op()
  {
    return _store_op;
  }

  constexpr const vk::attachment_store_op& store_op() const
  {
    return _store_op;
  }

  void store_op(vk::attachment_store_op new_store_op)
  {
    _store_op = new_store_op;
  }

  vk::attachment_load_op& stencil_load_op()
  {
    return _stencil_load_op;
  }

  constexpr const vk::attachment_load_op& stencil_load_op() const
  {
    return _stencil_load_op;
  }

  void stencil_load_op(vk::attachment_load_op new_stencil_load_op)
  {
    _stencil_load_op = new_stencil_load_op;
  }

  vk::attachment_store_op& stencil_store_op()
  {
    return _stencil_store_op;
  }

  constexpr const vk::attachment_store_op& stencil_store_op() const
  {
    return _stencil_store_op;
  }

  void stencil_store_op(vk::attachment_store_op new_stencil_store_op)
  {
    _stencil_store_op = new_stencil_store_op;
  }

  vk::image_layout& initial_layout()
  {
    return _initial_layout;
  }

  constexpr const vk::image_layout& initial_layout() const
  {
    return _initial_layout;
  }

  void initial_layout(vk::image_layout new_initial_layout)
  {
    _initial_layout = new_initial_layout;
  }

  vk::image_layout& final_layout()
  {
    return _final_layout;
  }

  constexpr const vk::image_layout& final_layout() const
  {
    return _final_layout;
  }

  void final_layout(vk::image_layout new_final_layout)
  {
    _final_layout = new_final_layout;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::attachment_description_2_khr;
  const void* _next = nullptr;
  vk::attachment_description_flags _flags =
    vk::attachment_description_flag::none;
  vk::format _format = vk::format::undefined;
  vk::sample_count_flag _samples = vk::sample_count_flag::none;
  /// Load operation for color or depth data
  vk::attachment_load_op _load_op = vk::attachment_load_op::load;
  /// Store operation for color or depth data
  vk::attachment_store_op _store_op = vk::attachment_store_op::store;
  /// Load operation for stencil data
  vk::attachment_load_op _stencil_load_op = vk::attachment_load_op::load;
  /// Store operation for stencil data
  vk::attachment_store_op _stencil_store_op = vk::attachment_store_op::store;
  vk::image_layout _initial_layout = vk::image_layout::undefined;
  vk::image_layout _final_layout = vk::image_layout::undefined;
};
static_assert(sizeof(attachment_description_2_khr) ==
                sizeof(::VkAttachmentDescription2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkAttachmentReference2KHR.
class attachment_reference_2_khr
{
public:
  /// Default constructor.
  constexpr attachment_reference_2_khr() = default;

  /// Constructor.
  constexpr attachment_reference_2_khr(
    const void* initial_next, uint32_t initial_attachment,
    vk::image_layout initial_layout,
    vk::image_aspect_flags initial_aspect_mask) noexcept
  : _next(std::move(initial_next)),
    _attachment(std::move(initial_attachment)),
    _layout(std::move(initial_layout)),
    _aspect_mask(std::move(initial_aspect_mask))
  {
  }

  /// Copy constructor.
  constexpr attachment_reference_2_khr(
    const attachment_reference_2_khr& other) noexcept
  : _next(other._next),
    _attachment(other._attachment),
    _layout(other._layout),
    _aspect_mask(other._aspect_mask)
  {
  }

  /// Move constructor.
  constexpr attachment_reference_2_khr(
    attachment_reference_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _attachment(std::move(other._attachment)),
    _layout(std::move(other._layout)),
    _aspect_mask(std::move(other._aspect_mask))
  {
  }

  /// Copy assignment operator.
  constexpr attachment_reference_2_khr& operator=(
    const attachment_reference_2_khr& other) noexcept
  {
    _next = other._next;
    _attachment = other._attachment;
    _layout = other._layout;
    _aspect_mask = other._aspect_mask;
    return *this;
  }

  /// Move assignment operator.
  constexpr attachment_reference_2_khr& operator=(
    attachment_reference_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _attachment = std::move(other._attachment);
    _layout = std::move(other._layout);
    _aspect_mask = std::move(other._aspect_mask);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkAttachmentReference2KHR&() const
  {
    return *reinterpret_cast<const VkAttachmentReference2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& attachment()
  {
    return _attachment;
  }

  constexpr const uint32_t& attachment() const
  {
    return _attachment;
  }

  void attachment(uint32_t new_attachment)
  {
    _attachment = new_attachment;
  }

  vk::image_layout& layout()
  {
    return _layout;
  }

  constexpr const vk::image_layout& layout() const
  {
    return _layout;
  }

  void layout(vk::image_layout new_layout)
  {
    _layout = new_layout;
  }

  vk::image_aspect_flags& aspect_mask()
  {
    return _aspect_mask;
  }

  constexpr const vk::image_aspect_flags& aspect_mask() const
  {
    return _aspect_mask;
  }

  void aspect_mask(vk::image_aspect_flags new_aspect_mask)
  {
    _aspect_mask = new_aspect_mask;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::attachment_reference_2_khr;
  const void* _next = nullptr;
  uint32_t _attachment = 0;
  vk::image_layout _layout = vk::image_layout::undefined;
  vk::image_aspect_flags _aspect_mask = vk::image_aspect_flag::none;
};
static_assert(sizeof(attachment_reference_2_khr) ==
                sizeof(::VkAttachmentReference2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSubpassDescription2KHR.
class subpass_description_2_khr
{
public:
  /// Default constructor.
  constexpr subpass_description_2_khr() = default;

  /// Constructor.
  constexpr subpass_description_2_khr(
    const void* initial_next, vk::subpass_description_flags initial_flags,
    vk::pipeline_bind_point initial_pipeline_bind_point,
    uint32_t initial_view_mask, uint32_t initial_input_attachment_count,
    const vk::attachment_reference_2_khr* initial_input_attachments,
    uint32_t initial_color_attachment_count,
    const vk::attachment_reference_2_khr* initial_color_attachments,
    const vk::attachment_reference_2_khr* initial_resolve_attachments,
    const vk::attachment_reference_2_khr* initial_depth_stencil_attachment,
    uint32_t initial_preserve_attachment_count,
    const uint32_t* initial_preserve_attachments) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _pipeline_bind_point(std::move(initial_pipeline_bind_point)),
    _view_mask(std::move(initial_view_mask)),
    _input_attachment_count(std::move(initial_input_attachment_count)),
    _input_attachments(std::move(initial_input_attachments)),
    _color_attachment_count(std::move(initial_color_attachment_count)),
    _color_attachments(std::move(initial_color_attachments)),
    _resolve_attachments(std::move(initial_resolve_attachments)),
    _depth_stencil_attachment(std::move(initial_depth_stencil_attachment)),
    _preserve_attachment_count(std::move(initial_preserve_attachment_count)),
    _preserve_attachments(std::move(initial_preserve_attachments))
  {
  }

  /// Copy constructor.
  constexpr subpass_description_2_khr(
    const subpass_description_2_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _pipeline_bind_point(other._pipeline_bind_point),
    _view_mask(other._view_mask),
    _input_attachment_count(other._input_attachment_count),
    _input_attachments(other._input_attachments),
    _color_attachment_count(other._color_attachment_count),
    _color_attachments(other._color_attachments),
    _resolve_attachments(other._resolve_attachments),
    _depth_stencil_attachment(other._depth_stencil_attachment),
    _preserve_attachment_count(other._preserve_attachment_count),
    _preserve_attachments(other._preserve_attachments)
  {
  }

  /// Move constructor.
  constexpr subpass_description_2_khr(
    subpass_description_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _pipeline_bind_point(std::move(other._pipeline_bind_point)),
    _view_mask(std::move(other._view_mask)),
    _input_attachment_count(std::move(other._input_attachment_count)),
    _input_attachments(std::move(other._input_attachments)),
    _color_attachment_count(std::move(other._color_attachment_count)),
    _color_attachments(std::move(other._color_attachments)),
    _resolve_attachments(std::move(other._resolve_attachments)),
    _depth_stencil_attachment(std::move(other._depth_stencil_attachment)),
    _preserve_attachment_count(std::move(other._preserve_attachment_count)),
    _preserve_attachments(std::move(other._preserve_attachments))
  {
  }

  /// Copy assignment operator.
  constexpr subpass_description_2_khr& operator=(
    const subpass_description_2_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _pipeline_bind_point = other._pipeline_bind_point;
    _view_mask = other._view_mask;
    _input_attachment_count = other._input_attachment_count;
    _input_attachments = other._input_attachments;
    _color_attachment_count = other._color_attachment_count;
    _color_attachments = other._color_attachments;
    _resolve_attachments = other._resolve_attachments;
    _depth_stencil_attachment = other._depth_stencil_attachment;
    _preserve_attachment_count = other._preserve_attachment_count;
    _preserve_attachments = other._preserve_attachments;
    return *this;
  }

  /// Move assignment operator.
  constexpr subpass_description_2_khr& operator=(
    subpass_description_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _pipeline_bind_point = std::move(other._pipeline_bind_point);
    _view_mask = std::move(other._view_mask);
    _input_attachment_count = std::move(other._input_attachment_count);
    _input_attachments = std::move(other._input_attachments);
    _color_attachment_count = std::move(other._color_attachment_count);
    _color_attachments = std::move(other._color_attachments);
    _resolve_attachments = std::move(other._resolve_attachments);
    _depth_stencil_attachment = std::move(other._depth_stencil_attachment);
    _preserve_attachment_count = std::move(other._preserve_attachment_count);
    _preserve_attachments = std::move(other._preserve_attachments);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSubpassDescription2KHR&() const
  {
    return *reinterpret_cast<const VkSubpassDescription2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::subpass_description_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::subpass_description_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::subpass_description_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::pipeline_bind_point& pipeline_bind_point()
  {
    return _pipeline_bind_point;
  }

  constexpr const vk::pipeline_bind_point& pipeline_bind_point() const
  {
    return _pipeline_bind_point;
  }

  void pipeline_bind_point(vk::pipeline_bind_point new_pipeline_bind_point)
  {
    _pipeline_bind_point = new_pipeline_bind_point;
  }

  uint32_t& view_mask()
  {
    return _view_mask;
  }

  constexpr const uint32_t& view_mask() const
  {
    return _view_mask;
  }

  void view_mask(uint32_t new_view_mask)
  {
    _view_mask = new_view_mask;
  }

  uint32_t& input_attachment_count()
  {
    return _input_attachment_count;
  }

  constexpr const uint32_t& input_attachment_count() const
  {
    return _input_attachment_count;
  }

  void input_attachment_count(uint32_t new_input_attachment_count)
  {
    _input_attachment_count = new_input_attachment_count;
  }

  const vk::attachment_reference_2_khr* input_attachments()
  {
    return _input_attachments;
  }

  constexpr const vk::attachment_reference_2_khr* input_attachments() const
  {
    return _input_attachments;
  }

  void input_attachments(
    const vk::attachment_reference_2_khr* new_input_attachments)
  {
    _input_attachments = new_input_attachments;
  }

  template <std::size_t Count>
  void input_attachments(const std::array<vk::attachment_reference_2_khr,
                                          Count>& new_input_attachments)
  {
    _input_attachment_count =
      static_cast<uint32_t>(new_input_attachments.size());
    _input_attachments = new_input_attachments.data();
  }

  void input_attachments(
    const std::vector<vk::attachment_reference_2_khr>& new_input_attachments)
  {
    _input_attachment_count =
      static_cast<uint32_t>(new_input_attachments.size());
    _input_attachments = new_input_attachments.data();
  }

  uint32_t& color_attachment_count()
  {
    return _color_attachment_count;
  }

  constexpr const uint32_t& color_attachment_count() const
  {
    return _color_attachment_count;
  }

  void color_attachment_count(uint32_t new_color_attachment_count)
  {
    _color_attachment_count = new_color_attachment_count;
  }

  const vk::attachment_reference_2_khr* color_attachments()
  {
    return _color_attachments;
  }

  constexpr const vk::attachment_reference_2_khr* color_attachments() const
  {
    return _color_attachments;
  }

  void color_attachments(
    const vk::attachment_reference_2_khr* new_color_attachments)
  {
    _color_attachments = new_color_attachments;
  }

  template <std::size_t Count>
  void color_attachments(const std::array<vk::attachment_reference_2_khr,
                                          Count>& new_color_attachments)
  {
    _color_attachment_count =
      static_cast<uint32_t>(new_color_attachments.size());
    _color_attachments = new_color_attachments.data();
  }

  void color_attachments(
    const std::vector<vk::attachment_reference_2_khr>& new_color_attachments)
  {
    _color_attachment_count =
      static_cast<uint32_t>(new_color_attachments.size());
    _color_attachments = new_color_attachments.data();
  }

  const vk::attachment_reference_2_khr* resolve_attachments()
  {
    return _resolve_attachments;
  }

  constexpr const vk::attachment_reference_2_khr* resolve_attachments() const
  {
    return _resolve_attachments;
  }

  void resolve_attachments(
    const vk::attachment_reference_2_khr* new_resolve_attachments)
  {
    _resolve_attachments = new_resolve_attachments;
  }

  template <std::size_t Count>
  void resolve_attachments(const std::array<vk::attachment_reference_2_khr,
                                            Count>& new_resolve_attachments)
  {
    _color_attachment_count =
      static_cast<uint32_t>(new_resolve_attachments.size());
    _resolve_attachments = new_resolve_attachments.data();
  }

  void resolve_attachments(
    const std::vector<vk::attachment_reference_2_khr>& new_resolve_attachments)
  {
    _color_attachment_count =
      static_cast<uint32_t>(new_resolve_attachments.size());
    _resolve_attachments = new_resolve_attachments.data();
  }

  const vk::attachment_reference_2_khr* depth_stencil_attachment()
  {
    return _depth_stencil_attachment;
  }

  constexpr const vk::attachment_reference_2_khr* depth_stencil_attachment()
    const
  {
    return _depth_stencil_attachment;
  }

  void depth_stencil_attachment(
    const vk::attachment_reference_2_khr* new_depth_stencil_attachment)
  {
    _depth_stencil_attachment = new_depth_stencil_attachment;
  }

  uint32_t& preserve_attachment_count()
  {
    return _preserve_attachment_count;
  }

  constexpr const uint32_t& preserve_attachment_count() const
  {
    return _preserve_attachment_count;
  }

  void preserve_attachment_count(uint32_t new_preserve_attachment_count)
  {
    _preserve_attachment_count = new_preserve_attachment_count;
  }

  const uint32_t* preserve_attachments()
  {
    return _preserve_attachments;
  }

  constexpr const uint32_t* preserve_attachments() const
  {
    return _preserve_attachments;
  }

  void preserve_attachments(const uint32_t* new_preserve_attachments)
  {
    _preserve_attachments = new_preserve_attachments;
  }

  template <std::size_t Count>
  void preserve_attachments(
    const std::array<uint32_t, Count>& new_preserve_attachments)
  {
    _preserve_attachment_count =
      static_cast<uint32_t>(new_preserve_attachments.size());
    _preserve_attachments = new_preserve_attachments.data();
  }

  void preserve_attachments(
    const std::vector<uint32_t>& new_preserve_attachments)
  {
    _preserve_attachment_count =
      static_cast<uint32_t>(new_preserve_attachments.size());
    _preserve_attachments = new_preserve_attachments.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::subpass_description_2_khr;
  const void* _next = nullptr;
  vk::subpass_description_flags _flags = vk::subpass_description_flag::none;
  vk::pipeline_bind_point _pipeline_bind_point =
    vk::pipeline_bind_point::graphics;
  uint32_t _view_mask = 0;
  uint32_t _input_attachment_count = 0;
  const vk::attachment_reference_2_khr* _input_attachments = nullptr;
  uint32_t _color_attachment_count = 0;
  const vk::attachment_reference_2_khr* _color_attachments = nullptr;
  const vk::attachment_reference_2_khr* _resolve_attachments = nullptr;
  const vk::attachment_reference_2_khr* _depth_stencil_attachment = nullptr;
  uint32_t _preserve_attachment_count = 0;
  const uint32_t* _preserve_attachments = nullptr;
};
static_assert(sizeof(subpass_description_2_khr) ==
                sizeof(::VkSubpassDescription2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSubpassDependency2KHR.
class subpass_dependency_2_khr
{
public:
  /// Default constructor.
  constexpr subpass_dependency_2_khr() = default;

  /// Constructor.
  constexpr subpass_dependency_2_khr(
    const void* initial_next, uint32_t initial_src_subpass,
    uint32_t initial_dst_subpass,
    vk::pipeline_stage_flags initial_src_stage_mask,
    vk::pipeline_stage_flags initial_dst_stage_mask,
    vk::access_flags initial_src_access_mask,
    vk::access_flags initial_dst_access_mask,
    vk::dependency_flags initial_dependency_flags,
    int32_t initial_view_offset) noexcept
  : _next(std::move(initial_next)),
    _src_subpass(std::move(initial_src_subpass)),
    _dst_subpass(std::move(initial_dst_subpass)),
    _src_stage_mask(std::move(initial_src_stage_mask)),
    _dst_stage_mask(std::move(initial_dst_stage_mask)),
    _src_access_mask(std::move(initial_src_access_mask)),
    _dst_access_mask(std::move(initial_dst_access_mask)),
    _dependency_flags(std::move(initial_dependency_flags)),
    _view_offset(std::move(initial_view_offset))
  {
  }

  /// Copy constructor.
  constexpr subpass_dependency_2_khr(
    const subpass_dependency_2_khr& other) noexcept
  : _next(other._next),
    _src_subpass(other._src_subpass),
    _dst_subpass(other._dst_subpass),
    _src_stage_mask(other._src_stage_mask),
    _dst_stage_mask(other._dst_stage_mask),
    _src_access_mask(other._src_access_mask),
    _dst_access_mask(other._dst_access_mask),
    _dependency_flags(other._dependency_flags),
    _view_offset(other._view_offset)
  {
  }

  /// Move constructor.
  constexpr subpass_dependency_2_khr(subpass_dependency_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _src_subpass(std::move(other._src_subpass)),
    _dst_subpass(std::move(other._dst_subpass)),
    _src_stage_mask(std::move(other._src_stage_mask)),
    _dst_stage_mask(std::move(other._dst_stage_mask)),
    _src_access_mask(std::move(other._src_access_mask)),
    _dst_access_mask(std::move(other._dst_access_mask)),
    _dependency_flags(std::move(other._dependency_flags)),
    _view_offset(std::move(other._view_offset))
  {
  }

  /// Copy assignment operator.
  constexpr subpass_dependency_2_khr& operator=(
    const subpass_dependency_2_khr& other) noexcept
  {
    _next = other._next;
    _src_subpass = other._src_subpass;
    _dst_subpass = other._dst_subpass;
    _src_stage_mask = other._src_stage_mask;
    _dst_stage_mask = other._dst_stage_mask;
    _src_access_mask = other._src_access_mask;
    _dst_access_mask = other._dst_access_mask;
    _dependency_flags = other._dependency_flags;
    _view_offset = other._view_offset;
    return *this;
  }

  /// Move assignment operator.
  constexpr subpass_dependency_2_khr& operator=(
    subpass_dependency_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _src_subpass = std::move(other._src_subpass);
    _dst_subpass = std::move(other._dst_subpass);
    _src_stage_mask = std::move(other._src_stage_mask);
    _dst_stage_mask = std::move(other._dst_stage_mask);
    _src_access_mask = std::move(other._src_access_mask);
    _dst_access_mask = std::move(other._dst_access_mask);
    _dependency_flags = std::move(other._dependency_flags);
    _view_offset = std::move(other._view_offset);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSubpassDependency2KHR&() const
  {
    return *reinterpret_cast<const VkSubpassDependency2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& src_subpass()
  {
    return _src_subpass;
  }

  constexpr const uint32_t& src_subpass() const
  {
    return _src_subpass;
  }

  void src_subpass(uint32_t new_src_subpass)
  {
    _src_subpass = new_src_subpass;
  }

  uint32_t& dst_subpass()
  {
    return _dst_subpass;
  }

  constexpr const uint32_t& dst_subpass() const
  {
    return _dst_subpass;
  }

  void dst_subpass(uint32_t new_dst_subpass)
  {
    _dst_subpass = new_dst_subpass;
  }

  vk::pipeline_stage_flags& src_stage_mask()
  {
    return _src_stage_mask;
  }

  constexpr const vk::pipeline_stage_flags& src_stage_mask() const
  {
    return _src_stage_mask;
  }

  void src_stage_mask(vk::pipeline_stage_flags new_src_stage_mask)
  {
    _src_stage_mask = new_src_stage_mask;
  }

  vk::pipeline_stage_flags& dst_stage_mask()
  {
    return _dst_stage_mask;
  }

  constexpr const vk::pipeline_stage_flags& dst_stage_mask() const
  {
    return _dst_stage_mask;
  }

  void dst_stage_mask(vk::pipeline_stage_flags new_dst_stage_mask)
  {
    _dst_stage_mask = new_dst_stage_mask;
  }

  vk::access_flags& src_access_mask()
  {
    return _src_access_mask;
  }

  constexpr const vk::access_flags& src_access_mask() const
  {
    return _src_access_mask;
  }

  void src_access_mask(vk::access_flags new_src_access_mask)
  {
    _src_access_mask = new_src_access_mask;
  }

  vk::access_flags& dst_access_mask()
  {
    return _dst_access_mask;
  }

  constexpr const vk::access_flags& dst_access_mask() const
  {
    return _dst_access_mask;
  }

  void dst_access_mask(vk::access_flags new_dst_access_mask)
  {
    _dst_access_mask = new_dst_access_mask;
  }

  vk::dependency_flags& dependency_flags()
  {
    return _dependency_flags;
  }

  constexpr const vk::dependency_flags& dependency_flags() const
  {
    return _dependency_flags;
  }

  void dependency_flags(vk::dependency_flags new_dependency_flags)
  {
    _dependency_flags = new_dependency_flags;
  }

  int32_t& view_offset()
  {
    return _view_offset;
  }

  constexpr const int32_t& view_offset() const
  {
    return _view_offset;
  }

  void view_offset(int32_t new_view_offset)
  {
    _view_offset = new_view_offset;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::subpass_dependency_2_khr;
  const void* _next = nullptr;
  uint32_t _src_subpass = 0;
  uint32_t _dst_subpass = 0;
  vk::pipeline_stage_flags _src_stage_mask = vk::pipeline_stage_flag::none;
  vk::pipeline_stage_flags _dst_stage_mask = vk::pipeline_stage_flag::none;
  vk::access_flags _src_access_mask = vk::access_flag::none;
  vk::access_flags _dst_access_mask = vk::access_flag::none;
  vk::dependency_flags _dependency_flags = vk::dependency_flag::none;
  int32_t _view_offset = 0;
};
static_assert(sizeof(subpass_dependency_2_khr) ==
                sizeof(::VkSubpassDependency2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkRenderPassCreateInfo2KHR.
class render_pass_create_info_2_khr
{
public:
  /// Default constructor.
  constexpr render_pass_create_info_2_khr() = default;

  /// Constructor.
  constexpr render_pass_create_info_2_khr(
    const void* initial_next, vk::render_pass_create_flags initial_flags,
    uint32_t initial_attachment_count,
    const vk::attachment_description_2_khr* initial_attachments,
    uint32_t initial_subpass_count,
    const vk::subpass_description_2_khr* initial_subpasses,
    uint32_t initial_dependency_count,
    const vk::subpass_dependency_2_khr* initial_dependencies,
    uint32_t initial_correlated_view_mask_count,
    const uint32_t* initial_correlated_view_masks) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _attachment_count(std::move(initial_attachment_count)),
    _attachments(std::move(initial_attachments)),
    _subpass_count(std::move(initial_subpass_count)),
    _subpasses(std::move(initial_subpasses)),
    _dependency_count(std::move(initial_dependency_count)),
    _dependencies(std::move(initial_dependencies)),
    _correlated_view_mask_count(std::move(initial_correlated_view_mask_count)),
    _correlated_view_masks(std::move(initial_correlated_view_masks))
  {
  }

  /// Copy constructor.
  constexpr render_pass_create_info_2_khr(
    const render_pass_create_info_2_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _attachment_count(other._attachment_count),
    _attachments(other._attachments),
    _subpass_count(other._subpass_count),
    _subpasses(other._subpasses),
    _dependency_count(other._dependency_count),
    _dependencies(other._dependencies),
    _correlated_view_mask_count(other._correlated_view_mask_count),
    _correlated_view_masks(other._correlated_view_masks)
  {
  }

  /// Move constructor.
  constexpr render_pass_create_info_2_khr(
    render_pass_create_info_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _attachment_count(std::move(other._attachment_count)),
    _attachments(std::move(other._attachments)),
    _subpass_count(std::move(other._subpass_count)),
    _subpasses(std::move(other._subpasses)),
    _dependency_count(std::move(other._dependency_count)),
    _dependencies(std::move(other._dependencies)),
    _correlated_view_mask_count(std::move(other._correlated_view_mask_count)),
    _correlated_view_masks(std::move(other._correlated_view_masks))
  {
  }

  /// Copy assignment operator.
  constexpr render_pass_create_info_2_khr& operator=(
    const render_pass_create_info_2_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _attachment_count = other._attachment_count;
    _attachments = other._attachments;
    _subpass_count = other._subpass_count;
    _subpasses = other._subpasses;
    _dependency_count = other._dependency_count;
    _dependencies = other._dependencies;
    _correlated_view_mask_count = other._correlated_view_mask_count;
    _correlated_view_masks = other._correlated_view_masks;
    return *this;
  }

  /// Move assignment operator.
  constexpr render_pass_create_info_2_khr& operator=(
    render_pass_create_info_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _attachment_count = std::move(other._attachment_count);
    _attachments = std::move(other._attachments);
    _subpass_count = std::move(other._subpass_count);
    _subpasses = std::move(other._subpasses);
    _dependency_count = std::move(other._dependency_count);
    _dependencies = std::move(other._dependencies);
    _correlated_view_mask_count = std::move(other._correlated_view_mask_count);
    _correlated_view_masks = std::move(other._correlated_view_masks);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkRenderPassCreateInfo2KHR&() const
  {
    return *reinterpret_cast<const VkRenderPassCreateInfo2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::render_pass_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::render_pass_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::render_pass_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& attachment_count()
  {
    return _attachment_count;
  }

  constexpr const uint32_t& attachment_count() const
  {
    return _attachment_count;
  }

  void attachment_count(uint32_t new_attachment_count)
  {
    _attachment_count = new_attachment_count;
  }

  const vk::attachment_description_2_khr* attachments()
  {
    return _attachments;
  }

  constexpr const vk::attachment_description_2_khr* attachments() const
  {
    return _attachments;
  }

  void attachments(const vk::attachment_description_2_khr* new_attachments)
  {
    _attachments = new_attachments;
  }

  template <std::size_t Count>
  void attachments(
    const std::array<vk::attachment_description_2_khr, Count>& new_attachments)
  {
    _attachment_count = static_cast<uint32_t>(new_attachments.size());
    _attachments = new_attachments.data();
  }

  void attachments(
    const std::vector<vk::attachment_description_2_khr>& new_attachments)
  {
    _attachment_count = static_cast<uint32_t>(new_attachments.size());
    _attachments = new_attachments.data();
  }

  uint32_t& subpass_count()
  {
    return _subpass_count;
  }

  constexpr const uint32_t& subpass_count() const
  {
    return _subpass_count;
  }

  void subpass_count(uint32_t new_subpass_count)
  {
    _subpass_count = new_subpass_count;
  }

  const vk::subpass_description_2_khr* subpasses()
  {
    return _subpasses;
  }

  constexpr const vk::subpass_description_2_khr* subpasses() const
  {
    return _subpasses;
  }

  void subpasses(const vk::subpass_description_2_khr* new_subpasses)
  {
    _subpasses = new_subpasses;
  }

  template <std::size_t Count>
  void subpasses(
    const std::array<vk::subpass_description_2_khr, Count>& new_subpasses)
  {
    _subpass_count = static_cast<uint32_t>(new_subpasses.size());
    _subpasses = new_subpasses.data();
  }

  void subpasses(
    const std::vector<vk::subpass_description_2_khr>& new_subpasses)
  {
    _subpass_count = static_cast<uint32_t>(new_subpasses.size());
    _subpasses = new_subpasses.data();
  }

  uint32_t& dependency_count()
  {
    return _dependency_count;
  }

  constexpr const uint32_t& dependency_count() const
  {
    return _dependency_count;
  }

  void dependency_count(uint32_t new_dependency_count)
  {
    _dependency_count = new_dependency_count;
  }

  const vk::subpass_dependency_2_khr* dependencies()
  {
    return _dependencies;
  }

  constexpr const vk::subpass_dependency_2_khr* dependencies() const
  {
    return _dependencies;
  }

  void dependencies(const vk::subpass_dependency_2_khr* new_dependencies)
  {
    _dependencies = new_dependencies;
  }

  template <std::size_t Count>
  void dependencies(
    const std::array<vk::subpass_dependency_2_khr, Count>& new_dependencies)
  {
    _dependency_count = static_cast<uint32_t>(new_dependencies.size());
    _dependencies = new_dependencies.data();
  }

  void dependencies(
    const std::vector<vk::subpass_dependency_2_khr>& new_dependencies)
  {
    _dependency_count = static_cast<uint32_t>(new_dependencies.size());
    _dependencies = new_dependencies.data();
  }

  uint32_t& correlated_view_mask_count()
  {
    return _correlated_view_mask_count;
  }

  constexpr const uint32_t& correlated_view_mask_count() const
  {
    return _correlated_view_mask_count;
  }

  void correlated_view_mask_count(uint32_t new_correlated_view_mask_count)
  {
    _correlated_view_mask_count = new_correlated_view_mask_count;
  }

  const uint32_t* correlated_view_masks()
  {
    return _correlated_view_masks;
  }

  constexpr const uint32_t* correlated_view_masks() const
  {
    return _correlated_view_masks;
  }

  void correlated_view_masks(const uint32_t* new_correlated_view_masks)
  {
    _correlated_view_masks = new_correlated_view_masks;
  }

  template <std::size_t Count>
  void correlated_view_masks(
    const std::array<uint32_t, Count>& new_correlated_view_masks)
  {
    _correlated_view_mask_count =
      static_cast<uint32_t>(new_correlated_view_masks.size());
    _correlated_view_masks = new_correlated_view_masks.data();
  }

  void correlated_view_masks(
    const std::vector<uint32_t>& new_correlated_view_masks)
  {
    _correlated_view_mask_count =
      static_cast<uint32_t>(new_correlated_view_masks.size());
    _correlated_view_masks = new_correlated_view_masks.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::render_pass_create_info_2_khr;
  const void* _next = nullptr;
  vk::render_pass_create_flags _flags = vk::render_pass_create_flag::none;
  uint32_t _attachment_count = 0;
  const vk::attachment_description_2_khr* _attachments = nullptr;
  uint32_t _subpass_count = 0;
  const vk::subpass_description_2_khr* _subpasses = nullptr;
  uint32_t _dependency_count = 0;
  const vk::subpass_dependency_2_khr* _dependencies = nullptr;
  uint32_t _correlated_view_mask_count = 0;
  const uint32_t* _correlated_view_masks = nullptr;
};
static_assert(sizeof(render_pass_create_info_2_khr) ==
                sizeof(::VkRenderPassCreateInfo2KHR),
              "struct and wrapper have different size!");

inline vk::result create_render_pass_2_khr(
  VkDevice device, const vk::render_pass_create_info_2_khr* create_info,
  const vk::allocation_callbacks* allocator, VkRenderPass* render_pass)
{
  return static_cast<vk::result>(vkCreateRenderPass2KHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkRenderPassCreateInfo2KHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkRenderPass*>(render_pass)));
}

/// Enhanced replacement type for VkSubpassBeginInfoKHR.
class subpass_begin_info_khr
{
public:
  /// Default constructor.
  constexpr subpass_begin_info_khr() = default;

  /// Constructor.
  constexpr subpass_begin_info_khr(
    const void* initial_next, vk::subpass_contents initial_contents) noexcept
  : _next(std::move(initial_next)), _contents(std::move(initial_contents))
  {
  }

  /// Copy constructor.
  constexpr subpass_begin_info_khr(const subpass_begin_info_khr& other) noexcept
  : _next(other._next), _contents(other._contents)
  {
  }

  /// Move constructor.
  constexpr subpass_begin_info_khr(subpass_begin_info_khr&& other) noexcept
  : _next(std::move(other._next)), _contents(std::move(other._contents))
  {
  }

  /// Copy assignment operator.
  constexpr subpass_begin_info_khr& operator=(
    const subpass_begin_info_khr& other) noexcept
  {
    _next = other._next;
    _contents = other._contents;
    return *this;
  }

  /// Move assignment operator.
  constexpr subpass_begin_info_khr& operator=(
    subpass_begin_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _contents = std::move(other._contents);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSubpassBeginInfoKHR&() const
  {
    return *reinterpret_cast<const VkSubpassBeginInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::subpass_contents& contents()
  {
    return _contents;
  }

  constexpr const vk::subpass_contents& contents() const
  {
    return _contents;
  }

  void contents(vk::subpass_contents new_contents)
  {
    _contents = new_contents;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::subpass_begin_info_khr;
  const void* _next = nullptr;
  vk::subpass_contents _contents = vk::subpass_contents::inline_commands;
};
static_assert(sizeof(subpass_begin_info_khr) == sizeof(::VkSubpassBeginInfoKHR),
              "struct and wrapper have different size!");

inline void cmd_begin_render_pass_2_khr(
  VkCommandBuffer command_buffer,
  const vk::render_pass_begin_info* render_pass_begin,
  const vk::subpass_begin_info_khr* subpass_begin_info)
{
  vkCmdBeginRenderPass2KHR(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkRenderPassBeginInfo*>(render_pass_begin),
    reinterpret_cast<const VkSubpassBeginInfoKHR*>(subpass_begin_info));
}

/// Enhanced replacement type for VkSubpassEndInfoKHR.
class subpass_end_info_khr
{
public:
  /// Default constructor.
  constexpr subpass_end_info_khr() = default;

  /// Constructor.
  constexpr subpass_end_info_khr(const void* initial_next) noexcept
  : _next(std::move(initial_next))
  {
  }

  /// Copy constructor.
  constexpr subpass_end_info_khr(const subpass_end_info_khr& other) noexcept
  : _next(other._next)
  {
  }

  /// Move constructor.
  constexpr subpass_end_info_khr(subpass_end_info_khr&& other) noexcept
  : _next(std::move(other._next))
  {
  }

  /// Copy assignment operator.
  constexpr subpass_end_info_khr& operator=(
    const subpass_end_info_khr& other) noexcept
  {
    _next = other._next;
    return *this;
  }

  /// Move assignment operator.
  constexpr subpass_end_info_khr& operator=(
    subpass_end_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSubpassEndInfoKHR&() const
  {
    return *reinterpret_cast<const VkSubpassEndInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::subpass_end_info_khr;
  const void* _next = nullptr;
};
static_assert(sizeof(subpass_end_info_khr) == sizeof(::VkSubpassEndInfoKHR),
              "struct and wrapper have different size!");

inline void cmd_next_subpass_2_khr(
  VkCommandBuffer command_buffer,
  const vk::subpass_begin_info_khr* subpass_begin_info,
  const vk::subpass_end_info_khr* subpass_end_info)
{
  vkCmdNextSubpass2KHR(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkSubpassBeginInfoKHR*>(subpass_begin_info),
    reinterpret_cast<const VkSubpassEndInfoKHR*>(subpass_end_info));
}
inline void cmd_end_render_pass_2_khr(
  VkCommandBuffer command_buffer,
  const vk::subpass_end_info_khr* subpass_end_info)
{
  vkCmdEndRenderPass2KHR(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkSubpassEndInfoKHR*>(subpass_end_info));
}

/// Enhanced replacement type for VkSharedPresentSurfaceCapabilitiesKHR.
class shared_present_surface_capabilities_khr
{
public:
  /// Default constructor.
  constexpr shared_present_surface_capabilities_khr() = default;

  /// Constructor.
  constexpr shared_present_surface_capabilities_khr(
    void* initial_next,
    vk::image_usage_flags initial_shared_present_supported_usage_flags) noexcept
  : _next(std::move(initial_next)),
    _shared_present_supported_usage_flags(
      std::move(initial_shared_present_supported_usage_flags))
  {
  }

  /// Copy constructor.
  constexpr shared_present_surface_capabilities_khr(
    const shared_present_surface_capabilities_khr& other) noexcept
  : _next(other._next),
    _shared_present_supported_usage_flags(
      other._shared_present_supported_usage_flags)
  {
  }

  /// Move constructor.
  constexpr shared_present_surface_capabilities_khr(
    shared_present_surface_capabilities_khr&& other) noexcept
  : _next(std::move(other._next)),
    _shared_present_supported_usage_flags(
      std::move(other._shared_present_supported_usage_flags))
  {
  }

  /// Copy assignment operator.
  constexpr shared_present_surface_capabilities_khr& operator=(
    const shared_present_surface_capabilities_khr& other) noexcept
  {
    _next = other._next;
    _shared_present_supported_usage_flags =
      other._shared_present_supported_usage_flags;
    return *this;
  }

  /// Move assignment operator.
  constexpr shared_present_surface_capabilities_khr& operator=(
    shared_present_surface_capabilities_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _shared_present_supported_usage_flags =
      std::move(other._shared_present_supported_usage_flags);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSharedPresentSurfaceCapabilitiesKHR&() const
  {
    return *reinterpret_cast<const VkSharedPresentSurfaceCapabilitiesKHR*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::image_usage_flags& shared_present_supported_usage_flags()
  {
    return _shared_present_supported_usage_flags;
  }

  constexpr const vk::image_usage_flags& shared_present_supported_usage_flags()
    const
  {
    return _shared_present_supported_usage_flags;
  }

  void shared_present_supported_usage_flags(
    vk::image_usage_flags new_shared_present_supported_usage_flags)
  {
    _shared_present_supported_usage_flags =
      new_shared_present_supported_usage_flags;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::shared_present_surface_capabilities_khr;
  void* _next = nullptr;
  /// Supported image usage flags if swapchain created using a shared present
  /// mode
  vk::image_usage_flags _shared_present_supported_usage_flags =
    vk::image_usage_flag::none;
};
static_assert(sizeof(shared_present_surface_capabilities_khr) ==
                sizeof(::VkSharedPresentSurfaceCapabilitiesKHR),
              "struct and wrapper have different size!");

inline vk::result get_swapchain_status_khr(VkDevice device,
                                           VkSwapchainKHR swapchain)
{
  return static_cast<vk::result>(vkGetSwapchainStatusKHR(
    static_cast<VkDevice>(device), static_cast<VkSwapchainKHR>(swapchain)));
}

/// Enhanced replacement type for VkImportFenceFdInfoKHR.
class import_fence_fd_info_khr
{
public:
  /// Default constructor.
  constexpr import_fence_fd_info_khr() = default;

  /// Constructor.
  constexpr import_fence_fd_info_khr(
    const void* initial_next, VkFence initial_fence,
    vk::fence_import_flags initial_flags,
    vk::external_fence_handle_type_flag initial_handle_type,
    int initial_fd) noexcept
  : _next(std::move(initial_next)),
    _fence(std::move(initial_fence)),
    _flags(std::move(initial_flags)),
    _handle_type(std::move(initial_handle_type)),
    _fd(std::move(initial_fd))
  {
  }

  /// Copy constructor.
  constexpr import_fence_fd_info_khr(
    const import_fence_fd_info_khr& other) noexcept
  : _next(other._next),
    _fence(other._fence),
    _flags(other._flags),
    _handle_type(other._handle_type),
    _fd(other._fd)
  {
  }

  /// Move constructor.
  constexpr import_fence_fd_info_khr(import_fence_fd_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _fence(std::move(other._fence)),
    _flags(std::move(other._flags)),
    _handle_type(std::move(other._handle_type)),
    _fd(std::move(other._fd))
  {
  }

  /// Copy assignment operator.
  constexpr import_fence_fd_info_khr& operator=(
    const import_fence_fd_info_khr& other) noexcept
  {
    _next = other._next;
    _fence = other._fence;
    _flags = other._flags;
    _handle_type = other._handle_type;
    _fd = other._fd;
    return *this;
  }

  /// Move assignment operator.
  constexpr import_fence_fd_info_khr& operator=(
    import_fence_fd_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _fence = std::move(other._fence);
    _flags = std::move(other._flags);
    _handle_type = std::move(other._handle_type);
    _fd = std::move(other._fd);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImportFenceFdInfoKHR&() const
  {
    return *reinterpret_cast<const VkImportFenceFdInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkFence& fence()
  {
    return _fence;
  }

  constexpr const VkFence& fence() const
  {
    return _fence;
  }

  void fence(VkFence new_fence)
  {
    _fence = new_fence;
  }

  vk::fence_import_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::fence_import_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::fence_import_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::external_fence_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_fence_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_fence_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

  int& fd()
  {
    return _fd;
  }

  constexpr const int& fd() const
  {
    return _fd;
  }

  void fd(int new_fd)
  {
    _fd = new_fd;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::import_fence_fd_info_khr;
  const void* _next = nullptr;
  VkFence _fence = nullptr;
  vk::fence_import_flags _flags = vk::fence_import_flag::none;
  vk::external_fence_handle_type_flag _handle_type =
    vk::external_fence_handle_type_flag::none;
  int _fd = 0;
};
static_assert(sizeof(import_fence_fd_info_khr) ==
                sizeof(::VkImportFenceFdInfoKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkFenceGetFdInfoKHR.
class fence_get_fd_info_khr
{
public:
  /// Default constructor.
  constexpr fence_get_fd_info_khr() = default;

  /// Constructor.
  constexpr fence_get_fd_info_khr(
    const void* initial_next, VkFence initial_fence,
    vk::external_fence_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)),
    _fence(std::move(initial_fence)),
    _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr fence_get_fd_info_khr(const fence_get_fd_info_khr& other) noexcept
  : _next(other._next), _fence(other._fence), _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr fence_get_fd_info_khr(fence_get_fd_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _fence(std::move(other._fence)),
    _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr fence_get_fd_info_khr& operator=(
    const fence_get_fd_info_khr& other) noexcept
  {
    _next = other._next;
    _fence = other._fence;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr fence_get_fd_info_khr& operator=(
    fence_get_fd_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _fence = std::move(other._fence);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkFenceGetFdInfoKHR&() const
  {
    return *reinterpret_cast<const VkFenceGetFdInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkFence& fence()
  {
    return _fence;
  }

  constexpr const VkFence& fence() const
  {
    return _fence;
  }

  void fence(VkFence new_fence)
  {
    _fence = new_fence;
  }

  vk::external_fence_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_fence_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_fence_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::fence_get_fd_info_khr;
  const void* _next = nullptr;
  VkFence _fence = nullptr;
  vk::external_fence_handle_type_flag _handle_type =
    vk::external_fence_handle_type_flag::none;
};
static_assert(sizeof(fence_get_fd_info_khr) == sizeof(::VkFenceGetFdInfoKHR),
              "struct and wrapper have different size!");

inline vk::result import_fence_fd_khr(
  VkDevice device, const vk::import_fence_fd_info_khr* import_fence_fd_info)
{
  return static_cast<vk::result>(vkImportFenceFdKHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkImportFenceFdInfoKHR*>(import_fence_fd_info)));
}
inline vk::result get_fence_fd_khr(VkDevice device,
                                   const vk::fence_get_fd_info_khr* get_fd_info,
                                   int* fd)
{
  return static_cast<vk::result>(
    vkGetFenceFdKHR(static_cast<VkDevice>(device),
                    reinterpret_cast<const VkFenceGetFdInfoKHR*>(get_fd_info),
                    reinterpret_cast<int*>(fd)));
}

/// Enhanced replacement type for VkPhysicalDeviceSurfaceInfo2KHR.
class physical_device_surface_info_2_khr
{
public:
  /// Default constructor.
  constexpr physical_device_surface_info_2_khr() = default;

  /// Constructor.
  constexpr physical_device_surface_info_2_khr(
    const void* initial_next, VkSurfaceKHR initial_surface) noexcept
  : _next(std::move(initial_next)), _surface(std::move(initial_surface))
  {
  }

  /// Copy constructor.
  constexpr physical_device_surface_info_2_khr(
    const physical_device_surface_info_2_khr& other) noexcept
  : _next(other._next), _surface(other._surface)
  {
  }

  /// Move constructor.
  constexpr physical_device_surface_info_2_khr(
    physical_device_surface_info_2_khr&& other) noexcept
  : _next(std::move(other._next)), _surface(std::move(other._surface))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_surface_info_2_khr& operator=(
    const physical_device_surface_info_2_khr& other) noexcept
  {
    _next = other._next;
    _surface = other._surface;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_surface_info_2_khr& operator=(
    physical_device_surface_info_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _surface = std::move(other._surface);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceSurfaceInfo2KHR&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkSurfaceKHR& surface()
  {
    return _surface;
  }

  constexpr const VkSurfaceKHR& surface() const
  {
    return _surface;
  }

  void surface(VkSurfaceKHR new_surface)
  {
    _surface = new_surface;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_surface_info_2_khr;
  const void* _next = nullptr;
  VkSurfaceKHR _surface = nullptr;
};
static_assert(sizeof(physical_device_surface_info_2_khr) ==
                sizeof(::VkPhysicalDeviceSurfaceInfo2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSurfaceCapabilities2KHR.
class surface_capabilities_2_khr
{
public:
  /// Default constructor.
  constexpr surface_capabilities_2_khr() = default;

  /// Constructor.
  constexpr surface_capabilities_2_khr(
    void* initial_next,
    vk::surface_capabilities_khr initial_surface_capabilities) noexcept
  : _next(std::move(initial_next)),
    _surface_capabilities(std::move(initial_surface_capabilities))
  {
  }

  /// Copy constructor.
  constexpr surface_capabilities_2_khr(
    const surface_capabilities_2_khr& other) noexcept
  : _next(other._next), _surface_capabilities(other._surface_capabilities)
  {
  }

  /// Move constructor.
  constexpr surface_capabilities_2_khr(
    surface_capabilities_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _surface_capabilities(std::move(other._surface_capabilities))
  {
  }

  /// Copy assignment operator.
  constexpr surface_capabilities_2_khr& operator=(
    const surface_capabilities_2_khr& other) noexcept
  {
    _next = other._next;
    _surface_capabilities = other._surface_capabilities;
    return *this;
  }

  /// Move assignment operator.
  constexpr surface_capabilities_2_khr& operator=(
    surface_capabilities_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _surface_capabilities = std::move(other._surface_capabilities);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSurfaceCapabilities2KHR&() const
  {
    return *reinterpret_cast<const VkSurfaceCapabilities2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::surface_capabilities_khr& surface_capabilities()
  {
    return _surface_capabilities;
  }

  constexpr const vk::surface_capabilities_khr& surface_capabilities() const
  {
    return _surface_capabilities;
  }

  void surface_capabilities(
    vk::surface_capabilities_khr new_surface_capabilities)
  {
    _surface_capabilities = new_surface_capabilities;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::surface_capabilities_2_khr;
  void* _next = nullptr;
  vk::surface_capabilities_khr _surface_capabilities =
    vk::surface_capabilities_khr{};
};
static_assert(sizeof(surface_capabilities_2_khr) ==
                sizeof(::VkSurfaceCapabilities2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSurfaceFormat2KHR.
class surface_format_2_khr
{
public:
  /// Default constructor.
  constexpr surface_format_2_khr() = default;

  /// Constructor.
  constexpr surface_format_2_khr(
    void* initial_next, vk::surface_format_khr initial_surface_format) noexcept
  : _next(std::move(initial_next)),
    _surface_format(std::move(initial_surface_format))
  {
  }

  /// Copy constructor.
  constexpr surface_format_2_khr(const surface_format_2_khr& other) noexcept
  : _next(other._next), _surface_format(other._surface_format)
  {
  }

  /// Move constructor.
  constexpr surface_format_2_khr(surface_format_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _surface_format(std::move(other._surface_format))
  {
  }

  /// Copy assignment operator.
  constexpr surface_format_2_khr& operator=(
    const surface_format_2_khr& other) noexcept
  {
    _next = other._next;
    _surface_format = other._surface_format;
    return *this;
  }

  /// Move assignment operator.
  constexpr surface_format_2_khr& operator=(
    surface_format_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _surface_format = std::move(other._surface_format);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSurfaceFormat2KHR&() const
  {
    return *reinterpret_cast<const VkSurfaceFormat2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::surface_format_khr& surface_format()
  {
    return _surface_format;
  }

  constexpr const vk::surface_format_khr& surface_format() const
  {
    return _surface_format;
  }

  void surface_format(vk::surface_format_khr new_surface_format)
  {
    _surface_format = new_surface_format;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::surface_format_2_khr;
  void* _next = nullptr;
  vk::surface_format_khr _surface_format = vk::surface_format_khr{};
};
static_assert(sizeof(surface_format_2_khr) == sizeof(::VkSurfaceFormat2KHR),
              "struct and wrapper have different size!");

inline vk::result get_physical_device_surface_capabilities_2_khr(
  VkPhysicalDevice physical_device,
  const vk::physical_device_surface_info_2_khr* surface_info,
  vk::surface_capabilities_2_khr* surface_capabilities)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceSurfaceCapabilities2KHR(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>(surface_info),
    reinterpret_cast<VkSurfaceCapabilities2KHR*>(surface_capabilities)));
}
inline vk::result get_physical_device_surface_formats_2_khr(
  VkPhysicalDevice physical_device,
  const vk::physical_device_surface_info_2_khr* surface_info,
  uint32_t* surface_format_count, vk::surface_format_2_khr* surface_formats)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceSurfaceFormats2KHR(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>(surface_info),
    reinterpret_cast<uint32_t*>(surface_format_count),
    reinterpret_cast<VkSurfaceFormat2KHR*>(surface_formats)));
}

/// Enhanced replacement type for VkDisplayProperties2KHR.
class display_properties_2_khr
{
public:
  /// Default constructor.
  constexpr display_properties_2_khr() = default;

  /// Constructor.
  constexpr display_properties_2_khr(
    void* initial_next,
    vk::display_properties_khr initial_display_properties) noexcept
  : _next(std::move(initial_next)),
    _display_properties(std::move(initial_display_properties))
  {
  }

  /// Copy constructor.
  constexpr display_properties_2_khr(
    const display_properties_2_khr& other) noexcept
  : _next(other._next), _display_properties(other._display_properties)
  {
  }

  /// Move constructor.
  constexpr display_properties_2_khr(display_properties_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _display_properties(std::move(other._display_properties))
  {
  }

  /// Copy assignment operator.
  constexpr display_properties_2_khr& operator=(
    const display_properties_2_khr& other) noexcept
  {
    _next = other._next;
    _display_properties = other._display_properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_properties_2_khr& operator=(
    display_properties_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _display_properties = std::move(other._display_properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayProperties2KHR&() const
  {
    return *reinterpret_cast<const VkDisplayProperties2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::display_properties_khr& display_properties()
  {
    return _display_properties;
  }

  constexpr const vk::display_properties_khr& display_properties() const
  {
    return _display_properties;
  }

  void display_properties(vk::display_properties_khr new_display_properties)
  {
    _display_properties = new_display_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_properties_2_khr;
  void* _next = nullptr;
  vk::display_properties_khr _display_properties = vk::display_properties_khr{};
};
static_assert(sizeof(display_properties_2_khr) ==
                sizeof(::VkDisplayProperties2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDisplayPlaneProperties2KHR.
class display_plane_properties_2_khr
{
public:
  /// Default constructor.
  constexpr display_plane_properties_2_khr() = default;

  /// Constructor.
  constexpr display_plane_properties_2_khr(
    void* initial_next,
    vk::display_plane_properties_khr initial_display_plane_properties) noexcept
  : _next(std::move(initial_next)),
    _display_plane_properties(std::move(initial_display_plane_properties))
  {
  }

  /// Copy constructor.
  constexpr display_plane_properties_2_khr(
    const display_plane_properties_2_khr& other) noexcept
  : _next(other._next),
    _display_plane_properties(other._display_plane_properties)
  {
  }

  /// Move constructor.
  constexpr display_plane_properties_2_khr(
    display_plane_properties_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _display_plane_properties(std::move(other._display_plane_properties))
  {
  }

  /// Copy assignment operator.
  constexpr display_plane_properties_2_khr& operator=(
    const display_plane_properties_2_khr& other) noexcept
  {
    _next = other._next;
    _display_plane_properties = other._display_plane_properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_plane_properties_2_khr& operator=(
    display_plane_properties_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _display_plane_properties = std::move(other._display_plane_properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayPlaneProperties2KHR&() const
  {
    return *reinterpret_cast<const VkDisplayPlaneProperties2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::display_plane_properties_khr& display_plane_properties()
  {
    return _display_plane_properties;
  }

  constexpr const vk::display_plane_properties_khr& display_plane_properties()
    const
  {
    return _display_plane_properties;
  }

  void display_plane_properties(
    vk::display_plane_properties_khr new_display_plane_properties)
  {
    _display_plane_properties = new_display_plane_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_plane_properties_2_khr;
  void* _next = nullptr;
  vk::display_plane_properties_khr _display_plane_properties =
    vk::display_plane_properties_khr{};
};
static_assert(sizeof(display_plane_properties_2_khr) ==
                sizeof(::VkDisplayPlaneProperties2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDisplayModeProperties2KHR.
class display_mode_properties_2_khr
{
public:
  /// Default constructor.
  constexpr display_mode_properties_2_khr() = default;

  /// Constructor.
  constexpr display_mode_properties_2_khr(
    void* initial_next,
    vk::display_mode_properties_khr initial_display_mode_properties) noexcept
  : _next(std::move(initial_next)),
    _display_mode_properties(std::move(initial_display_mode_properties))
  {
  }

  /// Copy constructor.
  constexpr display_mode_properties_2_khr(
    const display_mode_properties_2_khr& other) noexcept
  : _next(other._next), _display_mode_properties(other._display_mode_properties)
  {
  }

  /// Move constructor.
  constexpr display_mode_properties_2_khr(
    display_mode_properties_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _display_mode_properties(std::move(other._display_mode_properties))
  {
  }

  /// Copy assignment operator.
  constexpr display_mode_properties_2_khr& operator=(
    const display_mode_properties_2_khr& other) noexcept
  {
    _next = other._next;
    _display_mode_properties = other._display_mode_properties;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_mode_properties_2_khr& operator=(
    display_mode_properties_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _display_mode_properties = std::move(other._display_mode_properties);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayModeProperties2KHR&() const
  {
    return *reinterpret_cast<const VkDisplayModeProperties2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::display_mode_properties_khr& display_mode_properties()
  {
    return _display_mode_properties;
  }

  constexpr const vk::display_mode_properties_khr& display_mode_properties()
    const
  {
    return _display_mode_properties;
  }

  void display_mode_properties(
    vk::display_mode_properties_khr new_display_mode_properties)
  {
    _display_mode_properties = new_display_mode_properties;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_mode_properties_2_khr;
  void* _next = nullptr;
  vk::display_mode_properties_khr _display_mode_properties =
    vk::display_mode_properties_khr{};
};
static_assert(sizeof(display_mode_properties_2_khr) ==
                sizeof(::VkDisplayModeProperties2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDisplayPlaneInfo2KHR.
class display_plane_info_2_khr
{
public:
  /// Default constructor.
  constexpr display_plane_info_2_khr() = default;

  /// Constructor.
  constexpr display_plane_info_2_khr(const void* initial_next,
                                     VkDisplayModeKHR initial_mode,
                                     uint32_t initial_plane_index) noexcept
  : _next(std::move(initial_next)),
    _mode(std::move(initial_mode)),
    _plane_index(std::move(initial_plane_index))
  {
  }

  /// Copy constructor.
  constexpr display_plane_info_2_khr(
    const display_plane_info_2_khr& other) noexcept
  : _next(other._next), _mode(other._mode), _plane_index(other._plane_index)
  {
  }

  /// Move constructor.
  constexpr display_plane_info_2_khr(display_plane_info_2_khr&& other) noexcept
  : _next(std::move(other._next)),
    _mode(std::move(other._mode)),
    _plane_index(std::move(other._plane_index))
  {
  }

  /// Copy assignment operator.
  constexpr display_plane_info_2_khr& operator=(
    const display_plane_info_2_khr& other) noexcept
  {
    _next = other._next;
    _mode = other._mode;
    _plane_index = other._plane_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_plane_info_2_khr& operator=(
    display_plane_info_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _mode = std::move(other._mode);
    _plane_index = std::move(other._plane_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayPlaneInfo2KHR&() const
  {
    return *reinterpret_cast<const VkDisplayPlaneInfo2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkDisplayModeKHR& mode()
  {
    return _mode;
  }

  constexpr const VkDisplayModeKHR& mode() const
  {
    return _mode;
  }

  void mode(VkDisplayModeKHR new_mode)
  {
    _mode = new_mode;
  }

  uint32_t& plane_index()
  {
    return _plane_index;
  }

  constexpr const uint32_t& plane_index() const
  {
    return _plane_index;
  }

  void plane_index(uint32_t new_plane_index)
  {
    _plane_index = new_plane_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_plane_info_2_khr;
  const void* _next = nullptr;
  VkDisplayModeKHR _mode = nullptr;
  uint32_t _plane_index = 0;
};
static_assert(sizeof(display_plane_info_2_khr) ==
                sizeof(::VkDisplayPlaneInfo2KHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDisplayPlaneCapabilities2KHR.
class display_plane_capabilities_2_khr
{
public:
  /// Default constructor.
  constexpr display_plane_capabilities_2_khr() = default;

  /// Constructor.
  constexpr display_plane_capabilities_2_khr(
    void* initial_next,
    vk::display_plane_capabilities_khr initial_capabilities) noexcept
  : _next(std::move(initial_next)),
    _capabilities(std::move(initial_capabilities))
  {
  }

  /// Copy constructor.
  constexpr display_plane_capabilities_2_khr(
    const display_plane_capabilities_2_khr& other) noexcept
  : _next(other._next), _capabilities(other._capabilities)
  {
  }

  /// Move constructor.
  constexpr display_plane_capabilities_2_khr(
    display_plane_capabilities_2_khr&& other) noexcept
  : _next(std::move(other._next)), _capabilities(std::move(other._capabilities))
  {
  }

  /// Copy assignment operator.
  constexpr display_plane_capabilities_2_khr& operator=(
    const display_plane_capabilities_2_khr& other) noexcept
  {
    _next = other._next;
    _capabilities = other._capabilities;
    return *this;
  }

  /// Move assignment operator.
  constexpr display_plane_capabilities_2_khr& operator=(
    display_plane_capabilities_2_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _capabilities = std::move(other._capabilities);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDisplayPlaneCapabilities2KHR&() const
  {
    return *reinterpret_cast<const VkDisplayPlaneCapabilities2KHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::display_plane_capabilities_khr& capabilities()
  {
    return _capabilities;
  }

  constexpr const vk::display_plane_capabilities_khr& capabilities() const
  {
    return _capabilities;
  }

  void capabilities(vk::display_plane_capabilities_khr new_capabilities)
  {
    _capabilities = new_capabilities;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::display_plane_capabilities_2_khr;
  void* _next = nullptr;
  vk::display_plane_capabilities_khr _capabilities =
    vk::display_plane_capabilities_khr{};
};
static_assert(sizeof(display_plane_capabilities_2_khr) ==
                sizeof(::VkDisplayPlaneCapabilities2KHR),
              "struct and wrapper have different size!");

inline vk::result get_physical_device_display_properties_2_khr(
  VkPhysicalDevice physical_device, uint32_t* property_count,
  vk::display_properties_2_khr* properties)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceDisplayProperties2KHR(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkDisplayProperties2KHR*>(properties)));
}
inline vk::result get_physical_device_display_plane_properties_2_khr(
  VkPhysicalDevice physical_device, uint32_t* property_count,
  vk::display_plane_properties_2_khr* properties)
{
  return static_cast<vk::result>(vkGetPhysicalDeviceDisplayPlaneProperties2KHR(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkDisplayPlaneProperties2KHR*>(properties)));
}
inline vk::result get_display_mode_properties_2_khr(
  VkPhysicalDevice physical_device, VkDisplayKHR display,
  uint32_t* property_count, vk::display_mode_properties_2_khr* properties)
{
  return static_cast<vk::result>(vkGetDisplayModeProperties2KHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkDisplayKHR>(display),
    reinterpret_cast<uint32_t*>(property_count),
    reinterpret_cast<VkDisplayModeProperties2KHR*>(properties)));
}
inline vk::result get_display_plane_capabilities_2_khr(
  VkPhysicalDevice physical_device,
  const vk::display_plane_info_2_khr* display_plane_info,
  vk::display_plane_capabilities_2_khr* capabilities)
{
  return static_cast<vk::result>(vkGetDisplayPlaneCapabilities2KHR(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<const VkDisplayPlaneInfo2KHR*>(display_plane_info),
    reinterpret_cast<VkDisplayPlaneCapabilities2KHR*>(capabilities)));
}

/// Enhanced replacement type for VkDebugUtilsObjectNameInfoEXT.
class debug_utils_object_name_info_ext
{
public:
  /// Default constructor.
  constexpr debug_utils_object_name_info_ext() = default;

  /// Constructor.
  constexpr debug_utils_object_name_info_ext(
    const void* initial_next, vk::object_type initial_object_type,
    uint64_t initial_object_handle, const char* initial_object_name) noexcept
  : _next(std::move(initial_next)),
    _object_type(std::move(initial_object_type)),
    _object_handle(std::move(initial_object_handle)),
    _object_name(std::move(initial_object_name))
  {
  }

  /// Copy constructor.
  constexpr debug_utils_object_name_info_ext(
    const debug_utils_object_name_info_ext& other) noexcept
  : _next(other._next),
    _object_type(other._object_type),
    _object_handle(other._object_handle),
    _object_name(other._object_name)
  {
  }

  /// Move constructor.
  constexpr debug_utils_object_name_info_ext(
    debug_utils_object_name_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _object_type(std::move(other._object_type)),
    _object_handle(std::move(other._object_handle)),
    _object_name(std::move(other._object_name))
  {
  }

  /// Copy assignment operator.
  constexpr debug_utils_object_name_info_ext& operator=(
    const debug_utils_object_name_info_ext& other) noexcept
  {
    _next = other._next;
    _object_type = other._object_type;
    _object_handle = other._object_handle;
    _object_name = other._object_name;
    return *this;
  }

  /// Move assignment operator.
  constexpr debug_utils_object_name_info_ext& operator=(
    debug_utils_object_name_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _object_type = std::move(other._object_type);
    _object_handle = std::move(other._object_handle);
    _object_name = std::move(other._object_name);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDebugUtilsObjectNameInfoEXT&() const
  {
    return *reinterpret_cast<const VkDebugUtilsObjectNameInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::object_type& object_type()
  {
    return _object_type;
  }

  constexpr const vk::object_type& object_type() const
  {
    return _object_type;
  }

  void object_type(vk::object_type new_object_type)
  {
    _object_type = new_object_type;
  }

  uint64_t& object_handle()
  {
    return _object_handle;
  }

  constexpr const uint64_t& object_handle() const
  {
    return _object_handle;
  }

  void object_handle(uint64_t new_object_handle)
  {
    _object_handle = new_object_handle;
  }

  const char* object_name()
  {
    return _object_name;
  }

  constexpr const char* object_name() const
  {
    return _object_name;
  }

  void object_name(const char* new_object_name)
  {
    _object_name = new_object_name;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::debug_utils_object_name_info_ext;
  const void* _next = nullptr;
  vk::object_type _object_type = vk::object_type::unknown;
  uint64_t _object_handle = 0;
  const char* _object_name = nullptr;
};
static_assert(sizeof(debug_utils_object_name_info_ext) ==
                sizeof(::VkDebugUtilsObjectNameInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDebugUtilsObjectTagInfoEXT.
class debug_utils_object_tag_info_ext
{
public:
  /// Default constructor.
  constexpr debug_utils_object_tag_info_ext() = default;

  /// Constructor.
  constexpr debug_utils_object_tag_info_ext(const void* initial_next,
                                            vk::object_type initial_object_type,
                                            uint64_t initial_object_handle,
                                            uint64_t initial_tag_name,
                                            size_t initial_tag_size,
                                            const void* initial_tag) noexcept
  : _next(std::move(initial_next)),
    _object_type(std::move(initial_object_type)),
    _object_handle(std::move(initial_object_handle)),
    _tag_name(std::move(initial_tag_name)),
    _tag_size(std::move(initial_tag_size)),
    _tag(std::move(initial_tag))
  {
  }

  /// Copy constructor.
  constexpr debug_utils_object_tag_info_ext(
    const debug_utils_object_tag_info_ext& other) noexcept
  : _next(other._next),
    _object_type(other._object_type),
    _object_handle(other._object_handle),
    _tag_name(other._tag_name),
    _tag_size(other._tag_size),
    _tag(other._tag)
  {
  }

  /// Move constructor.
  constexpr debug_utils_object_tag_info_ext(
    debug_utils_object_tag_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _object_type(std::move(other._object_type)),
    _object_handle(std::move(other._object_handle)),
    _tag_name(std::move(other._tag_name)),
    _tag_size(std::move(other._tag_size)),
    _tag(std::move(other._tag))
  {
  }

  /// Copy assignment operator.
  constexpr debug_utils_object_tag_info_ext& operator=(
    const debug_utils_object_tag_info_ext& other) noexcept
  {
    _next = other._next;
    _object_type = other._object_type;
    _object_handle = other._object_handle;
    _tag_name = other._tag_name;
    _tag_size = other._tag_size;
    _tag = other._tag;
    return *this;
  }

  /// Move assignment operator.
  constexpr debug_utils_object_tag_info_ext& operator=(
    debug_utils_object_tag_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _object_type = std::move(other._object_type);
    _object_handle = std::move(other._object_handle);
    _tag_name = std::move(other._tag_name);
    _tag_size = std::move(other._tag_size);
    _tag = std::move(other._tag);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDebugUtilsObjectTagInfoEXT&() const
  {
    return *reinterpret_cast<const VkDebugUtilsObjectTagInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::object_type& object_type()
  {
    return _object_type;
  }

  constexpr const vk::object_type& object_type() const
  {
    return _object_type;
  }

  void object_type(vk::object_type new_object_type)
  {
    _object_type = new_object_type;
  }

  uint64_t& object_handle()
  {
    return _object_handle;
  }

  constexpr const uint64_t& object_handle() const
  {
    return _object_handle;
  }

  void object_handle(uint64_t new_object_handle)
  {
    _object_handle = new_object_handle;
  }

  uint64_t& tag_name()
  {
    return _tag_name;
  }

  constexpr const uint64_t& tag_name() const
  {
    return _tag_name;
  }

  void tag_name(uint64_t new_tag_name)
  {
    _tag_name = new_tag_name;
  }

  size_t& tag_size()
  {
    return _tag_size;
  }

  constexpr const size_t& tag_size() const
  {
    return _tag_size;
  }

  void tag_size(size_t new_tag_size)
  {
    _tag_size = new_tag_size;
  }

  const void* tag()
  {
    return _tag;
  }

  constexpr const void* tag() const
  {
    return _tag;
  }

  void tag(const void* new_tag)
  {
    _tag = new_tag;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::debug_utils_object_tag_info_ext;
  const void* _next = nullptr;
  vk::object_type _object_type = vk::object_type::unknown;
  uint64_t _object_handle = 0;
  uint64_t _tag_name = 0;
  size_t _tag_size = 0;
  const void* _tag = nullptr;
};
static_assert(sizeof(debug_utils_object_tag_info_ext) ==
                sizeof(::VkDebugUtilsObjectTagInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDebugUtilsLabelEXT.
class debug_utils_label_ext
{
public:
  /// Default constructor.
  constexpr debug_utils_label_ext() = default;

  /// Constructor.
  constexpr debug_utils_label_ext(const void* initial_next,
                                  const char* initial_label_name,
                                  std::array<float, 4> initial_color) noexcept
  : _next(std::move(initial_next)),
    _label_name(std::move(initial_label_name)),
    _color(std::move(initial_color))
  {
  }

  /// Copy constructor.
  constexpr debug_utils_label_ext(const debug_utils_label_ext& other) noexcept
  : _next(other._next), _label_name(other._label_name), _color(other._color)
  {
  }

  /// Move constructor.
  constexpr debug_utils_label_ext(debug_utils_label_ext&& other) noexcept
  : _next(std::move(other._next)),
    _label_name(std::move(other._label_name)),
    _color(std::move(other._color))
  {
  }

  /// Copy assignment operator.
  constexpr debug_utils_label_ext& operator=(
    const debug_utils_label_ext& other) noexcept
  {
    _next = other._next;
    _label_name = other._label_name;
    _color = other._color;
    return *this;
  }

  /// Move assignment operator.
  constexpr debug_utils_label_ext& operator=(
    debug_utils_label_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _label_name = std::move(other._label_name);
    _color = std::move(other._color);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDebugUtilsLabelEXT&() const
  {
    return *reinterpret_cast<const VkDebugUtilsLabelEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  const char* label_name()
  {
    return _label_name;
  }

  constexpr const char* label_name() const
  {
    return _label_name;
  }

  void label_name(const char* new_label_name)
  {
    _label_name = new_label_name;
  }

  std::array<float, 4>& color()
  {
    return _color;
  }

  constexpr const std::array<float, 4>& color() const
  {
    return _color;
  }

  void color(std::array<float, 4> new_color)
  {
    _color = new_color;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::debug_utils_label_ext;
  const void* _next = nullptr;
  const char* _label_name = nullptr;
  std::array<float, 4> _color = {};
};
static_assert(sizeof(debug_utils_label_ext) == sizeof(::VkDebugUtilsLabelEXT),
              "struct and wrapper have different size!");

using debug_utils_messenger_callback_data_flags_ext = VkFlags;

/// Enhanced replacement type for VkDebugUtilsMessengerCallbackDataEXT.
class debug_utils_messenger_callback_data_ext
{
public:
  /// Default constructor.
  constexpr debug_utils_messenger_callback_data_ext() = default;

  /// Constructor.
  constexpr debug_utils_messenger_callback_data_ext(
    const void* initial_next,
    vk::debug_utils_messenger_callback_data_flags_ext initial_flags,
    const char* initial_message_id_name, int32_t initial_message_id_number,
    const char* initial_message, uint32_t initial_queue_label_count,
    vk::debug_utils_label_ext* initial_queue_labels,
    uint32_t initial_cmd_buf_label_count,
    vk::debug_utils_label_ext* initial_cmd_buf_labels,
    uint32_t initial_object_count,
    vk::debug_utils_object_name_info_ext* initial_objects) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _message_id_name(std::move(initial_message_id_name)),
    _message_id_number(std::move(initial_message_id_number)),
    _message(std::move(initial_message)),
    _queue_label_count(std::move(initial_queue_label_count)),
    _queue_labels(std::move(initial_queue_labels)),
    _cmd_buf_label_count(std::move(initial_cmd_buf_label_count)),
    _cmd_buf_labels(std::move(initial_cmd_buf_labels)),
    _object_count(std::move(initial_object_count)),
    _objects(std::move(initial_objects))
  {
  }

  /// Copy constructor.
  constexpr debug_utils_messenger_callback_data_ext(
    const debug_utils_messenger_callback_data_ext& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _message_id_name(other._message_id_name),
    _message_id_number(other._message_id_number),
    _message(other._message),
    _queue_label_count(other._queue_label_count),
    _queue_labels(other._queue_labels),
    _cmd_buf_label_count(other._cmd_buf_label_count),
    _cmd_buf_labels(other._cmd_buf_labels),
    _object_count(other._object_count),
    _objects(other._objects)
  {
  }

  /// Move constructor.
  constexpr debug_utils_messenger_callback_data_ext(
    debug_utils_messenger_callback_data_ext&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _message_id_name(std::move(other._message_id_name)),
    _message_id_number(std::move(other._message_id_number)),
    _message(std::move(other._message)),
    _queue_label_count(std::move(other._queue_label_count)),
    _queue_labels(std::move(other._queue_labels)),
    _cmd_buf_label_count(std::move(other._cmd_buf_label_count)),
    _cmd_buf_labels(std::move(other._cmd_buf_labels)),
    _object_count(std::move(other._object_count)),
    _objects(std::move(other._objects))
  {
  }

  /// Copy assignment operator.
  constexpr debug_utils_messenger_callback_data_ext& operator=(
    const debug_utils_messenger_callback_data_ext& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _message_id_name = other._message_id_name;
    _message_id_number = other._message_id_number;
    _message = other._message;
    _queue_label_count = other._queue_label_count;
    _queue_labels = other._queue_labels;
    _cmd_buf_label_count = other._cmd_buf_label_count;
    _cmd_buf_labels = other._cmd_buf_labels;
    _object_count = other._object_count;
    _objects = other._objects;
    return *this;
  }

  /// Move assignment operator.
  constexpr debug_utils_messenger_callback_data_ext& operator=(
    debug_utils_messenger_callback_data_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _message_id_name = std::move(other._message_id_name);
    _message_id_number = std::move(other._message_id_number);
    _message = std::move(other._message);
    _queue_label_count = std::move(other._queue_label_count);
    _queue_labels = std::move(other._queue_labels);
    _cmd_buf_label_count = std::move(other._cmd_buf_label_count);
    _cmd_buf_labels = std::move(other._cmd_buf_labels);
    _object_count = std::move(other._object_count);
    _objects = std::move(other._objects);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDebugUtilsMessengerCallbackDataEXT&() const
  {
    return *reinterpret_cast<const VkDebugUtilsMessengerCallbackDataEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::debug_utils_messenger_callback_data_flags_ext& flags()
  {
    return _flags;
  }

  constexpr const vk::debug_utils_messenger_callback_data_flags_ext& flags()
    const
  {
    return _flags;
  }

  void flags(vk::debug_utils_messenger_callback_data_flags_ext new_flags)
  {
    _flags = new_flags;
  }

  const char* message_id_name()
  {
    return _message_id_name;
  }

  constexpr const char* message_id_name() const
  {
    return _message_id_name;
  }

  void message_id_name(const char* new_message_id_name)
  {
    _message_id_name = new_message_id_name;
  }

  int32_t& message_id_number()
  {
    return _message_id_number;
  }

  constexpr const int32_t& message_id_number() const
  {
    return _message_id_number;
  }

  void message_id_number(int32_t new_message_id_number)
  {
    _message_id_number = new_message_id_number;
  }

  const char* message()
  {
    return _message;
  }

  constexpr const char* message() const
  {
    return _message;
  }

  void message(const char* new_message)
  {
    _message = new_message;
  }

  uint32_t& queue_label_count()
  {
    return _queue_label_count;
  }

  constexpr const uint32_t& queue_label_count() const
  {
    return _queue_label_count;
  }

  void queue_label_count(uint32_t new_queue_label_count)
  {
    _queue_label_count = new_queue_label_count;
  }

  vk::debug_utils_label_ext* queue_labels()
  {
    return _queue_labels;
  }

  constexpr vk::debug_utils_label_ext* queue_labels() const
  {
    return _queue_labels;
  }

  void queue_labels(vk::debug_utils_label_ext* new_queue_labels)
  {
    _queue_labels = new_queue_labels;
  }

  template <std::size_t Count>
  void queue_labels(
    std::array<vk::debug_utils_label_ext, Count>& new_queue_labels)
  {
    _queue_label_count = static_cast<uint32_t>(new_queue_labels.size());
    _queue_labels = new_queue_labels.data();
  }

  void queue_labels(std::vector<vk::debug_utils_label_ext>& new_queue_labels)
  {
    _queue_label_count = static_cast<uint32_t>(new_queue_labels.size());
    _queue_labels = new_queue_labels.data();
  }

  uint32_t& cmd_buf_label_count()
  {
    return _cmd_buf_label_count;
  }

  constexpr const uint32_t& cmd_buf_label_count() const
  {
    return _cmd_buf_label_count;
  }

  void cmd_buf_label_count(uint32_t new_cmd_buf_label_count)
  {
    _cmd_buf_label_count = new_cmd_buf_label_count;
  }

  vk::debug_utils_label_ext* cmd_buf_labels()
  {
    return _cmd_buf_labels;
  }

  constexpr vk::debug_utils_label_ext* cmd_buf_labels() const
  {
    return _cmd_buf_labels;
  }

  void cmd_buf_labels(vk::debug_utils_label_ext* new_cmd_buf_labels)
  {
    _cmd_buf_labels = new_cmd_buf_labels;
  }

  template <std::size_t Count>
  void cmd_buf_labels(
    std::array<vk::debug_utils_label_ext, Count>& new_cmd_buf_labels)
  {
    _cmd_buf_label_count = static_cast<uint32_t>(new_cmd_buf_labels.size());
    _cmd_buf_labels = new_cmd_buf_labels.data();
  }

  void cmd_buf_labels(
    std::vector<vk::debug_utils_label_ext>& new_cmd_buf_labels)
  {
    _cmd_buf_label_count = static_cast<uint32_t>(new_cmd_buf_labels.size());
    _cmd_buf_labels = new_cmd_buf_labels.data();
  }

  uint32_t& object_count()
  {
    return _object_count;
  }

  constexpr const uint32_t& object_count() const
  {
    return _object_count;
  }

  void object_count(uint32_t new_object_count)
  {
    _object_count = new_object_count;
  }

  vk::debug_utils_object_name_info_ext* objects()
  {
    return _objects;
  }

  constexpr vk::debug_utils_object_name_info_ext* objects() const
  {
    return _objects;
  }

  void objects(vk::debug_utils_object_name_info_ext* new_objects)
  {
    _objects = new_objects;
  }

  template <std::size_t Count>
  void objects(
    std::array<vk::debug_utils_object_name_info_ext, Count>& new_objects)
  {
    _object_count = static_cast<uint32_t>(new_objects.size());
    _objects = new_objects.data();
  }

  void objects(std::vector<vk::debug_utils_object_name_info_ext>& new_objects)
  {
    _object_count = static_cast<uint32_t>(new_objects.size());
    _objects = new_objects.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::debug_utils_messenger_callback_data_ext;
  const void* _next = nullptr;
  vk::debug_utils_messenger_callback_data_flags_ext _flags = 0;
  const char* _message_id_name = nullptr;
  int32_t _message_id_number = 0;
  const char* _message = nullptr;
  uint32_t _queue_label_count = 0;
  vk::debug_utils_label_ext* _queue_labels = nullptr;
  uint32_t _cmd_buf_label_count = 0;
  vk::debug_utils_label_ext* _cmd_buf_labels = nullptr;
  uint32_t _object_count = 0;
  vk::debug_utils_object_name_info_ext* _objects = nullptr;
};
static_assert(sizeof(debug_utils_messenger_callback_data_ext) ==
                sizeof(::VkDebugUtilsMessengerCallbackDataEXT),
              "struct and wrapper have different size!");

using debug_utils_messenger_create_flags_ext = VkFlags;
enum class debug_utils_message_severity_flag_ext
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT
  verbose_bit_ext = 1 << 0,
  /// @see VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT
  info_bit_ext = 1 << 4,
  /// @see VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT
  warning_bit_ext = 1 << 8,
  /// @see VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT
  error_bit_ext = 1 << 12,
};
using debug_utils_message_severity_flags_ext =
  shift::core::bit_field<debug_utils_message_severity_flag_ext,
                         VkDebugUtilsMessageSeverityFlagsEXT>;
inline constexpr debug_utils_message_severity_flags_ext operator|(
  debug_utils_message_severity_flag_ext lhs,
  debug_utils_message_severity_flag_ext rhs)
{
  return debug_utils_message_severity_flags_ext{lhs} | rhs;
}
enum class debug_utils_message_type_flag_ext
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT
  general_bit_ext = 1 << 0,
  /// @see VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT
  validation_bit_ext = 1 << 1,
  /// @see VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT
  performance_bit_ext = 1 << 2,
};
using debug_utils_message_type_flags_ext =
  shift::core::bit_field<debug_utils_message_type_flag_ext,
                         VkDebugUtilsMessageTypeFlagsEXT>;
inline constexpr debug_utils_message_type_flags_ext operator|(
  debug_utils_message_type_flag_ext lhs, debug_utils_message_type_flag_ext rhs)
{
  return debug_utils_message_type_flags_ext{lhs} | rhs;
}
/// Enhanced replacement type for VkDebugUtilsMessengerCreateInfoEXT.
class debug_utils_messenger_create_info_ext
{
public:
  /// Default constructor.
  constexpr debug_utils_messenger_create_info_ext() = default;

  /// Constructor.
  constexpr debug_utils_messenger_create_info_ext(
    const void* initial_next,
    vk::debug_utils_messenger_create_flags_ext initial_flags,
    vk::debug_utils_message_severity_flags_ext initial_message_severity,
    vk::debug_utils_message_type_flags_ext initial_message_type,
    PFN_vkDebugUtilsMessengerCallbackEXT initial_pfn_user_callback,
    void* initial_user_data) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _message_severity(std::move(initial_message_severity)),
    _message_type(std::move(initial_message_type)),
    _pfn_user_callback(std::move(initial_pfn_user_callback)),
    _user_data(std::move(initial_user_data))
  {
  }

  /// Copy constructor.
  constexpr debug_utils_messenger_create_info_ext(
    const debug_utils_messenger_create_info_ext& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _message_severity(other._message_severity),
    _message_type(other._message_type),
    _pfn_user_callback(other._pfn_user_callback),
    _user_data(other._user_data)
  {
  }

  /// Move constructor.
  constexpr debug_utils_messenger_create_info_ext(
    debug_utils_messenger_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _message_severity(std::move(other._message_severity)),
    _message_type(std::move(other._message_type)),
    _pfn_user_callback(std::move(other._pfn_user_callback)),
    _user_data(std::move(other._user_data))
  {
  }

  /// Copy assignment operator.
  constexpr debug_utils_messenger_create_info_ext& operator=(
    const debug_utils_messenger_create_info_ext& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _message_severity = other._message_severity;
    _message_type = other._message_type;
    _pfn_user_callback = other._pfn_user_callback;
    _user_data = other._user_data;
    return *this;
  }

  /// Move assignment operator.
  constexpr debug_utils_messenger_create_info_ext& operator=(
    debug_utils_messenger_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _message_severity = std::move(other._message_severity);
    _message_type = std::move(other._message_type);
    _pfn_user_callback = std::move(other._pfn_user_callback);
    _user_data = std::move(other._user_data);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDebugUtilsMessengerCreateInfoEXT&() const
  {
    return *reinterpret_cast<const VkDebugUtilsMessengerCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::debug_utils_messenger_create_flags_ext& flags()
  {
    return _flags;
  }

  constexpr const vk::debug_utils_messenger_create_flags_ext& flags() const
  {
    return _flags;
  }

  void flags(vk::debug_utils_messenger_create_flags_ext new_flags)
  {
    _flags = new_flags;
  }

  vk::debug_utils_message_severity_flags_ext& message_severity()
  {
    return _message_severity;
  }

  constexpr const vk::debug_utils_message_severity_flags_ext& message_severity()
    const
  {
    return _message_severity;
  }

  void message_severity(
    vk::debug_utils_message_severity_flags_ext new_message_severity)
  {
    _message_severity = new_message_severity;
  }

  vk::debug_utils_message_type_flags_ext& message_type()
  {
    return _message_type;
  }

  constexpr const vk::debug_utils_message_type_flags_ext& message_type() const
  {
    return _message_type;
  }

  void message_type(vk::debug_utils_message_type_flags_ext new_message_type)
  {
    _message_type = new_message_type;
  }

  PFN_vkDebugUtilsMessengerCallbackEXT& pfn_user_callback()
  {
    return _pfn_user_callback;
  }

  constexpr const PFN_vkDebugUtilsMessengerCallbackEXT& pfn_user_callback()
    const
  {
    return _pfn_user_callback;
  }

  void pfn_user_callback(
    PFN_vkDebugUtilsMessengerCallbackEXT new_pfn_user_callback)
  {
    _pfn_user_callback = new_pfn_user_callback;
  }

  void* user_data()
  {
    return _user_data;
  }

  constexpr void* user_data() const
  {
    return _user_data;
  }

  void user_data(void* new_user_data)
  {
    _user_data = new_user_data;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::debug_utils_messenger_create_info_ext;
  const void* _next = nullptr;
  vk::debug_utils_messenger_create_flags_ext _flags = 0;
  vk::debug_utils_message_severity_flags_ext _message_severity =
    vk::debug_utils_message_severity_flag_ext::none;
  vk::debug_utils_message_type_flags_ext _message_type =
    vk::debug_utils_message_type_flag_ext::none;
  PFN_vkDebugUtilsMessengerCallbackEXT _pfn_user_callback = nullptr;
  void* _user_data = nullptr;
};
static_assert(sizeof(debug_utils_messenger_create_info_ext) ==
                sizeof(::VkDebugUtilsMessengerCreateInfoEXT),
              "struct and wrapper have different size!");

inline vk::result set_debug_utils_object_name_ext(
  VkDevice device, const vk::debug_utils_object_name_info_ext* name_info)
{
  return static_cast<vk::result>(vkSetDebugUtilsObjectNameEXT(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDebugUtilsObjectNameInfoEXT*>(name_info)));
}
inline vk::result set_debug_utils_object_tag_ext(
  VkDevice device, const vk::debug_utils_object_tag_info_ext* tag_info)
{
  return static_cast<vk::result>(vkSetDebugUtilsObjectTagEXT(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkDebugUtilsObjectTagInfoEXT*>(tag_info)));
}
inline void queue_begin_debug_utils_label_ext(
  VkQueue queue, const vk::debug_utils_label_ext* label_info)
{
  vkQueueBeginDebugUtilsLabelEXT(
    static_cast<VkQueue>(queue),
    reinterpret_cast<const VkDebugUtilsLabelEXT*>(label_info));
}
inline void queue_end_debug_utils_label_ext(VkQueue queue)
{
  vkQueueEndDebugUtilsLabelEXT(static_cast<VkQueue>(queue));
}
inline void queue_insert_debug_utils_label_ext(
  VkQueue queue, const vk::debug_utils_label_ext* label_info)
{
  vkQueueInsertDebugUtilsLabelEXT(
    static_cast<VkQueue>(queue),
    reinterpret_cast<const VkDebugUtilsLabelEXT*>(label_info));
}
inline void cmd_begin_debug_utils_label_ext(
  VkCommandBuffer command_buffer, const vk::debug_utils_label_ext* label_info)
{
  vkCmdBeginDebugUtilsLabelEXT(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkDebugUtilsLabelEXT*>(label_info));
}
inline void cmd_end_debug_utils_label_ext(VkCommandBuffer command_buffer)
{
  vkCmdEndDebugUtilsLabelEXT(static_cast<VkCommandBuffer>(command_buffer));
}
inline void cmd_insert_debug_utils_label_ext(
  VkCommandBuffer command_buffer, const vk::debug_utils_label_ext* label_info)
{
  vkCmdInsertDebugUtilsLabelEXT(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkDebugUtilsLabelEXT*>(label_info));
}
inline vk::result create_debug_utils_messenger_ext(
  VkInstance instance,
  const vk::debug_utils_messenger_create_info_ext* create_info,
  const vk::allocation_callbacks* allocator,
  VkDebugUtilsMessengerEXT* messenger)
{
  return static_cast<vk::result>(vkCreateDebugUtilsMessengerEXT(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkDebugUtilsMessengerCreateInfoEXT*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkDebugUtilsMessengerEXT*>(messenger)));
}
inline void destroy_debug_utils_messenger_ext(
  VkInstance instance, VkDebugUtilsMessengerEXT messenger,
  const vk::allocation_callbacks* allocator)
{
  vkDestroyDebugUtilsMessengerEXT(
    static_cast<VkInstance>(instance),
    static_cast<VkDebugUtilsMessengerEXT>(messenger),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline void submit_debug_utils_message_ext(
  VkInstance instance,
  vk::debug_utils_message_severity_flag_ext message_severity,
  vk::debug_utils_message_type_flags_ext message_types,
  const vk::debug_utils_messenger_callback_data_ext* callback_data)
{
  vkSubmitDebugUtilsMessageEXT(
    static_cast<VkInstance>(instance),
    static_cast<VkDebugUtilsMessageSeverityFlagBitsEXT>(message_severity),
    static_cast<VkDebugUtilsMessageTypeFlagsEXT>(message_types),
    reinterpret_cast<const VkDebugUtilsMessengerCallbackDataEXT*>(
      callback_data));
}
enum class sampler_reduction_mode_ext
{
  /// @see VK_SAMPLER_REDUCTION_MODE_WEIGHTED_AVERAGE_EXT
  sampler_reduction_mode_weighted_average_ext = 0,
  /// @see VK_SAMPLER_REDUCTION_MODE_MIN_EXT
  sampler_reduction_mode_min_ext = 1,
  /// @see VK_SAMPLER_REDUCTION_MODE_MAX_EXT
  sampler_reduction_mode_max_ext = 2,
};

/// Enhanced replacement type for VkSamplerReductionModeCreateInfoEXT.
class sampler_reduction_mode_create_info_ext
{
public:
  /// Default constructor.
  constexpr sampler_reduction_mode_create_info_ext() = default;

  /// Constructor.
  constexpr sampler_reduction_mode_create_info_ext(
    const void* initial_next,
    vk::sampler_reduction_mode_ext initial_reduction_mode) noexcept
  : _next(std::move(initial_next)),
    _reduction_mode(std::move(initial_reduction_mode))
  {
  }

  /// Copy constructor.
  constexpr sampler_reduction_mode_create_info_ext(
    const sampler_reduction_mode_create_info_ext& other) noexcept
  : _next(other._next), _reduction_mode(other._reduction_mode)
  {
  }

  /// Move constructor.
  constexpr sampler_reduction_mode_create_info_ext(
    sampler_reduction_mode_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _reduction_mode(std::move(other._reduction_mode))
  {
  }

  /// Copy assignment operator.
  constexpr sampler_reduction_mode_create_info_ext& operator=(
    const sampler_reduction_mode_create_info_ext& other) noexcept
  {
    _next = other._next;
    _reduction_mode = other._reduction_mode;
    return *this;
  }

  /// Move assignment operator.
  constexpr sampler_reduction_mode_create_info_ext& operator=(
    sampler_reduction_mode_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _reduction_mode = std::move(other._reduction_mode);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSamplerReductionModeCreateInfoEXT&() const
  {
    return *reinterpret_cast<const VkSamplerReductionModeCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::sampler_reduction_mode_ext& reduction_mode()
  {
    return _reduction_mode;
  }

  constexpr const vk::sampler_reduction_mode_ext& reduction_mode() const
  {
    return _reduction_mode;
  }

  void reduction_mode(vk::sampler_reduction_mode_ext new_reduction_mode)
  {
    _reduction_mode = new_reduction_mode;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::sampler_reduction_mode_create_info_ext;
  const void* _next = nullptr;
  vk::sampler_reduction_mode_ext _reduction_mode =
    vk::sampler_reduction_mode_ext::sampler_reduction_mode_weighted_average_ext;
};
static_assert(sizeof(sampler_reduction_mode_create_info_ext) ==
                sizeof(::VkSamplerReductionModeCreateInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT.
class physical_device_sampler_filter_minmax_properties_ext
{
public:
  /// Default constructor.
  constexpr physical_device_sampler_filter_minmax_properties_ext() = default;

  /// Constructor.
  constexpr physical_device_sampler_filter_minmax_properties_ext(
    void* initial_next, VkBool32 initial_filter_minmax_single_component_formats,
    VkBool32 initial_filter_minmax_image_component_mapping) noexcept
  : _next(std::move(initial_next)),
    _filter_minmax_single_component_formats(
      std::move(initial_filter_minmax_single_component_formats)),
    _filter_minmax_image_component_mapping(
      std::move(initial_filter_minmax_image_component_mapping))
  {
  }

  /// Copy constructor.
  constexpr physical_device_sampler_filter_minmax_properties_ext(
    const physical_device_sampler_filter_minmax_properties_ext& other) noexcept
  : _next(other._next),
    _filter_minmax_single_component_formats(
      other._filter_minmax_single_component_formats),
    _filter_minmax_image_component_mapping(
      other._filter_minmax_image_component_mapping)
  {
  }

  /// Move constructor.
  constexpr physical_device_sampler_filter_minmax_properties_ext(
    physical_device_sampler_filter_minmax_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _filter_minmax_single_component_formats(
      std::move(other._filter_minmax_single_component_formats)),
    _filter_minmax_image_component_mapping(
      std::move(other._filter_minmax_image_component_mapping))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_sampler_filter_minmax_properties_ext& operator=(
    const physical_device_sampler_filter_minmax_properties_ext& other) noexcept
  {
    _next = other._next;
    _filter_minmax_single_component_formats =
      other._filter_minmax_single_component_formats;
    _filter_minmax_image_component_mapping =
      other._filter_minmax_image_component_mapping;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_sampler_filter_minmax_properties_ext& operator=(
    physical_device_sampler_filter_minmax_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _filter_minmax_single_component_formats =
      std::move(other._filter_minmax_single_component_formats);
    _filter_minmax_image_component_mapping =
      std::move(other._filter_minmax_image_component_mapping);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& filter_minmax_single_component_formats()
  {
    return _filter_minmax_single_component_formats;
  }

  constexpr const VkBool32& filter_minmax_single_component_formats() const
  {
    return _filter_minmax_single_component_formats;
  }

  void filter_minmax_single_component_formats(
    VkBool32 new_filter_minmax_single_component_formats)
  {
    _filter_minmax_single_component_formats =
      new_filter_minmax_single_component_formats;
  }

  VkBool32& filter_minmax_image_component_mapping()
  {
    return _filter_minmax_image_component_mapping;
  }

  constexpr const VkBool32& filter_minmax_image_component_mapping() const
  {
    return _filter_minmax_image_component_mapping;
  }

  void filter_minmax_image_component_mapping(
    VkBool32 new_filter_minmax_image_component_mapping)
  {
    _filter_minmax_image_component_mapping =
      new_filter_minmax_image_component_mapping;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_sampler_filter_minmax_properties_ext;
  void* _next = nullptr;
  VkBool32 _filter_minmax_single_component_formats = VK_FALSE;
  VkBool32 _filter_minmax_image_component_mapping = VK_FALSE;
};
static_assert(sizeof(physical_device_sampler_filter_minmax_properties_ext) ==
                sizeof(::VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceInlineUniformBlockFeaturesEXT.
class physical_device_inline_uniform_block_features_ext
{
public:
  /// Default constructor.
  constexpr physical_device_inline_uniform_block_features_ext() = default;

  /// Constructor.
  constexpr physical_device_inline_uniform_block_features_ext(
    void* initial_next, VkBool32 initial_inline_uniform_block,
    VkBool32
      initial_descriptor_binding_inline_uniform_block_update_after_bind) noexcept
  : _next(std::move(initial_next)),
    _inline_uniform_block(std::move(initial_inline_uniform_block)),
    _descriptor_binding_inline_uniform_block_update_after_bind(std::move(
      initial_descriptor_binding_inline_uniform_block_update_after_bind))
  {
  }

  /// Copy constructor.
  constexpr physical_device_inline_uniform_block_features_ext(
    const physical_device_inline_uniform_block_features_ext& other) noexcept
  : _next(other._next),
    _inline_uniform_block(other._inline_uniform_block),
    _descriptor_binding_inline_uniform_block_update_after_bind(
      other._descriptor_binding_inline_uniform_block_update_after_bind)
  {
  }

  /// Move constructor.
  constexpr physical_device_inline_uniform_block_features_ext(
    physical_device_inline_uniform_block_features_ext&& other) noexcept
  : _next(std::move(other._next)),
    _inline_uniform_block(std::move(other._inline_uniform_block)),
    _descriptor_binding_inline_uniform_block_update_after_bind(std::move(
      other._descriptor_binding_inline_uniform_block_update_after_bind))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_inline_uniform_block_features_ext& operator=(
    const physical_device_inline_uniform_block_features_ext& other) noexcept
  {
    _next = other._next;
    _inline_uniform_block = other._inline_uniform_block;
    _descriptor_binding_inline_uniform_block_update_after_bind =
      other._descriptor_binding_inline_uniform_block_update_after_bind;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_inline_uniform_block_features_ext& operator=(
    physical_device_inline_uniform_block_features_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _inline_uniform_block = std::move(other._inline_uniform_block);
    _descriptor_binding_inline_uniform_block_update_after_bind = std::move(
      other._descriptor_binding_inline_uniform_block_update_after_bind);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceInlineUniformBlockFeaturesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceInlineUniformBlockFeaturesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& inline_uniform_block()
  {
    return _inline_uniform_block;
  }

  constexpr const VkBool32& inline_uniform_block() const
  {
    return _inline_uniform_block;
  }

  void inline_uniform_block(VkBool32 new_inline_uniform_block)
  {
    _inline_uniform_block = new_inline_uniform_block;
  }

  VkBool32& descriptor_binding_inline_uniform_block_update_after_bind()
  {
    return _descriptor_binding_inline_uniform_block_update_after_bind;
  }

  constexpr const VkBool32&
  descriptor_binding_inline_uniform_block_update_after_bind() const
  {
    return _descriptor_binding_inline_uniform_block_update_after_bind;
  }

  void descriptor_binding_inline_uniform_block_update_after_bind(
    VkBool32 new_descriptor_binding_inline_uniform_block_update_after_bind)
  {
    _descriptor_binding_inline_uniform_block_update_after_bind =
      new_descriptor_binding_inline_uniform_block_update_after_bind;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_inline_uniform_block_features_ext;
  void* _next = nullptr;
  VkBool32 _inline_uniform_block = VK_FALSE;
  VkBool32 _descriptor_binding_inline_uniform_block_update_after_bind =
    VK_FALSE;
};
static_assert(sizeof(physical_device_inline_uniform_block_features_ext) ==
                sizeof(::VkPhysicalDeviceInlineUniformBlockFeaturesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceInlineUniformBlockPropertiesEXT.
class physical_device_inline_uniform_block_properties_ext
{
public:
  /// Default constructor.
  constexpr physical_device_inline_uniform_block_properties_ext() = default;

  /// Constructor.
  constexpr physical_device_inline_uniform_block_properties_ext(
    void* initial_next, uint32_t initial_max_inline_uniform_block_size,
    uint32_t initial_max_per_stage_descriptor_inline_uniform_blocks,
    uint32_t
      initial_max_per_stage_descriptor_update_after_bind_inline_uniform_blocks,
    uint32_t initial_max_descriptor_set_inline_uniform_blocks,
    uint32_t
      initial_max_descriptor_set_update_after_bind_inline_uniform_blocks) noexcept
  : _next(std::move(initial_next)),
    _max_inline_uniform_block_size(
      std::move(initial_max_inline_uniform_block_size)),
    _max_per_stage_descriptor_inline_uniform_blocks(
      std::move(initial_max_per_stage_descriptor_inline_uniform_blocks)),
    _max_per_stage_descriptor_update_after_bind_inline_uniform_blocks(std::move(
      initial_max_per_stage_descriptor_update_after_bind_inline_uniform_blocks)),
    _max_descriptor_set_inline_uniform_blocks(
      std::move(initial_max_descriptor_set_inline_uniform_blocks)),
    _max_descriptor_set_update_after_bind_inline_uniform_blocks(std::move(
      initial_max_descriptor_set_update_after_bind_inline_uniform_blocks))
  {
  }

  /// Copy constructor.
  constexpr physical_device_inline_uniform_block_properties_ext(
    const physical_device_inline_uniform_block_properties_ext& other) noexcept
  : _next(other._next),
    _max_inline_uniform_block_size(other._max_inline_uniform_block_size),
    _max_per_stage_descriptor_inline_uniform_blocks(
      other._max_per_stage_descriptor_inline_uniform_blocks),
    _max_per_stage_descriptor_update_after_bind_inline_uniform_blocks(
      other._max_per_stage_descriptor_update_after_bind_inline_uniform_blocks),
    _max_descriptor_set_inline_uniform_blocks(
      other._max_descriptor_set_inline_uniform_blocks),
    _max_descriptor_set_update_after_bind_inline_uniform_blocks(
      other._max_descriptor_set_update_after_bind_inline_uniform_blocks)
  {
  }

  /// Move constructor.
  constexpr physical_device_inline_uniform_block_properties_ext(
    physical_device_inline_uniform_block_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _max_inline_uniform_block_size(
      std::move(other._max_inline_uniform_block_size)),
    _max_per_stage_descriptor_inline_uniform_blocks(
      std::move(other._max_per_stage_descriptor_inline_uniform_blocks)),
    _max_per_stage_descriptor_update_after_bind_inline_uniform_blocks(std::move(
      other._max_per_stage_descriptor_update_after_bind_inline_uniform_blocks)),
    _max_descriptor_set_inline_uniform_blocks(
      std::move(other._max_descriptor_set_inline_uniform_blocks)),
    _max_descriptor_set_update_after_bind_inline_uniform_blocks(std::move(
      other._max_descriptor_set_update_after_bind_inline_uniform_blocks))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_inline_uniform_block_properties_ext& operator=(
    const physical_device_inline_uniform_block_properties_ext& other) noexcept
  {
    _next = other._next;
    _max_inline_uniform_block_size = other._max_inline_uniform_block_size;
    _max_per_stage_descriptor_inline_uniform_blocks =
      other._max_per_stage_descriptor_inline_uniform_blocks;
    _max_per_stage_descriptor_update_after_bind_inline_uniform_blocks =
      other._max_per_stage_descriptor_update_after_bind_inline_uniform_blocks;
    _max_descriptor_set_inline_uniform_blocks =
      other._max_descriptor_set_inline_uniform_blocks;
    _max_descriptor_set_update_after_bind_inline_uniform_blocks =
      other._max_descriptor_set_update_after_bind_inline_uniform_blocks;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_inline_uniform_block_properties_ext& operator=(
    physical_device_inline_uniform_block_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _max_inline_uniform_block_size =
      std::move(other._max_inline_uniform_block_size);
    _max_per_stage_descriptor_inline_uniform_blocks =
      std::move(other._max_per_stage_descriptor_inline_uniform_blocks);
    _max_per_stage_descriptor_update_after_bind_inline_uniform_blocks =
      std::move(
        other
          ._max_per_stage_descriptor_update_after_bind_inline_uniform_blocks);
    _max_descriptor_set_inline_uniform_blocks =
      std::move(other._max_descriptor_set_inline_uniform_blocks);
    _max_descriptor_set_update_after_bind_inline_uniform_blocks = std::move(
      other._max_descriptor_set_update_after_bind_inline_uniform_blocks);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceInlineUniformBlockPropertiesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceInlineUniformBlockPropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_inline_uniform_block_size()
  {
    return _max_inline_uniform_block_size;
  }

  constexpr const uint32_t& max_inline_uniform_block_size() const
  {
    return _max_inline_uniform_block_size;
  }

  void max_inline_uniform_block_size(uint32_t new_max_inline_uniform_block_size)
  {
    _max_inline_uniform_block_size = new_max_inline_uniform_block_size;
  }

  uint32_t& max_per_stage_descriptor_inline_uniform_blocks()
  {
    return _max_per_stage_descriptor_inline_uniform_blocks;
  }

  constexpr const uint32_t& max_per_stage_descriptor_inline_uniform_blocks()
    const
  {
    return _max_per_stage_descriptor_inline_uniform_blocks;
  }

  void max_per_stage_descriptor_inline_uniform_blocks(
    uint32_t new_max_per_stage_descriptor_inline_uniform_blocks)
  {
    _max_per_stage_descriptor_inline_uniform_blocks =
      new_max_per_stage_descriptor_inline_uniform_blocks;
  }

  uint32_t& max_per_stage_descriptor_update_after_bind_inline_uniform_blocks()
  {
    return _max_per_stage_descriptor_update_after_bind_inline_uniform_blocks;
  }

  constexpr const uint32_t&
  max_per_stage_descriptor_update_after_bind_inline_uniform_blocks() const
  {
    return _max_per_stage_descriptor_update_after_bind_inline_uniform_blocks;
  }

  void max_per_stage_descriptor_update_after_bind_inline_uniform_blocks(
    uint32_t
      new_max_per_stage_descriptor_update_after_bind_inline_uniform_blocks)
  {
    _max_per_stage_descriptor_update_after_bind_inline_uniform_blocks =
      new_max_per_stage_descriptor_update_after_bind_inline_uniform_blocks;
  }

  uint32_t& max_descriptor_set_inline_uniform_blocks()
  {
    return _max_descriptor_set_inline_uniform_blocks;
  }

  constexpr const uint32_t& max_descriptor_set_inline_uniform_blocks() const
  {
    return _max_descriptor_set_inline_uniform_blocks;
  }

  void max_descriptor_set_inline_uniform_blocks(
    uint32_t new_max_descriptor_set_inline_uniform_blocks)
  {
    _max_descriptor_set_inline_uniform_blocks =
      new_max_descriptor_set_inline_uniform_blocks;
  }

  uint32_t& max_descriptor_set_update_after_bind_inline_uniform_blocks()
  {
    return _max_descriptor_set_update_after_bind_inline_uniform_blocks;
  }

  constexpr const uint32_t&
  max_descriptor_set_update_after_bind_inline_uniform_blocks() const
  {
    return _max_descriptor_set_update_after_bind_inline_uniform_blocks;
  }

  void max_descriptor_set_update_after_bind_inline_uniform_blocks(
    uint32_t new_max_descriptor_set_update_after_bind_inline_uniform_blocks)
  {
    _max_descriptor_set_update_after_bind_inline_uniform_blocks =
      new_max_descriptor_set_update_after_bind_inline_uniform_blocks;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_inline_uniform_block_properties_ext;
  void* _next = nullptr;
  uint32_t _max_inline_uniform_block_size = 0;
  uint32_t _max_per_stage_descriptor_inline_uniform_blocks = 0;
  uint32_t _max_per_stage_descriptor_update_after_bind_inline_uniform_blocks =
    0;
  uint32_t _max_descriptor_set_inline_uniform_blocks = 0;
  uint32_t _max_descriptor_set_update_after_bind_inline_uniform_blocks = 0;
};
static_assert(sizeof(physical_device_inline_uniform_block_properties_ext) ==
                sizeof(::VkPhysicalDeviceInlineUniformBlockPropertiesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkWriteDescriptorSetInlineUniformBlockEXT.
class write_descriptor_set_inline_uniform_block_ext
{
public:
  /// Default constructor.
  constexpr write_descriptor_set_inline_uniform_block_ext() = default;

  /// Constructor.
  constexpr write_descriptor_set_inline_uniform_block_ext(
    const void* initial_next, uint32_t initial_data_size,
    const void* initial_data) noexcept
  : _next(std::move(initial_next)),
    _data_size(std::move(initial_data_size)),
    _data(std::move(initial_data))
  {
  }

  /// Copy constructor.
  constexpr write_descriptor_set_inline_uniform_block_ext(
    const write_descriptor_set_inline_uniform_block_ext& other) noexcept
  : _next(other._next), _data_size(other._data_size), _data(other._data)
  {
  }

  /// Move constructor.
  constexpr write_descriptor_set_inline_uniform_block_ext(
    write_descriptor_set_inline_uniform_block_ext&& other) noexcept
  : _next(std::move(other._next)),
    _data_size(std::move(other._data_size)),
    _data(std::move(other._data))
  {
  }

  /// Copy assignment operator.
  constexpr write_descriptor_set_inline_uniform_block_ext& operator=(
    const write_descriptor_set_inline_uniform_block_ext& other) noexcept
  {
    _next = other._next;
    _data_size = other._data_size;
    _data = other._data;
    return *this;
  }

  /// Move assignment operator.
  constexpr write_descriptor_set_inline_uniform_block_ext& operator=(
    write_descriptor_set_inline_uniform_block_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _data_size = std::move(other._data_size);
    _data = std::move(other._data);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkWriteDescriptorSetInlineUniformBlockEXT&() const
  {
    return *reinterpret_cast<const VkWriteDescriptorSetInlineUniformBlockEXT*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& data_size()
  {
    return _data_size;
  }

  constexpr const uint32_t& data_size() const
  {
    return _data_size;
  }

  void data_size(uint32_t new_data_size)
  {
    _data_size = new_data_size;
  }

  const void* data()
  {
    return _data;
  }

  constexpr const void* data() const
  {
    return _data;
  }

  void data(const void* new_data)
  {
    _data = new_data;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::write_descriptor_set_inline_uniform_block_ext;
  const void* _next = nullptr;
  uint32_t _data_size = 0;
  const void* _data = nullptr;
};
static_assert(sizeof(write_descriptor_set_inline_uniform_block_ext) ==
                sizeof(::VkWriteDescriptorSetInlineUniformBlockEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkDescriptorPoolInlineUniformBlockCreateInfoEXT.
class descriptor_pool_inline_uniform_block_create_info_ext
{
public:
  /// Default constructor.
  constexpr descriptor_pool_inline_uniform_block_create_info_ext() = default;

  /// Constructor.
  constexpr descriptor_pool_inline_uniform_block_create_info_ext(
    const void* initial_next,
    uint32_t initial_max_inline_uniform_block_bindings) noexcept
  : _next(std::move(initial_next)),
    _max_inline_uniform_block_bindings(
      std::move(initial_max_inline_uniform_block_bindings))
  {
  }

  /// Copy constructor.
  constexpr descriptor_pool_inline_uniform_block_create_info_ext(
    const descriptor_pool_inline_uniform_block_create_info_ext& other) noexcept
  : _next(other._next),
    _max_inline_uniform_block_bindings(other._max_inline_uniform_block_bindings)
  {
  }

  /// Move constructor.
  constexpr descriptor_pool_inline_uniform_block_create_info_ext(
    descriptor_pool_inline_uniform_block_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _max_inline_uniform_block_bindings(
      std::move(other._max_inline_uniform_block_bindings))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_pool_inline_uniform_block_create_info_ext& operator=(
    const descriptor_pool_inline_uniform_block_create_info_ext& other) noexcept
  {
    _next = other._next;
    _max_inline_uniform_block_bindings =
      other._max_inline_uniform_block_bindings;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_pool_inline_uniform_block_create_info_ext& operator=(
    descriptor_pool_inline_uniform_block_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _max_inline_uniform_block_bindings =
      std::move(other._max_inline_uniform_block_bindings);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorPoolInlineUniformBlockCreateInfoEXT&() const
  {
    return *reinterpret_cast<
      const VkDescriptorPoolInlineUniformBlockCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_inline_uniform_block_bindings()
  {
    return _max_inline_uniform_block_bindings;
  }

  constexpr const uint32_t& max_inline_uniform_block_bindings() const
  {
    return _max_inline_uniform_block_bindings;
  }

  void max_inline_uniform_block_bindings(
    uint32_t new_max_inline_uniform_block_bindings)
  {
    _max_inline_uniform_block_bindings = new_max_inline_uniform_block_bindings;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::descriptor_pool_inline_uniform_block_create_info_ext;
  const void* _next = nullptr;
  uint32_t _max_inline_uniform_block_bindings = 0;
};
static_assert(sizeof(descriptor_pool_inline_uniform_block_create_info_ext) ==
                sizeof(::VkDescriptorPoolInlineUniformBlockCreateInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSampleLocationEXT.
class sample_location_ext
{
public:
  /// Default constructor.
  constexpr sample_location_ext() = default;

  /// Constructor.
  constexpr sample_location_ext(float initial_x, float initial_y) noexcept
  : _x(std::move(initial_x)), _y(std::move(initial_y))
  {
  }

  /// Copy constructor.
  constexpr sample_location_ext(const sample_location_ext& other) = default;

  /// Move constructor.
  constexpr sample_location_ext(sample_location_ext&& other) = default;

  /// Copy assignment operator.
  constexpr sample_location_ext& operator=(const sample_location_ext& other) =
    default;

  /// Move assignment operator.
  constexpr sample_location_ext& operator=(sample_location_ext&& other) =
    default;

  /// Conversion operator to original Vulkan type.
  operator const VkSampleLocationEXT&() const
  {
    return *reinterpret_cast<const VkSampleLocationEXT*>(this);
  }

  float& x()
  {
    return _x;
  }

  constexpr const float& x() const
  {
    return _x;
  }

  void x(float new_x)
  {
    _x = new_x;
  }

  float& y()
  {
    return _y;
  }

  constexpr const float& y() const
  {
    return _y;
  }

  void y(float new_y)
  {
    _y = new_y;
  }

private:
  float _x = 0.0f;
  float _y = 0.0f;
};
static_assert(sizeof(sample_location_ext) == sizeof(::VkSampleLocationEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSampleLocationsInfoEXT.
class sample_locations_info_ext
{
public:
  /// Default constructor.
  constexpr sample_locations_info_ext() = default;

  /// Constructor.
  constexpr sample_locations_info_ext(
    const void* initial_next,
    vk::sample_count_flag initial_sample_locations_per_pixel,
    vk::extent_2d initial_sample_location_grid_size,
    uint32_t initial_sample_locations_count,
    const vk::sample_location_ext* initial_sample_locations) noexcept
  : _next(std::move(initial_next)),
    _sample_locations_per_pixel(std::move(initial_sample_locations_per_pixel)),
    _sample_location_grid_size(std::move(initial_sample_location_grid_size)),
    _sample_locations_count(std::move(initial_sample_locations_count)),
    _sample_locations(std::move(initial_sample_locations))
  {
  }

  /// Copy constructor.
  constexpr sample_locations_info_ext(
    const sample_locations_info_ext& other) noexcept
  : _next(other._next),
    _sample_locations_per_pixel(other._sample_locations_per_pixel),
    _sample_location_grid_size(other._sample_location_grid_size),
    _sample_locations_count(other._sample_locations_count),
    _sample_locations(other._sample_locations)
  {
  }

  /// Move constructor.
  constexpr sample_locations_info_ext(
    sample_locations_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _sample_locations_per_pixel(std::move(other._sample_locations_per_pixel)),
    _sample_location_grid_size(std::move(other._sample_location_grid_size)),
    _sample_locations_count(std::move(other._sample_locations_count)),
    _sample_locations(std::move(other._sample_locations))
  {
  }

  /// Copy assignment operator.
  constexpr sample_locations_info_ext& operator=(
    const sample_locations_info_ext& other) noexcept
  {
    _next = other._next;
    _sample_locations_per_pixel = other._sample_locations_per_pixel;
    _sample_location_grid_size = other._sample_location_grid_size;
    _sample_locations_count = other._sample_locations_count;
    _sample_locations = other._sample_locations;
    return *this;
  }

  /// Move assignment operator.
  constexpr sample_locations_info_ext& operator=(
    sample_locations_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _sample_locations_per_pixel = std::move(other._sample_locations_per_pixel);
    _sample_location_grid_size = std::move(other._sample_location_grid_size);
    _sample_locations_count = std::move(other._sample_locations_count);
    _sample_locations = std::move(other._sample_locations);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSampleLocationsInfoEXT&() const
  {
    return *reinterpret_cast<const VkSampleLocationsInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::sample_count_flag& sample_locations_per_pixel()
  {
    return _sample_locations_per_pixel;
  }

  constexpr const vk::sample_count_flag& sample_locations_per_pixel() const
  {
    return _sample_locations_per_pixel;
  }

  void sample_locations_per_pixel(
    vk::sample_count_flag new_sample_locations_per_pixel)
  {
    _sample_locations_per_pixel = new_sample_locations_per_pixel;
  }

  vk::extent_2d& sample_location_grid_size()
  {
    return _sample_location_grid_size;
  }

  constexpr const vk::extent_2d& sample_location_grid_size() const
  {
    return _sample_location_grid_size;
  }

  void sample_location_grid_size(vk::extent_2d new_sample_location_grid_size)
  {
    _sample_location_grid_size = new_sample_location_grid_size;
  }

  uint32_t& sample_locations_count()
  {
    return _sample_locations_count;
  }

  constexpr const uint32_t& sample_locations_count() const
  {
    return _sample_locations_count;
  }

  void sample_locations_count(uint32_t new_sample_locations_count)
  {
    _sample_locations_count = new_sample_locations_count;
  }

  const vk::sample_location_ext* sample_locations()
  {
    return _sample_locations;
  }

  constexpr const vk::sample_location_ext* sample_locations() const
  {
    return _sample_locations;
  }

  void sample_locations(const vk::sample_location_ext* new_sample_locations)
  {
    _sample_locations = new_sample_locations;
  }

  template <std::size_t Count>
  void sample_locations(
    const std::array<vk::sample_location_ext, Count>& new_sample_locations)
  {
    _sample_locations_count =
      static_cast<uint32_t>(new_sample_locations.size());
    _sample_locations = new_sample_locations.data();
  }

  void sample_locations(
    const std::vector<vk::sample_location_ext>& new_sample_locations)
  {
    _sample_locations_count =
      static_cast<uint32_t>(new_sample_locations.size());
    _sample_locations = new_sample_locations.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::sample_locations_info_ext;
  const void* _next = nullptr;
  vk::sample_count_flag _sample_locations_per_pixel =
    vk::sample_count_flag::none;
  vk::extent_2d _sample_location_grid_size = vk::extent_2d{};
  uint32_t _sample_locations_count = 0;
  const vk::sample_location_ext* _sample_locations = nullptr;
};
static_assert(sizeof(sample_locations_info_ext) ==
                sizeof(::VkSampleLocationsInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkAttachmentSampleLocationsEXT.
class attachment_sample_locations_ext
{
public:
  /// Default constructor.
  constexpr attachment_sample_locations_ext() = default;

  /// Constructor.
  constexpr attachment_sample_locations_ext(
    uint32_t initial_attachment_index,
    vk::sample_locations_info_ext initial_sample_locations_info) noexcept
  : _attachment_index(std::move(initial_attachment_index)),
    _sample_locations_info(std::move(initial_sample_locations_info))
  {
  }

  /// Copy constructor.
  constexpr attachment_sample_locations_ext(
    const attachment_sample_locations_ext& other) = default;

  /// Move constructor.
  constexpr attachment_sample_locations_ext(
    attachment_sample_locations_ext&& other) = default;

  /// Copy assignment operator.
  constexpr attachment_sample_locations_ext& operator=(
    const attachment_sample_locations_ext& other) = default;

  /// Move assignment operator.
  constexpr attachment_sample_locations_ext& operator=(
    attachment_sample_locations_ext&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkAttachmentSampleLocationsEXT&() const
  {
    return *reinterpret_cast<const VkAttachmentSampleLocationsEXT*>(this);
  }

  uint32_t& attachment_index()
  {
    return _attachment_index;
  }

  constexpr const uint32_t& attachment_index() const
  {
    return _attachment_index;
  }

  void attachment_index(uint32_t new_attachment_index)
  {
    _attachment_index = new_attachment_index;
  }

  vk::sample_locations_info_ext& sample_locations_info()
  {
    return _sample_locations_info;
  }

  constexpr const vk::sample_locations_info_ext& sample_locations_info() const
  {
    return _sample_locations_info;
  }

  void sample_locations_info(
    vk::sample_locations_info_ext new_sample_locations_info)
  {
    _sample_locations_info = new_sample_locations_info;
  }

private:
  uint32_t _attachment_index = 0;
  vk::sample_locations_info_ext _sample_locations_info =
    vk::sample_locations_info_ext{};
};
static_assert(sizeof(attachment_sample_locations_ext) ==
                sizeof(::VkAttachmentSampleLocationsEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkSubpassSampleLocationsEXT.
class subpass_sample_locations_ext
{
public:
  /// Default constructor.
  constexpr subpass_sample_locations_ext() = default;

  /// Constructor.
  constexpr subpass_sample_locations_ext(
    uint32_t initial_subpass_index,
    vk::sample_locations_info_ext initial_sample_locations_info) noexcept
  : _subpass_index(std::move(initial_subpass_index)),
    _sample_locations_info(std::move(initial_sample_locations_info))
  {
  }

  /// Copy constructor.
  constexpr subpass_sample_locations_ext(
    const subpass_sample_locations_ext& other) = default;

  /// Move constructor.
  constexpr subpass_sample_locations_ext(subpass_sample_locations_ext&& other) =
    default;

  /// Copy assignment operator.
  constexpr subpass_sample_locations_ext& operator=(
    const subpass_sample_locations_ext& other) = default;

  /// Move assignment operator.
  constexpr subpass_sample_locations_ext& operator=(
    subpass_sample_locations_ext&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkSubpassSampleLocationsEXT&() const
  {
    return *reinterpret_cast<const VkSubpassSampleLocationsEXT*>(this);
  }

  uint32_t& subpass_index()
  {
    return _subpass_index;
  }

  constexpr const uint32_t& subpass_index() const
  {
    return _subpass_index;
  }

  void subpass_index(uint32_t new_subpass_index)
  {
    _subpass_index = new_subpass_index;
  }

  vk::sample_locations_info_ext& sample_locations_info()
  {
    return _sample_locations_info;
  }

  constexpr const vk::sample_locations_info_ext& sample_locations_info() const
  {
    return _sample_locations_info;
  }

  void sample_locations_info(
    vk::sample_locations_info_ext new_sample_locations_info)
  {
    _sample_locations_info = new_sample_locations_info;
  }

private:
  uint32_t _subpass_index = 0;
  vk::sample_locations_info_ext _sample_locations_info =
    vk::sample_locations_info_ext{};
};
static_assert(sizeof(subpass_sample_locations_ext) ==
                sizeof(::VkSubpassSampleLocationsEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkRenderPassSampleLocationsBeginInfoEXT.
class render_pass_sample_locations_begin_info_ext
{
public:
  /// Default constructor.
  constexpr render_pass_sample_locations_begin_info_ext() = default;

  /// Constructor.
  constexpr render_pass_sample_locations_begin_info_ext(
    const void* initial_next,
    uint32_t initial_attachment_initial_sample_locations_count,
    const vk::attachment_sample_locations_ext*
      initial_attachment_initial_sample_locations,
    uint32_t initial_post_subpass_sample_locations_count,
    const vk::subpass_sample_locations_ext*
      initial_post_subpass_sample_locations) noexcept
  : _next(std::move(initial_next)),
    _attachment_initial_sample_locations_count(
      std::move(initial_attachment_initial_sample_locations_count)),
    _attachment_initial_sample_locations(
      std::move(initial_attachment_initial_sample_locations)),
    _post_subpass_sample_locations_count(
      std::move(initial_post_subpass_sample_locations_count)),
    _post_subpass_sample_locations(
      std::move(initial_post_subpass_sample_locations))
  {
  }

  /// Copy constructor.
  constexpr render_pass_sample_locations_begin_info_ext(
    const render_pass_sample_locations_begin_info_ext& other) noexcept
  : _next(other._next),
    _attachment_initial_sample_locations_count(
      other._attachment_initial_sample_locations_count),
    _attachment_initial_sample_locations(
      other._attachment_initial_sample_locations),
    _post_subpass_sample_locations_count(
      other._post_subpass_sample_locations_count),
    _post_subpass_sample_locations(other._post_subpass_sample_locations)
  {
  }

  /// Move constructor.
  constexpr render_pass_sample_locations_begin_info_ext(
    render_pass_sample_locations_begin_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _attachment_initial_sample_locations_count(
      std::move(other._attachment_initial_sample_locations_count)),
    _attachment_initial_sample_locations(
      std::move(other._attachment_initial_sample_locations)),
    _post_subpass_sample_locations_count(
      std::move(other._post_subpass_sample_locations_count)),
    _post_subpass_sample_locations(
      std::move(other._post_subpass_sample_locations))
  {
  }

  /// Copy assignment operator.
  constexpr render_pass_sample_locations_begin_info_ext& operator=(
    const render_pass_sample_locations_begin_info_ext& other) noexcept
  {
    _next = other._next;
    _attachment_initial_sample_locations_count =
      other._attachment_initial_sample_locations_count;
    _attachment_initial_sample_locations =
      other._attachment_initial_sample_locations;
    _post_subpass_sample_locations_count =
      other._post_subpass_sample_locations_count;
    _post_subpass_sample_locations = other._post_subpass_sample_locations;
    return *this;
  }

  /// Move assignment operator.
  constexpr render_pass_sample_locations_begin_info_ext& operator=(
    render_pass_sample_locations_begin_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _attachment_initial_sample_locations_count =
      std::move(other._attachment_initial_sample_locations_count);
    _attachment_initial_sample_locations =
      std::move(other._attachment_initial_sample_locations);
    _post_subpass_sample_locations_count =
      std::move(other._post_subpass_sample_locations_count);
    _post_subpass_sample_locations =
      std::move(other._post_subpass_sample_locations);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkRenderPassSampleLocationsBeginInfoEXT&() const
  {
    return *reinterpret_cast<const VkRenderPassSampleLocationsBeginInfoEXT*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& attachment_initial_sample_locations_count()
  {
    return _attachment_initial_sample_locations_count;
  }

  constexpr const uint32_t& attachment_initial_sample_locations_count() const
  {
    return _attachment_initial_sample_locations_count;
  }

  void attachment_initial_sample_locations_count(
    uint32_t new_attachment_initial_sample_locations_count)
  {
    _attachment_initial_sample_locations_count =
      new_attachment_initial_sample_locations_count;
  }

  const vk::attachment_sample_locations_ext*
  attachment_initial_sample_locations()
  {
    return _attachment_initial_sample_locations;
  }

  constexpr const vk::attachment_sample_locations_ext*
  attachment_initial_sample_locations() const
  {
    return _attachment_initial_sample_locations;
  }

  void attachment_initial_sample_locations(
    const vk::attachment_sample_locations_ext*
      new_attachment_initial_sample_locations)
  {
    _attachment_initial_sample_locations =
      new_attachment_initial_sample_locations;
  }

  template <std::size_t Count>
  void attachment_initial_sample_locations(
    const std::array<vk::attachment_sample_locations_ext, Count>&
      new_attachment_initial_sample_locations)
  {
    _attachment_initial_sample_locations_count =
      static_cast<uint32_t>(new_attachment_initial_sample_locations.size());
    _attachment_initial_sample_locations =
      new_attachment_initial_sample_locations.data();
  }

  void attachment_initial_sample_locations(
    const std::vector<vk::attachment_sample_locations_ext>&
      new_attachment_initial_sample_locations)
  {
    _attachment_initial_sample_locations_count =
      static_cast<uint32_t>(new_attachment_initial_sample_locations.size());
    _attachment_initial_sample_locations =
      new_attachment_initial_sample_locations.data();
  }

  uint32_t& post_subpass_sample_locations_count()
  {
    return _post_subpass_sample_locations_count;
  }

  constexpr const uint32_t& post_subpass_sample_locations_count() const
  {
    return _post_subpass_sample_locations_count;
  }

  void post_subpass_sample_locations_count(
    uint32_t new_post_subpass_sample_locations_count)
  {
    _post_subpass_sample_locations_count =
      new_post_subpass_sample_locations_count;
  }

  const vk::subpass_sample_locations_ext* post_subpass_sample_locations()
  {
    return _post_subpass_sample_locations;
  }

  constexpr const vk::subpass_sample_locations_ext*
  post_subpass_sample_locations() const
  {
    return _post_subpass_sample_locations;
  }

  void post_subpass_sample_locations(
    const vk::subpass_sample_locations_ext* new_post_subpass_sample_locations)
  {
    _post_subpass_sample_locations = new_post_subpass_sample_locations;
  }

  template <std::size_t Count>
  void post_subpass_sample_locations(
    const std::array<vk::subpass_sample_locations_ext, Count>&
      new_post_subpass_sample_locations)
  {
    _post_subpass_sample_locations_count =
      static_cast<uint32_t>(new_post_subpass_sample_locations.size());
    _post_subpass_sample_locations = new_post_subpass_sample_locations.data();
  }

  void post_subpass_sample_locations(
    const std::vector<vk::subpass_sample_locations_ext>&
      new_post_subpass_sample_locations)
  {
    _post_subpass_sample_locations_count =
      static_cast<uint32_t>(new_post_subpass_sample_locations.size());
    _post_subpass_sample_locations = new_post_subpass_sample_locations.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::render_pass_sample_locations_begin_info_ext;
  const void* _next = nullptr;
  uint32_t _attachment_initial_sample_locations_count = 0;
  const vk::attachment_sample_locations_ext*
    _attachment_initial_sample_locations = nullptr;
  uint32_t _post_subpass_sample_locations_count = 0;
  const vk::subpass_sample_locations_ext* _post_subpass_sample_locations =
    nullptr;
};
static_assert(sizeof(render_pass_sample_locations_begin_info_ext) ==
                sizeof(::VkRenderPassSampleLocationsBeginInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPipelineSampleLocationsStateCreateInfoEXT.
class pipeline_sample_locations_state_create_info_ext
{
public:
  /// Default constructor.
  constexpr pipeline_sample_locations_state_create_info_ext() = default;

  /// Constructor.
  constexpr pipeline_sample_locations_state_create_info_ext(
    const void* initial_next, VkBool32 initial_sample_locations_enable,
    vk::sample_locations_info_ext initial_sample_locations_info) noexcept
  : _next(std::move(initial_next)),
    _sample_locations_enable(std::move(initial_sample_locations_enable)),
    _sample_locations_info(std::move(initial_sample_locations_info))
  {
  }

  /// Copy constructor.
  constexpr pipeline_sample_locations_state_create_info_ext(
    const pipeline_sample_locations_state_create_info_ext& other) noexcept
  : _next(other._next),
    _sample_locations_enable(other._sample_locations_enable),
    _sample_locations_info(other._sample_locations_info)
  {
  }

  /// Move constructor.
  constexpr pipeline_sample_locations_state_create_info_ext(
    pipeline_sample_locations_state_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _sample_locations_enable(std::move(other._sample_locations_enable)),
    _sample_locations_info(std::move(other._sample_locations_info))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_sample_locations_state_create_info_ext& operator=(
    const pipeline_sample_locations_state_create_info_ext& other) noexcept
  {
    _next = other._next;
    _sample_locations_enable = other._sample_locations_enable;
    _sample_locations_info = other._sample_locations_info;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_sample_locations_state_create_info_ext& operator=(
    pipeline_sample_locations_state_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _sample_locations_enable = std::move(other._sample_locations_enable);
    _sample_locations_info = std::move(other._sample_locations_info);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineSampleLocationsStateCreateInfoEXT&() const
  {
    return *reinterpret_cast<
      const VkPipelineSampleLocationsStateCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& sample_locations_enable()
  {
    return _sample_locations_enable;
  }

  constexpr const VkBool32& sample_locations_enable() const
  {
    return _sample_locations_enable;
  }

  void sample_locations_enable(VkBool32 new_sample_locations_enable)
  {
    _sample_locations_enable = new_sample_locations_enable;
  }

  vk::sample_locations_info_ext& sample_locations_info()
  {
    return _sample_locations_info;
  }

  constexpr const vk::sample_locations_info_ext& sample_locations_info() const
  {
    return _sample_locations_info;
  }

  void sample_locations_info(
    vk::sample_locations_info_ext new_sample_locations_info)
  {
    _sample_locations_info = new_sample_locations_info;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_sample_locations_state_create_info_ext;
  const void* _next = nullptr;
  VkBool32 _sample_locations_enable = VK_FALSE;
  vk::sample_locations_info_ext _sample_locations_info =
    vk::sample_locations_info_ext{};
};
static_assert(sizeof(pipeline_sample_locations_state_create_info_ext) ==
                sizeof(::VkPipelineSampleLocationsStateCreateInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceSampleLocationsPropertiesEXT.
class physical_device_sample_locations_properties_ext
{
public:
  /// Default constructor.
  constexpr physical_device_sample_locations_properties_ext() = default;

  /// Constructor.
  constexpr physical_device_sample_locations_properties_ext(
    void* initial_next,
    vk::sample_count_flags initial_sample_location_sample_counts,
    vk::extent_2d initial_max_sample_location_grid_size,
    std::array<float, 2> initial_sample_location_coordinate_range,
    uint32_t initial_sample_location_sub_pixel_bits,
    VkBool32 initial_variable_sample_locations) noexcept
  : _next(std::move(initial_next)),
    _sample_location_sample_counts(
      std::move(initial_sample_location_sample_counts)),
    _max_sample_location_grid_size(
      std::move(initial_max_sample_location_grid_size)),
    _sample_location_coordinate_range(
      std::move(initial_sample_location_coordinate_range)),
    _sample_location_sub_pixel_bits(
      std::move(initial_sample_location_sub_pixel_bits)),
    _variable_sample_locations(std::move(initial_variable_sample_locations))
  {
  }

  /// Copy constructor.
  constexpr physical_device_sample_locations_properties_ext(
    const physical_device_sample_locations_properties_ext& other) noexcept
  : _next(other._next),
    _sample_location_sample_counts(other._sample_location_sample_counts),
    _max_sample_location_grid_size(other._max_sample_location_grid_size),
    _sample_location_coordinate_range(other._sample_location_coordinate_range),
    _sample_location_sub_pixel_bits(other._sample_location_sub_pixel_bits),
    _variable_sample_locations(other._variable_sample_locations)
  {
  }

  /// Move constructor.
  constexpr physical_device_sample_locations_properties_ext(
    physical_device_sample_locations_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _sample_location_sample_counts(
      std::move(other._sample_location_sample_counts)),
    _max_sample_location_grid_size(
      std::move(other._max_sample_location_grid_size)),
    _sample_location_coordinate_range(
      std::move(other._sample_location_coordinate_range)),
    _sample_location_sub_pixel_bits(
      std::move(other._sample_location_sub_pixel_bits)),
    _variable_sample_locations(std::move(other._variable_sample_locations))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_sample_locations_properties_ext& operator=(
    const physical_device_sample_locations_properties_ext& other) noexcept
  {
    _next = other._next;
    _sample_location_sample_counts = other._sample_location_sample_counts;
    _max_sample_location_grid_size = other._max_sample_location_grid_size;
    _sample_location_coordinate_range = other._sample_location_coordinate_range;
    _sample_location_sub_pixel_bits = other._sample_location_sub_pixel_bits;
    _variable_sample_locations = other._variable_sample_locations;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_sample_locations_properties_ext& operator=(
    physical_device_sample_locations_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _sample_location_sample_counts =
      std::move(other._sample_location_sample_counts);
    _max_sample_location_grid_size =
      std::move(other._max_sample_location_grid_size);
    _sample_location_coordinate_range =
      std::move(other._sample_location_coordinate_range);
    _sample_location_sub_pixel_bits =
      std::move(other._sample_location_sub_pixel_bits);
    _variable_sample_locations = std::move(other._variable_sample_locations);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceSampleLocationsPropertiesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceSampleLocationsPropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::sample_count_flags& sample_location_sample_counts()
  {
    return _sample_location_sample_counts;
  }

  constexpr const vk::sample_count_flags& sample_location_sample_counts() const
  {
    return _sample_location_sample_counts;
  }

  void sample_location_sample_counts(
    vk::sample_count_flags new_sample_location_sample_counts)
  {
    _sample_location_sample_counts = new_sample_location_sample_counts;
  }

  vk::extent_2d& max_sample_location_grid_size()
  {
    return _max_sample_location_grid_size;
  }

  constexpr const vk::extent_2d& max_sample_location_grid_size() const
  {
    return _max_sample_location_grid_size;
  }

  void max_sample_location_grid_size(
    vk::extent_2d new_max_sample_location_grid_size)
  {
    _max_sample_location_grid_size = new_max_sample_location_grid_size;
  }

  std::array<float, 2>& sample_location_coordinate_range()
  {
    return _sample_location_coordinate_range;
  }

  constexpr const std::array<float, 2>& sample_location_coordinate_range() const
  {
    return _sample_location_coordinate_range;
  }

  void sample_location_coordinate_range(
    std::array<float, 2> new_sample_location_coordinate_range)
  {
    _sample_location_coordinate_range = new_sample_location_coordinate_range;
  }

  uint32_t& sample_location_sub_pixel_bits()
  {
    return _sample_location_sub_pixel_bits;
  }

  constexpr const uint32_t& sample_location_sub_pixel_bits() const
  {
    return _sample_location_sub_pixel_bits;
  }

  void sample_location_sub_pixel_bits(
    uint32_t new_sample_location_sub_pixel_bits)
  {
    _sample_location_sub_pixel_bits = new_sample_location_sub_pixel_bits;
  }

  VkBool32& variable_sample_locations()
  {
    return _variable_sample_locations;
  }

  constexpr const VkBool32& variable_sample_locations() const
  {
    return _variable_sample_locations;
  }

  void variable_sample_locations(VkBool32 new_variable_sample_locations)
  {
    _variable_sample_locations = new_variable_sample_locations;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_sample_locations_properties_ext;
  void* _next = nullptr;
  vk::sample_count_flags _sample_location_sample_counts =
    vk::sample_count_flag::none;
  vk::extent_2d _max_sample_location_grid_size = vk::extent_2d{};
  std::array<float, 2> _sample_location_coordinate_range = {};
  uint32_t _sample_location_sub_pixel_bits = 0;
  VkBool32 _variable_sample_locations = VK_FALSE;
};
static_assert(sizeof(physical_device_sample_locations_properties_ext) ==
                sizeof(::VkPhysicalDeviceSampleLocationsPropertiesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkMultisamplePropertiesEXT.
class multisample_properties_ext
{
public:
  /// Default constructor.
  constexpr multisample_properties_ext() = default;

  /// Constructor.
  constexpr multisample_properties_ext(
    void* initial_next,
    vk::extent_2d initial_max_sample_location_grid_size) noexcept
  : _next(std::move(initial_next)),
    _max_sample_location_grid_size(
      std::move(initial_max_sample_location_grid_size))
  {
  }

  /// Copy constructor.
  constexpr multisample_properties_ext(
    const multisample_properties_ext& other) noexcept
  : _next(other._next),
    _max_sample_location_grid_size(other._max_sample_location_grid_size)
  {
  }

  /// Move constructor.
  constexpr multisample_properties_ext(
    multisample_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _max_sample_location_grid_size(
      std::move(other._max_sample_location_grid_size))
  {
  }

  /// Copy assignment operator.
  constexpr multisample_properties_ext& operator=(
    const multisample_properties_ext& other) noexcept
  {
    _next = other._next;
    _max_sample_location_grid_size = other._max_sample_location_grid_size;
    return *this;
  }

  /// Move assignment operator.
  constexpr multisample_properties_ext& operator=(
    multisample_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _max_sample_location_grid_size =
      std::move(other._max_sample_location_grid_size);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMultisamplePropertiesEXT&() const
  {
    return *reinterpret_cast<const VkMultisamplePropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::extent_2d& max_sample_location_grid_size()
  {
    return _max_sample_location_grid_size;
  }

  constexpr const vk::extent_2d& max_sample_location_grid_size() const
  {
    return _max_sample_location_grid_size;
  }

  void max_sample_location_grid_size(
    vk::extent_2d new_max_sample_location_grid_size)
  {
    _max_sample_location_grid_size = new_max_sample_location_grid_size;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::multisample_properties_ext;
  void* _next = nullptr;
  vk::extent_2d _max_sample_location_grid_size = vk::extent_2d{};
};
static_assert(sizeof(multisample_properties_ext) ==
                sizeof(::VkMultisamplePropertiesEXT),
              "struct and wrapper have different size!");

inline void cmd_set_sample_locations_ext(
  VkCommandBuffer command_buffer,
  const vk::sample_locations_info_ext* sample_locations_info)
{
  vkCmdSetSampleLocationsEXT(
    static_cast<VkCommandBuffer>(command_buffer),
    reinterpret_cast<const VkSampleLocationsInfoEXT*>(sample_locations_info));
}
inline void get_physical_device_multisample_properties_ext(
  VkPhysicalDevice physical_device, vk::sample_count_flag samples,
  vk::multisample_properties_ext* multisample_properties)
{
  vkGetPhysicalDeviceMultisamplePropertiesEXT(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<VkSampleCountFlagBits>(samples),
    reinterpret_cast<VkMultisamplePropertiesEXT*>(multisample_properties));
}

/// Enhanced replacement type for VkImageFormatListCreateInfoKHR.
class image_format_list_create_info_khr
{
public:
  /// Default constructor.
  constexpr image_format_list_create_info_khr() = default;

  /// Constructor.
  constexpr image_format_list_create_info_khr(
    const void* initial_next, uint32_t initial_view_format_count,
    const vk::format* initial_view_formats) noexcept
  : _next(std::move(initial_next)),
    _view_format_count(std::move(initial_view_format_count)),
    _view_formats(std::move(initial_view_formats))
  {
  }

  /// Copy constructor.
  constexpr image_format_list_create_info_khr(
    const image_format_list_create_info_khr& other) noexcept
  : _next(other._next),
    _view_format_count(other._view_format_count),
    _view_formats(other._view_formats)
  {
  }

  /// Move constructor.
  constexpr image_format_list_create_info_khr(
    image_format_list_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _view_format_count(std::move(other._view_format_count)),
    _view_formats(std::move(other._view_formats))
  {
  }

  /// Copy assignment operator.
  constexpr image_format_list_create_info_khr& operator=(
    const image_format_list_create_info_khr& other) noexcept
  {
    _next = other._next;
    _view_format_count = other._view_format_count;
    _view_formats = other._view_formats;
    return *this;
  }

  /// Move assignment operator.
  constexpr image_format_list_create_info_khr& operator=(
    image_format_list_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _view_format_count = std::move(other._view_format_count);
    _view_formats = std::move(other._view_formats);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImageFormatListCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkImageFormatListCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& view_format_count()
  {
    return _view_format_count;
  }

  constexpr const uint32_t& view_format_count() const
  {
    return _view_format_count;
  }

  void view_format_count(uint32_t new_view_format_count)
  {
    _view_format_count = new_view_format_count;
  }

  const vk::format* view_formats()
  {
    return _view_formats;
  }

  constexpr const vk::format* view_formats() const
  {
    return _view_formats;
  }

  void view_formats(const vk::format* new_view_formats)
  {
    _view_formats = new_view_formats;
  }

  template <std::size_t Count>
  void view_formats(const std::array<vk::format, Count>& new_view_formats)
  {
    _view_format_count = static_cast<uint32_t>(new_view_formats.size());
    _view_formats = new_view_formats.data();
  }

  void view_formats(const std::vector<vk::format>& new_view_formats)
  {
    _view_format_count = static_cast<uint32_t>(new_view_formats.size());
    _view_formats = new_view_formats.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::image_format_list_create_info_khr;
  const void* _next = nullptr;
  uint32_t _view_format_count = 0;
  const vk::format* _view_formats = nullptr;
};
static_assert(sizeof(image_format_list_create_info_khr) ==
                sizeof(::VkImageFormatListCreateInfoKHR),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT.
class physical_device_blend_operation_advanced_features_ext
{
public:
  /// Default constructor.
  constexpr physical_device_blend_operation_advanced_features_ext() = default;

  /// Constructor.
  constexpr physical_device_blend_operation_advanced_features_ext(
    void* initial_next,
    VkBool32 initial_advanced_blend_coherent_operations) noexcept
  : _next(std::move(initial_next)),
    _advanced_blend_coherent_operations(
      std::move(initial_advanced_blend_coherent_operations))
  {
  }

  /// Copy constructor.
  constexpr physical_device_blend_operation_advanced_features_ext(
    const physical_device_blend_operation_advanced_features_ext& other) noexcept
  : _next(other._next),
    _advanced_blend_coherent_operations(
      other._advanced_blend_coherent_operations)
  {
  }

  /// Move constructor.
  constexpr physical_device_blend_operation_advanced_features_ext(
    physical_device_blend_operation_advanced_features_ext&& other) noexcept
  : _next(std::move(other._next)),
    _advanced_blend_coherent_operations(
      std::move(other._advanced_blend_coherent_operations))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_blend_operation_advanced_features_ext& operator=(
    const physical_device_blend_operation_advanced_features_ext& other) noexcept
  {
    _next = other._next;
    _advanced_blend_coherent_operations =
      other._advanced_blend_coherent_operations;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_blend_operation_advanced_features_ext& operator=(
    physical_device_blend_operation_advanced_features_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _advanced_blend_coherent_operations =
      std::move(other._advanced_blend_coherent_operations);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& advanced_blend_coherent_operations()
  {
    return _advanced_blend_coherent_operations;
  }

  constexpr const VkBool32& advanced_blend_coherent_operations() const
  {
    return _advanced_blend_coherent_operations;
  }

  void advanced_blend_coherent_operations(
    VkBool32 new_advanced_blend_coherent_operations)
  {
    _advanced_blend_coherent_operations =
      new_advanced_blend_coherent_operations;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_blend_operation_advanced_features_ext;
  void* _next = nullptr;
  VkBool32 _advanced_blend_coherent_operations = VK_FALSE;
};
static_assert(sizeof(physical_device_blend_operation_advanced_features_ext) ==
                sizeof(::VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT.
class physical_device_blend_operation_advanced_properties_ext
{
public:
  /// Default constructor.
  constexpr physical_device_blend_operation_advanced_properties_ext() = default;

  /// Constructor.
  constexpr physical_device_blend_operation_advanced_properties_ext(
    void* initial_next, uint32_t initial_advanced_blend_max_color_attachments,
    VkBool32 initial_advanced_blend_independent_blend,
    VkBool32 initial_advanced_blend_non_premultiplied_src_color,
    VkBool32 initial_advanced_blend_non_premultiplied_dst_color,
    VkBool32 initial_advanced_blend_correlated_overlap,
    VkBool32 initial_advanced_blend_all_operations) noexcept
  : _next(std::move(initial_next)),
    _advanced_blend_max_color_attachments(
      std::move(initial_advanced_blend_max_color_attachments)),
    _advanced_blend_independent_blend(
      std::move(initial_advanced_blend_independent_blend)),
    _advanced_blend_non_premultiplied_src_color(
      std::move(initial_advanced_blend_non_premultiplied_src_color)),
    _advanced_blend_non_premultiplied_dst_color(
      std::move(initial_advanced_blend_non_premultiplied_dst_color)),
    _advanced_blend_correlated_overlap(
      std::move(initial_advanced_blend_correlated_overlap)),
    _advanced_blend_all_operations(
      std::move(initial_advanced_blend_all_operations))
  {
  }

  /// Copy constructor.
  constexpr physical_device_blend_operation_advanced_properties_ext(
    const physical_device_blend_operation_advanced_properties_ext&
      other) noexcept
  : _next(other._next),
    _advanced_blend_max_color_attachments(
      other._advanced_blend_max_color_attachments),
    _advanced_blend_independent_blend(other._advanced_blend_independent_blend),
    _advanced_blend_non_premultiplied_src_color(
      other._advanced_blend_non_premultiplied_src_color),
    _advanced_blend_non_premultiplied_dst_color(
      other._advanced_blend_non_premultiplied_dst_color),
    _advanced_blend_correlated_overlap(
      other._advanced_blend_correlated_overlap),
    _advanced_blend_all_operations(other._advanced_blend_all_operations)
  {
  }

  /// Move constructor.
  constexpr physical_device_blend_operation_advanced_properties_ext(
    physical_device_blend_operation_advanced_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _advanced_blend_max_color_attachments(
      std::move(other._advanced_blend_max_color_attachments)),
    _advanced_blend_independent_blend(
      std::move(other._advanced_blend_independent_blend)),
    _advanced_blend_non_premultiplied_src_color(
      std::move(other._advanced_blend_non_premultiplied_src_color)),
    _advanced_blend_non_premultiplied_dst_color(
      std::move(other._advanced_blend_non_premultiplied_dst_color)),
    _advanced_blend_correlated_overlap(
      std::move(other._advanced_blend_correlated_overlap)),
    _advanced_blend_all_operations(
      std::move(other._advanced_blend_all_operations))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_blend_operation_advanced_properties_ext& operator=(
    const physical_device_blend_operation_advanced_properties_ext&
      other) noexcept
  {
    _next = other._next;
    _advanced_blend_max_color_attachments =
      other._advanced_blend_max_color_attachments;
    _advanced_blend_independent_blend = other._advanced_blend_independent_blend;
    _advanced_blend_non_premultiplied_src_color =
      other._advanced_blend_non_premultiplied_src_color;
    _advanced_blend_non_premultiplied_dst_color =
      other._advanced_blend_non_premultiplied_dst_color;
    _advanced_blend_correlated_overlap =
      other._advanced_blend_correlated_overlap;
    _advanced_blend_all_operations = other._advanced_blend_all_operations;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_blend_operation_advanced_properties_ext& operator=(
    physical_device_blend_operation_advanced_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _advanced_blend_max_color_attachments =
      std::move(other._advanced_blend_max_color_attachments);
    _advanced_blend_independent_blend =
      std::move(other._advanced_blend_independent_blend);
    _advanced_blend_non_premultiplied_src_color =
      std::move(other._advanced_blend_non_premultiplied_src_color);
    _advanced_blend_non_premultiplied_dst_color =
      std::move(other._advanced_blend_non_premultiplied_dst_color);
    _advanced_blend_correlated_overlap =
      std::move(other._advanced_blend_correlated_overlap);
    _advanced_blend_all_operations =
      std::move(other._advanced_blend_all_operations);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& advanced_blend_max_color_attachments()
  {
    return _advanced_blend_max_color_attachments;
  }

  constexpr const uint32_t& advanced_blend_max_color_attachments() const
  {
    return _advanced_blend_max_color_attachments;
  }

  void advanced_blend_max_color_attachments(
    uint32_t new_advanced_blend_max_color_attachments)
  {
    _advanced_blend_max_color_attachments =
      new_advanced_blend_max_color_attachments;
  }

  VkBool32& advanced_blend_independent_blend()
  {
    return _advanced_blend_independent_blend;
  }

  constexpr const VkBool32& advanced_blend_independent_blend() const
  {
    return _advanced_blend_independent_blend;
  }

  void advanced_blend_independent_blend(
    VkBool32 new_advanced_blend_independent_blend)
  {
    _advanced_blend_independent_blend = new_advanced_blend_independent_blend;
  }

  VkBool32& advanced_blend_non_premultiplied_src_color()
  {
    return _advanced_blend_non_premultiplied_src_color;
  }

  constexpr const VkBool32& advanced_blend_non_premultiplied_src_color() const
  {
    return _advanced_blend_non_premultiplied_src_color;
  }

  void advanced_blend_non_premultiplied_src_color(
    VkBool32 new_advanced_blend_non_premultiplied_src_color)
  {
    _advanced_blend_non_premultiplied_src_color =
      new_advanced_blend_non_premultiplied_src_color;
  }

  VkBool32& advanced_blend_non_premultiplied_dst_color()
  {
    return _advanced_blend_non_premultiplied_dst_color;
  }

  constexpr const VkBool32& advanced_blend_non_premultiplied_dst_color() const
  {
    return _advanced_blend_non_premultiplied_dst_color;
  }

  void advanced_blend_non_premultiplied_dst_color(
    VkBool32 new_advanced_blend_non_premultiplied_dst_color)
  {
    _advanced_blend_non_premultiplied_dst_color =
      new_advanced_blend_non_premultiplied_dst_color;
  }

  VkBool32& advanced_blend_correlated_overlap()
  {
    return _advanced_blend_correlated_overlap;
  }

  constexpr const VkBool32& advanced_blend_correlated_overlap() const
  {
    return _advanced_blend_correlated_overlap;
  }

  void advanced_blend_correlated_overlap(
    VkBool32 new_advanced_blend_correlated_overlap)
  {
    _advanced_blend_correlated_overlap = new_advanced_blend_correlated_overlap;
  }

  VkBool32& advanced_blend_all_operations()
  {
    return _advanced_blend_all_operations;
  }

  constexpr const VkBool32& advanced_blend_all_operations() const
  {
    return _advanced_blend_all_operations;
  }

  void advanced_blend_all_operations(VkBool32 new_advanced_blend_all_operations)
  {
    _advanced_blend_all_operations = new_advanced_blend_all_operations;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_blend_operation_advanced_properties_ext;
  void* _next = nullptr;
  uint32_t _advanced_blend_max_color_attachments = 0;
  VkBool32 _advanced_blend_independent_blend = VK_FALSE;
  VkBool32 _advanced_blend_non_premultiplied_src_color = VK_FALSE;
  VkBool32 _advanced_blend_non_premultiplied_dst_color = VK_FALSE;
  VkBool32 _advanced_blend_correlated_overlap = VK_FALSE;
  VkBool32 _advanced_blend_all_operations = VK_FALSE;
};
static_assert(sizeof(physical_device_blend_operation_advanced_properties_ext) ==
                sizeof(::VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT),
              "struct and wrapper have different size!");

enum class blend_overlap_ext
{
  /// @see VK_BLEND_OVERLAP_UNCORRELATED_EXT
  blend_overlap_uncorrelated_ext = 0,
  /// @see VK_BLEND_OVERLAP_DISJOINT_EXT
  blend_overlap_disjoint_ext = 1,
  /// @see VK_BLEND_OVERLAP_CONJOINT_EXT
  blend_overlap_conjoint_ext = 2,
};

/// Enhanced replacement type for
/// VkPipelineColorBlendAdvancedStateCreateInfoEXT.
class pipeline_color_blend_advanced_state_create_info_ext
{
public:
  /// Default constructor.
  constexpr pipeline_color_blend_advanced_state_create_info_ext() = default;

  /// Constructor.
  constexpr pipeline_color_blend_advanced_state_create_info_ext(
    const void* initial_next, VkBool32 initial_src_premultiplied,
    VkBool32 initial_dst_premultiplied,
    vk::blend_overlap_ext initial_blend_overlap) noexcept
  : _next(std::move(initial_next)),
    _src_premultiplied(std::move(initial_src_premultiplied)),
    _dst_premultiplied(std::move(initial_dst_premultiplied)),
    _blend_overlap(std::move(initial_blend_overlap))
  {
  }

  /// Copy constructor.
  constexpr pipeline_color_blend_advanced_state_create_info_ext(
    const pipeline_color_blend_advanced_state_create_info_ext& other) noexcept
  : _next(other._next),
    _src_premultiplied(other._src_premultiplied),
    _dst_premultiplied(other._dst_premultiplied),
    _blend_overlap(other._blend_overlap)
  {
  }

  /// Move constructor.
  constexpr pipeline_color_blend_advanced_state_create_info_ext(
    pipeline_color_blend_advanced_state_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _src_premultiplied(std::move(other._src_premultiplied)),
    _dst_premultiplied(std::move(other._dst_premultiplied)),
    _blend_overlap(std::move(other._blend_overlap))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_color_blend_advanced_state_create_info_ext& operator=(
    const pipeline_color_blend_advanced_state_create_info_ext& other) noexcept
  {
    _next = other._next;
    _src_premultiplied = other._src_premultiplied;
    _dst_premultiplied = other._dst_premultiplied;
    _blend_overlap = other._blend_overlap;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_color_blend_advanced_state_create_info_ext& operator=(
    pipeline_color_blend_advanced_state_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _src_premultiplied = std::move(other._src_premultiplied);
    _dst_premultiplied = std::move(other._dst_premultiplied);
    _blend_overlap = std::move(other._blend_overlap);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineColorBlendAdvancedStateCreateInfoEXT&() const
  {
    return *reinterpret_cast<
      const VkPipelineColorBlendAdvancedStateCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& src_premultiplied()
  {
    return _src_premultiplied;
  }

  constexpr const VkBool32& src_premultiplied() const
  {
    return _src_premultiplied;
  }

  void src_premultiplied(VkBool32 new_src_premultiplied)
  {
    _src_premultiplied = new_src_premultiplied;
  }

  VkBool32& dst_premultiplied()
  {
    return _dst_premultiplied;
  }

  constexpr const VkBool32& dst_premultiplied() const
  {
    return _dst_premultiplied;
  }

  void dst_premultiplied(VkBool32 new_dst_premultiplied)
  {
    _dst_premultiplied = new_dst_premultiplied;
  }

  vk::blend_overlap_ext& blend_overlap()
  {
    return _blend_overlap;
  }

  constexpr const vk::blend_overlap_ext& blend_overlap() const
  {
    return _blend_overlap;
  }

  void blend_overlap(vk::blend_overlap_ext new_blend_overlap)
  {
    _blend_overlap = new_blend_overlap;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_color_blend_advanced_state_create_info_ext;
  const void* _next = nullptr;
  VkBool32 _src_premultiplied = VK_FALSE;
  VkBool32 _dst_premultiplied = VK_FALSE;
  vk::blend_overlap_ext _blend_overlap =
    vk::blend_overlap_ext::blend_overlap_uncorrelated_ext;
};
static_assert(sizeof(pipeline_color_blend_advanced_state_create_info_ext) ==
                sizeof(::VkPipelineColorBlendAdvancedStateCreateInfoEXT),
              "struct and wrapper have different size!");

using pipeline_coverage_to_color_state_create_flags_nv = VkFlags;

/// Enhanced replacement type for VkPipelineCoverageToColorStateCreateInfoNV.
class pipeline_coverage_to_color_state_create_info_nv
{
public:
  /// Default constructor.
  constexpr pipeline_coverage_to_color_state_create_info_nv() = default;

  /// Constructor.
  constexpr pipeline_coverage_to_color_state_create_info_nv(
    const void* initial_next,
    vk::pipeline_coverage_to_color_state_create_flags_nv initial_flags,
    VkBool32 initial_coverage_to_color_enable,
    uint32_t initial_coverage_to_color_location) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _coverage_to_color_enable(std::move(initial_coverage_to_color_enable)),
    _coverage_to_color_location(std::move(initial_coverage_to_color_location))
  {
  }

  /// Copy constructor.
  constexpr pipeline_coverage_to_color_state_create_info_nv(
    const pipeline_coverage_to_color_state_create_info_nv& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _coverage_to_color_enable(other._coverage_to_color_enable),
    _coverage_to_color_location(other._coverage_to_color_location)
  {
  }

  /// Move constructor.
  constexpr pipeline_coverage_to_color_state_create_info_nv(
    pipeline_coverage_to_color_state_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _coverage_to_color_enable(std::move(other._coverage_to_color_enable)),
    _coverage_to_color_location(std::move(other._coverage_to_color_location))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_coverage_to_color_state_create_info_nv& operator=(
    const pipeline_coverage_to_color_state_create_info_nv& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _coverage_to_color_enable = other._coverage_to_color_enable;
    _coverage_to_color_location = other._coverage_to_color_location;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_coverage_to_color_state_create_info_nv& operator=(
    pipeline_coverage_to_color_state_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _coverage_to_color_enable = std::move(other._coverage_to_color_enable);
    _coverage_to_color_location = std::move(other._coverage_to_color_location);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineCoverageToColorStateCreateInfoNV&() const
  {
    return *reinterpret_cast<const VkPipelineCoverageToColorStateCreateInfoNV*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_coverage_to_color_state_create_flags_nv& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_coverage_to_color_state_create_flags_nv& flags()
    const
  {
    return _flags;
  }

  void flags(vk::pipeline_coverage_to_color_state_create_flags_nv new_flags)
  {
    _flags = new_flags;
  }

  VkBool32& coverage_to_color_enable()
  {
    return _coverage_to_color_enable;
  }

  constexpr const VkBool32& coverage_to_color_enable() const
  {
    return _coverage_to_color_enable;
  }

  void coverage_to_color_enable(VkBool32 new_coverage_to_color_enable)
  {
    _coverage_to_color_enable = new_coverage_to_color_enable;
  }

  uint32_t& coverage_to_color_location()
  {
    return _coverage_to_color_location;
  }

  constexpr const uint32_t& coverage_to_color_location() const
  {
    return _coverage_to_color_location;
  }

  void coverage_to_color_location(uint32_t new_coverage_to_color_location)
  {
    _coverage_to_color_location = new_coverage_to_color_location;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_coverage_to_color_state_create_info_nv;
  const void* _next = nullptr;
  vk::pipeline_coverage_to_color_state_create_flags_nv _flags = 0;
  VkBool32 _coverage_to_color_enable = VK_FALSE;
  uint32_t _coverage_to_color_location = 0;
};
static_assert(sizeof(pipeline_coverage_to_color_state_create_info_nv) ==
                sizeof(::VkPipelineCoverageToColorStateCreateInfoNV),
              "struct and wrapper have different size!");

using pipeline_coverage_modulation_state_create_flags_nv = VkFlags;
enum class coverage_modulation_mode_nv
{
  /// @see VK_COVERAGE_MODULATION_MODE_NONE_NV
  coverage_modulation_mode_none_nv = 0,
  /// @see VK_COVERAGE_MODULATION_MODE_RGB_NV
  coverage_modulation_mode_rgb_nv = 1,
  /// @see VK_COVERAGE_MODULATION_MODE_ALPHA_NV
  coverage_modulation_mode_alpha_nv = 2,
  /// @see VK_COVERAGE_MODULATION_MODE_RGBA_NV
  coverage_modulation_mode_rgba_nv = 3,
};

/// Enhanced replacement type for VkPipelineCoverageModulationStateCreateInfoNV.
class pipeline_coverage_modulation_state_create_info_nv
{
public:
  /// Default constructor.
  constexpr pipeline_coverage_modulation_state_create_info_nv() = default;

  /// Constructor.
  constexpr pipeline_coverage_modulation_state_create_info_nv(
    const void* initial_next,
    vk::pipeline_coverage_modulation_state_create_flags_nv initial_flags,
    vk::coverage_modulation_mode_nv initial_coverage_modulation_mode,
    VkBool32 initial_coverage_modulation_table_enable,
    uint32_t initial_coverage_modulation_table_count,
    const float* initial_coverage_modulation_table) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _coverage_modulation_mode(std::move(initial_coverage_modulation_mode)),
    _coverage_modulation_table_enable(
      std::move(initial_coverage_modulation_table_enable)),
    _coverage_modulation_table_count(
      std::move(initial_coverage_modulation_table_count)),
    _coverage_modulation_table(std::move(initial_coverage_modulation_table))
  {
  }

  /// Copy constructor.
  constexpr pipeline_coverage_modulation_state_create_info_nv(
    const pipeline_coverage_modulation_state_create_info_nv& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _coverage_modulation_mode(other._coverage_modulation_mode),
    _coverage_modulation_table_enable(other._coverage_modulation_table_enable),
    _coverage_modulation_table_count(other._coverage_modulation_table_count),
    _coverage_modulation_table(other._coverage_modulation_table)
  {
  }

  /// Move constructor.
  constexpr pipeline_coverage_modulation_state_create_info_nv(
    pipeline_coverage_modulation_state_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _coverage_modulation_mode(std::move(other._coverage_modulation_mode)),
    _coverage_modulation_table_enable(
      std::move(other._coverage_modulation_table_enable)),
    _coverage_modulation_table_count(
      std::move(other._coverage_modulation_table_count)),
    _coverage_modulation_table(std::move(other._coverage_modulation_table))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_coverage_modulation_state_create_info_nv& operator=(
    const pipeline_coverage_modulation_state_create_info_nv& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _coverage_modulation_mode = other._coverage_modulation_mode;
    _coverage_modulation_table_enable = other._coverage_modulation_table_enable;
    _coverage_modulation_table_count = other._coverage_modulation_table_count;
    _coverage_modulation_table = other._coverage_modulation_table;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_coverage_modulation_state_create_info_nv& operator=(
    pipeline_coverage_modulation_state_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _coverage_modulation_mode = std::move(other._coverage_modulation_mode);
    _coverage_modulation_table_enable =
      std::move(other._coverage_modulation_table_enable);
    _coverage_modulation_table_count =
      std::move(other._coverage_modulation_table_count);
    _coverage_modulation_table = std::move(other._coverage_modulation_table);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineCoverageModulationStateCreateInfoNV&() const
  {
    return *reinterpret_cast<
      const VkPipelineCoverageModulationStateCreateInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_coverage_modulation_state_create_flags_nv& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_coverage_modulation_state_create_flags_nv&
  flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_coverage_modulation_state_create_flags_nv new_flags)
  {
    _flags = new_flags;
  }

  vk::coverage_modulation_mode_nv& coverage_modulation_mode()
  {
    return _coverage_modulation_mode;
  }

  constexpr const vk::coverage_modulation_mode_nv& coverage_modulation_mode()
    const
  {
    return _coverage_modulation_mode;
  }

  void coverage_modulation_mode(
    vk::coverage_modulation_mode_nv new_coverage_modulation_mode)
  {
    _coverage_modulation_mode = new_coverage_modulation_mode;
  }

  VkBool32& coverage_modulation_table_enable()
  {
    return _coverage_modulation_table_enable;
  }

  constexpr const VkBool32& coverage_modulation_table_enable() const
  {
    return _coverage_modulation_table_enable;
  }

  void coverage_modulation_table_enable(
    VkBool32 new_coverage_modulation_table_enable)
  {
    _coverage_modulation_table_enable = new_coverage_modulation_table_enable;
  }

  uint32_t& coverage_modulation_table_count()
  {
    return _coverage_modulation_table_count;
  }

  constexpr const uint32_t& coverage_modulation_table_count() const
  {
    return _coverage_modulation_table_count;
  }

  void coverage_modulation_table_count(
    uint32_t new_coverage_modulation_table_count)
  {
    _coverage_modulation_table_count = new_coverage_modulation_table_count;
  }

  const float* coverage_modulation_table()
  {
    return _coverage_modulation_table;
  }

  constexpr const float* coverage_modulation_table() const
  {
    return _coverage_modulation_table;
  }

  void coverage_modulation_table(const float* new_coverage_modulation_table)
  {
    _coverage_modulation_table = new_coverage_modulation_table;
  }

  template <std::size_t Count>
  void coverage_modulation_table(
    const std::array<float, Count>& new_coverage_modulation_table)
  {
    _coverage_modulation_table_count =
      static_cast<uint32_t>(new_coverage_modulation_table.size());
    _coverage_modulation_table = new_coverage_modulation_table.data();
  }

  void coverage_modulation_table(
    const std::vector<float>& new_coverage_modulation_table)
  {
    _coverage_modulation_table_count =
      static_cast<uint32_t>(new_coverage_modulation_table.size());
    _coverage_modulation_table = new_coverage_modulation_table.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_coverage_modulation_state_create_info_nv;
  const void* _next = nullptr;
  vk::pipeline_coverage_modulation_state_create_flags_nv _flags = 0;
  vk::coverage_modulation_mode_nv _coverage_modulation_mode =
    vk::coverage_modulation_mode_nv::coverage_modulation_mode_none_nv;
  VkBool32 _coverage_modulation_table_enable = VK_FALSE;
  uint32_t _coverage_modulation_table_count = 0;
  const float* _coverage_modulation_table = nullptr;
};
static_assert(sizeof(pipeline_coverage_modulation_state_create_info_nv) ==
                sizeof(::VkPipelineCoverageModulationStateCreateInfoNV),
              "struct and wrapper have different size!");

using validation_cache_create_flags_ext = VkFlags;

/// Enhanced replacement type for VkValidationCacheCreateInfoEXT.
class validation_cache_create_info_ext
{
public:
  /// Default constructor.
  constexpr validation_cache_create_info_ext() = default;

  /// Constructor.
  constexpr validation_cache_create_info_ext(
    const void* initial_next,
    vk::validation_cache_create_flags_ext initial_flags,
    size_t initial_initial_data_size, const void* initial_initial_data) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _initial_data_size(std::move(initial_initial_data_size)),
    _initial_data(std::move(initial_initial_data))
  {
  }

  /// Copy constructor.
  constexpr validation_cache_create_info_ext(
    const validation_cache_create_info_ext& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _initial_data_size(other._initial_data_size),
    _initial_data(other._initial_data)
  {
  }

  /// Move constructor.
  constexpr validation_cache_create_info_ext(
    validation_cache_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _initial_data_size(std::move(other._initial_data_size)),
    _initial_data(std::move(other._initial_data))
  {
  }

  /// Copy assignment operator.
  constexpr validation_cache_create_info_ext& operator=(
    const validation_cache_create_info_ext& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _initial_data_size = other._initial_data_size;
    _initial_data = other._initial_data;
    return *this;
  }

  /// Move assignment operator.
  constexpr validation_cache_create_info_ext& operator=(
    validation_cache_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _initial_data_size = std::move(other._initial_data_size);
    _initial_data = std::move(other._initial_data);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkValidationCacheCreateInfoEXT&() const
  {
    return *reinterpret_cast<const VkValidationCacheCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::validation_cache_create_flags_ext& flags()
  {
    return _flags;
  }

  constexpr const vk::validation_cache_create_flags_ext& flags() const
  {
    return _flags;
  }

  void flags(vk::validation_cache_create_flags_ext new_flags)
  {
    _flags = new_flags;
  }

  size_t& initial_data_size()
  {
    return _initial_data_size;
  }

  constexpr const size_t& initial_data_size() const
  {
    return _initial_data_size;
  }

  void initial_data_size(size_t new_initial_data_size)
  {
    _initial_data_size = new_initial_data_size;
  }

  const void* initial_data()
  {
    return _initial_data;
  }

  constexpr const void* initial_data() const
  {
    return _initial_data;
  }

  void initial_data(const void* new_initial_data)
  {
    _initial_data = new_initial_data;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::validation_cache_create_info_ext;
  const void* _next = nullptr;
  vk::validation_cache_create_flags_ext _flags = 0;
  size_t _initial_data_size = 0;
  const void* _initial_data = nullptr;
};
static_assert(sizeof(validation_cache_create_info_ext) ==
                sizeof(::VkValidationCacheCreateInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkShaderModuleValidationCacheCreateInfoEXT.
class shader_module_validation_cache_create_info_ext
{
public:
  /// Default constructor.
  constexpr shader_module_validation_cache_create_info_ext() = default;

  /// Constructor.
  constexpr shader_module_validation_cache_create_info_ext(
    const void* initial_next,
    VkValidationCacheEXT initial_validation_cache) noexcept
  : _next(std::move(initial_next)),
    _validation_cache(std::move(initial_validation_cache))
  {
  }

  /// Copy constructor.
  constexpr shader_module_validation_cache_create_info_ext(
    const shader_module_validation_cache_create_info_ext& other) noexcept
  : _next(other._next), _validation_cache(other._validation_cache)
  {
  }

  /// Move constructor.
  constexpr shader_module_validation_cache_create_info_ext(
    shader_module_validation_cache_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _validation_cache(std::move(other._validation_cache))
  {
  }

  /// Copy assignment operator.
  constexpr shader_module_validation_cache_create_info_ext& operator=(
    const shader_module_validation_cache_create_info_ext& other) noexcept
  {
    _next = other._next;
    _validation_cache = other._validation_cache;
    return *this;
  }

  /// Move assignment operator.
  constexpr shader_module_validation_cache_create_info_ext& operator=(
    shader_module_validation_cache_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _validation_cache = std::move(other._validation_cache);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkShaderModuleValidationCacheCreateInfoEXT&() const
  {
    return *reinterpret_cast<const VkShaderModuleValidationCacheCreateInfoEXT*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkValidationCacheEXT& validation_cache()
  {
    return _validation_cache;
  }

  constexpr const VkValidationCacheEXT& validation_cache() const
  {
    return _validation_cache;
  }

  void validation_cache(VkValidationCacheEXT new_validation_cache)
  {
    _validation_cache = new_validation_cache;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::shader_module_validation_cache_create_info_ext;
  const void* _next = nullptr;
  VkValidationCacheEXT _validation_cache = nullptr;
};
static_assert(sizeof(shader_module_validation_cache_create_info_ext) ==
                sizeof(::VkShaderModuleValidationCacheCreateInfoEXT),
              "struct and wrapper have different size!");

enum class validation_cache_header_version_ext
{
  /// @see VK_VALIDATION_CACHE_HEADER_VERSION_ONE_EXT
  validation_cache_header_version_one_ext = 1,
};
inline vk::result create_validation_cache_ext(
  VkDevice device, const vk::validation_cache_create_info_ext* create_info,
  const vk::allocation_callbacks* allocator,
  VkValidationCacheEXT* validation_cache)
{
  return static_cast<vk::result>(vkCreateValidationCacheEXT(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkValidationCacheCreateInfoEXT*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkValidationCacheEXT*>(validation_cache)));
}
inline void destroy_validation_cache_ext(
  VkDevice device, VkValidationCacheEXT validation_cache,
  const vk::allocation_callbacks* allocator)
{
  vkDestroyValidationCacheEXT(
    static_cast<VkDevice>(device),
    static_cast<VkValidationCacheEXT>(validation_cache),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline vk::result merge_validation_caches_ext(
  VkDevice device, VkValidationCacheEXT dst_cache, uint32_t src_cache_count,
  const VkValidationCacheEXT* src_caches)
{
  return static_cast<vk::result>(vkMergeValidationCachesEXT(
    static_cast<VkDevice>(device), static_cast<VkValidationCacheEXT>(dst_cache),
    static_cast<uint32_t>(src_cache_count),
    reinterpret_cast<const VkValidationCacheEXT*>(src_caches)));
}
inline vk::result get_validation_cache_data_ext(
  VkDevice device, VkValidationCacheEXT validation_cache, size_t* data_size,
  void* data)
{
  return static_cast<vk::result>(vkGetValidationCacheDataEXT(
    static_cast<VkDevice>(device),
    static_cast<VkValidationCacheEXT>(validation_cache),
    reinterpret_cast<size_t*>(data_size), reinterpret_cast<void*>(data)));
}
enum class descriptor_binding_flag_ext
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_DESCRIPTOR_BINDING_UPDATE_AFTER_BIND_BIT_EXT
  update_after_bind_bit_ext = 1 << 0,
  /// @see VK_DESCRIPTOR_BINDING_UPDATE_UNUSED_WHILE_PENDING_BIT_EXT
  update_unused_while_pending_bit_ext = 1 << 1,
  /// @see VK_DESCRIPTOR_BINDING_PARTIALLY_BOUND_BIT_EXT
  partially_bound_bit_ext = 1 << 2,
  /// @see VK_DESCRIPTOR_BINDING_VARIABLE_DESCRIPTOR_COUNT_BIT_EXT
  variable_descriptor_count_bit_ext = 1 << 3,
};
using descriptor_binding_flags_ext =
  shift::core::bit_field<descriptor_binding_flag_ext,
                         VkDescriptorBindingFlagsEXT>;
inline constexpr descriptor_binding_flags_ext operator|(
  descriptor_binding_flag_ext lhs, descriptor_binding_flag_ext rhs)
{
  return descriptor_binding_flags_ext{lhs} | rhs;
}
/// Enhanced replacement type for
/// VkDescriptorSetLayoutBindingFlagsCreateInfoEXT.
class descriptor_set_layout_binding_flags_create_info_ext
{
public:
  /// Default constructor.
  constexpr descriptor_set_layout_binding_flags_create_info_ext() = default;

  /// Constructor.
  constexpr descriptor_set_layout_binding_flags_create_info_ext(
    const void* initial_next, uint32_t initial_binding_count,
    const vk::descriptor_binding_flags_ext* initial_binding_flags) noexcept
  : _next(std::move(initial_next)),
    _binding_count(std::move(initial_binding_count)),
    _binding_flags(std::move(initial_binding_flags))
  {
  }

  /// Copy constructor.
  constexpr descriptor_set_layout_binding_flags_create_info_ext(
    const descriptor_set_layout_binding_flags_create_info_ext& other) noexcept
  : _next(other._next),
    _binding_count(other._binding_count),
    _binding_flags(other._binding_flags)
  {
  }

  /// Move constructor.
  constexpr descriptor_set_layout_binding_flags_create_info_ext(
    descriptor_set_layout_binding_flags_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _binding_count(std::move(other._binding_count)),
    _binding_flags(std::move(other._binding_flags))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_set_layout_binding_flags_create_info_ext& operator=(
    const descriptor_set_layout_binding_flags_create_info_ext& other) noexcept
  {
    _next = other._next;
    _binding_count = other._binding_count;
    _binding_flags = other._binding_flags;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_set_layout_binding_flags_create_info_ext& operator=(
    descriptor_set_layout_binding_flags_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _binding_count = std::move(other._binding_count);
    _binding_flags = std::move(other._binding_flags);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorSetLayoutBindingFlagsCreateInfoEXT&() const
  {
    return *reinterpret_cast<
      const VkDescriptorSetLayoutBindingFlagsCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& binding_count()
  {
    return _binding_count;
  }

  constexpr const uint32_t& binding_count() const
  {
    return _binding_count;
  }

  void binding_count(uint32_t new_binding_count)
  {
    _binding_count = new_binding_count;
  }

  const vk::descriptor_binding_flags_ext* binding_flags()
  {
    return _binding_flags;
  }

  constexpr const vk::descriptor_binding_flags_ext* binding_flags() const
  {
    return _binding_flags;
  }

  void binding_flags(const vk::descriptor_binding_flags_ext* new_binding_flags)
  {
    _binding_flags = new_binding_flags;
  }

  template <std::size_t Count>
  void binding_flags(const std::array<vk::descriptor_binding_flags_ext, Count>&
                       new_binding_flags)
  {
    _binding_count = static_cast<uint32_t>(new_binding_flags.size());
    _binding_flags = new_binding_flags.data();
  }

  void binding_flags(
    const std::vector<vk::descriptor_binding_flags_ext>& new_binding_flags)
  {
    _binding_count = static_cast<uint32_t>(new_binding_flags.size());
    _binding_flags = new_binding_flags.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::descriptor_set_layout_binding_flags_create_info_ext;
  const void* _next = nullptr;
  uint32_t _binding_count = 0;
  const vk::descriptor_binding_flags_ext* _binding_flags = nullptr;
};
static_assert(sizeof(descriptor_set_layout_binding_flags_create_info_ext) ==
                sizeof(::VkDescriptorSetLayoutBindingFlagsCreateInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceDescriptorIndexingFeaturesEXT.
class physical_device_descriptor_indexing_features_ext
{
public:
  /// Default constructor.
  constexpr physical_device_descriptor_indexing_features_ext() = default;

  /// Constructor.
  constexpr physical_device_descriptor_indexing_features_ext(
    void* initial_next,
    VkBool32 initial_shader_input_attachment_array_dynamic_indexing,
    VkBool32 initial_shader_uniform_texel_buffer_array_dynamic_indexing,
    VkBool32 initial_shader_storage_texel_buffer_array_dynamic_indexing,
    VkBool32 initial_shader_uniform_buffer_array_non_uniform_indexing,
    VkBool32 initial_shader_sampled_image_array_non_uniform_indexing,
    VkBool32 initial_shader_storage_buffer_array_non_uniform_indexing,
    VkBool32 initial_shader_storage_image_array_non_uniform_indexing,
    VkBool32 initial_shader_input_attachment_array_non_uniform_indexing,
    VkBool32 initial_shader_uniform_texel_buffer_array_non_uniform_indexing,
    VkBool32 initial_shader_storage_texel_buffer_array_non_uniform_indexing,
    VkBool32 initial_descriptor_binding_uniform_buffer_update_after_bind,
    VkBool32 initial_descriptor_binding_sampled_image_update_after_bind,
    VkBool32 initial_descriptor_binding_storage_image_update_after_bind,
    VkBool32 initial_descriptor_binding_storage_buffer_update_after_bind,
    VkBool32 initial_descriptor_binding_uniform_texel_buffer_update_after_bind,
    VkBool32 initial_descriptor_binding_storage_texel_buffer_update_after_bind,
    VkBool32 initial_descriptor_binding_update_unused_while_pending,
    VkBool32 initial_descriptor_binding_partially_bound,
    VkBool32 initial_descriptor_binding_variable_descriptor_count,
    VkBool32 initial_runtime_descriptor_array) noexcept
  : _next(std::move(initial_next)),
    _shader_input_attachment_array_dynamic_indexing(
      std::move(initial_shader_input_attachment_array_dynamic_indexing)),
    _shader_uniform_texel_buffer_array_dynamic_indexing(
      std::move(initial_shader_uniform_texel_buffer_array_dynamic_indexing)),
    _shader_storage_texel_buffer_array_dynamic_indexing(
      std::move(initial_shader_storage_texel_buffer_array_dynamic_indexing)),
    _shader_uniform_buffer_array_non_uniform_indexing(
      std::move(initial_shader_uniform_buffer_array_non_uniform_indexing)),
    _shader_sampled_image_array_non_uniform_indexing(
      std::move(initial_shader_sampled_image_array_non_uniform_indexing)),
    _shader_storage_buffer_array_non_uniform_indexing(
      std::move(initial_shader_storage_buffer_array_non_uniform_indexing)),
    _shader_storage_image_array_non_uniform_indexing(
      std::move(initial_shader_storage_image_array_non_uniform_indexing)),
    _shader_input_attachment_array_non_uniform_indexing(
      std::move(initial_shader_input_attachment_array_non_uniform_indexing)),
    _shader_uniform_texel_buffer_array_non_uniform_indexing(std::move(
      initial_shader_uniform_texel_buffer_array_non_uniform_indexing)),
    _shader_storage_texel_buffer_array_non_uniform_indexing(std::move(
      initial_shader_storage_texel_buffer_array_non_uniform_indexing)),
    _descriptor_binding_uniform_buffer_update_after_bind(
      std::move(initial_descriptor_binding_uniform_buffer_update_after_bind)),
    _descriptor_binding_sampled_image_update_after_bind(
      std::move(initial_descriptor_binding_sampled_image_update_after_bind)),
    _descriptor_binding_storage_image_update_after_bind(
      std::move(initial_descriptor_binding_storage_image_update_after_bind)),
    _descriptor_binding_storage_buffer_update_after_bind(
      std::move(initial_descriptor_binding_storage_buffer_update_after_bind)),
    _descriptor_binding_uniform_texel_buffer_update_after_bind(std::move(
      initial_descriptor_binding_uniform_texel_buffer_update_after_bind)),
    _descriptor_binding_storage_texel_buffer_update_after_bind(std::move(
      initial_descriptor_binding_storage_texel_buffer_update_after_bind)),
    _descriptor_binding_update_unused_while_pending(
      std::move(initial_descriptor_binding_update_unused_while_pending)),
    _descriptor_binding_partially_bound(
      std::move(initial_descriptor_binding_partially_bound)),
    _descriptor_binding_variable_descriptor_count(
      std::move(initial_descriptor_binding_variable_descriptor_count)),
    _runtime_descriptor_array(std::move(initial_runtime_descriptor_array))
  {
  }

  /// Copy constructor.
  constexpr physical_device_descriptor_indexing_features_ext(
    const physical_device_descriptor_indexing_features_ext& other) noexcept
  : _next(other._next),
    _shader_input_attachment_array_dynamic_indexing(
      other._shader_input_attachment_array_dynamic_indexing),
    _shader_uniform_texel_buffer_array_dynamic_indexing(
      other._shader_uniform_texel_buffer_array_dynamic_indexing),
    _shader_storage_texel_buffer_array_dynamic_indexing(
      other._shader_storage_texel_buffer_array_dynamic_indexing),
    _shader_uniform_buffer_array_non_uniform_indexing(
      other._shader_uniform_buffer_array_non_uniform_indexing),
    _shader_sampled_image_array_non_uniform_indexing(
      other._shader_sampled_image_array_non_uniform_indexing),
    _shader_storage_buffer_array_non_uniform_indexing(
      other._shader_storage_buffer_array_non_uniform_indexing),
    _shader_storage_image_array_non_uniform_indexing(
      other._shader_storage_image_array_non_uniform_indexing),
    _shader_input_attachment_array_non_uniform_indexing(
      other._shader_input_attachment_array_non_uniform_indexing),
    _shader_uniform_texel_buffer_array_non_uniform_indexing(
      other._shader_uniform_texel_buffer_array_non_uniform_indexing),
    _shader_storage_texel_buffer_array_non_uniform_indexing(
      other._shader_storage_texel_buffer_array_non_uniform_indexing),
    _descriptor_binding_uniform_buffer_update_after_bind(
      other._descriptor_binding_uniform_buffer_update_after_bind),
    _descriptor_binding_sampled_image_update_after_bind(
      other._descriptor_binding_sampled_image_update_after_bind),
    _descriptor_binding_storage_image_update_after_bind(
      other._descriptor_binding_storage_image_update_after_bind),
    _descriptor_binding_storage_buffer_update_after_bind(
      other._descriptor_binding_storage_buffer_update_after_bind),
    _descriptor_binding_uniform_texel_buffer_update_after_bind(
      other._descriptor_binding_uniform_texel_buffer_update_after_bind),
    _descriptor_binding_storage_texel_buffer_update_after_bind(
      other._descriptor_binding_storage_texel_buffer_update_after_bind),
    _descriptor_binding_update_unused_while_pending(
      other._descriptor_binding_update_unused_while_pending),
    _descriptor_binding_partially_bound(
      other._descriptor_binding_partially_bound),
    _descriptor_binding_variable_descriptor_count(
      other._descriptor_binding_variable_descriptor_count),
    _runtime_descriptor_array(other._runtime_descriptor_array)
  {
  }

  /// Move constructor.
  constexpr physical_device_descriptor_indexing_features_ext(
    physical_device_descriptor_indexing_features_ext&& other) noexcept
  : _next(std::move(other._next)),
    _shader_input_attachment_array_dynamic_indexing(
      std::move(other._shader_input_attachment_array_dynamic_indexing)),
    _shader_uniform_texel_buffer_array_dynamic_indexing(
      std::move(other._shader_uniform_texel_buffer_array_dynamic_indexing)),
    _shader_storage_texel_buffer_array_dynamic_indexing(
      std::move(other._shader_storage_texel_buffer_array_dynamic_indexing)),
    _shader_uniform_buffer_array_non_uniform_indexing(
      std::move(other._shader_uniform_buffer_array_non_uniform_indexing)),
    _shader_sampled_image_array_non_uniform_indexing(
      std::move(other._shader_sampled_image_array_non_uniform_indexing)),
    _shader_storage_buffer_array_non_uniform_indexing(
      std::move(other._shader_storage_buffer_array_non_uniform_indexing)),
    _shader_storage_image_array_non_uniform_indexing(
      std::move(other._shader_storage_image_array_non_uniform_indexing)),
    _shader_input_attachment_array_non_uniform_indexing(
      std::move(other._shader_input_attachment_array_non_uniform_indexing)),
    _shader_uniform_texel_buffer_array_non_uniform_indexing(
      std::move(other._shader_uniform_texel_buffer_array_non_uniform_indexing)),
    _shader_storage_texel_buffer_array_non_uniform_indexing(
      std::move(other._shader_storage_texel_buffer_array_non_uniform_indexing)),
    _descriptor_binding_uniform_buffer_update_after_bind(
      std::move(other._descriptor_binding_uniform_buffer_update_after_bind)),
    _descriptor_binding_sampled_image_update_after_bind(
      std::move(other._descriptor_binding_sampled_image_update_after_bind)),
    _descriptor_binding_storage_image_update_after_bind(
      std::move(other._descriptor_binding_storage_image_update_after_bind)),
    _descriptor_binding_storage_buffer_update_after_bind(
      std::move(other._descriptor_binding_storage_buffer_update_after_bind)),
    _descriptor_binding_uniform_texel_buffer_update_after_bind(std::move(
      other._descriptor_binding_uniform_texel_buffer_update_after_bind)),
    _descriptor_binding_storage_texel_buffer_update_after_bind(std::move(
      other._descriptor_binding_storage_texel_buffer_update_after_bind)),
    _descriptor_binding_update_unused_while_pending(
      std::move(other._descriptor_binding_update_unused_while_pending)),
    _descriptor_binding_partially_bound(
      std::move(other._descriptor_binding_partially_bound)),
    _descriptor_binding_variable_descriptor_count(
      std::move(other._descriptor_binding_variable_descriptor_count)),
    _runtime_descriptor_array(std::move(other._runtime_descriptor_array))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_descriptor_indexing_features_ext& operator=(
    const physical_device_descriptor_indexing_features_ext& other) noexcept
  {
    _next = other._next;
    _shader_input_attachment_array_dynamic_indexing =
      other._shader_input_attachment_array_dynamic_indexing;
    _shader_uniform_texel_buffer_array_dynamic_indexing =
      other._shader_uniform_texel_buffer_array_dynamic_indexing;
    _shader_storage_texel_buffer_array_dynamic_indexing =
      other._shader_storage_texel_buffer_array_dynamic_indexing;
    _shader_uniform_buffer_array_non_uniform_indexing =
      other._shader_uniform_buffer_array_non_uniform_indexing;
    _shader_sampled_image_array_non_uniform_indexing =
      other._shader_sampled_image_array_non_uniform_indexing;
    _shader_storage_buffer_array_non_uniform_indexing =
      other._shader_storage_buffer_array_non_uniform_indexing;
    _shader_storage_image_array_non_uniform_indexing =
      other._shader_storage_image_array_non_uniform_indexing;
    _shader_input_attachment_array_non_uniform_indexing =
      other._shader_input_attachment_array_non_uniform_indexing;
    _shader_uniform_texel_buffer_array_non_uniform_indexing =
      other._shader_uniform_texel_buffer_array_non_uniform_indexing;
    _shader_storage_texel_buffer_array_non_uniform_indexing =
      other._shader_storage_texel_buffer_array_non_uniform_indexing;
    _descriptor_binding_uniform_buffer_update_after_bind =
      other._descriptor_binding_uniform_buffer_update_after_bind;
    _descriptor_binding_sampled_image_update_after_bind =
      other._descriptor_binding_sampled_image_update_after_bind;
    _descriptor_binding_storage_image_update_after_bind =
      other._descriptor_binding_storage_image_update_after_bind;
    _descriptor_binding_storage_buffer_update_after_bind =
      other._descriptor_binding_storage_buffer_update_after_bind;
    _descriptor_binding_uniform_texel_buffer_update_after_bind =
      other._descriptor_binding_uniform_texel_buffer_update_after_bind;
    _descriptor_binding_storage_texel_buffer_update_after_bind =
      other._descriptor_binding_storage_texel_buffer_update_after_bind;
    _descriptor_binding_update_unused_while_pending =
      other._descriptor_binding_update_unused_while_pending;
    _descriptor_binding_partially_bound =
      other._descriptor_binding_partially_bound;
    _descriptor_binding_variable_descriptor_count =
      other._descriptor_binding_variable_descriptor_count;
    _runtime_descriptor_array = other._runtime_descriptor_array;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_descriptor_indexing_features_ext& operator=(
    physical_device_descriptor_indexing_features_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _shader_input_attachment_array_dynamic_indexing =
      std::move(other._shader_input_attachment_array_dynamic_indexing);
    _shader_uniform_texel_buffer_array_dynamic_indexing =
      std::move(other._shader_uniform_texel_buffer_array_dynamic_indexing);
    _shader_storage_texel_buffer_array_dynamic_indexing =
      std::move(other._shader_storage_texel_buffer_array_dynamic_indexing);
    _shader_uniform_buffer_array_non_uniform_indexing =
      std::move(other._shader_uniform_buffer_array_non_uniform_indexing);
    _shader_sampled_image_array_non_uniform_indexing =
      std::move(other._shader_sampled_image_array_non_uniform_indexing);
    _shader_storage_buffer_array_non_uniform_indexing =
      std::move(other._shader_storage_buffer_array_non_uniform_indexing);
    _shader_storage_image_array_non_uniform_indexing =
      std::move(other._shader_storage_image_array_non_uniform_indexing);
    _shader_input_attachment_array_non_uniform_indexing =
      std::move(other._shader_input_attachment_array_non_uniform_indexing);
    _shader_uniform_texel_buffer_array_non_uniform_indexing =
      std::move(other._shader_uniform_texel_buffer_array_non_uniform_indexing);
    _shader_storage_texel_buffer_array_non_uniform_indexing =
      std::move(other._shader_storage_texel_buffer_array_non_uniform_indexing);
    _descriptor_binding_uniform_buffer_update_after_bind =
      std::move(other._descriptor_binding_uniform_buffer_update_after_bind);
    _descriptor_binding_sampled_image_update_after_bind =
      std::move(other._descriptor_binding_sampled_image_update_after_bind);
    _descriptor_binding_storage_image_update_after_bind =
      std::move(other._descriptor_binding_storage_image_update_after_bind);
    _descriptor_binding_storage_buffer_update_after_bind =
      std::move(other._descriptor_binding_storage_buffer_update_after_bind);
    _descriptor_binding_uniform_texel_buffer_update_after_bind = std::move(
      other._descriptor_binding_uniform_texel_buffer_update_after_bind);
    _descriptor_binding_storage_texel_buffer_update_after_bind = std::move(
      other._descriptor_binding_storage_texel_buffer_update_after_bind);
    _descriptor_binding_update_unused_while_pending =
      std::move(other._descriptor_binding_update_unused_while_pending);
    _descriptor_binding_partially_bound =
      std::move(other._descriptor_binding_partially_bound);
    _descriptor_binding_variable_descriptor_count =
      std::move(other._descriptor_binding_variable_descriptor_count);
    _runtime_descriptor_array = std::move(other._runtime_descriptor_array);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceDescriptorIndexingFeaturesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceDescriptorIndexingFeaturesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& shader_input_attachment_array_dynamic_indexing()
  {
    return _shader_input_attachment_array_dynamic_indexing;
  }

  constexpr const VkBool32& shader_input_attachment_array_dynamic_indexing()
    const
  {
    return _shader_input_attachment_array_dynamic_indexing;
  }

  void shader_input_attachment_array_dynamic_indexing(
    VkBool32 new_shader_input_attachment_array_dynamic_indexing)
  {
    _shader_input_attachment_array_dynamic_indexing =
      new_shader_input_attachment_array_dynamic_indexing;
  }

  VkBool32& shader_uniform_texel_buffer_array_dynamic_indexing()
  {
    return _shader_uniform_texel_buffer_array_dynamic_indexing;
  }

  constexpr const VkBool32& shader_uniform_texel_buffer_array_dynamic_indexing()
    const
  {
    return _shader_uniform_texel_buffer_array_dynamic_indexing;
  }

  void shader_uniform_texel_buffer_array_dynamic_indexing(
    VkBool32 new_shader_uniform_texel_buffer_array_dynamic_indexing)
  {
    _shader_uniform_texel_buffer_array_dynamic_indexing =
      new_shader_uniform_texel_buffer_array_dynamic_indexing;
  }

  VkBool32& shader_storage_texel_buffer_array_dynamic_indexing()
  {
    return _shader_storage_texel_buffer_array_dynamic_indexing;
  }

  constexpr const VkBool32& shader_storage_texel_buffer_array_dynamic_indexing()
    const
  {
    return _shader_storage_texel_buffer_array_dynamic_indexing;
  }

  void shader_storage_texel_buffer_array_dynamic_indexing(
    VkBool32 new_shader_storage_texel_buffer_array_dynamic_indexing)
  {
    _shader_storage_texel_buffer_array_dynamic_indexing =
      new_shader_storage_texel_buffer_array_dynamic_indexing;
  }

  VkBool32& shader_uniform_buffer_array_non_uniform_indexing()
  {
    return _shader_uniform_buffer_array_non_uniform_indexing;
  }

  constexpr const VkBool32& shader_uniform_buffer_array_non_uniform_indexing()
    const
  {
    return _shader_uniform_buffer_array_non_uniform_indexing;
  }

  void shader_uniform_buffer_array_non_uniform_indexing(
    VkBool32 new_shader_uniform_buffer_array_non_uniform_indexing)
  {
    _shader_uniform_buffer_array_non_uniform_indexing =
      new_shader_uniform_buffer_array_non_uniform_indexing;
  }

  VkBool32& shader_sampled_image_array_non_uniform_indexing()
  {
    return _shader_sampled_image_array_non_uniform_indexing;
  }

  constexpr const VkBool32& shader_sampled_image_array_non_uniform_indexing()
    const
  {
    return _shader_sampled_image_array_non_uniform_indexing;
  }

  void shader_sampled_image_array_non_uniform_indexing(
    VkBool32 new_shader_sampled_image_array_non_uniform_indexing)
  {
    _shader_sampled_image_array_non_uniform_indexing =
      new_shader_sampled_image_array_non_uniform_indexing;
  }

  VkBool32& shader_storage_buffer_array_non_uniform_indexing()
  {
    return _shader_storage_buffer_array_non_uniform_indexing;
  }

  constexpr const VkBool32& shader_storage_buffer_array_non_uniform_indexing()
    const
  {
    return _shader_storage_buffer_array_non_uniform_indexing;
  }

  void shader_storage_buffer_array_non_uniform_indexing(
    VkBool32 new_shader_storage_buffer_array_non_uniform_indexing)
  {
    _shader_storage_buffer_array_non_uniform_indexing =
      new_shader_storage_buffer_array_non_uniform_indexing;
  }

  VkBool32& shader_storage_image_array_non_uniform_indexing()
  {
    return _shader_storage_image_array_non_uniform_indexing;
  }

  constexpr const VkBool32& shader_storage_image_array_non_uniform_indexing()
    const
  {
    return _shader_storage_image_array_non_uniform_indexing;
  }

  void shader_storage_image_array_non_uniform_indexing(
    VkBool32 new_shader_storage_image_array_non_uniform_indexing)
  {
    _shader_storage_image_array_non_uniform_indexing =
      new_shader_storage_image_array_non_uniform_indexing;
  }

  VkBool32& shader_input_attachment_array_non_uniform_indexing()
  {
    return _shader_input_attachment_array_non_uniform_indexing;
  }

  constexpr const VkBool32& shader_input_attachment_array_non_uniform_indexing()
    const
  {
    return _shader_input_attachment_array_non_uniform_indexing;
  }

  void shader_input_attachment_array_non_uniform_indexing(
    VkBool32 new_shader_input_attachment_array_non_uniform_indexing)
  {
    _shader_input_attachment_array_non_uniform_indexing =
      new_shader_input_attachment_array_non_uniform_indexing;
  }

  VkBool32& shader_uniform_texel_buffer_array_non_uniform_indexing()
  {
    return _shader_uniform_texel_buffer_array_non_uniform_indexing;
  }

  constexpr const VkBool32&
  shader_uniform_texel_buffer_array_non_uniform_indexing() const
  {
    return _shader_uniform_texel_buffer_array_non_uniform_indexing;
  }

  void shader_uniform_texel_buffer_array_non_uniform_indexing(
    VkBool32 new_shader_uniform_texel_buffer_array_non_uniform_indexing)
  {
    _shader_uniform_texel_buffer_array_non_uniform_indexing =
      new_shader_uniform_texel_buffer_array_non_uniform_indexing;
  }

  VkBool32& shader_storage_texel_buffer_array_non_uniform_indexing()
  {
    return _shader_storage_texel_buffer_array_non_uniform_indexing;
  }

  constexpr const VkBool32&
  shader_storage_texel_buffer_array_non_uniform_indexing() const
  {
    return _shader_storage_texel_buffer_array_non_uniform_indexing;
  }

  void shader_storage_texel_buffer_array_non_uniform_indexing(
    VkBool32 new_shader_storage_texel_buffer_array_non_uniform_indexing)
  {
    _shader_storage_texel_buffer_array_non_uniform_indexing =
      new_shader_storage_texel_buffer_array_non_uniform_indexing;
  }

  VkBool32& descriptor_binding_uniform_buffer_update_after_bind()
  {
    return _descriptor_binding_uniform_buffer_update_after_bind;
  }

  constexpr const VkBool32&
  descriptor_binding_uniform_buffer_update_after_bind() const
  {
    return _descriptor_binding_uniform_buffer_update_after_bind;
  }

  void descriptor_binding_uniform_buffer_update_after_bind(
    VkBool32 new_descriptor_binding_uniform_buffer_update_after_bind)
  {
    _descriptor_binding_uniform_buffer_update_after_bind =
      new_descriptor_binding_uniform_buffer_update_after_bind;
  }

  VkBool32& descriptor_binding_sampled_image_update_after_bind()
  {
    return _descriptor_binding_sampled_image_update_after_bind;
  }

  constexpr const VkBool32& descriptor_binding_sampled_image_update_after_bind()
    const
  {
    return _descriptor_binding_sampled_image_update_after_bind;
  }

  void descriptor_binding_sampled_image_update_after_bind(
    VkBool32 new_descriptor_binding_sampled_image_update_after_bind)
  {
    _descriptor_binding_sampled_image_update_after_bind =
      new_descriptor_binding_sampled_image_update_after_bind;
  }

  VkBool32& descriptor_binding_storage_image_update_after_bind()
  {
    return _descriptor_binding_storage_image_update_after_bind;
  }

  constexpr const VkBool32& descriptor_binding_storage_image_update_after_bind()
    const
  {
    return _descriptor_binding_storage_image_update_after_bind;
  }

  void descriptor_binding_storage_image_update_after_bind(
    VkBool32 new_descriptor_binding_storage_image_update_after_bind)
  {
    _descriptor_binding_storage_image_update_after_bind =
      new_descriptor_binding_storage_image_update_after_bind;
  }

  VkBool32& descriptor_binding_storage_buffer_update_after_bind()
  {
    return _descriptor_binding_storage_buffer_update_after_bind;
  }

  constexpr const VkBool32&
  descriptor_binding_storage_buffer_update_after_bind() const
  {
    return _descriptor_binding_storage_buffer_update_after_bind;
  }

  void descriptor_binding_storage_buffer_update_after_bind(
    VkBool32 new_descriptor_binding_storage_buffer_update_after_bind)
  {
    _descriptor_binding_storage_buffer_update_after_bind =
      new_descriptor_binding_storage_buffer_update_after_bind;
  }

  VkBool32& descriptor_binding_uniform_texel_buffer_update_after_bind()
  {
    return _descriptor_binding_uniform_texel_buffer_update_after_bind;
  }

  constexpr const VkBool32&
  descriptor_binding_uniform_texel_buffer_update_after_bind() const
  {
    return _descriptor_binding_uniform_texel_buffer_update_after_bind;
  }

  void descriptor_binding_uniform_texel_buffer_update_after_bind(
    VkBool32 new_descriptor_binding_uniform_texel_buffer_update_after_bind)
  {
    _descriptor_binding_uniform_texel_buffer_update_after_bind =
      new_descriptor_binding_uniform_texel_buffer_update_after_bind;
  }

  VkBool32& descriptor_binding_storage_texel_buffer_update_after_bind()
  {
    return _descriptor_binding_storage_texel_buffer_update_after_bind;
  }

  constexpr const VkBool32&
  descriptor_binding_storage_texel_buffer_update_after_bind() const
  {
    return _descriptor_binding_storage_texel_buffer_update_after_bind;
  }

  void descriptor_binding_storage_texel_buffer_update_after_bind(
    VkBool32 new_descriptor_binding_storage_texel_buffer_update_after_bind)
  {
    _descriptor_binding_storage_texel_buffer_update_after_bind =
      new_descriptor_binding_storage_texel_buffer_update_after_bind;
  }

  VkBool32& descriptor_binding_update_unused_while_pending()
  {
    return _descriptor_binding_update_unused_while_pending;
  }

  constexpr const VkBool32& descriptor_binding_update_unused_while_pending()
    const
  {
    return _descriptor_binding_update_unused_while_pending;
  }

  void descriptor_binding_update_unused_while_pending(
    VkBool32 new_descriptor_binding_update_unused_while_pending)
  {
    _descriptor_binding_update_unused_while_pending =
      new_descriptor_binding_update_unused_while_pending;
  }

  VkBool32& descriptor_binding_partially_bound()
  {
    return _descriptor_binding_partially_bound;
  }

  constexpr const VkBool32& descriptor_binding_partially_bound() const
  {
    return _descriptor_binding_partially_bound;
  }

  void descriptor_binding_partially_bound(
    VkBool32 new_descriptor_binding_partially_bound)
  {
    _descriptor_binding_partially_bound =
      new_descriptor_binding_partially_bound;
  }

  VkBool32& descriptor_binding_variable_descriptor_count()
  {
    return _descriptor_binding_variable_descriptor_count;
  }

  constexpr const VkBool32& descriptor_binding_variable_descriptor_count() const
  {
    return _descriptor_binding_variable_descriptor_count;
  }

  void descriptor_binding_variable_descriptor_count(
    VkBool32 new_descriptor_binding_variable_descriptor_count)
  {
    _descriptor_binding_variable_descriptor_count =
      new_descriptor_binding_variable_descriptor_count;
  }

  VkBool32& runtime_descriptor_array()
  {
    return _runtime_descriptor_array;
  }

  constexpr const VkBool32& runtime_descriptor_array() const
  {
    return _runtime_descriptor_array;
  }

  void runtime_descriptor_array(VkBool32 new_runtime_descriptor_array)
  {
    _runtime_descriptor_array = new_runtime_descriptor_array;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_descriptor_indexing_features_ext;
  void* _next = nullptr;
  VkBool32 _shader_input_attachment_array_dynamic_indexing = VK_FALSE;
  VkBool32 _shader_uniform_texel_buffer_array_dynamic_indexing = VK_FALSE;
  VkBool32 _shader_storage_texel_buffer_array_dynamic_indexing = VK_FALSE;
  VkBool32 _shader_uniform_buffer_array_non_uniform_indexing = VK_FALSE;
  VkBool32 _shader_sampled_image_array_non_uniform_indexing = VK_FALSE;
  VkBool32 _shader_storage_buffer_array_non_uniform_indexing = VK_FALSE;
  VkBool32 _shader_storage_image_array_non_uniform_indexing = VK_FALSE;
  VkBool32 _shader_input_attachment_array_non_uniform_indexing = VK_FALSE;
  VkBool32 _shader_uniform_texel_buffer_array_non_uniform_indexing = VK_FALSE;
  VkBool32 _shader_storage_texel_buffer_array_non_uniform_indexing = VK_FALSE;
  VkBool32 _descriptor_binding_uniform_buffer_update_after_bind = VK_FALSE;
  VkBool32 _descriptor_binding_sampled_image_update_after_bind = VK_FALSE;
  VkBool32 _descriptor_binding_storage_image_update_after_bind = VK_FALSE;
  VkBool32 _descriptor_binding_storage_buffer_update_after_bind = VK_FALSE;
  VkBool32 _descriptor_binding_uniform_texel_buffer_update_after_bind =
    VK_FALSE;
  VkBool32 _descriptor_binding_storage_texel_buffer_update_after_bind =
    VK_FALSE;
  VkBool32 _descriptor_binding_update_unused_while_pending = VK_FALSE;
  VkBool32 _descriptor_binding_partially_bound = VK_FALSE;
  VkBool32 _descriptor_binding_variable_descriptor_count = VK_FALSE;
  VkBool32 _runtime_descriptor_array = VK_FALSE;
};
static_assert(sizeof(physical_device_descriptor_indexing_features_ext) ==
                sizeof(::VkPhysicalDeviceDescriptorIndexingFeaturesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceDescriptorIndexingPropertiesEXT.
class physical_device_descriptor_indexing_properties_ext
{
public:
  /// Default constructor.
  constexpr physical_device_descriptor_indexing_properties_ext() = default;

  /// Constructor.
  constexpr physical_device_descriptor_indexing_properties_ext(
    void* initial_next,
    uint32_t initial_max_update_after_bind_descriptors_in_all_pools,
    VkBool32 initial_shader_uniform_buffer_array_non_uniform_indexing_native,
    VkBool32 initial_shader_sampled_image_array_non_uniform_indexing_native,
    VkBool32 initial_shader_storage_buffer_array_non_uniform_indexing_native,
    VkBool32 initial_shader_storage_image_array_non_uniform_indexing_native,
    VkBool32 initial_shader_input_attachment_array_non_uniform_indexing_native,
    VkBool32 initial_robust_buffer_access_update_after_bind,
    VkBool32 initial_quad_divergent_implicit_lod,
    uint32_t initial_max_per_stage_descriptor_update_after_bind_samplers,
    uint32_t initial_max_per_stage_descriptor_update_after_bind_uniform_buffers,
    uint32_t initial_max_per_stage_descriptor_update_after_bind_storage_buffers,
    uint32_t initial_max_per_stage_descriptor_update_after_bind_sampled_images,
    uint32_t initial_max_per_stage_descriptor_update_after_bind_storage_images,
    uint32_t
      initial_max_per_stage_descriptor_update_after_bind_input_attachments,
    uint32_t initial_max_per_stage_update_after_bind_resources,
    uint32_t initial_max_descriptor_set_update_after_bind_samplers,
    uint32_t initial_max_descriptor_set_update_after_bind_uniform_buffers,
    uint32_t
      initial_max_descriptor_set_update_after_bind_uniform_buffers_dynamic,
    uint32_t initial_max_descriptor_set_update_after_bind_storage_buffers,
    uint32_t
      initial_max_descriptor_set_update_after_bind_storage_buffers_dynamic,
    uint32_t initial_max_descriptor_set_update_after_bind_sampled_images,
    uint32_t initial_max_descriptor_set_update_after_bind_storage_images,
    uint32_t
      initial_max_descriptor_set_update_after_bind_input_attachments) noexcept
  : _next(std::move(initial_next)),
    _max_update_after_bind_descriptors_in_all_pools(
      std::move(initial_max_update_after_bind_descriptors_in_all_pools)),
    _shader_uniform_buffer_array_non_uniform_indexing_native(std::move(
      initial_shader_uniform_buffer_array_non_uniform_indexing_native)),
    _shader_sampled_image_array_non_uniform_indexing_native(std::move(
      initial_shader_sampled_image_array_non_uniform_indexing_native)),
    _shader_storage_buffer_array_non_uniform_indexing_native(std::move(
      initial_shader_storage_buffer_array_non_uniform_indexing_native)),
    _shader_storage_image_array_non_uniform_indexing_native(std::move(
      initial_shader_storage_image_array_non_uniform_indexing_native)),
    _shader_input_attachment_array_non_uniform_indexing_native(std::move(
      initial_shader_input_attachment_array_non_uniform_indexing_native)),
    _robust_buffer_access_update_after_bind(
      std::move(initial_robust_buffer_access_update_after_bind)),
    _quad_divergent_implicit_lod(
      std::move(initial_quad_divergent_implicit_lod)),
    _max_per_stage_descriptor_update_after_bind_samplers(
      std::move(initial_max_per_stage_descriptor_update_after_bind_samplers)),
    _max_per_stage_descriptor_update_after_bind_uniform_buffers(std::move(
      initial_max_per_stage_descriptor_update_after_bind_uniform_buffers)),
    _max_per_stage_descriptor_update_after_bind_storage_buffers(std::move(
      initial_max_per_stage_descriptor_update_after_bind_storage_buffers)),
    _max_per_stage_descriptor_update_after_bind_sampled_images(std::move(
      initial_max_per_stage_descriptor_update_after_bind_sampled_images)),
    _max_per_stage_descriptor_update_after_bind_storage_images(std::move(
      initial_max_per_stage_descriptor_update_after_bind_storage_images)),
    _max_per_stage_descriptor_update_after_bind_input_attachments(std::move(
      initial_max_per_stage_descriptor_update_after_bind_input_attachments)),
    _max_per_stage_update_after_bind_resources(
      std::move(initial_max_per_stage_update_after_bind_resources)),
    _max_descriptor_set_update_after_bind_samplers(
      std::move(initial_max_descriptor_set_update_after_bind_samplers)),
    _max_descriptor_set_update_after_bind_uniform_buffers(
      std::move(initial_max_descriptor_set_update_after_bind_uniform_buffers)),
    _max_descriptor_set_update_after_bind_uniform_buffers_dynamic(std::move(
      initial_max_descriptor_set_update_after_bind_uniform_buffers_dynamic)),
    _max_descriptor_set_update_after_bind_storage_buffers(
      std::move(initial_max_descriptor_set_update_after_bind_storage_buffers)),
    _max_descriptor_set_update_after_bind_storage_buffers_dynamic(std::move(
      initial_max_descriptor_set_update_after_bind_storage_buffers_dynamic)),
    _max_descriptor_set_update_after_bind_sampled_images(
      std::move(initial_max_descriptor_set_update_after_bind_sampled_images)),
    _max_descriptor_set_update_after_bind_storage_images(
      std::move(initial_max_descriptor_set_update_after_bind_storage_images)),
    _max_descriptor_set_update_after_bind_input_attachments(
      std::move(initial_max_descriptor_set_update_after_bind_input_attachments))
  {
  }

  /// Copy constructor.
  constexpr physical_device_descriptor_indexing_properties_ext(
    const physical_device_descriptor_indexing_properties_ext& other) noexcept
  : _next(other._next),
    _max_update_after_bind_descriptors_in_all_pools(
      other._max_update_after_bind_descriptors_in_all_pools),
    _shader_uniform_buffer_array_non_uniform_indexing_native(
      other._shader_uniform_buffer_array_non_uniform_indexing_native),
    _shader_sampled_image_array_non_uniform_indexing_native(
      other._shader_sampled_image_array_non_uniform_indexing_native),
    _shader_storage_buffer_array_non_uniform_indexing_native(
      other._shader_storage_buffer_array_non_uniform_indexing_native),
    _shader_storage_image_array_non_uniform_indexing_native(
      other._shader_storage_image_array_non_uniform_indexing_native),
    _shader_input_attachment_array_non_uniform_indexing_native(
      other._shader_input_attachment_array_non_uniform_indexing_native),
    _robust_buffer_access_update_after_bind(
      other._robust_buffer_access_update_after_bind),
    _quad_divergent_implicit_lod(other._quad_divergent_implicit_lod),
    _max_per_stage_descriptor_update_after_bind_samplers(
      other._max_per_stage_descriptor_update_after_bind_samplers),
    _max_per_stage_descriptor_update_after_bind_uniform_buffers(
      other._max_per_stage_descriptor_update_after_bind_uniform_buffers),
    _max_per_stage_descriptor_update_after_bind_storage_buffers(
      other._max_per_stage_descriptor_update_after_bind_storage_buffers),
    _max_per_stage_descriptor_update_after_bind_sampled_images(
      other._max_per_stage_descriptor_update_after_bind_sampled_images),
    _max_per_stage_descriptor_update_after_bind_storage_images(
      other._max_per_stage_descriptor_update_after_bind_storage_images),
    _max_per_stage_descriptor_update_after_bind_input_attachments(
      other._max_per_stage_descriptor_update_after_bind_input_attachments),
    _max_per_stage_update_after_bind_resources(
      other._max_per_stage_update_after_bind_resources),
    _max_descriptor_set_update_after_bind_samplers(
      other._max_descriptor_set_update_after_bind_samplers),
    _max_descriptor_set_update_after_bind_uniform_buffers(
      other._max_descriptor_set_update_after_bind_uniform_buffers),
    _max_descriptor_set_update_after_bind_uniform_buffers_dynamic(
      other._max_descriptor_set_update_after_bind_uniform_buffers_dynamic),
    _max_descriptor_set_update_after_bind_storage_buffers(
      other._max_descriptor_set_update_after_bind_storage_buffers),
    _max_descriptor_set_update_after_bind_storage_buffers_dynamic(
      other._max_descriptor_set_update_after_bind_storage_buffers_dynamic),
    _max_descriptor_set_update_after_bind_sampled_images(
      other._max_descriptor_set_update_after_bind_sampled_images),
    _max_descriptor_set_update_after_bind_storage_images(
      other._max_descriptor_set_update_after_bind_storage_images),
    _max_descriptor_set_update_after_bind_input_attachments(
      other._max_descriptor_set_update_after_bind_input_attachments)
  {
  }

  /// Move constructor.
  constexpr physical_device_descriptor_indexing_properties_ext(
    physical_device_descriptor_indexing_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _max_update_after_bind_descriptors_in_all_pools(
      std::move(other._max_update_after_bind_descriptors_in_all_pools)),
    _shader_uniform_buffer_array_non_uniform_indexing_native(std::move(
      other._shader_uniform_buffer_array_non_uniform_indexing_native)),
    _shader_sampled_image_array_non_uniform_indexing_native(
      std::move(other._shader_sampled_image_array_non_uniform_indexing_native)),
    _shader_storage_buffer_array_non_uniform_indexing_native(std::move(
      other._shader_storage_buffer_array_non_uniform_indexing_native)),
    _shader_storage_image_array_non_uniform_indexing_native(
      std::move(other._shader_storage_image_array_non_uniform_indexing_native)),
    _shader_input_attachment_array_non_uniform_indexing_native(std::move(
      other._shader_input_attachment_array_non_uniform_indexing_native)),
    _robust_buffer_access_update_after_bind(
      std::move(other._robust_buffer_access_update_after_bind)),
    _quad_divergent_implicit_lod(std::move(other._quad_divergent_implicit_lod)),
    _max_per_stage_descriptor_update_after_bind_samplers(
      std::move(other._max_per_stage_descriptor_update_after_bind_samplers)),
    _max_per_stage_descriptor_update_after_bind_uniform_buffers(std::move(
      other._max_per_stage_descriptor_update_after_bind_uniform_buffers)),
    _max_per_stage_descriptor_update_after_bind_storage_buffers(std::move(
      other._max_per_stage_descriptor_update_after_bind_storage_buffers)),
    _max_per_stage_descriptor_update_after_bind_sampled_images(std::move(
      other._max_per_stage_descriptor_update_after_bind_sampled_images)),
    _max_per_stage_descriptor_update_after_bind_storage_images(std::move(
      other._max_per_stage_descriptor_update_after_bind_storage_images)),
    _max_per_stage_descriptor_update_after_bind_input_attachments(std::move(
      other._max_per_stage_descriptor_update_after_bind_input_attachments)),
    _max_per_stage_update_after_bind_resources(
      std::move(other._max_per_stage_update_after_bind_resources)),
    _max_descriptor_set_update_after_bind_samplers(
      std::move(other._max_descriptor_set_update_after_bind_samplers)),
    _max_descriptor_set_update_after_bind_uniform_buffers(
      std::move(other._max_descriptor_set_update_after_bind_uniform_buffers)),
    _max_descriptor_set_update_after_bind_uniform_buffers_dynamic(std::move(
      other._max_descriptor_set_update_after_bind_uniform_buffers_dynamic)),
    _max_descriptor_set_update_after_bind_storage_buffers(
      std::move(other._max_descriptor_set_update_after_bind_storage_buffers)),
    _max_descriptor_set_update_after_bind_storage_buffers_dynamic(std::move(
      other._max_descriptor_set_update_after_bind_storage_buffers_dynamic)),
    _max_descriptor_set_update_after_bind_sampled_images(
      std::move(other._max_descriptor_set_update_after_bind_sampled_images)),
    _max_descriptor_set_update_after_bind_storage_images(
      std::move(other._max_descriptor_set_update_after_bind_storage_images)),
    _max_descriptor_set_update_after_bind_input_attachments(
      std::move(other._max_descriptor_set_update_after_bind_input_attachments))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_descriptor_indexing_properties_ext& operator=(
    const physical_device_descriptor_indexing_properties_ext& other) noexcept
  {
    _next = other._next;
    _max_update_after_bind_descriptors_in_all_pools =
      other._max_update_after_bind_descriptors_in_all_pools;
    _shader_uniform_buffer_array_non_uniform_indexing_native =
      other._shader_uniform_buffer_array_non_uniform_indexing_native;
    _shader_sampled_image_array_non_uniform_indexing_native =
      other._shader_sampled_image_array_non_uniform_indexing_native;
    _shader_storage_buffer_array_non_uniform_indexing_native =
      other._shader_storage_buffer_array_non_uniform_indexing_native;
    _shader_storage_image_array_non_uniform_indexing_native =
      other._shader_storage_image_array_non_uniform_indexing_native;
    _shader_input_attachment_array_non_uniform_indexing_native =
      other._shader_input_attachment_array_non_uniform_indexing_native;
    _robust_buffer_access_update_after_bind =
      other._robust_buffer_access_update_after_bind;
    _quad_divergent_implicit_lod = other._quad_divergent_implicit_lod;
    _max_per_stage_descriptor_update_after_bind_samplers =
      other._max_per_stage_descriptor_update_after_bind_samplers;
    _max_per_stage_descriptor_update_after_bind_uniform_buffers =
      other._max_per_stage_descriptor_update_after_bind_uniform_buffers;
    _max_per_stage_descriptor_update_after_bind_storage_buffers =
      other._max_per_stage_descriptor_update_after_bind_storage_buffers;
    _max_per_stage_descriptor_update_after_bind_sampled_images =
      other._max_per_stage_descriptor_update_after_bind_sampled_images;
    _max_per_stage_descriptor_update_after_bind_storage_images =
      other._max_per_stage_descriptor_update_after_bind_storage_images;
    _max_per_stage_descriptor_update_after_bind_input_attachments =
      other._max_per_stage_descriptor_update_after_bind_input_attachments;
    _max_per_stage_update_after_bind_resources =
      other._max_per_stage_update_after_bind_resources;
    _max_descriptor_set_update_after_bind_samplers =
      other._max_descriptor_set_update_after_bind_samplers;
    _max_descriptor_set_update_after_bind_uniform_buffers =
      other._max_descriptor_set_update_after_bind_uniform_buffers;
    _max_descriptor_set_update_after_bind_uniform_buffers_dynamic =
      other._max_descriptor_set_update_after_bind_uniform_buffers_dynamic;
    _max_descriptor_set_update_after_bind_storage_buffers =
      other._max_descriptor_set_update_after_bind_storage_buffers;
    _max_descriptor_set_update_after_bind_storage_buffers_dynamic =
      other._max_descriptor_set_update_after_bind_storage_buffers_dynamic;
    _max_descriptor_set_update_after_bind_sampled_images =
      other._max_descriptor_set_update_after_bind_sampled_images;
    _max_descriptor_set_update_after_bind_storage_images =
      other._max_descriptor_set_update_after_bind_storage_images;
    _max_descriptor_set_update_after_bind_input_attachments =
      other._max_descriptor_set_update_after_bind_input_attachments;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_descriptor_indexing_properties_ext& operator=(
    physical_device_descriptor_indexing_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _max_update_after_bind_descriptors_in_all_pools =
      std::move(other._max_update_after_bind_descriptors_in_all_pools);
    _shader_uniform_buffer_array_non_uniform_indexing_native =
      std::move(other._shader_uniform_buffer_array_non_uniform_indexing_native);
    _shader_sampled_image_array_non_uniform_indexing_native =
      std::move(other._shader_sampled_image_array_non_uniform_indexing_native);
    _shader_storage_buffer_array_non_uniform_indexing_native =
      std::move(other._shader_storage_buffer_array_non_uniform_indexing_native);
    _shader_storage_image_array_non_uniform_indexing_native =
      std::move(other._shader_storage_image_array_non_uniform_indexing_native);
    _shader_input_attachment_array_non_uniform_indexing_native = std::move(
      other._shader_input_attachment_array_non_uniform_indexing_native);
    _robust_buffer_access_update_after_bind =
      std::move(other._robust_buffer_access_update_after_bind);
    _quad_divergent_implicit_lod =
      std::move(other._quad_divergent_implicit_lod);
    _max_per_stage_descriptor_update_after_bind_samplers =
      std::move(other._max_per_stage_descriptor_update_after_bind_samplers);
    _max_per_stage_descriptor_update_after_bind_uniform_buffers = std::move(
      other._max_per_stage_descriptor_update_after_bind_uniform_buffers);
    _max_per_stage_descriptor_update_after_bind_storage_buffers = std::move(
      other._max_per_stage_descriptor_update_after_bind_storage_buffers);
    _max_per_stage_descriptor_update_after_bind_sampled_images = std::move(
      other._max_per_stage_descriptor_update_after_bind_sampled_images);
    _max_per_stage_descriptor_update_after_bind_storage_images = std::move(
      other._max_per_stage_descriptor_update_after_bind_storage_images);
    _max_per_stage_descriptor_update_after_bind_input_attachments = std::move(
      other._max_per_stage_descriptor_update_after_bind_input_attachments);
    _max_per_stage_update_after_bind_resources =
      std::move(other._max_per_stage_update_after_bind_resources);
    _max_descriptor_set_update_after_bind_samplers =
      std::move(other._max_descriptor_set_update_after_bind_samplers);
    _max_descriptor_set_update_after_bind_uniform_buffers =
      std::move(other._max_descriptor_set_update_after_bind_uniform_buffers);
    _max_descriptor_set_update_after_bind_uniform_buffers_dynamic = std::move(
      other._max_descriptor_set_update_after_bind_uniform_buffers_dynamic);
    _max_descriptor_set_update_after_bind_storage_buffers =
      std::move(other._max_descriptor_set_update_after_bind_storage_buffers);
    _max_descriptor_set_update_after_bind_storage_buffers_dynamic = std::move(
      other._max_descriptor_set_update_after_bind_storage_buffers_dynamic);
    _max_descriptor_set_update_after_bind_sampled_images =
      std::move(other._max_descriptor_set_update_after_bind_sampled_images);
    _max_descriptor_set_update_after_bind_storage_images =
      std::move(other._max_descriptor_set_update_after_bind_storage_images);
    _max_descriptor_set_update_after_bind_input_attachments =
      std::move(other._max_descriptor_set_update_after_bind_input_attachments);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceDescriptorIndexingPropertiesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceDescriptorIndexingPropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_update_after_bind_descriptors_in_all_pools()
  {
    return _max_update_after_bind_descriptors_in_all_pools;
  }

  constexpr const uint32_t& max_update_after_bind_descriptors_in_all_pools()
    const
  {
    return _max_update_after_bind_descriptors_in_all_pools;
  }

  void max_update_after_bind_descriptors_in_all_pools(
    uint32_t new_max_update_after_bind_descriptors_in_all_pools)
  {
    _max_update_after_bind_descriptors_in_all_pools =
      new_max_update_after_bind_descriptors_in_all_pools;
  }

  VkBool32& shader_uniform_buffer_array_non_uniform_indexing_native()
  {
    return _shader_uniform_buffer_array_non_uniform_indexing_native;
  }

  constexpr const VkBool32&
  shader_uniform_buffer_array_non_uniform_indexing_native() const
  {
    return _shader_uniform_buffer_array_non_uniform_indexing_native;
  }

  void shader_uniform_buffer_array_non_uniform_indexing_native(
    VkBool32 new_shader_uniform_buffer_array_non_uniform_indexing_native)
  {
    _shader_uniform_buffer_array_non_uniform_indexing_native =
      new_shader_uniform_buffer_array_non_uniform_indexing_native;
  }

  VkBool32& shader_sampled_image_array_non_uniform_indexing_native()
  {
    return _shader_sampled_image_array_non_uniform_indexing_native;
  }

  constexpr const VkBool32&
  shader_sampled_image_array_non_uniform_indexing_native() const
  {
    return _shader_sampled_image_array_non_uniform_indexing_native;
  }

  void shader_sampled_image_array_non_uniform_indexing_native(
    VkBool32 new_shader_sampled_image_array_non_uniform_indexing_native)
  {
    _shader_sampled_image_array_non_uniform_indexing_native =
      new_shader_sampled_image_array_non_uniform_indexing_native;
  }

  VkBool32& shader_storage_buffer_array_non_uniform_indexing_native()
  {
    return _shader_storage_buffer_array_non_uniform_indexing_native;
  }

  constexpr const VkBool32&
  shader_storage_buffer_array_non_uniform_indexing_native() const
  {
    return _shader_storage_buffer_array_non_uniform_indexing_native;
  }

  void shader_storage_buffer_array_non_uniform_indexing_native(
    VkBool32 new_shader_storage_buffer_array_non_uniform_indexing_native)
  {
    _shader_storage_buffer_array_non_uniform_indexing_native =
      new_shader_storage_buffer_array_non_uniform_indexing_native;
  }

  VkBool32& shader_storage_image_array_non_uniform_indexing_native()
  {
    return _shader_storage_image_array_non_uniform_indexing_native;
  }

  constexpr const VkBool32&
  shader_storage_image_array_non_uniform_indexing_native() const
  {
    return _shader_storage_image_array_non_uniform_indexing_native;
  }

  void shader_storage_image_array_non_uniform_indexing_native(
    VkBool32 new_shader_storage_image_array_non_uniform_indexing_native)
  {
    _shader_storage_image_array_non_uniform_indexing_native =
      new_shader_storage_image_array_non_uniform_indexing_native;
  }

  VkBool32& shader_input_attachment_array_non_uniform_indexing_native()
  {
    return _shader_input_attachment_array_non_uniform_indexing_native;
  }

  constexpr const VkBool32&
  shader_input_attachment_array_non_uniform_indexing_native() const
  {
    return _shader_input_attachment_array_non_uniform_indexing_native;
  }

  void shader_input_attachment_array_non_uniform_indexing_native(
    VkBool32 new_shader_input_attachment_array_non_uniform_indexing_native)
  {
    _shader_input_attachment_array_non_uniform_indexing_native =
      new_shader_input_attachment_array_non_uniform_indexing_native;
  }

  VkBool32& robust_buffer_access_update_after_bind()
  {
    return _robust_buffer_access_update_after_bind;
  }

  constexpr const VkBool32& robust_buffer_access_update_after_bind() const
  {
    return _robust_buffer_access_update_after_bind;
  }

  void robust_buffer_access_update_after_bind(
    VkBool32 new_robust_buffer_access_update_after_bind)
  {
    _robust_buffer_access_update_after_bind =
      new_robust_buffer_access_update_after_bind;
  }

  VkBool32& quad_divergent_implicit_lod()
  {
    return _quad_divergent_implicit_lod;
  }

  constexpr const VkBool32& quad_divergent_implicit_lod() const
  {
    return _quad_divergent_implicit_lod;
  }

  void quad_divergent_implicit_lod(VkBool32 new_quad_divergent_implicit_lod)
  {
    _quad_divergent_implicit_lod = new_quad_divergent_implicit_lod;
  }

  uint32_t& max_per_stage_descriptor_update_after_bind_samplers()
  {
    return _max_per_stage_descriptor_update_after_bind_samplers;
  }

  constexpr const uint32_t&
  max_per_stage_descriptor_update_after_bind_samplers() const
  {
    return _max_per_stage_descriptor_update_after_bind_samplers;
  }

  void max_per_stage_descriptor_update_after_bind_samplers(
    uint32_t new_max_per_stage_descriptor_update_after_bind_samplers)
  {
    _max_per_stage_descriptor_update_after_bind_samplers =
      new_max_per_stage_descriptor_update_after_bind_samplers;
  }

  uint32_t& max_per_stage_descriptor_update_after_bind_uniform_buffers()
  {
    return _max_per_stage_descriptor_update_after_bind_uniform_buffers;
  }

  constexpr const uint32_t&
  max_per_stage_descriptor_update_after_bind_uniform_buffers() const
  {
    return _max_per_stage_descriptor_update_after_bind_uniform_buffers;
  }

  void max_per_stage_descriptor_update_after_bind_uniform_buffers(
    uint32_t new_max_per_stage_descriptor_update_after_bind_uniform_buffers)
  {
    _max_per_stage_descriptor_update_after_bind_uniform_buffers =
      new_max_per_stage_descriptor_update_after_bind_uniform_buffers;
  }

  uint32_t& max_per_stage_descriptor_update_after_bind_storage_buffers()
  {
    return _max_per_stage_descriptor_update_after_bind_storage_buffers;
  }

  constexpr const uint32_t&
  max_per_stage_descriptor_update_after_bind_storage_buffers() const
  {
    return _max_per_stage_descriptor_update_after_bind_storage_buffers;
  }

  void max_per_stage_descriptor_update_after_bind_storage_buffers(
    uint32_t new_max_per_stage_descriptor_update_after_bind_storage_buffers)
  {
    _max_per_stage_descriptor_update_after_bind_storage_buffers =
      new_max_per_stage_descriptor_update_after_bind_storage_buffers;
  }

  uint32_t& max_per_stage_descriptor_update_after_bind_sampled_images()
  {
    return _max_per_stage_descriptor_update_after_bind_sampled_images;
  }

  constexpr const uint32_t&
  max_per_stage_descriptor_update_after_bind_sampled_images() const
  {
    return _max_per_stage_descriptor_update_after_bind_sampled_images;
  }

  void max_per_stage_descriptor_update_after_bind_sampled_images(
    uint32_t new_max_per_stage_descriptor_update_after_bind_sampled_images)
  {
    _max_per_stage_descriptor_update_after_bind_sampled_images =
      new_max_per_stage_descriptor_update_after_bind_sampled_images;
  }

  uint32_t& max_per_stage_descriptor_update_after_bind_storage_images()
  {
    return _max_per_stage_descriptor_update_after_bind_storage_images;
  }

  constexpr const uint32_t&
  max_per_stage_descriptor_update_after_bind_storage_images() const
  {
    return _max_per_stage_descriptor_update_after_bind_storage_images;
  }

  void max_per_stage_descriptor_update_after_bind_storage_images(
    uint32_t new_max_per_stage_descriptor_update_after_bind_storage_images)
  {
    _max_per_stage_descriptor_update_after_bind_storage_images =
      new_max_per_stage_descriptor_update_after_bind_storage_images;
  }

  uint32_t& max_per_stage_descriptor_update_after_bind_input_attachments()
  {
    return _max_per_stage_descriptor_update_after_bind_input_attachments;
  }

  constexpr const uint32_t&
  max_per_stage_descriptor_update_after_bind_input_attachments() const
  {
    return _max_per_stage_descriptor_update_after_bind_input_attachments;
  }

  void max_per_stage_descriptor_update_after_bind_input_attachments(
    uint32_t new_max_per_stage_descriptor_update_after_bind_input_attachments)
  {
    _max_per_stage_descriptor_update_after_bind_input_attachments =
      new_max_per_stage_descriptor_update_after_bind_input_attachments;
  }

  uint32_t& max_per_stage_update_after_bind_resources()
  {
    return _max_per_stage_update_after_bind_resources;
  }

  constexpr const uint32_t& max_per_stage_update_after_bind_resources() const
  {
    return _max_per_stage_update_after_bind_resources;
  }

  void max_per_stage_update_after_bind_resources(
    uint32_t new_max_per_stage_update_after_bind_resources)
  {
    _max_per_stage_update_after_bind_resources =
      new_max_per_stage_update_after_bind_resources;
  }

  uint32_t& max_descriptor_set_update_after_bind_samplers()
  {
    return _max_descriptor_set_update_after_bind_samplers;
  }

  constexpr const uint32_t& max_descriptor_set_update_after_bind_samplers()
    const
  {
    return _max_descriptor_set_update_after_bind_samplers;
  }

  void max_descriptor_set_update_after_bind_samplers(
    uint32_t new_max_descriptor_set_update_after_bind_samplers)
  {
    _max_descriptor_set_update_after_bind_samplers =
      new_max_descriptor_set_update_after_bind_samplers;
  }

  uint32_t& max_descriptor_set_update_after_bind_uniform_buffers()
  {
    return _max_descriptor_set_update_after_bind_uniform_buffers;
  }

  constexpr const uint32_t&
  max_descriptor_set_update_after_bind_uniform_buffers() const
  {
    return _max_descriptor_set_update_after_bind_uniform_buffers;
  }

  void max_descriptor_set_update_after_bind_uniform_buffers(
    uint32_t new_max_descriptor_set_update_after_bind_uniform_buffers)
  {
    _max_descriptor_set_update_after_bind_uniform_buffers =
      new_max_descriptor_set_update_after_bind_uniform_buffers;
  }

  uint32_t& max_descriptor_set_update_after_bind_uniform_buffers_dynamic()
  {
    return _max_descriptor_set_update_after_bind_uniform_buffers_dynamic;
  }

  constexpr const uint32_t&
  max_descriptor_set_update_after_bind_uniform_buffers_dynamic() const
  {
    return _max_descriptor_set_update_after_bind_uniform_buffers_dynamic;
  }

  void max_descriptor_set_update_after_bind_uniform_buffers_dynamic(
    uint32_t new_max_descriptor_set_update_after_bind_uniform_buffers_dynamic)
  {
    _max_descriptor_set_update_after_bind_uniform_buffers_dynamic =
      new_max_descriptor_set_update_after_bind_uniform_buffers_dynamic;
  }

  uint32_t& max_descriptor_set_update_after_bind_storage_buffers()
  {
    return _max_descriptor_set_update_after_bind_storage_buffers;
  }

  constexpr const uint32_t&
  max_descriptor_set_update_after_bind_storage_buffers() const
  {
    return _max_descriptor_set_update_after_bind_storage_buffers;
  }

  void max_descriptor_set_update_after_bind_storage_buffers(
    uint32_t new_max_descriptor_set_update_after_bind_storage_buffers)
  {
    _max_descriptor_set_update_after_bind_storage_buffers =
      new_max_descriptor_set_update_after_bind_storage_buffers;
  }

  uint32_t& max_descriptor_set_update_after_bind_storage_buffers_dynamic()
  {
    return _max_descriptor_set_update_after_bind_storage_buffers_dynamic;
  }

  constexpr const uint32_t&
  max_descriptor_set_update_after_bind_storage_buffers_dynamic() const
  {
    return _max_descriptor_set_update_after_bind_storage_buffers_dynamic;
  }

  void max_descriptor_set_update_after_bind_storage_buffers_dynamic(
    uint32_t new_max_descriptor_set_update_after_bind_storage_buffers_dynamic)
  {
    _max_descriptor_set_update_after_bind_storage_buffers_dynamic =
      new_max_descriptor_set_update_after_bind_storage_buffers_dynamic;
  }

  uint32_t& max_descriptor_set_update_after_bind_sampled_images()
  {
    return _max_descriptor_set_update_after_bind_sampled_images;
  }

  constexpr const uint32_t&
  max_descriptor_set_update_after_bind_sampled_images() const
  {
    return _max_descriptor_set_update_after_bind_sampled_images;
  }

  void max_descriptor_set_update_after_bind_sampled_images(
    uint32_t new_max_descriptor_set_update_after_bind_sampled_images)
  {
    _max_descriptor_set_update_after_bind_sampled_images =
      new_max_descriptor_set_update_after_bind_sampled_images;
  }

  uint32_t& max_descriptor_set_update_after_bind_storage_images()
  {
    return _max_descriptor_set_update_after_bind_storage_images;
  }

  constexpr const uint32_t&
  max_descriptor_set_update_after_bind_storage_images() const
  {
    return _max_descriptor_set_update_after_bind_storage_images;
  }

  void max_descriptor_set_update_after_bind_storage_images(
    uint32_t new_max_descriptor_set_update_after_bind_storage_images)
  {
    _max_descriptor_set_update_after_bind_storage_images =
      new_max_descriptor_set_update_after_bind_storage_images;
  }

  uint32_t& max_descriptor_set_update_after_bind_input_attachments()
  {
    return _max_descriptor_set_update_after_bind_input_attachments;
  }

  constexpr const uint32_t&
  max_descriptor_set_update_after_bind_input_attachments() const
  {
    return _max_descriptor_set_update_after_bind_input_attachments;
  }

  void max_descriptor_set_update_after_bind_input_attachments(
    uint32_t new_max_descriptor_set_update_after_bind_input_attachments)
  {
    _max_descriptor_set_update_after_bind_input_attachments =
      new_max_descriptor_set_update_after_bind_input_attachments;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_descriptor_indexing_properties_ext;
  void* _next = nullptr;
  uint32_t _max_update_after_bind_descriptors_in_all_pools = 0;
  VkBool32 _shader_uniform_buffer_array_non_uniform_indexing_native = VK_FALSE;
  VkBool32 _shader_sampled_image_array_non_uniform_indexing_native = VK_FALSE;
  VkBool32 _shader_storage_buffer_array_non_uniform_indexing_native = VK_FALSE;
  VkBool32 _shader_storage_image_array_non_uniform_indexing_native = VK_FALSE;
  VkBool32 _shader_input_attachment_array_non_uniform_indexing_native =
    VK_FALSE;
  VkBool32 _robust_buffer_access_update_after_bind = VK_FALSE;
  VkBool32 _quad_divergent_implicit_lod = VK_FALSE;
  uint32_t _max_per_stage_descriptor_update_after_bind_samplers = 0;
  uint32_t _max_per_stage_descriptor_update_after_bind_uniform_buffers = 0;
  uint32_t _max_per_stage_descriptor_update_after_bind_storage_buffers = 0;
  uint32_t _max_per_stage_descriptor_update_after_bind_sampled_images = 0;
  uint32_t _max_per_stage_descriptor_update_after_bind_storage_images = 0;
  uint32_t _max_per_stage_descriptor_update_after_bind_input_attachments = 0;
  uint32_t _max_per_stage_update_after_bind_resources = 0;
  uint32_t _max_descriptor_set_update_after_bind_samplers = 0;
  uint32_t _max_descriptor_set_update_after_bind_uniform_buffers = 0;
  uint32_t _max_descriptor_set_update_after_bind_uniform_buffers_dynamic = 0;
  uint32_t _max_descriptor_set_update_after_bind_storage_buffers = 0;
  uint32_t _max_descriptor_set_update_after_bind_storage_buffers_dynamic = 0;
  uint32_t _max_descriptor_set_update_after_bind_sampled_images = 0;
  uint32_t _max_descriptor_set_update_after_bind_storage_images = 0;
  uint32_t _max_descriptor_set_update_after_bind_input_attachments = 0;
};
static_assert(sizeof(physical_device_descriptor_indexing_properties_ext) ==
                sizeof(::VkPhysicalDeviceDescriptorIndexingPropertiesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkDescriptorSetVariableDescriptorCountAllocateInfoEXT.
class descriptor_set_variable_descriptor_count_allocate_info_ext
{
public:
  /// Default constructor.
  constexpr descriptor_set_variable_descriptor_count_allocate_info_ext() =
    default;

  /// Constructor.
  constexpr descriptor_set_variable_descriptor_count_allocate_info_ext(
    const void* initial_next, uint32_t initial_descriptor_set_count,
    const uint32_t* initial_descriptor_counts) noexcept
  : _next(std::move(initial_next)),
    _descriptor_set_count(std::move(initial_descriptor_set_count)),
    _descriptor_counts(std::move(initial_descriptor_counts))
  {
  }

  /// Copy constructor.
  constexpr descriptor_set_variable_descriptor_count_allocate_info_ext(
    const descriptor_set_variable_descriptor_count_allocate_info_ext&
      other) noexcept
  : _next(other._next),
    _descriptor_set_count(other._descriptor_set_count),
    _descriptor_counts(other._descriptor_counts)
  {
  }

  /// Move constructor.
  constexpr descriptor_set_variable_descriptor_count_allocate_info_ext(
    descriptor_set_variable_descriptor_count_allocate_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _descriptor_set_count(std::move(other._descriptor_set_count)),
    _descriptor_counts(std::move(other._descriptor_counts))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_set_variable_descriptor_count_allocate_info_ext&
  operator=(const descriptor_set_variable_descriptor_count_allocate_info_ext&
              other) noexcept
  {
    _next = other._next;
    _descriptor_set_count = other._descriptor_set_count;
    _descriptor_counts = other._descriptor_counts;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_set_variable_descriptor_count_allocate_info_ext&
  operator=(
    descriptor_set_variable_descriptor_count_allocate_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _descriptor_set_count = std::move(other._descriptor_set_count);
    _descriptor_counts = std::move(other._descriptor_counts);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorSetVariableDescriptorCountAllocateInfoEXT&() const
  {
    return *reinterpret_cast<
      const VkDescriptorSetVariableDescriptorCountAllocateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& descriptor_set_count()
  {
    return _descriptor_set_count;
  }

  constexpr const uint32_t& descriptor_set_count() const
  {
    return _descriptor_set_count;
  }

  void descriptor_set_count(uint32_t new_descriptor_set_count)
  {
    _descriptor_set_count = new_descriptor_set_count;
  }

  const uint32_t* descriptor_counts()
  {
    return _descriptor_counts;
  }

  constexpr const uint32_t* descriptor_counts() const
  {
    return _descriptor_counts;
  }

  void descriptor_counts(const uint32_t* new_descriptor_counts)
  {
    _descriptor_counts = new_descriptor_counts;
  }

  template <std::size_t Count>
  void descriptor_counts(
    const std::array<uint32_t, Count>& new_descriptor_counts)
  {
    _descriptor_set_count = static_cast<uint32_t>(new_descriptor_counts.size());
    _descriptor_counts = new_descriptor_counts.data();
  }

  void descriptor_counts(const std::vector<uint32_t>& new_descriptor_counts)
  {
    _descriptor_set_count = static_cast<uint32_t>(new_descriptor_counts.size());
    _descriptor_counts = new_descriptor_counts.data();
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    descriptor_set_variable_descriptor_count_allocate_info_ext;
  const void* _next = nullptr;
  uint32_t _descriptor_set_count = 0;
  const uint32_t* _descriptor_counts = nullptr;
};
static_assert(
  sizeof(descriptor_set_variable_descriptor_count_allocate_info_ext) ==
    sizeof(::VkDescriptorSetVariableDescriptorCountAllocateInfoEXT),
  "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkDescriptorSetVariableDescriptorCountLayoutSupportEXT.
class descriptor_set_variable_descriptor_count_layout_support_ext
{
public:
  /// Default constructor.
  constexpr descriptor_set_variable_descriptor_count_layout_support_ext() =
    default;

  /// Constructor.
  constexpr descriptor_set_variable_descriptor_count_layout_support_ext(
    void* initial_next, uint32_t initial_max_variable_descriptor_count) noexcept
  : _next(std::move(initial_next)),
    _max_variable_descriptor_count(
      std::move(initial_max_variable_descriptor_count))
  {
  }

  /// Copy constructor.
  constexpr descriptor_set_variable_descriptor_count_layout_support_ext(
    const descriptor_set_variable_descriptor_count_layout_support_ext&
      other) noexcept
  : _next(other._next),
    _max_variable_descriptor_count(other._max_variable_descriptor_count)
  {
  }

  /// Move constructor.
  constexpr descriptor_set_variable_descriptor_count_layout_support_ext(
    descriptor_set_variable_descriptor_count_layout_support_ext&&
      other) noexcept
  : _next(std::move(other._next)),
    _max_variable_descriptor_count(
      std::move(other._max_variable_descriptor_count))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_set_variable_descriptor_count_layout_support_ext&
  operator=(const descriptor_set_variable_descriptor_count_layout_support_ext&
              other) noexcept
  {
    _next = other._next;
    _max_variable_descriptor_count = other._max_variable_descriptor_count;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_set_variable_descriptor_count_layout_support_ext&
  operator=(descriptor_set_variable_descriptor_count_layout_support_ext&&
              other) noexcept
  {
    _next = std::move(other._next);
    _max_variable_descriptor_count =
      std::move(other._max_variable_descriptor_count);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorSetVariableDescriptorCountLayoutSupportEXT&() const
  {
    return *reinterpret_cast<
      const VkDescriptorSetVariableDescriptorCountLayoutSupportEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_variable_descriptor_count()
  {
    return _max_variable_descriptor_count;
  }

  constexpr const uint32_t& max_variable_descriptor_count() const
  {
    return _max_variable_descriptor_count;
  }

  void max_variable_descriptor_count(uint32_t new_max_variable_descriptor_count)
  {
    _max_variable_descriptor_count = new_max_variable_descriptor_count;
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    descriptor_set_variable_descriptor_count_layout_support_ext;
  void* _next = nullptr;
  uint32_t _max_variable_descriptor_count = 0;
};
static_assert(
  sizeof(descriptor_set_variable_descriptor_count_layout_support_ext) ==
    sizeof(::VkDescriptorSetVariableDescriptorCountLayoutSupportEXT),
  "struct and wrapper have different size!");

enum class shading_rate_palette_entry_nv
{
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_NO_INVOCATIONS_NV
  shading_rate_palette_entry_no_invocations_nv = 0,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_16_INVOCATIONS_PER_PIXEL_NV
  shading_rate_palette_entry_16_invocations_per_pixel_nv = 1,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_8_INVOCATIONS_PER_PIXEL_NV
  shading_rate_palette_entry_8_invocations_per_pixel_nv = 2,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_4_INVOCATIONS_PER_PIXEL_NV
  shading_rate_palette_entry_4_invocations_per_pixel_nv = 3,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_2_INVOCATIONS_PER_PIXEL_NV
  shading_rate_palette_entry_2_invocations_per_pixel_nv = 4,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_PIXEL_NV
  shading_rate_palette_entry_1_invocation_per_pixel_nv = 5,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_2X1_PIXELS_NV
  shading_rate_palette_entry_1_invocation_per_2_x1_pixels_nv = 6,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_1X2_PIXELS_NV
  shading_rate_palette_entry_1_invocation_per_1_x2_pixels_nv = 7,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_2X2_PIXELS_NV
  shading_rate_palette_entry_1_invocation_per_2_x2_pixels_nv = 8,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_4X2_PIXELS_NV
  shading_rate_palette_entry_1_invocation_per_4_x2_pixels_nv = 9,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_2X4_PIXELS_NV
  shading_rate_palette_entry_1_invocation_per_2_x4_pixels_nv = 10,
  /// @see VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_4X4_PIXELS_NV
  shading_rate_palette_entry_1_invocation_per_4_x4_pixels_nv = 11,
};

/// Enhanced replacement type for VkShadingRatePaletteNV.
class shading_rate_palette_nv
{
public:
  /// Default constructor.
  constexpr shading_rate_palette_nv() = default;

  /// Constructor.
  constexpr shading_rate_palette_nv(
    uint32_t initial_shading_rate_palette_entry_count,
    const vk::shading_rate_palette_entry_nv*
      initial_shading_rate_palette_entries) noexcept
  : _shading_rate_palette_entry_count(
      std::move(initial_shading_rate_palette_entry_count)),
    _shading_rate_palette_entries(
      std::move(initial_shading_rate_palette_entries))
  {
  }

  /// Copy constructor.
  constexpr shading_rate_palette_nv(const shading_rate_palette_nv& other) =
    default;

  /// Move constructor.
  constexpr shading_rate_palette_nv(shading_rate_palette_nv&& other) = default;

  /// Copy assignment operator.
  constexpr shading_rate_palette_nv& operator=(
    const shading_rate_palette_nv& other) = default;

  /// Move assignment operator.
  constexpr shading_rate_palette_nv& operator=(
    shading_rate_palette_nv&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkShadingRatePaletteNV&() const
  {
    return *reinterpret_cast<const VkShadingRatePaletteNV*>(this);
  }

  uint32_t& shading_rate_palette_entry_count()
  {
    return _shading_rate_palette_entry_count;
  }

  constexpr const uint32_t& shading_rate_palette_entry_count() const
  {
    return _shading_rate_palette_entry_count;
  }

  void shading_rate_palette_entry_count(
    uint32_t new_shading_rate_palette_entry_count)
  {
    _shading_rate_palette_entry_count = new_shading_rate_palette_entry_count;
  }

  const vk::shading_rate_palette_entry_nv* shading_rate_palette_entries()
  {
    return _shading_rate_palette_entries;
  }

  constexpr const vk::shading_rate_palette_entry_nv*
  shading_rate_palette_entries() const
  {
    return _shading_rate_palette_entries;
  }

  void shading_rate_palette_entries(
    const vk::shading_rate_palette_entry_nv* new_shading_rate_palette_entries)
  {
    _shading_rate_palette_entries = new_shading_rate_palette_entries;
  }

  template <std::size_t Count>
  void shading_rate_palette_entries(
    const std::array<vk::shading_rate_palette_entry_nv, Count>&
      new_shading_rate_palette_entries)
  {
    _shading_rate_palette_entry_count =
      static_cast<uint32_t>(new_shading_rate_palette_entries.size());
    _shading_rate_palette_entries = new_shading_rate_palette_entries.data();
  }

  void shading_rate_palette_entries(
    const std::vector<vk::shading_rate_palette_entry_nv>&
      new_shading_rate_palette_entries)
  {
    _shading_rate_palette_entry_count =
      static_cast<uint32_t>(new_shading_rate_palette_entries.size());
    _shading_rate_palette_entries = new_shading_rate_palette_entries.data();
  }

private:
  uint32_t _shading_rate_palette_entry_count = 0;
  const vk::shading_rate_palette_entry_nv* _shading_rate_palette_entries =
    nullptr;
};
static_assert(sizeof(shading_rate_palette_nv) ==
                sizeof(::VkShadingRatePaletteNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPipelineViewportShadingRateImageStateCreateInfoNV.
class pipeline_viewport_shading_rate_image_state_create_info_nv
{
public:
  /// Default constructor.
  constexpr pipeline_viewport_shading_rate_image_state_create_info_nv() =
    default;

  /// Constructor.
  constexpr pipeline_viewport_shading_rate_image_state_create_info_nv(
    const void* initial_next, VkBool32 initial_shading_rate_image_enable,
    uint32_t initial_viewport_count,
    const vk::shading_rate_palette_nv* initial_shading_rate_palettes) noexcept
  : _next(std::move(initial_next)),
    _shading_rate_image_enable(std::move(initial_shading_rate_image_enable)),
    _viewport_count(std::move(initial_viewport_count)),
    _shading_rate_palettes(std::move(initial_shading_rate_palettes))
  {
  }

  /// Copy constructor.
  constexpr pipeline_viewport_shading_rate_image_state_create_info_nv(
    const pipeline_viewport_shading_rate_image_state_create_info_nv&
      other) noexcept
  : _next(other._next),
    _shading_rate_image_enable(other._shading_rate_image_enable),
    _viewport_count(other._viewport_count),
    _shading_rate_palettes(other._shading_rate_palettes)
  {
  }

  /// Move constructor.
  constexpr pipeline_viewport_shading_rate_image_state_create_info_nv(
    pipeline_viewport_shading_rate_image_state_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _shading_rate_image_enable(std::move(other._shading_rate_image_enable)),
    _viewport_count(std::move(other._viewport_count)),
    _shading_rate_palettes(std::move(other._shading_rate_palettes))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_viewport_shading_rate_image_state_create_info_nv&
  operator=(const pipeline_viewport_shading_rate_image_state_create_info_nv&
              other) noexcept
  {
    _next = other._next;
    _shading_rate_image_enable = other._shading_rate_image_enable;
    _viewport_count = other._viewport_count;
    _shading_rate_palettes = other._shading_rate_palettes;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_viewport_shading_rate_image_state_create_info_nv&
  operator=(
    pipeline_viewport_shading_rate_image_state_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _shading_rate_image_enable = std::move(other._shading_rate_image_enable);
    _viewport_count = std::move(other._viewport_count);
    _shading_rate_palettes = std::move(other._shading_rate_palettes);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineViewportShadingRateImageStateCreateInfoNV&() const
  {
    return *reinterpret_cast<
      const VkPipelineViewportShadingRateImageStateCreateInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& shading_rate_image_enable()
  {
    return _shading_rate_image_enable;
  }

  constexpr const VkBool32& shading_rate_image_enable() const
  {
    return _shading_rate_image_enable;
  }

  void shading_rate_image_enable(VkBool32 new_shading_rate_image_enable)
  {
    _shading_rate_image_enable = new_shading_rate_image_enable;
  }

  uint32_t& viewport_count()
  {
    return _viewport_count;
  }

  constexpr const uint32_t& viewport_count() const
  {
    return _viewport_count;
  }

  void viewport_count(uint32_t new_viewport_count)
  {
    _viewport_count = new_viewport_count;
  }

  const vk::shading_rate_palette_nv* shading_rate_palettes()
  {
    return _shading_rate_palettes;
  }

  constexpr const vk::shading_rate_palette_nv* shading_rate_palettes() const
  {
    return _shading_rate_palettes;
  }

  void shading_rate_palettes(
    const vk::shading_rate_palette_nv* new_shading_rate_palettes)
  {
    _shading_rate_palettes = new_shading_rate_palettes;
  }

  template <std::size_t Count>
  void shading_rate_palettes(const std::array<vk::shading_rate_palette_nv,
                                              Count>& new_shading_rate_palettes)
  {
    _viewport_count = static_cast<uint32_t>(new_shading_rate_palettes.size());
    _shading_rate_palettes = new_shading_rate_palettes.data();
  }

  void shading_rate_palettes(
    const std::vector<vk::shading_rate_palette_nv>& new_shading_rate_palettes)
  {
    _viewport_count = static_cast<uint32_t>(new_shading_rate_palettes.size());
    _shading_rate_palettes = new_shading_rate_palettes.data();
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    pipeline_viewport_shading_rate_image_state_create_info_nv;
  const void* _next = nullptr;
  VkBool32 _shading_rate_image_enable = VK_FALSE;
  uint32_t _viewport_count = 0;
  const vk::shading_rate_palette_nv* _shading_rate_palettes = nullptr;
};
static_assert(
  sizeof(pipeline_viewport_shading_rate_image_state_create_info_nv) ==
    sizeof(::VkPipelineViewportShadingRateImageStateCreateInfoNV),
  "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceShadingRateImageFeaturesNV.
class physical_device_shading_rate_image_features_nv
{
public:
  /// Default constructor.
  constexpr physical_device_shading_rate_image_features_nv() = default;

  /// Constructor.
  constexpr physical_device_shading_rate_image_features_nv(
    void* initial_next, VkBool32 initial_shading_rate_image,
    VkBool32 initial_shading_rate_coarse_sample_order) noexcept
  : _next(std::move(initial_next)),
    _shading_rate_image(std::move(initial_shading_rate_image)),
    _shading_rate_coarse_sample_order(
      std::move(initial_shading_rate_coarse_sample_order))
  {
  }

  /// Copy constructor.
  constexpr physical_device_shading_rate_image_features_nv(
    const physical_device_shading_rate_image_features_nv& other) noexcept
  : _next(other._next),
    _shading_rate_image(other._shading_rate_image),
    _shading_rate_coarse_sample_order(other._shading_rate_coarse_sample_order)
  {
  }

  /// Move constructor.
  constexpr physical_device_shading_rate_image_features_nv(
    physical_device_shading_rate_image_features_nv&& other) noexcept
  : _next(std::move(other._next)),
    _shading_rate_image(std::move(other._shading_rate_image)),
    _shading_rate_coarse_sample_order(
      std::move(other._shading_rate_coarse_sample_order))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_shading_rate_image_features_nv& operator=(
    const physical_device_shading_rate_image_features_nv& other) noexcept
  {
    _next = other._next;
    _shading_rate_image = other._shading_rate_image;
    _shading_rate_coarse_sample_order = other._shading_rate_coarse_sample_order;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_shading_rate_image_features_nv& operator=(
    physical_device_shading_rate_image_features_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _shading_rate_image = std::move(other._shading_rate_image);
    _shading_rate_coarse_sample_order =
      std::move(other._shading_rate_coarse_sample_order);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceShadingRateImageFeaturesNV&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceShadingRateImageFeaturesNV*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& shading_rate_image()
  {
    return _shading_rate_image;
  }

  constexpr const VkBool32& shading_rate_image() const
  {
    return _shading_rate_image;
  }

  void shading_rate_image(VkBool32 new_shading_rate_image)
  {
    _shading_rate_image = new_shading_rate_image;
  }

  VkBool32& shading_rate_coarse_sample_order()
  {
    return _shading_rate_coarse_sample_order;
  }

  constexpr const VkBool32& shading_rate_coarse_sample_order() const
  {
    return _shading_rate_coarse_sample_order;
  }

  void shading_rate_coarse_sample_order(
    VkBool32 new_shading_rate_coarse_sample_order)
  {
    _shading_rate_coarse_sample_order = new_shading_rate_coarse_sample_order;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_shading_rate_image_features_nv;
  void* _next = nullptr;
  VkBool32 _shading_rate_image = VK_FALSE;
  VkBool32 _shading_rate_coarse_sample_order = VK_FALSE;
};
static_assert(sizeof(physical_device_shading_rate_image_features_nv) ==
                sizeof(::VkPhysicalDeviceShadingRateImageFeaturesNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceShadingRateImagePropertiesNV.
class physical_device_shading_rate_image_properties_nv
{
public:
  /// Default constructor.
  constexpr physical_device_shading_rate_image_properties_nv() = default;

  /// Constructor.
  constexpr physical_device_shading_rate_image_properties_nv(
    void* initial_next, vk::extent_2d initial_shading_rate_texel_size,
    uint32_t initial_shading_rate_palette_size,
    uint32_t initial_shading_rate_max_coarse_samples) noexcept
  : _next(std::move(initial_next)),
    _shading_rate_texel_size(std::move(initial_shading_rate_texel_size)),
    _shading_rate_palette_size(std::move(initial_shading_rate_palette_size)),
    _shading_rate_max_coarse_samples(
      std::move(initial_shading_rate_max_coarse_samples))
  {
  }

  /// Copy constructor.
  constexpr physical_device_shading_rate_image_properties_nv(
    const physical_device_shading_rate_image_properties_nv& other) noexcept
  : _next(other._next),
    _shading_rate_texel_size(other._shading_rate_texel_size),
    _shading_rate_palette_size(other._shading_rate_palette_size),
    _shading_rate_max_coarse_samples(other._shading_rate_max_coarse_samples)
  {
  }

  /// Move constructor.
  constexpr physical_device_shading_rate_image_properties_nv(
    physical_device_shading_rate_image_properties_nv&& other) noexcept
  : _next(std::move(other._next)),
    _shading_rate_texel_size(std::move(other._shading_rate_texel_size)),
    _shading_rate_palette_size(std::move(other._shading_rate_palette_size)),
    _shading_rate_max_coarse_samples(
      std::move(other._shading_rate_max_coarse_samples))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_shading_rate_image_properties_nv& operator=(
    const physical_device_shading_rate_image_properties_nv& other) noexcept
  {
    _next = other._next;
    _shading_rate_texel_size = other._shading_rate_texel_size;
    _shading_rate_palette_size = other._shading_rate_palette_size;
    _shading_rate_max_coarse_samples = other._shading_rate_max_coarse_samples;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_shading_rate_image_properties_nv& operator=(
    physical_device_shading_rate_image_properties_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _shading_rate_texel_size = std::move(other._shading_rate_texel_size);
    _shading_rate_palette_size = std::move(other._shading_rate_palette_size);
    _shading_rate_max_coarse_samples =
      std::move(other._shading_rate_max_coarse_samples);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceShadingRateImagePropertiesNV&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceShadingRateImagePropertiesNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::extent_2d& shading_rate_texel_size()
  {
    return _shading_rate_texel_size;
  }

  constexpr const vk::extent_2d& shading_rate_texel_size() const
  {
    return _shading_rate_texel_size;
  }

  void shading_rate_texel_size(vk::extent_2d new_shading_rate_texel_size)
  {
    _shading_rate_texel_size = new_shading_rate_texel_size;
  }

  uint32_t& shading_rate_palette_size()
  {
    return _shading_rate_palette_size;
  }

  constexpr const uint32_t& shading_rate_palette_size() const
  {
    return _shading_rate_palette_size;
  }

  void shading_rate_palette_size(uint32_t new_shading_rate_palette_size)
  {
    _shading_rate_palette_size = new_shading_rate_palette_size;
  }

  uint32_t& shading_rate_max_coarse_samples()
  {
    return _shading_rate_max_coarse_samples;
  }

  constexpr const uint32_t& shading_rate_max_coarse_samples() const
  {
    return _shading_rate_max_coarse_samples;
  }

  void shading_rate_max_coarse_samples(
    uint32_t new_shading_rate_max_coarse_samples)
  {
    _shading_rate_max_coarse_samples = new_shading_rate_max_coarse_samples;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_shading_rate_image_properties_nv;
  void* _next = nullptr;
  vk::extent_2d _shading_rate_texel_size = vk::extent_2d{};
  uint32_t _shading_rate_palette_size = 0;
  uint32_t _shading_rate_max_coarse_samples = 0;
};
static_assert(sizeof(physical_device_shading_rate_image_properties_nv) ==
                sizeof(::VkPhysicalDeviceShadingRateImagePropertiesNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkCoarseSampleLocationNV.
class coarse_sample_location_nv
{
public:
  /// Default constructor.
  constexpr coarse_sample_location_nv() = default;

  /// Constructor.
  constexpr coarse_sample_location_nv(uint32_t initial_pixel_x,
                                      uint32_t initial_pixel_y,
                                      uint32_t initial_sample) noexcept
  : _pixel_x(std::move(initial_pixel_x)),
    _pixel_y(std::move(initial_pixel_y)),
    _sample(std::move(initial_sample))
  {
  }

  /// Copy constructor.
  constexpr coarse_sample_location_nv(const coarse_sample_location_nv& other) =
    default;

  /// Move constructor.
  constexpr coarse_sample_location_nv(coarse_sample_location_nv&& other) =
    default;

  /// Copy assignment operator.
  constexpr coarse_sample_location_nv& operator=(
    const coarse_sample_location_nv& other) = default;

  /// Move assignment operator.
  constexpr coarse_sample_location_nv& operator=(
    coarse_sample_location_nv&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkCoarseSampleLocationNV&() const
  {
    return *reinterpret_cast<const VkCoarseSampleLocationNV*>(this);
  }

  uint32_t& pixel_x()
  {
    return _pixel_x;
  }

  constexpr const uint32_t& pixel_x() const
  {
    return _pixel_x;
  }

  void pixel_x(uint32_t new_pixel_x)
  {
    _pixel_x = new_pixel_x;
  }

  uint32_t& pixel_y()
  {
    return _pixel_y;
  }

  constexpr const uint32_t& pixel_y() const
  {
    return _pixel_y;
  }

  void pixel_y(uint32_t new_pixel_y)
  {
    _pixel_y = new_pixel_y;
  }

  uint32_t& sample()
  {
    return _sample;
  }

  constexpr const uint32_t& sample() const
  {
    return _sample;
  }

  void sample(uint32_t new_sample)
  {
    _sample = new_sample;
  }

private:
  uint32_t _pixel_x = 0;
  uint32_t _pixel_y = 0;
  uint32_t _sample = 0;
};
static_assert(sizeof(coarse_sample_location_nv) ==
                sizeof(::VkCoarseSampleLocationNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkCoarseSampleOrderCustomNV.
class coarse_sample_order_custom_nv
{
public:
  /// Default constructor.
  constexpr coarse_sample_order_custom_nv() = default;

  /// Constructor.
  constexpr coarse_sample_order_custom_nv(
    vk::shading_rate_palette_entry_nv initial_shading_rate,
    uint32_t initial_sample_count, uint32_t initial_sample_location_count,
    const vk::coarse_sample_location_nv* initial_sample_locations) noexcept
  : _shading_rate(std::move(initial_shading_rate)),
    _sample_count(std::move(initial_sample_count)),
    _sample_location_count(std::move(initial_sample_location_count)),
    _sample_locations(std::move(initial_sample_locations))
  {
  }

  /// Copy constructor.
  constexpr coarse_sample_order_custom_nv(
    const coarse_sample_order_custom_nv& other) = default;

  /// Move constructor.
  constexpr coarse_sample_order_custom_nv(
    coarse_sample_order_custom_nv&& other) = default;

  /// Copy assignment operator.
  constexpr coarse_sample_order_custom_nv& operator=(
    const coarse_sample_order_custom_nv& other) = default;

  /// Move assignment operator.
  constexpr coarse_sample_order_custom_nv& operator=(
    coarse_sample_order_custom_nv&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkCoarseSampleOrderCustomNV&() const
  {
    return *reinterpret_cast<const VkCoarseSampleOrderCustomNV*>(this);
  }

  vk::shading_rate_palette_entry_nv& shading_rate()
  {
    return _shading_rate;
  }

  constexpr const vk::shading_rate_palette_entry_nv& shading_rate() const
  {
    return _shading_rate;
  }

  void shading_rate(vk::shading_rate_palette_entry_nv new_shading_rate)
  {
    _shading_rate = new_shading_rate;
  }

  uint32_t& sample_count()
  {
    return _sample_count;
  }

  constexpr const uint32_t& sample_count() const
  {
    return _sample_count;
  }

  void sample_count(uint32_t new_sample_count)
  {
    _sample_count = new_sample_count;
  }

  uint32_t& sample_location_count()
  {
    return _sample_location_count;
  }

  constexpr const uint32_t& sample_location_count() const
  {
    return _sample_location_count;
  }

  void sample_location_count(uint32_t new_sample_location_count)
  {
    _sample_location_count = new_sample_location_count;
  }

  const vk::coarse_sample_location_nv* sample_locations()
  {
    return _sample_locations;
  }

  constexpr const vk::coarse_sample_location_nv* sample_locations() const
  {
    return _sample_locations;
  }

  void sample_locations(
    const vk::coarse_sample_location_nv* new_sample_locations)
  {
    _sample_locations = new_sample_locations;
  }

  template <std::size_t Count>
  void sample_locations(const std::array<vk::coarse_sample_location_nv, Count>&
                          new_sample_locations)
  {
    _sample_location_count = static_cast<uint32_t>(new_sample_locations.size());
    _sample_locations = new_sample_locations.data();
  }

  void sample_locations(
    const std::vector<vk::coarse_sample_location_nv>& new_sample_locations)
  {
    _sample_location_count = static_cast<uint32_t>(new_sample_locations.size());
    _sample_locations = new_sample_locations.data();
  }

private:
  vk::shading_rate_palette_entry_nv _shading_rate = vk::
    shading_rate_palette_entry_nv::shading_rate_palette_entry_no_invocations_nv;
  uint32_t _sample_count = 0;
  uint32_t _sample_location_count = 0;
  const vk::coarse_sample_location_nv* _sample_locations = nullptr;
};
static_assert(sizeof(coarse_sample_order_custom_nv) ==
                sizeof(::VkCoarseSampleOrderCustomNV),
              "struct and wrapper have different size!");

enum class coarse_sample_order_type_nv
{
  /// @see VK_COARSE_SAMPLE_ORDER_TYPE_DEFAULT_NV
  coarse_sample_order_type_default_nv = 0,
  /// @see VK_COARSE_SAMPLE_ORDER_TYPE_CUSTOM_NV
  coarse_sample_order_type_custom_nv = 1,
  /// @see VK_COARSE_SAMPLE_ORDER_TYPE_PIXEL_MAJOR_NV
  coarse_sample_order_type_pixel_major_nv = 2,
  /// @see VK_COARSE_SAMPLE_ORDER_TYPE_SAMPLE_MAJOR_NV
  coarse_sample_order_type_sample_major_nv = 3,
};

/// Enhanced replacement type for
/// VkPipelineViewportCoarseSampleOrderStateCreateInfoNV.
class pipeline_viewport_coarse_sample_order_state_create_info_nv
{
public:
  /// Default constructor.
  constexpr pipeline_viewport_coarse_sample_order_state_create_info_nv() =
    default;

  /// Constructor.
  constexpr pipeline_viewport_coarse_sample_order_state_create_info_nv(
    const void* initial_next,
    vk::coarse_sample_order_type_nv initial_sample_order_type,
    uint32_t initial_custom_sample_order_count,
    const vk::coarse_sample_order_custom_nv*
      initial_custom_sample_orders) noexcept
  : _next(std::move(initial_next)),
    _sample_order_type(std::move(initial_sample_order_type)),
    _custom_sample_order_count(std::move(initial_custom_sample_order_count)),
    _custom_sample_orders(std::move(initial_custom_sample_orders))
  {
  }

  /// Copy constructor.
  constexpr pipeline_viewport_coarse_sample_order_state_create_info_nv(
    const pipeline_viewport_coarse_sample_order_state_create_info_nv&
      other) noexcept
  : _next(other._next),
    _sample_order_type(other._sample_order_type),
    _custom_sample_order_count(other._custom_sample_order_count),
    _custom_sample_orders(other._custom_sample_orders)
  {
  }

  /// Move constructor.
  constexpr pipeline_viewport_coarse_sample_order_state_create_info_nv(
    pipeline_viewport_coarse_sample_order_state_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _sample_order_type(std::move(other._sample_order_type)),
    _custom_sample_order_count(std::move(other._custom_sample_order_count)),
    _custom_sample_orders(std::move(other._custom_sample_orders))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_viewport_coarse_sample_order_state_create_info_nv&
  operator=(const pipeline_viewport_coarse_sample_order_state_create_info_nv&
              other) noexcept
  {
    _next = other._next;
    _sample_order_type = other._sample_order_type;
    _custom_sample_order_count = other._custom_sample_order_count;
    _custom_sample_orders = other._custom_sample_orders;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_viewport_coarse_sample_order_state_create_info_nv&
  operator=(
    pipeline_viewport_coarse_sample_order_state_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _sample_order_type = std::move(other._sample_order_type);
    _custom_sample_order_count = std::move(other._custom_sample_order_count);
    _custom_sample_orders = std::move(other._custom_sample_orders);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineViewportCoarseSampleOrderStateCreateInfoNV&() const
  {
    return *reinterpret_cast<
      const VkPipelineViewportCoarseSampleOrderStateCreateInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::coarse_sample_order_type_nv& sample_order_type()
  {
    return _sample_order_type;
  }

  constexpr const vk::coarse_sample_order_type_nv& sample_order_type() const
  {
    return _sample_order_type;
  }

  void sample_order_type(vk::coarse_sample_order_type_nv new_sample_order_type)
  {
    _sample_order_type = new_sample_order_type;
  }

  uint32_t& custom_sample_order_count()
  {
    return _custom_sample_order_count;
  }

  constexpr const uint32_t& custom_sample_order_count() const
  {
    return _custom_sample_order_count;
  }

  void custom_sample_order_count(uint32_t new_custom_sample_order_count)
  {
    _custom_sample_order_count = new_custom_sample_order_count;
  }

  const vk::coarse_sample_order_custom_nv* custom_sample_orders()
  {
    return _custom_sample_orders;
  }

  constexpr const vk::coarse_sample_order_custom_nv* custom_sample_orders()
    const
  {
    return _custom_sample_orders;
  }

  void custom_sample_orders(
    const vk::coarse_sample_order_custom_nv* new_custom_sample_orders)
  {
    _custom_sample_orders = new_custom_sample_orders;
  }

  template <std::size_t Count>
  void custom_sample_orders(const std::array<vk::coarse_sample_order_custom_nv,
                                             Count>& new_custom_sample_orders)
  {
    _custom_sample_order_count =
      static_cast<uint32_t>(new_custom_sample_orders.size());
    _custom_sample_orders = new_custom_sample_orders.data();
  }

  void custom_sample_orders(
    const std::vector<vk::coarse_sample_order_custom_nv>&
      new_custom_sample_orders)
  {
    _custom_sample_order_count =
      static_cast<uint32_t>(new_custom_sample_orders.size());
    _custom_sample_orders = new_custom_sample_orders.data();
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    pipeline_viewport_coarse_sample_order_state_create_info_nv;
  const void* _next = nullptr;
  vk::coarse_sample_order_type_nv _sample_order_type =
    vk::coarse_sample_order_type_nv::coarse_sample_order_type_default_nv;
  uint32_t _custom_sample_order_count = 0;
  const vk::coarse_sample_order_custom_nv* _custom_sample_orders = nullptr;
};
static_assert(
  sizeof(pipeline_viewport_coarse_sample_order_state_create_info_nv) ==
    sizeof(::VkPipelineViewportCoarseSampleOrderStateCreateInfoNV),
  "struct and wrapper have different size!");

inline void cmd_bind_shading_rate_image_nv(VkCommandBuffer command_buffer,
                                           VkImageView image_view,
                                           vk::image_layout image_layout)
{
  vkCmdBindShadingRateImageNV(static_cast<VkCommandBuffer>(command_buffer),
                              static_cast<VkImageView>(image_view),
                              static_cast<VkImageLayout>(image_layout));
}
inline void cmd_set_viewport_shading_rate_palette_nv(
  VkCommandBuffer command_buffer, uint32_t first_viewport,
  uint32_t viewport_count,
  const vk::shading_rate_palette_nv* shading_rate_palettes)
{
  vkCmdSetViewportShadingRatePaletteNV(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<uint32_t>(first_viewport),
    static_cast<uint32_t>(viewport_count),
    reinterpret_cast<const VkShadingRatePaletteNV*>(shading_rate_palettes));
}
inline void cmd_set_coarse_sample_order_nv(
  VkCommandBuffer command_buffer,
  vk::coarse_sample_order_type_nv sample_order_type,
  uint32_t custom_sample_order_count,
  const vk::coarse_sample_order_custom_nv* custom_sample_orders)
{
  vkCmdSetCoarseSampleOrderNV(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<VkCoarseSampleOrderTypeNV>(sample_order_type),
    static_cast<uint32_t>(custom_sample_order_count),
    reinterpret_cast<const VkCoarseSampleOrderCustomNV*>(custom_sample_orders));
}

/// Enhanced replacement type for VkRaytracingPipelineCreateInfoNVX.
class raytracing_pipeline_create_info_nvx
{
public:
  /// Default constructor.
  constexpr raytracing_pipeline_create_info_nvx() = default;

  /// Constructor.
  constexpr raytracing_pipeline_create_info_nvx(
    const void* initial_next, vk::pipeline_create_flags initial_flags,
    uint32_t initial_stage_count,
    const vk::pipeline_shader_stage_create_info* initial_stages,
    const uint32_t* initial_group_numbers, uint32_t initial_max_recursion_depth,
    VkPipelineLayout initial_layout, VkPipeline initial_base_pipeline_handle,
    int32_t initial_base_pipeline_index) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _stage_count(std::move(initial_stage_count)),
    _stages(std::move(initial_stages)),
    _group_numbers(std::move(initial_group_numbers)),
    _max_recursion_depth(std::move(initial_max_recursion_depth)),
    _layout(std::move(initial_layout)),
    _base_pipeline_handle(std::move(initial_base_pipeline_handle)),
    _base_pipeline_index(std::move(initial_base_pipeline_index))
  {
  }

  /// Copy constructor.
  constexpr raytracing_pipeline_create_info_nvx(
    const raytracing_pipeline_create_info_nvx& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _stage_count(other._stage_count),
    _stages(other._stages),
    _group_numbers(other._group_numbers),
    _max_recursion_depth(other._max_recursion_depth),
    _layout(other._layout),
    _base_pipeline_handle(other._base_pipeline_handle),
    _base_pipeline_index(other._base_pipeline_index)
  {
  }

  /// Move constructor.
  constexpr raytracing_pipeline_create_info_nvx(
    raytracing_pipeline_create_info_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _stage_count(std::move(other._stage_count)),
    _stages(std::move(other._stages)),
    _group_numbers(std::move(other._group_numbers)),
    _max_recursion_depth(std::move(other._max_recursion_depth)),
    _layout(std::move(other._layout)),
    _base_pipeline_handle(std::move(other._base_pipeline_handle)),
    _base_pipeline_index(std::move(other._base_pipeline_index))
  {
  }

  /// Copy assignment operator.
  constexpr raytracing_pipeline_create_info_nvx& operator=(
    const raytracing_pipeline_create_info_nvx& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _stage_count = other._stage_count;
    _stages = other._stages;
    _group_numbers = other._group_numbers;
    _max_recursion_depth = other._max_recursion_depth;
    _layout = other._layout;
    _base_pipeline_handle = other._base_pipeline_handle;
    _base_pipeline_index = other._base_pipeline_index;
    return *this;
  }

  /// Move assignment operator.
  constexpr raytracing_pipeline_create_info_nvx& operator=(
    raytracing_pipeline_create_info_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _stage_count = std::move(other._stage_count);
    _stages = std::move(other._stages);
    _group_numbers = std::move(other._group_numbers);
    _max_recursion_depth = std::move(other._max_recursion_depth);
    _layout = std::move(other._layout);
    _base_pipeline_handle = std::move(other._base_pipeline_handle);
    _base_pipeline_index = std::move(other._base_pipeline_index);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkRaytracingPipelineCreateInfoNVX&() const
  {
    return *reinterpret_cast<const VkRaytracingPipelineCreateInfoNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_create_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::pipeline_create_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::pipeline_create_flags new_flags)
  {
    _flags = new_flags;
  }

  uint32_t& stage_count()
  {
    return _stage_count;
  }

  constexpr const uint32_t& stage_count() const
  {
    return _stage_count;
  }

  void stage_count(uint32_t new_stage_count)
  {
    _stage_count = new_stage_count;
  }

  const vk::pipeline_shader_stage_create_info* stages()
  {
    return _stages;
  }

  constexpr const vk::pipeline_shader_stage_create_info* stages() const
  {
    return _stages;
  }

  void stages(const vk::pipeline_shader_stage_create_info* new_stages)
  {
    _stages = new_stages;
  }

  template <std::size_t Count>
  void stages(
    const std::array<vk::pipeline_shader_stage_create_info, Count>& new_stages)
  {
    _stage_count = static_cast<uint32_t>(new_stages.size());
    _stages = new_stages.data();
  }

  void stages(
    const std::vector<vk::pipeline_shader_stage_create_info>& new_stages)
  {
    _stage_count = static_cast<uint32_t>(new_stages.size());
    _stages = new_stages.data();
  }

  const uint32_t* group_numbers()
  {
    return _group_numbers;
  }

  constexpr const uint32_t* group_numbers() const
  {
    return _group_numbers;
  }

  void group_numbers(const uint32_t* new_group_numbers)
  {
    _group_numbers = new_group_numbers;
  }

  template <std::size_t Count>
  void group_numbers(const std::array<uint32_t, Count>& new_group_numbers)
  {
    _stage_count = static_cast<uint32_t>(new_group_numbers.size());
    _group_numbers = new_group_numbers.data();
  }

  void group_numbers(const std::vector<uint32_t>& new_group_numbers)
  {
    _stage_count = static_cast<uint32_t>(new_group_numbers.size());
    _group_numbers = new_group_numbers.data();
  }

  uint32_t& max_recursion_depth()
  {
    return _max_recursion_depth;
  }

  constexpr const uint32_t& max_recursion_depth() const
  {
    return _max_recursion_depth;
  }

  void max_recursion_depth(uint32_t new_max_recursion_depth)
  {
    _max_recursion_depth = new_max_recursion_depth;
  }

  VkPipelineLayout& layout()
  {
    return _layout;
  }

  constexpr const VkPipelineLayout& layout() const
  {
    return _layout;
  }

  void layout(VkPipelineLayout new_layout)
  {
    _layout = new_layout;
  }

  VkPipeline& base_pipeline_handle()
  {
    return _base_pipeline_handle;
  }

  constexpr const VkPipeline& base_pipeline_handle() const
  {
    return _base_pipeline_handle;
  }

  void base_pipeline_handle(VkPipeline new_base_pipeline_handle)
  {
    _base_pipeline_handle = new_base_pipeline_handle;
  }

  int32_t& base_pipeline_index()
  {
    return _base_pipeline_index;
  }

  constexpr const int32_t& base_pipeline_index() const
  {
    return _base_pipeline_index;
  }

  void base_pipeline_index(int32_t new_base_pipeline_index)
  {
    _base_pipeline_index = new_base_pipeline_index;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::raytracing_pipeline_create_info_nvx;
  const void* _next = nullptr;
  /// Pipeline creation flags
  vk::pipeline_create_flags _flags = vk::pipeline_create_flag::none;
  uint32_t _stage_count = 0;
  /// One entry for each active shader stage
  const vk::pipeline_shader_stage_create_info* _stages = nullptr;
  /// One entry for each stage used as the query index and for grouping
  const uint32_t* _group_numbers = nullptr;
  uint32_t _max_recursion_depth = 0;
  /// Interface layout of the pipeline
  VkPipelineLayout _layout = nullptr;
  /// If VK_PIPELINE_CREATE_DERIVATIVE_BIT is set and this value is nonzero, it
  /// specifies the handle of the base pipeline this is a derivative of
  VkPipeline _base_pipeline_handle = nullptr;
  /// If VK_PIPELINE_CREATE_DERIVATIVE_BIT is set and this value is not -1, it
  /// specifies an index into pCreateInfos of the base pipeline this is a
  /// derivative of
  int32_t _base_pipeline_index = 0;
};
static_assert(sizeof(raytracing_pipeline_create_info_nvx) ==
                sizeof(::VkRaytracingPipelineCreateInfoNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkGeometryTrianglesNVX.
class geometry_triangles_nvx
{
public:
  /// Default constructor.
  constexpr geometry_triangles_nvx() = default;

  /// Constructor.
  constexpr geometry_triangles_nvx(
    const void* initial_next, VkBuffer initial_vertex_data,
    VkDeviceSize initial_vertex_offset, uint32_t initial_vertex_count,
    VkDeviceSize initial_vertex_stride, vk::format initial_vertex_format,
    VkBuffer initial_index_data, VkDeviceSize initial_index_offset,
    uint32_t initial_index_count, vk::index_type initial_index_type,
    VkBuffer initial_transform_data,
    VkDeviceSize initial_transform_offset) noexcept
  : _next(std::move(initial_next)),
    _vertex_data(std::move(initial_vertex_data)),
    _vertex_offset(std::move(initial_vertex_offset)),
    _vertex_count(std::move(initial_vertex_count)),
    _vertex_stride(std::move(initial_vertex_stride)),
    _vertex_format(std::move(initial_vertex_format)),
    _index_data(std::move(initial_index_data)),
    _index_offset(std::move(initial_index_offset)),
    _index_count(std::move(initial_index_count)),
    _index_type(std::move(initial_index_type)),
    _transform_data(std::move(initial_transform_data)),
    _transform_offset(std::move(initial_transform_offset))
  {
  }

  /// Copy constructor.
  constexpr geometry_triangles_nvx(const geometry_triangles_nvx& other) noexcept
  : _next(other._next),
    _vertex_data(other._vertex_data),
    _vertex_offset(other._vertex_offset),
    _vertex_count(other._vertex_count),
    _vertex_stride(other._vertex_stride),
    _vertex_format(other._vertex_format),
    _index_data(other._index_data),
    _index_offset(other._index_offset),
    _index_count(other._index_count),
    _index_type(other._index_type),
    _transform_data(other._transform_data),
    _transform_offset(other._transform_offset)
  {
  }

  /// Move constructor.
  constexpr geometry_triangles_nvx(geometry_triangles_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _vertex_data(std::move(other._vertex_data)),
    _vertex_offset(std::move(other._vertex_offset)),
    _vertex_count(std::move(other._vertex_count)),
    _vertex_stride(std::move(other._vertex_stride)),
    _vertex_format(std::move(other._vertex_format)),
    _index_data(std::move(other._index_data)),
    _index_offset(std::move(other._index_offset)),
    _index_count(std::move(other._index_count)),
    _index_type(std::move(other._index_type)),
    _transform_data(std::move(other._transform_data)),
    _transform_offset(std::move(other._transform_offset))
  {
  }

  /// Copy assignment operator.
  constexpr geometry_triangles_nvx& operator=(
    const geometry_triangles_nvx& other) noexcept
  {
    _next = other._next;
    _vertex_data = other._vertex_data;
    _vertex_offset = other._vertex_offset;
    _vertex_count = other._vertex_count;
    _vertex_stride = other._vertex_stride;
    _vertex_format = other._vertex_format;
    _index_data = other._index_data;
    _index_offset = other._index_offset;
    _index_count = other._index_count;
    _index_type = other._index_type;
    _transform_data = other._transform_data;
    _transform_offset = other._transform_offset;
    return *this;
  }

  /// Move assignment operator.
  constexpr geometry_triangles_nvx& operator=(
    geometry_triangles_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _vertex_data = std::move(other._vertex_data);
    _vertex_offset = std::move(other._vertex_offset);
    _vertex_count = std::move(other._vertex_count);
    _vertex_stride = std::move(other._vertex_stride);
    _vertex_format = std::move(other._vertex_format);
    _index_data = std::move(other._index_data);
    _index_offset = std::move(other._index_offset);
    _index_count = std::move(other._index_count);
    _index_type = std::move(other._index_type);
    _transform_data = std::move(other._transform_data);
    _transform_offset = std::move(other._transform_offset);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkGeometryTrianglesNVX&() const
  {
    return *reinterpret_cast<const VkGeometryTrianglesNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBuffer& vertex_data()
  {
    return _vertex_data;
  }

  constexpr const VkBuffer& vertex_data() const
  {
    return _vertex_data;
  }

  void vertex_data(VkBuffer new_vertex_data)
  {
    _vertex_data = new_vertex_data;
  }

  VkDeviceSize& vertex_offset()
  {
    return _vertex_offset;
  }

  constexpr const VkDeviceSize& vertex_offset() const
  {
    return _vertex_offset;
  }

  void vertex_offset(VkDeviceSize new_vertex_offset)
  {
    _vertex_offset = new_vertex_offset;
  }

  uint32_t& vertex_count()
  {
    return _vertex_count;
  }

  constexpr const uint32_t& vertex_count() const
  {
    return _vertex_count;
  }

  void vertex_count(uint32_t new_vertex_count)
  {
    _vertex_count = new_vertex_count;
  }

  VkDeviceSize& vertex_stride()
  {
    return _vertex_stride;
  }

  constexpr const VkDeviceSize& vertex_stride() const
  {
    return _vertex_stride;
  }

  void vertex_stride(VkDeviceSize new_vertex_stride)
  {
    _vertex_stride = new_vertex_stride;
  }

  vk::format& vertex_format()
  {
    return _vertex_format;
  }

  constexpr const vk::format& vertex_format() const
  {
    return _vertex_format;
  }

  void vertex_format(vk::format new_vertex_format)
  {
    _vertex_format = new_vertex_format;
  }

  VkBuffer& index_data()
  {
    return _index_data;
  }

  constexpr const VkBuffer& index_data() const
  {
    return _index_data;
  }

  void index_data(VkBuffer new_index_data)
  {
    _index_data = new_index_data;
  }

  VkDeviceSize& index_offset()
  {
    return _index_offset;
  }

  constexpr const VkDeviceSize& index_offset() const
  {
    return _index_offset;
  }

  void index_offset(VkDeviceSize new_index_offset)
  {
    _index_offset = new_index_offset;
  }

  uint32_t& index_count()
  {
    return _index_count;
  }

  constexpr const uint32_t& index_count() const
  {
    return _index_count;
  }

  void index_count(uint32_t new_index_count)
  {
    _index_count = new_index_count;
  }

  vk::index_type& index_type()
  {
    return _index_type;
  }

  constexpr const vk::index_type& index_type() const
  {
    return _index_type;
  }

  void index_type(vk::index_type new_index_type)
  {
    _index_type = new_index_type;
  }

  VkBuffer& transform_data()
  {
    return _transform_data;
  }

  constexpr const VkBuffer& transform_data() const
  {
    return _transform_data;
  }

  void transform_data(VkBuffer new_transform_data)
  {
    _transform_data = new_transform_data;
  }

  VkDeviceSize& transform_offset()
  {
    return _transform_offset;
  }

  constexpr const VkDeviceSize& transform_offset() const
  {
    return _transform_offset;
  }

  void transform_offset(VkDeviceSize new_transform_offset)
  {
    _transform_offset = new_transform_offset;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::geometry_triangles_nvx;
  const void* _next = nullptr;
  VkBuffer _vertex_data = nullptr;
  VkDeviceSize _vertex_offset = 0;
  uint32_t _vertex_count = 0;
  VkDeviceSize _vertex_stride = 0;
  /// VK_FORMAT_R32G32B32_SFLOAT, VK_FORMAT_R32G32B32A32_SFLOAT,
  /// VK_FORMAT_R16G16B16_SFLOAT, or VK_FORMAT_R16G16B16A16_SFLOAT
  vk::format _vertex_format = vk::format::undefined;
  VkBuffer _index_data = nullptr;
  VkDeviceSize _index_offset = 0;
  uint32_t _index_count = 0;
  vk::index_type _index_type = vk::index_type::uint16;
  /// Optional reference to array of floats representing a 3x4 row major affine
  /// transformation matrix.
  VkBuffer _transform_data = nullptr;
  VkDeviceSize _transform_offset = 0;
};
static_assert(sizeof(geometry_triangles_nvx) ==
                sizeof(::VkGeometryTrianglesNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkGeometryAABBNVX.
class geometry_aabbnvx
{
public:
  /// Default constructor.
  constexpr geometry_aabbnvx() = default;

  /// Constructor.
  constexpr geometry_aabbnvx(const void* initial_next,
                             VkBuffer initial_aabb_data,
                             uint32_t initial_num_aabbs,
                             uint32_t initial_stride,
                             VkDeviceSize initial_offset) noexcept
  : _next(std::move(initial_next)),
    _aabb_data(std::move(initial_aabb_data)),
    _num_aabbs(std::move(initial_num_aabbs)),
    _stride(std::move(initial_stride)),
    _offset(std::move(initial_offset))
  {
  }

  /// Copy constructor.
  constexpr geometry_aabbnvx(const geometry_aabbnvx& other) noexcept
  : _next(other._next),
    _aabb_data(other._aabb_data),
    _num_aabbs(other._num_aabbs),
    _stride(other._stride),
    _offset(other._offset)
  {
  }

  /// Move constructor.
  constexpr geometry_aabbnvx(geometry_aabbnvx&& other) noexcept
  : _next(std::move(other._next)),
    _aabb_data(std::move(other._aabb_data)),
    _num_aabbs(std::move(other._num_aabbs)),
    _stride(std::move(other._stride)),
    _offset(std::move(other._offset))
  {
  }

  /// Copy assignment operator.
  constexpr geometry_aabbnvx& operator=(const geometry_aabbnvx& other) noexcept
  {
    _next = other._next;
    _aabb_data = other._aabb_data;
    _num_aabbs = other._num_aabbs;
    _stride = other._stride;
    _offset = other._offset;
    return *this;
  }

  /// Move assignment operator.
  constexpr geometry_aabbnvx& operator=(geometry_aabbnvx&& other) noexcept
  {
    _next = std::move(other._next);
    _aabb_data = std::move(other._aabb_data);
    _num_aabbs = std::move(other._num_aabbs);
    _stride = std::move(other._stride);
    _offset = std::move(other._offset);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkGeometryAABBNVX&() const
  {
    return *reinterpret_cast<const VkGeometryAABBNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBuffer& aabb_data()
  {
    return _aabb_data;
  }

  constexpr const VkBuffer& aabb_data() const
  {
    return _aabb_data;
  }

  void aabb_data(VkBuffer new_aabb_data)
  {
    _aabb_data = new_aabb_data;
  }

  uint32_t& num_aabbs()
  {
    return _num_aabbs;
  }

  constexpr const uint32_t& num_aabbs() const
  {
    return _num_aabbs;
  }

  void num_aabbs(uint32_t new_num_aabbs)
  {
    _num_aabbs = new_num_aabbs;
  }

  uint32_t& stride()
  {
    return _stride;
  }

  constexpr const uint32_t& stride() const
  {
    return _stride;
  }

  void stride(uint32_t new_stride)
  {
    _stride = new_stride;
  }

  VkDeviceSize& offset()
  {
    return _offset;
  }

  constexpr const VkDeviceSize& offset() const
  {
    return _offset;
  }

  void offset(VkDeviceSize new_offset)
  {
    _offset = new_offset;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::geometry_aabb_nvx;
  const void* _next = nullptr;
  VkBuffer _aabb_data = nullptr;
  uint32_t _num_aabbs = 0;
  /// Stride in bytes between AABBs
  uint32_t _stride = 0;
  /// Offset in bytes of the first AABB in aabbData
  VkDeviceSize _offset = 0;
};
static_assert(sizeof(geometry_aabbnvx) == sizeof(::VkGeometryAABBNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkGeometryDataNVX.
class geometry_data_nvx
{
public:
  /// Default constructor.
  constexpr geometry_data_nvx() = default;

  /// Constructor.
  constexpr geometry_data_nvx(vk::geometry_triangles_nvx initial_triangles,
                              vk::geometry_aabbnvx initial_aabbs) noexcept
  : _triangles(std::move(initial_triangles)), _aabbs(std::move(initial_aabbs))
  {
  }

  /// Copy constructor.
  constexpr geometry_data_nvx(const geometry_data_nvx& other) = default;

  /// Move constructor.
  constexpr geometry_data_nvx(geometry_data_nvx&& other) = default;

  /// Copy assignment operator.
  constexpr geometry_data_nvx& operator=(const geometry_data_nvx& other) =
    default;

  /// Move assignment operator.
  constexpr geometry_data_nvx& operator=(geometry_data_nvx&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkGeometryDataNVX&() const
  {
    return *reinterpret_cast<const VkGeometryDataNVX*>(this);
  }

  vk::geometry_triangles_nvx& triangles()
  {
    return _triangles;
  }

  constexpr const vk::geometry_triangles_nvx& triangles() const
  {
    return _triangles;
  }

  void triangles(vk::geometry_triangles_nvx new_triangles)
  {
    _triangles = new_triangles;
  }

  vk::geometry_aabbnvx& aabbs()
  {
    return _aabbs;
  }

  constexpr const vk::geometry_aabbnvx& aabbs() const
  {
    return _aabbs;
  }

  void aabbs(vk::geometry_aabbnvx new_aabbs)
  {
    _aabbs = new_aabbs;
  }

private:
  vk::geometry_triangles_nvx _triangles = vk::geometry_triangles_nvx{};
  vk::geometry_aabbnvx _aabbs = vk::geometry_aabbnvx{};
};
static_assert(sizeof(geometry_data_nvx) == sizeof(::VkGeometryDataNVX),
              "struct and wrapper have different size!");

enum class geometry_type_nvx
{
  /// @see VK_GEOMETRY_TYPE_TRIANGLES_NVX
  geometry_type_triangles_nvx = 0,
  /// @see VK_GEOMETRY_TYPE_AABBS_NVX
  geometry_type_aabbs_nvx = 1,
};
enum class geometry_flag_nvx
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_GEOMETRY_OPAQUE_BIT_NVX
  opaque_bit_nvx = 1 << 0,
  /// @see VK_GEOMETRY_NO_DUPLICATE_ANY_HIT_INVOCATION_BIT_NVX
  no_duplicate_any_hit_invocation_bit_nvx = 1 << 1,
};
using geometry_flags_nvx =
  shift::core::bit_field<geometry_flag_nvx, VkGeometryFlagsNVX>;
inline constexpr geometry_flags_nvx operator|(geometry_flag_nvx lhs,
                                              geometry_flag_nvx rhs)
{
  return geometry_flags_nvx{lhs} | rhs;
}
/// Enhanced replacement type for VkGeometryNVX.
class geometry_nvx
{
public:
  /// Default constructor.
  constexpr geometry_nvx() = default;

  /// Constructor.
  constexpr geometry_nvx(const void* initial_next,
                         vk::geometry_type_nvx initial_geometry_type,
                         vk::geometry_data_nvx initial_geometry,
                         vk::geometry_flags_nvx initial_flags) noexcept
  : _next(std::move(initial_next)),
    _geometry_type(std::move(initial_geometry_type)),
    _geometry(std::move(initial_geometry)),
    _flags(std::move(initial_flags))
  {
  }

  /// Copy constructor.
  constexpr geometry_nvx(const geometry_nvx& other) noexcept
  : _next(other._next),
    _geometry_type(other._geometry_type),
    _geometry(other._geometry),
    _flags(other._flags)
  {
  }

  /// Move constructor.
  constexpr geometry_nvx(geometry_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _geometry_type(std::move(other._geometry_type)),
    _geometry(std::move(other._geometry)),
    _flags(std::move(other._flags))
  {
  }

  /// Copy assignment operator.
  constexpr geometry_nvx& operator=(const geometry_nvx& other) noexcept
  {
    _next = other._next;
    _geometry_type = other._geometry_type;
    _geometry = other._geometry;
    _flags = other._flags;
    return *this;
  }

  /// Move assignment operator.
  constexpr geometry_nvx& operator=(geometry_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _geometry_type = std::move(other._geometry_type);
    _geometry = std::move(other._geometry);
    _flags = std::move(other._flags);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkGeometryNVX&() const
  {
    return *reinterpret_cast<const VkGeometryNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::geometry_type_nvx& geometry_type()
  {
    return _geometry_type;
  }

  constexpr const vk::geometry_type_nvx& geometry_type() const
  {
    return _geometry_type;
  }

  void geometry_type(vk::geometry_type_nvx new_geometry_type)
  {
    _geometry_type = new_geometry_type;
  }

  vk::geometry_data_nvx& geometry()
  {
    return _geometry;
  }

  constexpr const vk::geometry_data_nvx& geometry() const
  {
    return _geometry;
  }

  void geometry(vk::geometry_data_nvx new_geometry)
  {
    _geometry = new_geometry;
  }

  vk::geometry_flags_nvx& flags()
  {
    return _flags;
  }

  constexpr const vk::geometry_flags_nvx& flags() const
  {
    return _flags;
  }

  void flags(vk::geometry_flags_nvx new_flags)
  {
    _flags = new_flags;
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::geometry_nvx;
  const void* _next = nullptr;
  vk::geometry_type_nvx _geometry_type =
    vk::geometry_type_nvx::geometry_type_triangles_nvx;
  vk::geometry_data_nvx _geometry = vk::geometry_data_nvx{};
  vk::geometry_flags_nvx _flags = vk::geometry_flag_nvx::none;
};
static_assert(sizeof(geometry_nvx) == sizeof(::VkGeometryNVX),
              "struct and wrapper have different size!");

enum class geometry_instance_flag_nvx
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_GEOMETRY_INSTANCE_TRIANGLE_CULL_DISABLE_BIT_NVX
  triangle_cull_disable_bit_nvx = 1 << 0,
  /// @see VK_GEOMETRY_INSTANCE_TRIANGLE_CULL_FLIP_WINDING_BIT_NVX
  triangle_cull_flip_winding_bit_nvx = 1 << 1,
  /// @see VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_NVX
  force_opaque_bit_nvx = 1 << 2,
  /// @see VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_NVX
  force_no_opaque_bit_nvx = 1 << 3,
};
using geometry_instance_flags_nvx =
  shift::core::bit_field<geometry_instance_flag_nvx,
                         VkGeometryInstanceFlagsNVX>;
inline constexpr geometry_instance_flags_nvx operator|(
  geometry_instance_flag_nvx lhs, geometry_instance_flag_nvx rhs)
{
  return geometry_instance_flags_nvx{lhs} | rhs;
}
enum class acceleration_structure_type_nvx
{
  /// @see VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_NVX
  acceleration_structure_type_top_level_nvx = 0,
  /// @see VK_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL_NVX
  acceleration_structure_type_bottom_level_nvx = 1,
};
enum class build_acceleration_structure_flag_nvx
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_UPDATE_BIT_NVX
  allow_update_bit_nvx = 1 << 0,
  /// @see VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_COMPACTION_BIT_NVX
  allow_compaction_bit_nvx = 1 << 1,
  /// @see VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_TRACE_BIT_NVX
  prefer_fast_trace_bit_nvx = 1 << 2,
  /// @see VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_BUILD_BIT_NVX
  prefer_fast_build_bit_nvx = 1 << 3,
  /// @see VK_BUILD_ACCELERATION_STRUCTURE_LOW_MEMORY_BIT_NVX
  low_memory_bit_nvx = 1 << 4,
};
using build_acceleration_structure_flags_nvx =
  shift::core::bit_field<build_acceleration_structure_flag_nvx,
                         VkBuildAccelerationStructureFlagsNVX>;
inline constexpr build_acceleration_structure_flags_nvx operator|(
  build_acceleration_structure_flag_nvx lhs,
  build_acceleration_structure_flag_nvx rhs)
{
  return build_acceleration_structure_flags_nvx{lhs} | rhs;
}
/// Enhanced replacement type for VkAccelerationStructureCreateInfoNVX.
class acceleration_structure_create_info_nvx
{
public:
  /// Default constructor.
  constexpr acceleration_structure_create_info_nvx() = default;

  /// Constructor.
  constexpr acceleration_structure_create_info_nvx(
    const void* initial_next, vk::acceleration_structure_type_nvx initial_type,
    vk::build_acceleration_structure_flags_nvx initial_flags,
    VkDeviceSize initial_compacted_size, uint32_t initial_instance_count,
    uint32_t initial_geometry_count,
    const vk::geometry_nvx* initial_geometries) noexcept
  : _next(std::move(initial_next)),
    _type(std::move(initial_type)),
    _flags(std::move(initial_flags)),
    _compacted_size(std::move(initial_compacted_size)),
    _instance_count(std::move(initial_instance_count)),
    _geometry_count(std::move(initial_geometry_count)),
    _geometries(std::move(initial_geometries))
  {
  }

  /// Copy constructor.
  constexpr acceleration_structure_create_info_nvx(
    const acceleration_structure_create_info_nvx& other) noexcept
  : _next(other._next),
    _type(other._type),
    _flags(other._flags),
    _compacted_size(other._compacted_size),
    _instance_count(other._instance_count),
    _geometry_count(other._geometry_count),
    _geometries(other._geometries)
  {
  }

  /// Move constructor.
  constexpr acceleration_structure_create_info_nvx(
    acceleration_structure_create_info_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _type(std::move(other._type)),
    _flags(std::move(other._flags)),
    _compacted_size(std::move(other._compacted_size)),
    _instance_count(std::move(other._instance_count)),
    _geometry_count(std::move(other._geometry_count)),
    _geometries(std::move(other._geometries))
  {
  }

  /// Copy assignment operator.
  constexpr acceleration_structure_create_info_nvx& operator=(
    const acceleration_structure_create_info_nvx& other) noexcept
  {
    _next = other._next;
    _type = other._type;
    _flags = other._flags;
    _compacted_size = other._compacted_size;
    _instance_count = other._instance_count;
    _geometry_count = other._geometry_count;
    _geometries = other._geometries;
    return *this;
  }

  /// Move assignment operator.
  constexpr acceleration_structure_create_info_nvx& operator=(
    acceleration_structure_create_info_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _type = std::move(other._type);
    _flags = std::move(other._flags);
    _compacted_size = std::move(other._compacted_size);
    _instance_count = std::move(other._instance_count);
    _geometry_count = std::move(other._geometry_count);
    _geometries = std::move(other._geometries);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkAccelerationStructureCreateInfoNVX&() const
  {
    return *reinterpret_cast<const VkAccelerationStructureCreateInfoNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::acceleration_structure_type_nvx& type()
  {
    return _type;
  }

  constexpr const vk::acceleration_structure_type_nvx& type() const
  {
    return _type;
  }

  void type(vk::acceleration_structure_type_nvx new_type)
  {
    _type = new_type;
  }

  vk::build_acceleration_structure_flags_nvx& flags()
  {
    return _flags;
  }

  constexpr const vk::build_acceleration_structure_flags_nvx& flags() const
  {
    return _flags;
  }

  void flags(vk::build_acceleration_structure_flags_nvx new_flags)
  {
    _flags = new_flags;
  }

  VkDeviceSize& compacted_size()
  {
    return _compacted_size;
  }

  constexpr const VkDeviceSize& compacted_size() const
  {
    return _compacted_size;
  }

  void compacted_size(VkDeviceSize new_compacted_size)
  {
    _compacted_size = new_compacted_size;
  }

  uint32_t& instance_count()
  {
    return _instance_count;
  }

  constexpr const uint32_t& instance_count() const
  {
    return _instance_count;
  }

  void instance_count(uint32_t new_instance_count)
  {
    _instance_count = new_instance_count;
  }

  uint32_t& geometry_count()
  {
    return _geometry_count;
  }

  constexpr const uint32_t& geometry_count() const
  {
    return _geometry_count;
  }

  void geometry_count(uint32_t new_geometry_count)
  {
    _geometry_count = new_geometry_count;
  }

  const vk::geometry_nvx* geometries()
  {
    return _geometries;
  }

  constexpr const vk::geometry_nvx* geometries() const
  {
    return _geometries;
  }

  void geometries(const vk::geometry_nvx* new_geometries)
  {
    _geometries = new_geometries;
  }

  template <std::size_t Count>
  void geometries(const std::array<vk::geometry_nvx, Count>& new_geometries)
  {
    _geometry_count = static_cast<uint32_t>(new_geometries.size());
    _geometries = new_geometries.data();
  }

  void geometries(const std::vector<vk::geometry_nvx>& new_geometries)
  {
    _geometry_count = static_cast<uint32_t>(new_geometries.size());
    _geometries = new_geometries.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::acceleration_structure_create_info_nvx;
  const void* _next = nullptr;
  vk::acceleration_structure_type_nvx _type = vk::
    acceleration_structure_type_nvx::acceleration_structure_type_top_level_nvx;
  vk::build_acceleration_structure_flags_nvx _flags =
    vk::build_acceleration_structure_flag_nvx::none;
  VkDeviceSize _compacted_size = 0;
  uint32_t _instance_count = 0;
  uint32_t _geometry_count = 0;
  const vk::geometry_nvx* _geometries = nullptr;
};
static_assert(sizeof(acceleration_structure_create_info_nvx) ==
                sizeof(::VkAccelerationStructureCreateInfoNVX),
              "struct and wrapper have different size!");

enum class copy_acceleration_structure_mode_nvx
{
  /// @see VK_COPY_ACCELERATION_STRUCTURE_MODE_CLONE_NVX
  copy_acceleration_structure_mode_clone_nvx = 0,
  /// @see VK_COPY_ACCELERATION_STRUCTURE_MODE_COMPACT_NVX
  copy_acceleration_structure_mode_compact_nvx = 1,
};

/// Enhanced replacement type for VkBindAccelerationStructureMemoryInfoNVX.
class bind_acceleration_structure_memory_info_nvx
{
public:
  /// Default constructor.
  constexpr bind_acceleration_structure_memory_info_nvx() = default;

  /// Constructor.
  constexpr bind_acceleration_structure_memory_info_nvx(
    const void* initial_next,
    VkAccelerationStructureNVX initial_acceleration_structure,
    VkDeviceMemory initial_memory, VkDeviceSize initial_memory_offset,
    uint32_t initial_device_index_count,
    const uint32_t* initial_device_indices) noexcept
  : _next(std::move(initial_next)),
    _acceleration_structure(std::move(initial_acceleration_structure)),
    _memory(std::move(initial_memory)),
    _memory_offset(std::move(initial_memory_offset)),
    _device_index_count(std::move(initial_device_index_count)),
    _device_indices(std::move(initial_device_indices))
  {
  }

  /// Copy constructor.
  constexpr bind_acceleration_structure_memory_info_nvx(
    const bind_acceleration_structure_memory_info_nvx& other) noexcept
  : _next(other._next),
    _acceleration_structure(other._acceleration_structure),
    _memory(other._memory),
    _memory_offset(other._memory_offset),
    _device_index_count(other._device_index_count),
    _device_indices(other._device_indices)
  {
  }

  /// Move constructor.
  constexpr bind_acceleration_structure_memory_info_nvx(
    bind_acceleration_structure_memory_info_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _acceleration_structure(std::move(other._acceleration_structure)),
    _memory(std::move(other._memory)),
    _memory_offset(std::move(other._memory_offset)),
    _device_index_count(std::move(other._device_index_count)),
    _device_indices(std::move(other._device_indices))
  {
  }

  /// Copy assignment operator.
  constexpr bind_acceleration_structure_memory_info_nvx& operator=(
    const bind_acceleration_structure_memory_info_nvx& other) noexcept
  {
    _next = other._next;
    _acceleration_structure = other._acceleration_structure;
    _memory = other._memory;
    _memory_offset = other._memory_offset;
    _device_index_count = other._device_index_count;
    _device_indices = other._device_indices;
    return *this;
  }

  /// Move assignment operator.
  constexpr bind_acceleration_structure_memory_info_nvx& operator=(
    bind_acceleration_structure_memory_info_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _acceleration_structure = std::move(other._acceleration_structure);
    _memory = std::move(other._memory);
    _memory_offset = std::move(other._memory_offset);
    _device_index_count = std::move(other._device_index_count);
    _device_indices = std::move(other._device_indices);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkBindAccelerationStructureMemoryInfoNVX&() const
  {
    return *reinterpret_cast<const VkBindAccelerationStructureMemoryInfoNVX*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkAccelerationStructureNVX& acceleration_structure()
  {
    return _acceleration_structure;
  }

  constexpr const VkAccelerationStructureNVX& acceleration_structure() const
  {
    return _acceleration_structure;
  }

  void acceleration_structure(
    VkAccelerationStructureNVX new_acceleration_structure)
  {
    _acceleration_structure = new_acceleration_structure;
  }

  VkDeviceMemory& memory()
  {
    return _memory;
  }

  constexpr const VkDeviceMemory& memory() const
  {
    return _memory;
  }

  void memory(VkDeviceMemory new_memory)
  {
    _memory = new_memory;
  }

  VkDeviceSize& memory_offset()
  {
    return _memory_offset;
  }

  constexpr const VkDeviceSize& memory_offset() const
  {
    return _memory_offset;
  }

  void memory_offset(VkDeviceSize new_memory_offset)
  {
    _memory_offset = new_memory_offset;
  }

  uint32_t& device_index_count()
  {
    return _device_index_count;
  }

  constexpr const uint32_t& device_index_count() const
  {
    return _device_index_count;
  }

  void device_index_count(uint32_t new_device_index_count)
  {
    _device_index_count = new_device_index_count;
  }

  const uint32_t* device_indices()
  {
    return _device_indices;
  }

  constexpr const uint32_t* device_indices() const
  {
    return _device_indices;
  }

  void device_indices(const uint32_t* new_device_indices)
  {
    _device_indices = new_device_indices;
  }

  template <std::size_t Count>
  void device_indices(const std::array<uint32_t, Count>& new_device_indices)
  {
    _device_index_count = static_cast<uint32_t>(new_device_indices.size());
    _device_indices = new_device_indices.data();
  }

  void device_indices(const std::vector<uint32_t>& new_device_indices)
  {
    _device_index_count = static_cast<uint32_t>(new_device_indices.size());
    _device_indices = new_device_indices.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::bind_acceleration_structure_memory_info_nvx;
  const void* _next = nullptr;
  VkAccelerationStructureNVX _acceleration_structure = nullptr;
  VkDeviceMemory _memory = nullptr;
  VkDeviceSize _memory_offset = 0;
  uint32_t _device_index_count = 0;
  const uint32_t* _device_indices = nullptr;
};
static_assert(sizeof(bind_acceleration_structure_memory_info_nvx) ==
                sizeof(::VkBindAccelerationStructureMemoryInfoNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDescriptorAccelerationStructureInfoNVX.
class descriptor_acceleration_structure_info_nvx
{
public:
  /// Default constructor.
  constexpr descriptor_acceleration_structure_info_nvx() = default;

  /// Constructor.
  constexpr descriptor_acceleration_structure_info_nvx(
    const void* initial_next, uint32_t initial_acceleration_structure_count,
    const VkAccelerationStructureNVX* initial_acceleration_structures) noexcept
  : _next(std::move(initial_next)),
    _acceleration_structure_count(
      std::move(initial_acceleration_structure_count)),
    _acceleration_structures(std::move(initial_acceleration_structures))
  {
  }

  /// Copy constructor.
  constexpr descriptor_acceleration_structure_info_nvx(
    const descriptor_acceleration_structure_info_nvx& other) noexcept
  : _next(other._next),
    _acceleration_structure_count(other._acceleration_structure_count),
    _acceleration_structures(other._acceleration_structures)
  {
  }

  /// Move constructor.
  constexpr descriptor_acceleration_structure_info_nvx(
    descriptor_acceleration_structure_info_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _acceleration_structure_count(
      std::move(other._acceleration_structure_count)),
    _acceleration_structures(std::move(other._acceleration_structures))
  {
  }

  /// Copy assignment operator.
  constexpr descriptor_acceleration_structure_info_nvx& operator=(
    const descriptor_acceleration_structure_info_nvx& other) noexcept
  {
    _next = other._next;
    _acceleration_structure_count = other._acceleration_structure_count;
    _acceleration_structures = other._acceleration_structures;
    return *this;
  }

  /// Move assignment operator.
  constexpr descriptor_acceleration_structure_info_nvx& operator=(
    descriptor_acceleration_structure_info_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _acceleration_structure_count =
      std::move(other._acceleration_structure_count);
    _acceleration_structures = std::move(other._acceleration_structures);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDescriptorAccelerationStructureInfoNVX&() const
  {
    return *reinterpret_cast<const VkDescriptorAccelerationStructureInfoNVX*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& acceleration_structure_count()
  {
    return _acceleration_structure_count;
  }

  constexpr const uint32_t& acceleration_structure_count() const
  {
    return _acceleration_structure_count;
  }

  void acceleration_structure_count(uint32_t new_acceleration_structure_count)
  {
    _acceleration_structure_count = new_acceleration_structure_count;
  }

  const VkAccelerationStructureNVX* acceleration_structures()
  {
    return _acceleration_structures;
  }

  constexpr const VkAccelerationStructureNVX* acceleration_structures() const
  {
    return _acceleration_structures;
  }

  void acceleration_structures(
    const VkAccelerationStructureNVX* new_acceleration_structures)
  {
    _acceleration_structures = new_acceleration_structures;
  }

  template <std::size_t Count>
  void acceleration_structures(
    const std::array<VkAccelerationStructureNVX, Count>&
      new_acceleration_structures)
  {
    _acceleration_structure_count =
      static_cast<uint32_t>(new_acceleration_structures.size());
    _acceleration_structures = new_acceleration_structures.data();
  }

  void acceleration_structures(
    const std::vector<VkAccelerationStructureNVX>& new_acceleration_structures)
  {
    _acceleration_structure_count =
      static_cast<uint32_t>(new_acceleration_structures.size());
    _acceleration_structures = new_acceleration_structures.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::descriptor_acceleration_structure_info_nvx;
  const void* _next = nullptr;
  uint32_t _acceleration_structure_count = 0;
  const VkAccelerationStructureNVX* _acceleration_structures = nullptr;
};
static_assert(sizeof(descriptor_acceleration_structure_info_nvx) ==
                sizeof(::VkDescriptorAccelerationStructureInfoNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkAccelerationStructureMemoryRequirementsInfoNVX.
class acceleration_structure_memory_requirements_info_nvx
{
public:
  /// Default constructor.
  constexpr acceleration_structure_memory_requirements_info_nvx() = default;

  /// Constructor.
  constexpr acceleration_structure_memory_requirements_info_nvx(
    const void* initial_next,
    VkAccelerationStructureNVX initial_acceleration_structure) noexcept
  : _next(std::move(initial_next)),
    _acceleration_structure(std::move(initial_acceleration_structure))
  {
  }

  /// Copy constructor.
  constexpr acceleration_structure_memory_requirements_info_nvx(
    const acceleration_structure_memory_requirements_info_nvx& other) noexcept
  : _next(other._next), _acceleration_structure(other._acceleration_structure)
  {
  }

  /// Move constructor.
  constexpr acceleration_structure_memory_requirements_info_nvx(
    acceleration_structure_memory_requirements_info_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _acceleration_structure(std::move(other._acceleration_structure))
  {
  }

  /// Copy assignment operator.
  constexpr acceleration_structure_memory_requirements_info_nvx& operator=(
    const acceleration_structure_memory_requirements_info_nvx& other) noexcept
  {
    _next = other._next;
    _acceleration_structure = other._acceleration_structure;
    return *this;
  }

  /// Move assignment operator.
  constexpr acceleration_structure_memory_requirements_info_nvx& operator=(
    acceleration_structure_memory_requirements_info_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _acceleration_structure = std::move(other._acceleration_structure);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkAccelerationStructureMemoryRequirementsInfoNVX&() const
  {
    return *reinterpret_cast<
      const VkAccelerationStructureMemoryRequirementsInfoNVX*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkAccelerationStructureNVX& acceleration_structure()
  {
    return _acceleration_structure;
  }

  constexpr const VkAccelerationStructureNVX& acceleration_structure() const
  {
    return _acceleration_structure;
  }

  void acceleration_structure(
    VkAccelerationStructureNVX new_acceleration_structure)
  {
    _acceleration_structure = new_acceleration_structure;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::acceleration_structure_memory_requirements_info_nvx;
  const void* _next = nullptr;
  VkAccelerationStructureNVX _acceleration_structure = nullptr;
};
static_assert(sizeof(acceleration_structure_memory_requirements_info_nvx) ==
                sizeof(::VkAccelerationStructureMemoryRequirementsInfoNVX),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceRaytracingPropertiesNVX.
class physical_device_raytracing_properties_nvx
{
public:
  /// Default constructor.
  constexpr physical_device_raytracing_properties_nvx() = default;

  /// Constructor.
  constexpr physical_device_raytracing_properties_nvx(
    void* initial_next, uint32_t initial_shader_header_size,
    uint32_t initial_max_recursion_depth,
    uint32_t initial_max_geometry_count) noexcept
  : _next(std::move(initial_next)),
    _shader_header_size(std::move(initial_shader_header_size)),
    _max_recursion_depth(std::move(initial_max_recursion_depth)),
    _max_geometry_count(std::move(initial_max_geometry_count))
  {
  }

  /// Copy constructor.
  constexpr physical_device_raytracing_properties_nvx(
    const physical_device_raytracing_properties_nvx& other) noexcept
  : _next(other._next),
    _shader_header_size(other._shader_header_size),
    _max_recursion_depth(other._max_recursion_depth),
    _max_geometry_count(other._max_geometry_count)
  {
  }

  /// Move constructor.
  constexpr physical_device_raytracing_properties_nvx(
    physical_device_raytracing_properties_nvx&& other) noexcept
  : _next(std::move(other._next)),
    _shader_header_size(std::move(other._shader_header_size)),
    _max_recursion_depth(std::move(other._max_recursion_depth)),
    _max_geometry_count(std::move(other._max_geometry_count))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_raytracing_properties_nvx& operator=(
    const physical_device_raytracing_properties_nvx& other) noexcept
  {
    _next = other._next;
    _shader_header_size = other._shader_header_size;
    _max_recursion_depth = other._max_recursion_depth;
    _max_geometry_count = other._max_geometry_count;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_raytracing_properties_nvx& operator=(
    physical_device_raytracing_properties_nvx&& other) noexcept
  {
    _next = std::move(other._next);
    _shader_header_size = std::move(other._shader_header_size);
    _max_recursion_depth = std::move(other._max_recursion_depth);
    _max_geometry_count = std::move(other._max_geometry_count);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceRaytracingPropertiesNVX&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceRaytracingPropertiesNVX*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& shader_header_size()
  {
    return _shader_header_size;
  }

  constexpr const uint32_t& shader_header_size() const
  {
    return _shader_header_size;
  }

  void shader_header_size(uint32_t new_shader_header_size)
  {
    _shader_header_size = new_shader_header_size;
  }

  uint32_t& max_recursion_depth()
  {
    return _max_recursion_depth;
  }

  constexpr const uint32_t& max_recursion_depth() const
  {
    return _max_recursion_depth;
  }

  void max_recursion_depth(uint32_t new_max_recursion_depth)
  {
    _max_recursion_depth = new_max_recursion_depth;
  }

  uint32_t& max_geometry_count()
  {
    return _max_geometry_count;
  }

  constexpr const uint32_t& max_geometry_count() const
  {
    return _max_geometry_count;
  }

  void max_geometry_count(uint32_t new_max_geometry_count)
  {
    _max_geometry_count = new_max_geometry_count;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_raytracing_properties_nvx;
  void* _next = nullptr;
  uint32_t _shader_header_size = 0;
  uint32_t _max_recursion_depth = 0;
  uint32_t _max_geometry_count = 0;
};
static_assert(sizeof(physical_device_raytracing_properties_nvx) ==
                sizeof(::VkPhysicalDeviceRaytracingPropertiesNVX),
              "struct and wrapper have different size!");

inline vk::result create_acceleration_structure_nvx(
  VkDevice device,
  const vk::acceleration_structure_create_info_nvx* create_info,
  const vk::allocation_callbacks* allocator,
  VkAccelerationStructureNVX* acceleration_structure)
{
  return static_cast<vk::result>(vkCreateAccelerationStructureNVX(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkAccelerationStructureCreateInfoNVX*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkAccelerationStructureNVX*>(acceleration_structure)));
}
inline void destroy_acceleration_structure_nvx(
  VkDevice device, VkAccelerationStructureNVX acceleration_structure,
  const vk::allocation_callbacks* allocator)
{
  vkDestroyAccelerationStructureNVX(
    static_cast<VkDevice>(device),
    static_cast<VkAccelerationStructureNVX>(acceleration_structure),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator));
}
inline void get_acceleration_structure_memory_requirements_nvx(
  VkDevice device,
  const vk::acceleration_structure_memory_requirements_info_nvx* info,
  vk::memory_requirements_2_khr* memory_requirements)
{
  vkGetAccelerationStructureMemoryRequirementsNVX(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkAccelerationStructureMemoryRequirementsInfoNVX*>(
      info),
    reinterpret_cast<VkMemoryRequirements2KHR*>(memory_requirements));
}
inline void get_acceleration_structure_scratch_memory_requirements_nvx(
  VkDevice device,
  const vk::acceleration_structure_memory_requirements_info_nvx* info,
  vk::memory_requirements_2_khr* memory_requirements)
{
  vkGetAccelerationStructureScratchMemoryRequirementsNVX(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkAccelerationStructureMemoryRequirementsInfoNVX*>(
      info),
    reinterpret_cast<VkMemoryRequirements2KHR*>(memory_requirements));
}
inline vk::result bind_acceleration_structure_memory_nvx(
  VkDevice device, uint32_t bind_info_count,
  const vk::bind_acceleration_structure_memory_info_nvx* bind_infos)
{
  return static_cast<vk::result>(vkBindAccelerationStructureMemoryNVX(
    static_cast<VkDevice>(device), static_cast<uint32_t>(bind_info_count),
    reinterpret_cast<const VkBindAccelerationStructureMemoryInfoNVX*>(
      bind_infos)));
}
inline void cmd_build_acceleration_structure_nvx(
  VkCommandBuffer cmd_buf, vk::acceleration_structure_type_nvx type,
  uint32_t instance_count, VkBuffer instance_data, VkDeviceSize instance_offset,
  uint32_t geometry_count, const vk::geometry_nvx* geometries,
  vk::build_acceleration_structure_flags_nvx flags, VkBool32 update,
  VkAccelerationStructureNVX dst, VkAccelerationStructureNVX src,
  VkBuffer scratch, VkDeviceSize scratch_offset)
{
  vkCmdBuildAccelerationStructureNVX(
    static_cast<VkCommandBuffer>(cmd_buf),
    static_cast<VkAccelerationStructureTypeNVX>(type),
    static_cast<uint32_t>(instance_count), static_cast<VkBuffer>(instance_data),
    static_cast<VkDeviceSize>(instance_offset),
    static_cast<uint32_t>(geometry_count),
    reinterpret_cast<const VkGeometryNVX*>(geometries),
    static_cast<VkBuildAccelerationStructureFlagsNVX>(flags),
    static_cast<VkBool32>(update), static_cast<VkAccelerationStructureNVX>(dst),
    static_cast<VkAccelerationStructureNVX>(src),
    static_cast<VkBuffer>(scratch), static_cast<VkDeviceSize>(scratch_offset));
}
inline void cmd_copy_acceleration_structure_nvx(
  VkCommandBuffer cmd_buf, VkAccelerationStructureNVX dst,
  VkAccelerationStructureNVX src, vk::copy_acceleration_structure_mode_nvx mode)
{
  vkCmdCopyAccelerationStructureNVX(
    static_cast<VkCommandBuffer>(cmd_buf),
    static_cast<VkAccelerationStructureNVX>(dst),
    static_cast<VkAccelerationStructureNVX>(src),
    static_cast<VkCopyAccelerationStructureModeNVX>(mode));
}
inline void cmd_trace_rays_nvx(VkCommandBuffer cmd_buf,
                               VkBuffer raygen_shader_binding_table_buffer,
                               VkDeviceSize raygen_shader_binding_offset,
                               VkBuffer miss_shader_binding_table_buffer,
                               VkDeviceSize miss_shader_binding_offset,
                               VkDeviceSize miss_shader_binding_stride,
                               VkBuffer hit_shader_binding_table_buffer,
                               VkDeviceSize hit_shader_binding_offset,
                               VkDeviceSize hit_shader_binding_stride,
                               uint32_t width, uint32_t height)
{
  vkCmdTraceRaysNVX(static_cast<VkCommandBuffer>(cmd_buf),
                    static_cast<VkBuffer>(raygen_shader_binding_table_buffer),
                    static_cast<VkDeviceSize>(raygen_shader_binding_offset),
                    static_cast<VkBuffer>(miss_shader_binding_table_buffer),
                    static_cast<VkDeviceSize>(miss_shader_binding_offset),
                    static_cast<VkDeviceSize>(miss_shader_binding_stride),
                    static_cast<VkBuffer>(hit_shader_binding_table_buffer),
                    static_cast<VkDeviceSize>(hit_shader_binding_offset),
                    static_cast<VkDeviceSize>(hit_shader_binding_stride),
                    static_cast<uint32_t>(width),
                    static_cast<uint32_t>(height));
}
inline vk::result create_raytracing_pipelines_nvx(
  VkDevice device, VkPipelineCache pipeline_cache, uint32_t create_info_count,
  const vk::raytracing_pipeline_create_info_nvx* create_infos,
  const vk::allocation_callbacks* allocator, VkPipeline* pipelines)
{
  return static_cast<vk::result>(vkCreateRaytracingPipelinesNVX(
    static_cast<VkDevice>(device), static_cast<VkPipelineCache>(pipeline_cache),
    static_cast<uint32_t>(create_info_count),
    reinterpret_cast<const VkRaytracingPipelineCreateInfoNVX*>(create_infos),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkPipeline*>(pipelines)));
}
inline vk::result get_raytracing_shader_handles_nvx(
  VkDevice device, VkPipeline pipeline, uint32_t first_group,
  uint32_t group_count, size_t data_size, void* data)
{
  return static_cast<vk::result>(vkGetRaytracingShaderHandlesNVX(
    static_cast<VkDevice>(device), static_cast<VkPipeline>(pipeline),
    static_cast<uint32_t>(first_group), static_cast<uint32_t>(group_count),
    static_cast<size_t>(data_size), reinterpret_cast<void*>(data)));
}
inline vk::result get_acceleration_structure_handle_nvx(
  VkDevice device, VkAccelerationStructureNVX acceleration_structure,
  size_t data_size, void* data)
{
  return static_cast<vk::result>(vkGetAccelerationStructureHandleNVX(
    static_cast<VkDevice>(device),
    static_cast<VkAccelerationStructureNVX>(acceleration_structure),
    static_cast<size_t>(data_size), reinterpret_cast<void*>(data)));
}
inline void cmd_write_acceleration_structure_properties_nvx(
  VkCommandBuffer cmd_buf, VkAccelerationStructureNVX acceleration_structure,
  vk::query_type query_type, VkQueryPool query_pool, uint32_t query)
{
  vkCmdWriteAccelerationStructurePropertiesNVX(
    static_cast<VkCommandBuffer>(cmd_buf),
    static_cast<VkAccelerationStructureNVX>(acceleration_structure),
    static_cast<VkQueryType>(query_type), static_cast<VkQueryPool>(query_pool),
    static_cast<uint32_t>(query));
}
inline vk::result compile_deferred_nvx(VkDevice device, VkPipeline pipeline,
                                       uint32_t shader)
{
  return static_cast<vk::result>(vkCompileDeferredNVX(
    static_cast<VkDevice>(device), static_cast<VkPipeline>(pipeline),
    static_cast<uint32_t>(shader)));
}

/// Enhanced replacement type for
/// VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV.
class physical_device_representative_fragment_test_features_nv
{
public:
  /// Default constructor.
  constexpr physical_device_representative_fragment_test_features_nv() =
    default;

  /// Constructor.
  constexpr physical_device_representative_fragment_test_features_nv(
    void* initial_next, VkBool32 initial_representative_fragment_test) noexcept
  : _next(std::move(initial_next)),
    _representative_fragment_test(
      std::move(initial_representative_fragment_test))
  {
  }

  /// Copy constructor.
  constexpr physical_device_representative_fragment_test_features_nv(
    const physical_device_representative_fragment_test_features_nv&
      other) noexcept
  : _next(other._next),
    _representative_fragment_test(other._representative_fragment_test)
  {
  }

  /// Move constructor.
  constexpr physical_device_representative_fragment_test_features_nv(
    physical_device_representative_fragment_test_features_nv&& other) noexcept
  : _next(std::move(other._next)),
    _representative_fragment_test(
      std::move(other._representative_fragment_test))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_representative_fragment_test_features_nv& operator=(
    const physical_device_representative_fragment_test_features_nv&
      other) noexcept
  {
    _next = other._next;
    _representative_fragment_test = other._representative_fragment_test;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_representative_fragment_test_features_nv& operator=(
    physical_device_representative_fragment_test_features_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _representative_fragment_test =
      std::move(other._representative_fragment_test);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& representative_fragment_test()
  {
    return _representative_fragment_test;
  }

  constexpr const VkBool32& representative_fragment_test() const
  {
    return _representative_fragment_test;
  }

  void representative_fragment_test(VkBool32 new_representative_fragment_test)
  {
    _representative_fragment_test = new_representative_fragment_test;
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    physical_device_representative_fragment_test_features_nv;
  void* _next = nullptr;
  VkBool32 _representative_fragment_test = VK_FALSE;
};
static_assert(
  sizeof(physical_device_representative_fragment_test_features_nv) ==
    sizeof(::VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV),
  "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPipelineRepresentativeFragmentTestStateCreateInfoNV.
class pipeline_representative_fragment_test_state_create_info_nv
{
public:
  /// Default constructor.
  constexpr pipeline_representative_fragment_test_state_create_info_nv() =
    default;

  /// Constructor.
  constexpr pipeline_representative_fragment_test_state_create_info_nv(
    const void* initial_next,
    VkBool32 initial_representative_fragment_test_enable) noexcept
  : _next(std::move(initial_next)),
    _representative_fragment_test_enable(
      std::move(initial_representative_fragment_test_enable))
  {
  }

  /// Copy constructor.
  constexpr pipeline_representative_fragment_test_state_create_info_nv(
    const pipeline_representative_fragment_test_state_create_info_nv&
      other) noexcept
  : _next(other._next),
    _representative_fragment_test_enable(
      other._representative_fragment_test_enable)
  {
  }

  /// Move constructor.
  constexpr pipeline_representative_fragment_test_state_create_info_nv(
    pipeline_representative_fragment_test_state_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _representative_fragment_test_enable(
      std::move(other._representative_fragment_test_enable))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_representative_fragment_test_state_create_info_nv&
  operator=(const pipeline_representative_fragment_test_state_create_info_nv&
              other) noexcept
  {
    _next = other._next;
    _representative_fragment_test_enable =
      other._representative_fragment_test_enable;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_representative_fragment_test_state_create_info_nv&
  operator=(
    pipeline_representative_fragment_test_state_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _representative_fragment_test_enable =
      std::move(other._representative_fragment_test_enable);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineRepresentativeFragmentTestStateCreateInfoNV&() const
  {
    return *reinterpret_cast<
      const VkPipelineRepresentativeFragmentTestStateCreateInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkBool32& representative_fragment_test_enable()
  {
    return _representative_fragment_test_enable;
  }

  constexpr const VkBool32& representative_fragment_test_enable() const
  {
    return _representative_fragment_test_enable;
  }

  void representative_fragment_test_enable(
    VkBool32 new_representative_fragment_test_enable)
  {
    _representative_fragment_test_enable =
      new_representative_fragment_test_enable;
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    pipeline_representative_fragment_test_state_create_info_nv;
  const void* _next = nullptr;
  VkBool32 _representative_fragment_test_enable = VK_FALSE;
};
static_assert(
  sizeof(pipeline_representative_fragment_test_state_create_info_nv) ==
    sizeof(::VkPipelineRepresentativeFragmentTestStateCreateInfoNV),
  "struct and wrapper have different size!");

inline void cmd_draw_indirect_count_khr(VkCommandBuffer command_buffer,
                                        VkBuffer buffer, VkDeviceSize offset,
                                        VkBuffer count_buffer,
                                        VkDeviceSize count_buffer_offset,
                                        uint32_t max_draw_count,
                                        uint32_t stride)
{
  vkCmdDrawIndirectCountKHR(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceSize>(offset), static_cast<VkBuffer>(count_buffer),
    static_cast<VkDeviceSize>(count_buffer_offset),
    static_cast<uint32_t>(max_draw_count), static_cast<uint32_t>(stride));
}
inline void cmd_draw_indexed_indirect_count_khr(
  VkCommandBuffer command_buffer, VkBuffer buffer, VkDeviceSize offset,
  VkBuffer count_buffer, VkDeviceSize count_buffer_offset,
  uint32_t max_draw_count, uint32_t stride)
{
  vkCmdDrawIndexedIndirectCountKHR(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceSize>(offset), static_cast<VkBuffer>(count_buffer),
    static_cast<VkDeviceSize>(count_buffer_offset),
    static_cast<uint32_t>(max_draw_count), static_cast<uint32_t>(stride));
}
enum class queue_global_priority_ext
{
  /// @see VK_QUEUE_GLOBAL_PRIORITY_LOW_EXT
  queue_global_priority_low_ext = 128,
  /// @see VK_QUEUE_GLOBAL_PRIORITY_MEDIUM_EXT
  queue_global_priority_medium_ext = 256,
  /// @see VK_QUEUE_GLOBAL_PRIORITY_HIGH_EXT
  queue_global_priority_high_ext = 512,
  /// @see VK_QUEUE_GLOBAL_PRIORITY_REALTIME_EXT
  queue_global_priority_realtime_ext = 1024,
};

/// Enhanced replacement type for VkDeviceQueueGlobalPriorityCreateInfoEXT.
class device_queue_global_priority_create_info_ext
{
public:
  /// Default constructor.
  constexpr device_queue_global_priority_create_info_ext() = default;

  /// Constructor.
  constexpr device_queue_global_priority_create_info_ext(
    const void* initial_next,
    vk::queue_global_priority_ext initial_global_priority) noexcept
  : _next(std::move(initial_next)),
    _global_priority(std::move(initial_global_priority))
  {
  }

  /// Copy constructor.
  constexpr device_queue_global_priority_create_info_ext(
    const device_queue_global_priority_create_info_ext& other) noexcept
  : _next(other._next), _global_priority(other._global_priority)
  {
  }

  /// Move constructor.
  constexpr device_queue_global_priority_create_info_ext(
    device_queue_global_priority_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _global_priority(std::move(other._global_priority))
  {
  }

  /// Copy assignment operator.
  constexpr device_queue_global_priority_create_info_ext& operator=(
    const device_queue_global_priority_create_info_ext& other) noexcept
  {
    _next = other._next;
    _global_priority = other._global_priority;
    return *this;
  }

  /// Move assignment operator.
  constexpr device_queue_global_priority_create_info_ext& operator=(
    device_queue_global_priority_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _global_priority = std::move(other._global_priority);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDeviceQueueGlobalPriorityCreateInfoEXT&() const
  {
    return *reinterpret_cast<const VkDeviceQueueGlobalPriorityCreateInfoEXT*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::queue_global_priority_ext& global_priority()
  {
    return _global_priority;
  }

  constexpr const vk::queue_global_priority_ext& global_priority() const
  {
    return _global_priority;
  }

  void global_priority(vk::queue_global_priority_ext new_global_priority)
  {
    _global_priority = new_global_priority;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::device_queue_global_priority_create_info_ext;
  const void* _next = nullptr;
  vk::queue_global_priority_ext _global_priority =
    vk::queue_global_priority_ext::queue_global_priority_low_ext;
};
static_assert(sizeof(device_queue_global_priority_create_info_ext) ==
                sizeof(::VkDeviceQueueGlobalPriorityCreateInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDevice8BitStorageFeaturesKHR.
class physical_device_8_bit_storage_features_khr
{
public:
  /// Default constructor.
  constexpr physical_device_8_bit_storage_features_khr() = default;

  /// Constructor.
  constexpr physical_device_8_bit_storage_features_khr(
    void* initial_next, VkBool32 initial_storage_buffer_8_bit_access,
    VkBool32 initial_uniform_and_storage_buffer_8_bit_access,
    VkBool32 initial_storage_push_constant_8) noexcept
  : _next(std::move(initial_next)),
    _storage_buffer_8_bit_access(
      std::move(initial_storage_buffer_8_bit_access)),
    _uniform_and_storage_buffer_8_bit_access(
      std::move(initial_uniform_and_storage_buffer_8_bit_access)),
    _storage_push_constant_8(std::move(initial_storage_push_constant_8))
  {
  }

  /// Copy constructor.
  constexpr physical_device_8_bit_storage_features_khr(
    const physical_device_8_bit_storage_features_khr& other) noexcept
  : _next(other._next),
    _storage_buffer_8_bit_access(other._storage_buffer_8_bit_access),
    _uniform_and_storage_buffer_8_bit_access(
      other._uniform_and_storage_buffer_8_bit_access),
    _storage_push_constant_8(other._storage_push_constant_8)
  {
  }

  /// Move constructor.
  constexpr physical_device_8_bit_storage_features_khr(
    physical_device_8_bit_storage_features_khr&& other) noexcept
  : _next(std::move(other._next)),
    _storage_buffer_8_bit_access(std::move(other._storage_buffer_8_bit_access)),
    _uniform_and_storage_buffer_8_bit_access(
      std::move(other._uniform_and_storage_buffer_8_bit_access)),
    _storage_push_constant_8(std::move(other._storage_push_constant_8))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_8_bit_storage_features_khr& operator=(
    const physical_device_8_bit_storage_features_khr& other) noexcept
  {
    _next = other._next;
    _storage_buffer_8_bit_access = other._storage_buffer_8_bit_access;
    _uniform_and_storage_buffer_8_bit_access =
      other._uniform_and_storage_buffer_8_bit_access;
    _storage_push_constant_8 = other._storage_push_constant_8;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_8_bit_storage_features_khr& operator=(
    physical_device_8_bit_storage_features_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _storage_buffer_8_bit_access =
      std::move(other._storage_buffer_8_bit_access);
    _uniform_and_storage_buffer_8_bit_access =
      std::move(other._uniform_and_storage_buffer_8_bit_access);
    _storage_push_constant_8 = std::move(other._storage_push_constant_8);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDevice8BitStorageFeaturesKHR&() const
  {
    return *reinterpret_cast<const VkPhysicalDevice8BitStorageFeaturesKHR*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& storage_buffer_8_bit_access()
  {
    return _storage_buffer_8_bit_access;
  }

  constexpr const VkBool32& storage_buffer_8_bit_access() const
  {
    return _storage_buffer_8_bit_access;
  }

  void storage_buffer_8_bit_access(VkBool32 new_storage_buffer_8_bit_access)
  {
    _storage_buffer_8_bit_access = new_storage_buffer_8_bit_access;
  }

  VkBool32& uniform_and_storage_buffer_8_bit_access()
  {
    return _uniform_and_storage_buffer_8_bit_access;
  }

  constexpr const VkBool32& uniform_and_storage_buffer_8_bit_access() const
  {
    return _uniform_and_storage_buffer_8_bit_access;
  }

  void uniform_and_storage_buffer_8_bit_access(
    VkBool32 new_uniform_and_storage_buffer_8_bit_access)
  {
    _uniform_and_storage_buffer_8_bit_access =
      new_uniform_and_storage_buffer_8_bit_access;
  }

  VkBool32& storage_push_constant_8()
  {
    return _storage_push_constant_8;
  }

  constexpr const VkBool32& storage_push_constant_8() const
  {
    return _storage_push_constant_8;
  }

  void storage_push_constant_8(VkBool32 new_storage_push_constant_8)
  {
    _storage_push_constant_8 = new_storage_push_constant_8;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_8_bit_storage_features_khr;
  void* _next = nullptr;
  /// 8-bit integer variables supported in StorageBuffer
  VkBool32 _storage_buffer_8_bit_access = VK_FALSE;
  /// 8-bit integer variables supported in StorageBuffer and Uniform
  VkBool32 _uniform_and_storage_buffer_8_bit_access = VK_FALSE;
  /// 8-bit integer variables supported in PushConstant
  VkBool32 _storage_push_constant_8 = VK_FALSE;
};
static_assert(sizeof(physical_device_8_bit_storage_features_khr) ==
                sizeof(::VkPhysicalDevice8BitStorageFeaturesKHR),
              "struct and wrapper have different size!");

enum class external_memory_handle_type_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using external_memory_handle_type_flags_khr =
  shift::core::bit_field<external_memory_handle_type_flag_khr,
                         VkExternalMemoryHandleTypeFlagsKHR>;
inline constexpr external_memory_handle_type_flags_khr operator|(
  external_memory_handle_type_flag_khr lhs,
  external_memory_handle_type_flag_khr rhs)
{
  return external_memory_handle_type_flags_khr{lhs} | rhs;
}
/// Enhanced replacement type for VkImportMemoryHostPointerInfoEXT.
class import_memory_host_pointer_info_ext
{
public:
  /// Default constructor.
  constexpr import_memory_host_pointer_info_ext() = default;

  /// Constructor.
  constexpr import_memory_host_pointer_info_ext(
    const void* initial_next,
    vk::external_memory_handle_type_flag initial_handle_type,
    void* initial_host_pointer) noexcept
  : _next(std::move(initial_next)),
    _handle_type(std::move(initial_handle_type)),
    _host_pointer(std::move(initial_host_pointer))
  {
  }

  /// Copy constructor.
  constexpr import_memory_host_pointer_info_ext(
    const import_memory_host_pointer_info_ext& other) noexcept
  : _next(other._next),
    _handle_type(other._handle_type),
    _host_pointer(other._host_pointer)
  {
  }

  /// Move constructor.
  constexpr import_memory_host_pointer_info_ext(
    import_memory_host_pointer_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _handle_type(std::move(other._handle_type)),
    _host_pointer(std::move(other._host_pointer))
  {
  }

  /// Copy assignment operator.
  constexpr import_memory_host_pointer_info_ext& operator=(
    const import_memory_host_pointer_info_ext& other) noexcept
  {
    _next = other._next;
    _handle_type = other._handle_type;
    _host_pointer = other._host_pointer;
    return *this;
  }

  /// Move assignment operator.
  constexpr import_memory_host_pointer_info_ext& operator=(
    import_memory_host_pointer_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_type = std::move(other._handle_type);
    _host_pointer = std::move(other._host_pointer);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImportMemoryHostPointerInfoEXT&() const
  {
    return *reinterpret_cast<const VkImportMemoryHostPointerInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_memory_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_memory_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

  void* host_pointer()
  {
    return _host_pointer;
  }

  constexpr void* host_pointer() const
  {
    return _host_pointer;
  }

  void host_pointer(void* new_host_pointer)
  {
    _host_pointer = new_host_pointer;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::import_memory_host_pointer_info_ext;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flag _handle_type =
    vk::external_memory_handle_type_flag::none;
  void* _host_pointer = nullptr;
};
static_assert(sizeof(import_memory_host_pointer_info_ext) ==
                sizeof(::VkImportMemoryHostPointerInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkMemoryHostPointerPropertiesEXT.
class memory_host_pointer_properties_ext
{
public:
  /// Default constructor.
  constexpr memory_host_pointer_properties_ext() = default;

  /// Constructor.
  constexpr memory_host_pointer_properties_ext(
    void* initial_next, uint32_t initial_memory_type_bits) noexcept
  : _next(std::move(initial_next)),
    _memory_type_bits(std::move(initial_memory_type_bits))
  {
  }

  /// Copy constructor.
  constexpr memory_host_pointer_properties_ext(
    const memory_host_pointer_properties_ext& other) noexcept
  : _next(other._next), _memory_type_bits(other._memory_type_bits)
  {
  }

  /// Move constructor.
  constexpr memory_host_pointer_properties_ext(
    memory_host_pointer_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _memory_type_bits(std::move(other._memory_type_bits))
  {
  }

  /// Copy assignment operator.
  constexpr memory_host_pointer_properties_ext& operator=(
    const memory_host_pointer_properties_ext& other) noexcept
  {
    _next = other._next;
    _memory_type_bits = other._memory_type_bits;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_host_pointer_properties_ext& operator=(
    memory_host_pointer_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _memory_type_bits = std::move(other._memory_type_bits);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryHostPointerPropertiesEXT&() const
  {
    return *reinterpret_cast<const VkMemoryHostPointerPropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& memory_type_bits()
  {
    return _memory_type_bits;
  }

  constexpr const uint32_t& memory_type_bits() const
  {
    return _memory_type_bits;
  }

  void memory_type_bits(uint32_t new_memory_type_bits)
  {
    _memory_type_bits = new_memory_type_bits;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_host_pointer_properties_ext;
  void* _next = nullptr;
  uint32_t _memory_type_bits = 0;
};
static_assert(sizeof(memory_host_pointer_properties_ext) ==
                sizeof(::VkMemoryHostPointerPropertiesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceExternalMemoryHostPropertiesEXT.
class physical_device_external_memory_host_properties_ext
{
public:
  /// Default constructor.
  constexpr physical_device_external_memory_host_properties_ext() = default;

  /// Constructor.
  constexpr physical_device_external_memory_host_properties_ext(
    void* initial_next,
    VkDeviceSize initial_min_imported_host_pointer_alignment) noexcept
  : _next(std::move(initial_next)),
    _min_imported_host_pointer_alignment(
      std::move(initial_min_imported_host_pointer_alignment))
  {
  }

  /// Copy constructor.
  constexpr physical_device_external_memory_host_properties_ext(
    const physical_device_external_memory_host_properties_ext& other) noexcept
  : _next(other._next),
    _min_imported_host_pointer_alignment(
      other._min_imported_host_pointer_alignment)
  {
  }

  /// Move constructor.
  constexpr physical_device_external_memory_host_properties_ext(
    physical_device_external_memory_host_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _min_imported_host_pointer_alignment(
      std::move(other._min_imported_host_pointer_alignment))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_external_memory_host_properties_ext& operator=(
    const physical_device_external_memory_host_properties_ext& other) noexcept
  {
    _next = other._next;
    _min_imported_host_pointer_alignment =
      other._min_imported_host_pointer_alignment;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_external_memory_host_properties_ext& operator=(
    physical_device_external_memory_host_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _min_imported_host_pointer_alignment =
      std::move(other._min_imported_host_pointer_alignment);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceExternalMemoryHostPropertiesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceExternalMemoryHostPropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkDeviceSize& min_imported_host_pointer_alignment()
  {
    return _min_imported_host_pointer_alignment;
  }

  constexpr const VkDeviceSize& min_imported_host_pointer_alignment() const
  {
    return _min_imported_host_pointer_alignment;
  }

  void min_imported_host_pointer_alignment(
    VkDeviceSize new_min_imported_host_pointer_alignment)
  {
    _min_imported_host_pointer_alignment =
      new_min_imported_host_pointer_alignment;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_external_memory_host_properties_ext;
  void* _next = nullptr;
  VkDeviceSize _min_imported_host_pointer_alignment = 0;
};
static_assert(sizeof(physical_device_external_memory_host_properties_ext) ==
                sizeof(::VkPhysicalDeviceExternalMemoryHostPropertiesEXT),
              "struct and wrapper have different size!");

inline vk::result get_memory_host_pointer_properties_ext(
  VkDevice device, vk::external_memory_handle_type_flag handle_type,
  const void* host_pointer,
  vk::memory_host_pointer_properties_ext* memory_host_pointer_properties)
{
  return static_cast<vk::result>(vkGetMemoryHostPointerPropertiesEXT(
    static_cast<VkDevice>(device),
    static_cast<VkExternalMemoryHandleTypeFlagBits>(handle_type),
    reinterpret_cast<const void*>(host_pointer),
    reinterpret_cast<VkMemoryHostPointerPropertiesEXT*>(
      memory_host_pointer_properties)));
}
inline void cmd_write_buffer_marker_amd(VkCommandBuffer command_buffer,
                                        vk::pipeline_stage_flag pipeline_stage,
                                        VkBuffer dst_buffer,
                                        VkDeviceSize dst_offset,
                                        uint32_t marker)
{
  vkCmdWriteBufferMarkerAMD(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<VkPipelineStageFlagBits>(pipeline_stage),
    static_cast<VkBuffer>(dst_buffer), static_cast<VkDeviceSize>(dst_offset),
    static_cast<uint32_t>(marker));
}

/// Enhanced replacement type for VkPhysicalDeviceShaderCorePropertiesAMD.
class physical_device_shader_core_properties_amd
{
public:
  /// Default constructor.
  constexpr physical_device_shader_core_properties_amd() = default;

  /// Constructor.
  constexpr physical_device_shader_core_properties_amd(
    void* initial_next, uint32_t initial_shader_engine_count,
    uint32_t initial_shader_arrays_per_engine_count,
    uint32_t initial_compute_units_per_shader_array,
    uint32_t initial_simd_per_compute_unit,
    uint32_t initial_wavefronts_per_simd, uint32_t initial_wavefront_size,
    uint32_t initial_sgprs_per_simd, uint32_t initial_min_sgpr_allocation,
    uint32_t initial_max_sgpr_allocation,
    uint32_t initial_sgpr_allocation_granularity,
    uint32_t initial_vgprs_per_simd, uint32_t initial_min_vgpr_allocation,
    uint32_t initial_max_vgpr_allocation,
    uint32_t initial_vgpr_allocation_granularity) noexcept
  : _next(std::move(initial_next)),
    _shader_engine_count(std::move(initial_shader_engine_count)),
    _shader_arrays_per_engine_count(
      std::move(initial_shader_arrays_per_engine_count)),
    _compute_units_per_shader_array(
      std::move(initial_compute_units_per_shader_array)),
    _simd_per_compute_unit(std::move(initial_simd_per_compute_unit)),
    _wavefronts_per_simd(std::move(initial_wavefronts_per_simd)),
    _wavefront_size(std::move(initial_wavefront_size)),
    _sgprs_per_simd(std::move(initial_sgprs_per_simd)),
    _min_sgpr_allocation(std::move(initial_min_sgpr_allocation)),
    _max_sgpr_allocation(std::move(initial_max_sgpr_allocation)),
    _sgpr_allocation_granularity(
      std::move(initial_sgpr_allocation_granularity)),
    _vgprs_per_simd(std::move(initial_vgprs_per_simd)),
    _min_vgpr_allocation(std::move(initial_min_vgpr_allocation)),
    _max_vgpr_allocation(std::move(initial_max_vgpr_allocation)),
    _vgpr_allocation_granularity(std::move(initial_vgpr_allocation_granularity))
  {
  }

  /// Copy constructor.
  constexpr physical_device_shader_core_properties_amd(
    const physical_device_shader_core_properties_amd& other) noexcept
  : _next(other._next),
    _shader_engine_count(other._shader_engine_count),
    _shader_arrays_per_engine_count(other._shader_arrays_per_engine_count),
    _compute_units_per_shader_array(other._compute_units_per_shader_array),
    _simd_per_compute_unit(other._simd_per_compute_unit),
    _wavefronts_per_simd(other._wavefronts_per_simd),
    _wavefront_size(other._wavefront_size),
    _sgprs_per_simd(other._sgprs_per_simd),
    _min_sgpr_allocation(other._min_sgpr_allocation),
    _max_sgpr_allocation(other._max_sgpr_allocation),
    _sgpr_allocation_granularity(other._sgpr_allocation_granularity),
    _vgprs_per_simd(other._vgprs_per_simd),
    _min_vgpr_allocation(other._min_vgpr_allocation),
    _max_vgpr_allocation(other._max_vgpr_allocation),
    _vgpr_allocation_granularity(other._vgpr_allocation_granularity)
  {
  }

  /// Move constructor.
  constexpr physical_device_shader_core_properties_amd(
    physical_device_shader_core_properties_amd&& other) noexcept
  : _next(std::move(other._next)),
    _shader_engine_count(std::move(other._shader_engine_count)),
    _shader_arrays_per_engine_count(
      std::move(other._shader_arrays_per_engine_count)),
    _compute_units_per_shader_array(
      std::move(other._compute_units_per_shader_array)),
    _simd_per_compute_unit(std::move(other._simd_per_compute_unit)),
    _wavefronts_per_simd(std::move(other._wavefronts_per_simd)),
    _wavefront_size(std::move(other._wavefront_size)),
    _sgprs_per_simd(std::move(other._sgprs_per_simd)),
    _min_sgpr_allocation(std::move(other._min_sgpr_allocation)),
    _max_sgpr_allocation(std::move(other._max_sgpr_allocation)),
    _sgpr_allocation_granularity(std::move(other._sgpr_allocation_granularity)),
    _vgprs_per_simd(std::move(other._vgprs_per_simd)),
    _min_vgpr_allocation(std::move(other._min_vgpr_allocation)),
    _max_vgpr_allocation(std::move(other._max_vgpr_allocation)),
    _vgpr_allocation_granularity(std::move(other._vgpr_allocation_granularity))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_shader_core_properties_amd& operator=(
    const physical_device_shader_core_properties_amd& other) noexcept
  {
    _next = other._next;
    _shader_engine_count = other._shader_engine_count;
    _shader_arrays_per_engine_count = other._shader_arrays_per_engine_count;
    _compute_units_per_shader_array = other._compute_units_per_shader_array;
    _simd_per_compute_unit = other._simd_per_compute_unit;
    _wavefronts_per_simd = other._wavefronts_per_simd;
    _wavefront_size = other._wavefront_size;
    _sgprs_per_simd = other._sgprs_per_simd;
    _min_sgpr_allocation = other._min_sgpr_allocation;
    _max_sgpr_allocation = other._max_sgpr_allocation;
    _sgpr_allocation_granularity = other._sgpr_allocation_granularity;
    _vgprs_per_simd = other._vgprs_per_simd;
    _min_vgpr_allocation = other._min_vgpr_allocation;
    _max_vgpr_allocation = other._max_vgpr_allocation;
    _vgpr_allocation_granularity = other._vgpr_allocation_granularity;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_shader_core_properties_amd& operator=(
    physical_device_shader_core_properties_amd&& other) noexcept
  {
    _next = std::move(other._next);
    _shader_engine_count = std::move(other._shader_engine_count);
    _shader_arrays_per_engine_count =
      std::move(other._shader_arrays_per_engine_count);
    _compute_units_per_shader_array =
      std::move(other._compute_units_per_shader_array);
    _simd_per_compute_unit = std::move(other._simd_per_compute_unit);
    _wavefronts_per_simd = std::move(other._wavefronts_per_simd);
    _wavefront_size = std::move(other._wavefront_size);
    _sgprs_per_simd = std::move(other._sgprs_per_simd);
    _min_sgpr_allocation = std::move(other._min_sgpr_allocation);
    _max_sgpr_allocation = std::move(other._max_sgpr_allocation);
    _sgpr_allocation_granularity =
      std::move(other._sgpr_allocation_granularity);
    _vgprs_per_simd = std::move(other._vgprs_per_simd);
    _min_vgpr_allocation = std::move(other._min_vgpr_allocation);
    _max_vgpr_allocation = std::move(other._max_vgpr_allocation);
    _vgpr_allocation_granularity =
      std::move(other._vgpr_allocation_granularity);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceShaderCorePropertiesAMD&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceShaderCorePropertiesAMD*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& shader_engine_count()
  {
    return _shader_engine_count;
  }

  constexpr const uint32_t& shader_engine_count() const
  {
    return _shader_engine_count;
  }

  void shader_engine_count(uint32_t new_shader_engine_count)
  {
    _shader_engine_count = new_shader_engine_count;
  }

  uint32_t& shader_arrays_per_engine_count()
  {
    return _shader_arrays_per_engine_count;
  }

  constexpr const uint32_t& shader_arrays_per_engine_count() const
  {
    return _shader_arrays_per_engine_count;
  }

  void shader_arrays_per_engine_count(
    uint32_t new_shader_arrays_per_engine_count)
  {
    _shader_arrays_per_engine_count = new_shader_arrays_per_engine_count;
  }

  uint32_t& compute_units_per_shader_array()
  {
    return _compute_units_per_shader_array;
  }

  constexpr const uint32_t& compute_units_per_shader_array() const
  {
    return _compute_units_per_shader_array;
  }

  void compute_units_per_shader_array(
    uint32_t new_compute_units_per_shader_array)
  {
    _compute_units_per_shader_array = new_compute_units_per_shader_array;
  }

  uint32_t& simd_per_compute_unit()
  {
    return _simd_per_compute_unit;
  }

  constexpr const uint32_t& simd_per_compute_unit() const
  {
    return _simd_per_compute_unit;
  }

  void simd_per_compute_unit(uint32_t new_simd_per_compute_unit)
  {
    _simd_per_compute_unit = new_simd_per_compute_unit;
  }

  uint32_t& wavefronts_per_simd()
  {
    return _wavefronts_per_simd;
  }

  constexpr const uint32_t& wavefronts_per_simd() const
  {
    return _wavefronts_per_simd;
  }

  void wavefronts_per_simd(uint32_t new_wavefronts_per_simd)
  {
    _wavefronts_per_simd = new_wavefronts_per_simd;
  }

  uint32_t& wavefront_size()
  {
    return _wavefront_size;
  }

  constexpr const uint32_t& wavefront_size() const
  {
    return _wavefront_size;
  }

  void wavefront_size(uint32_t new_wavefront_size)
  {
    _wavefront_size = new_wavefront_size;
  }

  uint32_t& sgprs_per_simd()
  {
    return _sgprs_per_simd;
  }

  constexpr const uint32_t& sgprs_per_simd() const
  {
    return _sgprs_per_simd;
  }

  void sgprs_per_simd(uint32_t new_sgprs_per_simd)
  {
    _sgprs_per_simd = new_sgprs_per_simd;
  }

  uint32_t& min_sgpr_allocation()
  {
    return _min_sgpr_allocation;
  }

  constexpr const uint32_t& min_sgpr_allocation() const
  {
    return _min_sgpr_allocation;
  }

  void min_sgpr_allocation(uint32_t new_min_sgpr_allocation)
  {
    _min_sgpr_allocation = new_min_sgpr_allocation;
  }

  uint32_t& max_sgpr_allocation()
  {
    return _max_sgpr_allocation;
  }

  constexpr const uint32_t& max_sgpr_allocation() const
  {
    return _max_sgpr_allocation;
  }

  void max_sgpr_allocation(uint32_t new_max_sgpr_allocation)
  {
    _max_sgpr_allocation = new_max_sgpr_allocation;
  }

  uint32_t& sgpr_allocation_granularity()
  {
    return _sgpr_allocation_granularity;
  }

  constexpr const uint32_t& sgpr_allocation_granularity() const
  {
    return _sgpr_allocation_granularity;
  }

  void sgpr_allocation_granularity(uint32_t new_sgpr_allocation_granularity)
  {
    _sgpr_allocation_granularity = new_sgpr_allocation_granularity;
  }

  uint32_t& vgprs_per_simd()
  {
    return _vgprs_per_simd;
  }

  constexpr const uint32_t& vgprs_per_simd() const
  {
    return _vgprs_per_simd;
  }

  void vgprs_per_simd(uint32_t new_vgprs_per_simd)
  {
    _vgprs_per_simd = new_vgprs_per_simd;
  }

  uint32_t& min_vgpr_allocation()
  {
    return _min_vgpr_allocation;
  }

  constexpr const uint32_t& min_vgpr_allocation() const
  {
    return _min_vgpr_allocation;
  }

  void min_vgpr_allocation(uint32_t new_min_vgpr_allocation)
  {
    _min_vgpr_allocation = new_min_vgpr_allocation;
  }

  uint32_t& max_vgpr_allocation()
  {
    return _max_vgpr_allocation;
  }

  constexpr const uint32_t& max_vgpr_allocation() const
  {
    return _max_vgpr_allocation;
  }

  void max_vgpr_allocation(uint32_t new_max_vgpr_allocation)
  {
    _max_vgpr_allocation = new_max_vgpr_allocation;
  }

  uint32_t& vgpr_allocation_granularity()
  {
    return _vgpr_allocation_granularity;
  }

  constexpr const uint32_t& vgpr_allocation_granularity() const
  {
    return _vgpr_allocation_granularity;
  }

  void vgpr_allocation_granularity(uint32_t new_vgpr_allocation_granularity)
  {
    _vgpr_allocation_granularity = new_vgpr_allocation_granularity;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_shader_core_properties_amd;
  /// Pointer to next structure
  void* _next = nullptr;
  /// number of shader engines
  uint32_t _shader_engine_count = 0;
  /// number of shader arrays
  uint32_t _shader_arrays_per_engine_count = 0;
  /// number of CUs per shader array
  uint32_t _compute_units_per_shader_array = 0;
  /// number of SIMDs per compute unit
  uint32_t _simd_per_compute_unit = 0;
  /// number of wavefront slots in each SIMD
  uint32_t _wavefronts_per_simd = 0;
  /// number of threads per wavefront
  uint32_t _wavefront_size = 0;
  /// number of physical SGPRs per SIMD
  uint32_t _sgprs_per_simd = 0;
  /// minimum number of SGPRs that can be allocated by a wave
  uint32_t _min_sgpr_allocation = 0;
  /// number of available SGPRs
  uint32_t _max_sgpr_allocation = 0;
  /// SGPRs are allocated in groups of this size
  uint32_t _sgpr_allocation_granularity = 0;
  /// number of physical VGPRs per SIMD
  uint32_t _vgprs_per_simd = 0;
  /// minimum number of VGPRs that can be allocated by a wave
  uint32_t _min_vgpr_allocation = 0;
  /// number of available VGPRs
  uint32_t _max_vgpr_allocation = 0;
  /// VGPRs are allocated in groups of this size
  uint32_t _vgpr_allocation_granularity = 0;
};
static_assert(sizeof(physical_device_shader_core_properties_amd) ==
                sizeof(::VkPhysicalDeviceShaderCorePropertiesAMD),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT.
class physical_device_vertex_attribute_divisor_properties_ext
{
public:
  /// Default constructor.
  constexpr physical_device_vertex_attribute_divisor_properties_ext() = default;

  /// Constructor.
  constexpr physical_device_vertex_attribute_divisor_properties_ext(
    void* initial_next, uint32_t initial_max_vertex_attrib_divisor) noexcept
  : _next(std::move(initial_next)),
    _max_vertex_attrib_divisor(std::move(initial_max_vertex_attrib_divisor))
  {
  }

  /// Copy constructor.
  constexpr physical_device_vertex_attribute_divisor_properties_ext(
    const physical_device_vertex_attribute_divisor_properties_ext&
      other) noexcept
  : _next(other._next),
    _max_vertex_attrib_divisor(other._max_vertex_attrib_divisor)
  {
  }

  /// Move constructor.
  constexpr physical_device_vertex_attribute_divisor_properties_ext(
    physical_device_vertex_attribute_divisor_properties_ext&& other) noexcept
  : _next(std::move(other._next)),
    _max_vertex_attrib_divisor(std::move(other._max_vertex_attrib_divisor))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_vertex_attribute_divisor_properties_ext& operator=(
    const physical_device_vertex_attribute_divisor_properties_ext&
      other) noexcept
  {
    _next = other._next;
    _max_vertex_attrib_divisor = other._max_vertex_attrib_divisor;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_vertex_attribute_divisor_properties_ext& operator=(
    physical_device_vertex_attribute_divisor_properties_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _max_vertex_attrib_divisor = std::move(other._max_vertex_attrib_divisor);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_vertex_attrib_divisor()
  {
    return _max_vertex_attrib_divisor;
  }

  constexpr const uint32_t& max_vertex_attrib_divisor() const
  {
    return _max_vertex_attrib_divisor;
  }

  void max_vertex_attrib_divisor(uint32_t new_max_vertex_attrib_divisor)
  {
    _max_vertex_attrib_divisor = new_max_vertex_attrib_divisor;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_vertex_attribute_divisor_properties_ext;
  void* _next = nullptr;
  /// max value of vertex attribute divisor
  uint32_t _max_vertex_attrib_divisor = 0;
};
static_assert(sizeof(physical_device_vertex_attribute_divisor_properties_ext) ==
                sizeof(::VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkVertexInputBindingDivisorDescriptionEXT.
class vertex_input_binding_divisor_description_ext
{
public:
  /// Default constructor.
  constexpr vertex_input_binding_divisor_description_ext() = default;

  /// Constructor.
  constexpr vertex_input_binding_divisor_description_ext(
    uint32_t initial_binding, uint32_t initial_divisor) noexcept
  : _binding(std::move(initial_binding)), _divisor(std::move(initial_divisor))
  {
  }

  /// Copy constructor.
  constexpr vertex_input_binding_divisor_description_ext(
    const vertex_input_binding_divisor_description_ext& other) = default;

  /// Move constructor.
  constexpr vertex_input_binding_divisor_description_ext(
    vertex_input_binding_divisor_description_ext&& other) = default;

  /// Copy assignment operator.
  constexpr vertex_input_binding_divisor_description_ext& operator=(
    const vertex_input_binding_divisor_description_ext& other) = default;

  /// Move assignment operator.
  constexpr vertex_input_binding_divisor_description_ext& operator=(
    vertex_input_binding_divisor_description_ext&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkVertexInputBindingDivisorDescriptionEXT&() const
  {
    return *reinterpret_cast<const VkVertexInputBindingDivisorDescriptionEXT*>(
      this);
  }

  uint32_t& binding()
  {
    return _binding;
  }

  constexpr const uint32_t& binding() const
  {
    return _binding;
  }

  void binding(uint32_t new_binding)
  {
    _binding = new_binding;
  }

  uint32_t& divisor()
  {
    return _divisor;
  }

  constexpr const uint32_t& divisor() const
  {
    return _divisor;
  }

  void divisor(uint32_t new_divisor)
  {
    _divisor = new_divisor;
  }

private:
  uint32_t _binding = 0;
  uint32_t _divisor = 0;
};
static_assert(sizeof(vertex_input_binding_divisor_description_ext) ==
                sizeof(::VkVertexInputBindingDivisorDescriptionEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPipelineVertexInputDivisorStateCreateInfoEXT.
class pipeline_vertex_input_divisor_state_create_info_ext
{
public:
  /// Default constructor.
  constexpr pipeline_vertex_input_divisor_state_create_info_ext() = default;

  /// Constructor.
  constexpr pipeline_vertex_input_divisor_state_create_info_ext(
    const void* initial_next, uint32_t initial_vertex_binding_divisor_count,
    const vk::vertex_input_binding_divisor_description_ext*
      initial_vertex_binding_divisors) noexcept
  : _next(std::move(initial_next)),
    _vertex_binding_divisor_count(
      std::move(initial_vertex_binding_divisor_count)),
    _vertex_binding_divisors(std::move(initial_vertex_binding_divisors))
  {
  }

  /// Copy constructor.
  constexpr pipeline_vertex_input_divisor_state_create_info_ext(
    const pipeline_vertex_input_divisor_state_create_info_ext& other) noexcept
  : _next(other._next),
    _vertex_binding_divisor_count(other._vertex_binding_divisor_count),
    _vertex_binding_divisors(other._vertex_binding_divisors)
  {
  }

  /// Move constructor.
  constexpr pipeline_vertex_input_divisor_state_create_info_ext(
    pipeline_vertex_input_divisor_state_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _vertex_binding_divisor_count(
      std::move(other._vertex_binding_divisor_count)),
    _vertex_binding_divisors(std::move(other._vertex_binding_divisors))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_vertex_input_divisor_state_create_info_ext& operator=(
    const pipeline_vertex_input_divisor_state_create_info_ext& other) noexcept
  {
    _next = other._next;
    _vertex_binding_divisor_count = other._vertex_binding_divisor_count;
    _vertex_binding_divisors = other._vertex_binding_divisors;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_vertex_input_divisor_state_create_info_ext& operator=(
    pipeline_vertex_input_divisor_state_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _vertex_binding_divisor_count =
      std::move(other._vertex_binding_divisor_count);
    _vertex_binding_divisors = std::move(other._vertex_binding_divisors);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineVertexInputDivisorStateCreateInfoEXT&() const
  {
    return *reinterpret_cast<
      const VkPipelineVertexInputDivisorStateCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& vertex_binding_divisor_count()
  {
    return _vertex_binding_divisor_count;
  }

  constexpr const uint32_t& vertex_binding_divisor_count() const
  {
    return _vertex_binding_divisor_count;
  }

  void vertex_binding_divisor_count(uint32_t new_vertex_binding_divisor_count)
  {
    _vertex_binding_divisor_count = new_vertex_binding_divisor_count;
  }

  const vk::vertex_input_binding_divisor_description_ext*
  vertex_binding_divisors()
  {
    return _vertex_binding_divisors;
  }

  constexpr const vk::vertex_input_binding_divisor_description_ext*
  vertex_binding_divisors() const
  {
    return _vertex_binding_divisors;
  }

  void vertex_binding_divisors(
    const vk::vertex_input_binding_divisor_description_ext*
      new_vertex_binding_divisors)
  {
    _vertex_binding_divisors = new_vertex_binding_divisors;
  }

  template <std::size_t Count>
  void vertex_binding_divisors(
    const std::array<vk::vertex_input_binding_divisor_description_ext, Count>&
      new_vertex_binding_divisors)
  {
    _vertex_binding_divisor_count =
      static_cast<uint32_t>(new_vertex_binding_divisors.size());
    _vertex_binding_divisors = new_vertex_binding_divisors.data();
  }

  void vertex_binding_divisors(
    const std::vector<vk::vertex_input_binding_divisor_description_ext>&
      new_vertex_binding_divisors)
  {
    _vertex_binding_divisor_count =
      static_cast<uint32_t>(new_vertex_binding_divisors.size());
    _vertex_binding_divisors = new_vertex_binding_divisors.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::pipeline_vertex_input_divisor_state_create_info_ext;
  const void* _next = nullptr;
  uint32_t _vertex_binding_divisor_count = 0;
  const vk::vertex_input_binding_divisor_description_ext*
    _vertex_binding_divisors = nullptr;
};
static_assert(sizeof(pipeline_vertex_input_divisor_state_create_info_ext) ==
                sizeof(::VkPipelineVertexInputDivisorStateCreateInfoEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT.
class physical_device_vertex_attribute_divisor_features_ext
{
public:
  /// Default constructor.
  constexpr physical_device_vertex_attribute_divisor_features_ext() = default;

  /// Constructor.
  constexpr physical_device_vertex_attribute_divisor_features_ext(
    void* initial_next, VkBool32 initial_vertex_attribute_instance_rate_divisor,
    VkBool32 initial_vertex_attribute_instance_rate_zero_divisor) noexcept
  : _next(std::move(initial_next)),
    _vertex_attribute_instance_rate_divisor(
      std::move(initial_vertex_attribute_instance_rate_divisor)),
    _vertex_attribute_instance_rate_zero_divisor(
      std::move(initial_vertex_attribute_instance_rate_zero_divisor))
  {
  }

  /// Copy constructor.
  constexpr physical_device_vertex_attribute_divisor_features_ext(
    const physical_device_vertex_attribute_divisor_features_ext& other) noexcept
  : _next(other._next),
    _vertex_attribute_instance_rate_divisor(
      other._vertex_attribute_instance_rate_divisor),
    _vertex_attribute_instance_rate_zero_divisor(
      other._vertex_attribute_instance_rate_zero_divisor)
  {
  }

  /// Move constructor.
  constexpr physical_device_vertex_attribute_divisor_features_ext(
    physical_device_vertex_attribute_divisor_features_ext&& other) noexcept
  : _next(std::move(other._next)),
    _vertex_attribute_instance_rate_divisor(
      std::move(other._vertex_attribute_instance_rate_divisor)),
    _vertex_attribute_instance_rate_zero_divisor(
      std::move(other._vertex_attribute_instance_rate_zero_divisor))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_vertex_attribute_divisor_features_ext& operator=(
    const physical_device_vertex_attribute_divisor_features_ext& other) noexcept
  {
    _next = other._next;
    _vertex_attribute_instance_rate_divisor =
      other._vertex_attribute_instance_rate_divisor;
    _vertex_attribute_instance_rate_zero_divisor =
      other._vertex_attribute_instance_rate_zero_divisor;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_vertex_attribute_divisor_features_ext& operator=(
    physical_device_vertex_attribute_divisor_features_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _vertex_attribute_instance_rate_divisor =
      std::move(other._vertex_attribute_instance_rate_divisor);
    _vertex_attribute_instance_rate_zero_divisor =
      std::move(other._vertex_attribute_instance_rate_zero_divisor);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& vertex_attribute_instance_rate_divisor()
  {
    return _vertex_attribute_instance_rate_divisor;
  }

  constexpr const VkBool32& vertex_attribute_instance_rate_divisor() const
  {
    return _vertex_attribute_instance_rate_divisor;
  }

  void vertex_attribute_instance_rate_divisor(
    VkBool32 new_vertex_attribute_instance_rate_divisor)
  {
    _vertex_attribute_instance_rate_divisor =
      new_vertex_attribute_instance_rate_divisor;
  }

  VkBool32& vertex_attribute_instance_rate_zero_divisor()
  {
    return _vertex_attribute_instance_rate_zero_divisor;
  }

  constexpr const VkBool32& vertex_attribute_instance_rate_zero_divisor() const
  {
    return _vertex_attribute_instance_rate_zero_divisor;
  }

  void vertex_attribute_instance_rate_zero_divisor(
    VkBool32 new_vertex_attribute_instance_rate_zero_divisor)
  {
    _vertex_attribute_instance_rate_zero_divisor =
      new_vertex_attribute_instance_rate_zero_divisor;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_vertex_attribute_divisor_features_ext;
  void* _next = nullptr;
  VkBool32 _vertex_attribute_instance_rate_divisor = VK_FALSE;
  VkBool32 _vertex_attribute_instance_rate_zero_divisor = VK_FALSE;
};
static_assert(sizeof(physical_device_vertex_attribute_divisor_features_ext) ==
                sizeof(::VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceComputeShaderDerivativesFeaturesNV.
class physical_device_compute_shader_derivatives_features_nv
{
public:
  /// Default constructor.
  constexpr physical_device_compute_shader_derivatives_features_nv() = default;

  /// Constructor.
  constexpr physical_device_compute_shader_derivatives_features_nv(
    void* initial_next, VkBool32 initial_compute_derivative_group_quads,
    VkBool32 initial_compute_derivative_group_linear) noexcept
  : _next(std::move(initial_next)),
    _compute_derivative_group_quads(
      std::move(initial_compute_derivative_group_quads)),
    _compute_derivative_group_linear(
      std::move(initial_compute_derivative_group_linear))
  {
  }

  /// Copy constructor.
  constexpr physical_device_compute_shader_derivatives_features_nv(
    const physical_device_compute_shader_derivatives_features_nv&
      other) noexcept
  : _next(other._next),
    _compute_derivative_group_quads(other._compute_derivative_group_quads),
    _compute_derivative_group_linear(other._compute_derivative_group_linear)
  {
  }

  /// Move constructor.
  constexpr physical_device_compute_shader_derivatives_features_nv(
    physical_device_compute_shader_derivatives_features_nv&& other) noexcept
  : _next(std::move(other._next)),
    _compute_derivative_group_quads(
      std::move(other._compute_derivative_group_quads)),
    _compute_derivative_group_linear(
      std::move(other._compute_derivative_group_linear))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_compute_shader_derivatives_features_nv& operator=(
    const physical_device_compute_shader_derivatives_features_nv&
      other) noexcept
  {
    _next = other._next;
    _compute_derivative_group_quads = other._compute_derivative_group_quads;
    _compute_derivative_group_linear = other._compute_derivative_group_linear;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_compute_shader_derivatives_features_nv& operator=(
    physical_device_compute_shader_derivatives_features_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _compute_derivative_group_quads =
      std::move(other._compute_derivative_group_quads);
    _compute_derivative_group_linear =
      std::move(other._compute_derivative_group_linear);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceComputeShaderDerivativesFeaturesNV&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceComputeShaderDerivativesFeaturesNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& compute_derivative_group_quads()
  {
    return _compute_derivative_group_quads;
  }

  constexpr const VkBool32& compute_derivative_group_quads() const
  {
    return _compute_derivative_group_quads;
  }

  void compute_derivative_group_quads(
    VkBool32 new_compute_derivative_group_quads)
  {
    _compute_derivative_group_quads = new_compute_derivative_group_quads;
  }

  VkBool32& compute_derivative_group_linear()
  {
    return _compute_derivative_group_linear;
  }

  constexpr const VkBool32& compute_derivative_group_linear() const
  {
    return _compute_derivative_group_linear;
  }

  void compute_derivative_group_linear(
    VkBool32 new_compute_derivative_group_linear)
  {
    _compute_derivative_group_linear = new_compute_derivative_group_linear;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_compute_shader_derivatives_features_nv;
  void* _next = nullptr;
  VkBool32 _compute_derivative_group_quads = VK_FALSE;
  VkBool32 _compute_derivative_group_linear = VK_FALSE;
};
static_assert(sizeof(physical_device_compute_shader_derivatives_features_nv) ==
                sizeof(::VkPhysicalDeviceComputeShaderDerivativesFeaturesNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceMeshShaderFeaturesNV.
class physical_device_mesh_shader_features_nv
{
public:
  /// Default constructor.
  constexpr physical_device_mesh_shader_features_nv() = default;

  /// Constructor.
  constexpr physical_device_mesh_shader_features_nv(
    void* initial_next, VkBool32 initial_task_shader,
    VkBool32 initial_mesh_shader) noexcept
  : _next(std::move(initial_next)),
    _task_shader(std::move(initial_task_shader)),
    _mesh_shader(std::move(initial_mesh_shader))
  {
  }

  /// Copy constructor.
  constexpr physical_device_mesh_shader_features_nv(
    const physical_device_mesh_shader_features_nv& other) noexcept
  : _next(other._next),
    _task_shader(other._task_shader),
    _mesh_shader(other._mesh_shader)
  {
  }

  /// Move constructor.
  constexpr physical_device_mesh_shader_features_nv(
    physical_device_mesh_shader_features_nv&& other) noexcept
  : _next(std::move(other._next)),
    _task_shader(std::move(other._task_shader)),
    _mesh_shader(std::move(other._mesh_shader))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_mesh_shader_features_nv& operator=(
    const physical_device_mesh_shader_features_nv& other) noexcept
  {
    _next = other._next;
    _task_shader = other._task_shader;
    _mesh_shader = other._mesh_shader;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_mesh_shader_features_nv& operator=(
    physical_device_mesh_shader_features_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _task_shader = std::move(other._task_shader);
    _mesh_shader = std::move(other._mesh_shader);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceMeshShaderFeaturesNV&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceMeshShaderFeaturesNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& task_shader()
  {
    return _task_shader;
  }

  constexpr const VkBool32& task_shader() const
  {
    return _task_shader;
  }

  void task_shader(VkBool32 new_task_shader)
  {
    _task_shader = new_task_shader;
  }

  VkBool32& mesh_shader()
  {
    return _mesh_shader;
  }

  constexpr const VkBool32& mesh_shader() const
  {
    return _mesh_shader;
  }

  void mesh_shader(VkBool32 new_mesh_shader)
  {
    _mesh_shader = new_mesh_shader;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_mesh_shader_features_nv;
  void* _next = nullptr;
  VkBool32 _task_shader = VK_FALSE;
  VkBool32 _mesh_shader = VK_FALSE;
};
static_assert(sizeof(physical_device_mesh_shader_features_nv) ==
                sizeof(::VkPhysicalDeviceMeshShaderFeaturesNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceMeshShaderPropertiesNV.
class physical_device_mesh_shader_properties_nv
{
public:
  /// Default constructor.
  constexpr physical_device_mesh_shader_properties_nv() = default;

  /// Constructor.
  constexpr physical_device_mesh_shader_properties_nv(
    void* initial_next, uint32_t initial_max_draw_mesh_tasks_count,
    uint32_t initial_max_task_work_group_invocations,
    std::array<uint32_t, 3> initial_max_task_work_group_size,
    uint32_t initial_max_task_total_memory_size,
    uint32_t initial_max_task_output_count,
    uint32_t initial_max_mesh_work_group_invocations,
    std::array<uint32_t, 3> initial_max_mesh_work_group_size,
    uint32_t initial_max_mesh_total_memory_size,
    uint32_t initial_max_mesh_output_vertices,
    uint32_t initial_max_mesh_output_primitives,
    uint32_t initial_max_mesh_multiview_view_count,
    uint32_t initial_mesh_output_per_vertex_granularity,
    uint32_t initial_mesh_output_per_primitive_granularity) noexcept
  : _next(std::move(initial_next)),
    _max_draw_mesh_tasks_count(std::move(initial_max_draw_mesh_tasks_count)),
    _max_task_work_group_invocations(
      std::move(initial_max_task_work_group_invocations)),
    _max_task_work_group_size(std::move(initial_max_task_work_group_size)),
    _max_task_total_memory_size(std::move(initial_max_task_total_memory_size)),
    _max_task_output_count(std::move(initial_max_task_output_count)),
    _max_mesh_work_group_invocations(
      std::move(initial_max_mesh_work_group_invocations)),
    _max_mesh_work_group_size(std::move(initial_max_mesh_work_group_size)),
    _max_mesh_total_memory_size(std::move(initial_max_mesh_total_memory_size)),
    _max_mesh_output_vertices(std::move(initial_max_mesh_output_vertices)),
    _max_mesh_output_primitives(std::move(initial_max_mesh_output_primitives)),
    _max_mesh_multiview_view_count(
      std::move(initial_max_mesh_multiview_view_count)),
    _mesh_output_per_vertex_granularity(
      std::move(initial_mesh_output_per_vertex_granularity)),
    _mesh_output_per_primitive_granularity(
      std::move(initial_mesh_output_per_primitive_granularity))
  {
  }

  /// Copy constructor.
  constexpr physical_device_mesh_shader_properties_nv(
    const physical_device_mesh_shader_properties_nv& other) noexcept
  : _next(other._next),
    _max_draw_mesh_tasks_count(other._max_draw_mesh_tasks_count),
    _max_task_work_group_invocations(other._max_task_work_group_invocations),
    _max_task_work_group_size(other._max_task_work_group_size),
    _max_task_total_memory_size(other._max_task_total_memory_size),
    _max_task_output_count(other._max_task_output_count),
    _max_mesh_work_group_invocations(other._max_mesh_work_group_invocations),
    _max_mesh_work_group_size(other._max_mesh_work_group_size),
    _max_mesh_total_memory_size(other._max_mesh_total_memory_size),
    _max_mesh_output_vertices(other._max_mesh_output_vertices),
    _max_mesh_output_primitives(other._max_mesh_output_primitives),
    _max_mesh_multiview_view_count(other._max_mesh_multiview_view_count),
    _mesh_output_per_vertex_granularity(
      other._mesh_output_per_vertex_granularity),
    _mesh_output_per_primitive_granularity(
      other._mesh_output_per_primitive_granularity)
  {
  }

  /// Move constructor.
  constexpr physical_device_mesh_shader_properties_nv(
    physical_device_mesh_shader_properties_nv&& other) noexcept
  : _next(std::move(other._next)),
    _max_draw_mesh_tasks_count(std::move(other._max_draw_mesh_tasks_count)),
    _max_task_work_group_invocations(
      std::move(other._max_task_work_group_invocations)),
    _max_task_work_group_size(std::move(other._max_task_work_group_size)),
    _max_task_total_memory_size(std::move(other._max_task_total_memory_size)),
    _max_task_output_count(std::move(other._max_task_output_count)),
    _max_mesh_work_group_invocations(
      std::move(other._max_mesh_work_group_invocations)),
    _max_mesh_work_group_size(std::move(other._max_mesh_work_group_size)),
    _max_mesh_total_memory_size(std::move(other._max_mesh_total_memory_size)),
    _max_mesh_output_vertices(std::move(other._max_mesh_output_vertices)),
    _max_mesh_output_primitives(std::move(other._max_mesh_output_primitives)),
    _max_mesh_multiview_view_count(
      std::move(other._max_mesh_multiview_view_count)),
    _mesh_output_per_vertex_granularity(
      std::move(other._mesh_output_per_vertex_granularity)),
    _mesh_output_per_primitive_granularity(
      std::move(other._mesh_output_per_primitive_granularity))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_mesh_shader_properties_nv& operator=(
    const physical_device_mesh_shader_properties_nv& other) noexcept
  {
    _next = other._next;
    _max_draw_mesh_tasks_count = other._max_draw_mesh_tasks_count;
    _max_task_work_group_invocations = other._max_task_work_group_invocations;
    _max_task_work_group_size = other._max_task_work_group_size;
    _max_task_total_memory_size = other._max_task_total_memory_size;
    _max_task_output_count = other._max_task_output_count;
    _max_mesh_work_group_invocations = other._max_mesh_work_group_invocations;
    _max_mesh_work_group_size = other._max_mesh_work_group_size;
    _max_mesh_total_memory_size = other._max_mesh_total_memory_size;
    _max_mesh_output_vertices = other._max_mesh_output_vertices;
    _max_mesh_output_primitives = other._max_mesh_output_primitives;
    _max_mesh_multiview_view_count = other._max_mesh_multiview_view_count;
    _mesh_output_per_vertex_granularity =
      other._mesh_output_per_vertex_granularity;
    _mesh_output_per_primitive_granularity =
      other._mesh_output_per_primitive_granularity;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_mesh_shader_properties_nv& operator=(
    physical_device_mesh_shader_properties_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _max_draw_mesh_tasks_count = std::move(other._max_draw_mesh_tasks_count);
    _max_task_work_group_invocations =
      std::move(other._max_task_work_group_invocations);
    _max_task_work_group_size = std::move(other._max_task_work_group_size);
    _max_task_total_memory_size = std::move(other._max_task_total_memory_size);
    _max_task_output_count = std::move(other._max_task_output_count);
    _max_mesh_work_group_invocations =
      std::move(other._max_mesh_work_group_invocations);
    _max_mesh_work_group_size = std::move(other._max_mesh_work_group_size);
    _max_mesh_total_memory_size = std::move(other._max_mesh_total_memory_size);
    _max_mesh_output_vertices = std::move(other._max_mesh_output_vertices);
    _max_mesh_output_primitives = std::move(other._max_mesh_output_primitives);
    _max_mesh_multiview_view_count =
      std::move(other._max_mesh_multiview_view_count);
    _mesh_output_per_vertex_granularity =
      std::move(other._mesh_output_per_vertex_granularity);
    _mesh_output_per_primitive_granularity =
      std::move(other._mesh_output_per_primitive_granularity);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceMeshShaderPropertiesNV&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceMeshShaderPropertiesNV*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& max_draw_mesh_tasks_count()
  {
    return _max_draw_mesh_tasks_count;
  }

  constexpr const uint32_t& max_draw_mesh_tasks_count() const
  {
    return _max_draw_mesh_tasks_count;
  }

  void max_draw_mesh_tasks_count(uint32_t new_max_draw_mesh_tasks_count)
  {
    _max_draw_mesh_tasks_count = new_max_draw_mesh_tasks_count;
  }

  uint32_t& max_task_work_group_invocations()
  {
    return _max_task_work_group_invocations;
  }

  constexpr const uint32_t& max_task_work_group_invocations() const
  {
    return _max_task_work_group_invocations;
  }

  void max_task_work_group_invocations(
    uint32_t new_max_task_work_group_invocations)
  {
    _max_task_work_group_invocations = new_max_task_work_group_invocations;
  }

  std::array<uint32_t, 3>& max_task_work_group_size()
  {
    return _max_task_work_group_size;
  }

  constexpr const std::array<uint32_t, 3>& max_task_work_group_size() const
  {
    return _max_task_work_group_size;
  }

  void max_task_work_group_size(
    std::array<uint32_t, 3> new_max_task_work_group_size)
  {
    _max_task_work_group_size = new_max_task_work_group_size;
  }

  uint32_t& max_task_total_memory_size()
  {
    return _max_task_total_memory_size;
  }

  constexpr const uint32_t& max_task_total_memory_size() const
  {
    return _max_task_total_memory_size;
  }

  void max_task_total_memory_size(uint32_t new_max_task_total_memory_size)
  {
    _max_task_total_memory_size = new_max_task_total_memory_size;
  }

  uint32_t& max_task_output_count()
  {
    return _max_task_output_count;
  }

  constexpr const uint32_t& max_task_output_count() const
  {
    return _max_task_output_count;
  }

  void max_task_output_count(uint32_t new_max_task_output_count)
  {
    _max_task_output_count = new_max_task_output_count;
  }

  uint32_t& max_mesh_work_group_invocations()
  {
    return _max_mesh_work_group_invocations;
  }

  constexpr const uint32_t& max_mesh_work_group_invocations() const
  {
    return _max_mesh_work_group_invocations;
  }

  void max_mesh_work_group_invocations(
    uint32_t new_max_mesh_work_group_invocations)
  {
    _max_mesh_work_group_invocations = new_max_mesh_work_group_invocations;
  }

  std::array<uint32_t, 3>& max_mesh_work_group_size()
  {
    return _max_mesh_work_group_size;
  }

  constexpr const std::array<uint32_t, 3>& max_mesh_work_group_size() const
  {
    return _max_mesh_work_group_size;
  }

  void max_mesh_work_group_size(
    std::array<uint32_t, 3> new_max_mesh_work_group_size)
  {
    _max_mesh_work_group_size = new_max_mesh_work_group_size;
  }

  uint32_t& max_mesh_total_memory_size()
  {
    return _max_mesh_total_memory_size;
  }

  constexpr const uint32_t& max_mesh_total_memory_size() const
  {
    return _max_mesh_total_memory_size;
  }

  void max_mesh_total_memory_size(uint32_t new_max_mesh_total_memory_size)
  {
    _max_mesh_total_memory_size = new_max_mesh_total_memory_size;
  }

  uint32_t& max_mesh_output_vertices()
  {
    return _max_mesh_output_vertices;
  }

  constexpr const uint32_t& max_mesh_output_vertices() const
  {
    return _max_mesh_output_vertices;
  }

  void max_mesh_output_vertices(uint32_t new_max_mesh_output_vertices)
  {
    _max_mesh_output_vertices = new_max_mesh_output_vertices;
  }

  uint32_t& max_mesh_output_primitives()
  {
    return _max_mesh_output_primitives;
  }

  constexpr const uint32_t& max_mesh_output_primitives() const
  {
    return _max_mesh_output_primitives;
  }

  void max_mesh_output_primitives(uint32_t new_max_mesh_output_primitives)
  {
    _max_mesh_output_primitives = new_max_mesh_output_primitives;
  }

  uint32_t& max_mesh_multiview_view_count()
  {
    return _max_mesh_multiview_view_count;
  }

  constexpr const uint32_t& max_mesh_multiview_view_count() const
  {
    return _max_mesh_multiview_view_count;
  }

  void max_mesh_multiview_view_count(uint32_t new_max_mesh_multiview_view_count)
  {
    _max_mesh_multiview_view_count = new_max_mesh_multiview_view_count;
  }

  uint32_t& mesh_output_per_vertex_granularity()
  {
    return _mesh_output_per_vertex_granularity;
  }

  constexpr const uint32_t& mesh_output_per_vertex_granularity() const
  {
    return _mesh_output_per_vertex_granularity;
  }

  void mesh_output_per_vertex_granularity(
    uint32_t new_mesh_output_per_vertex_granularity)
  {
    _mesh_output_per_vertex_granularity =
      new_mesh_output_per_vertex_granularity;
  }

  uint32_t& mesh_output_per_primitive_granularity()
  {
    return _mesh_output_per_primitive_granularity;
  }

  constexpr const uint32_t& mesh_output_per_primitive_granularity() const
  {
    return _mesh_output_per_primitive_granularity;
  }

  void mesh_output_per_primitive_granularity(
    uint32_t new_mesh_output_per_primitive_granularity)
  {
    _mesh_output_per_primitive_granularity =
      new_mesh_output_per_primitive_granularity;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_mesh_shader_properties_nv;
  void* _next = nullptr;
  uint32_t _max_draw_mesh_tasks_count = 0;
  uint32_t _max_task_work_group_invocations = 0;
  std::array<uint32_t, 3> _max_task_work_group_size = {};
  uint32_t _max_task_total_memory_size = 0;
  uint32_t _max_task_output_count = 0;
  uint32_t _max_mesh_work_group_invocations = 0;
  std::array<uint32_t, 3> _max_mesh_work_group_size = {};
  uint32_t _max_mesh_total_memory_size = 0;
  uint32_t _max_mesh_output_vertices = 0;
  uint32_t _max_mesh_output_primitives = 0;
  uint32_t _max_mesh_multiview_view_count = 0;
  uint32_t _mesh_output_per_vertex_granularity = 0;
  uint32_t _mesh_output_per_primitive_granularity = 0;
};
static_assert(sizeof(physical_device_mesh_shader_properties_nv) ==
                sizeof(::VkPhysicalDeviceMeshShaderPropertiesNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkDrawMeshTasksIndirectCommandNV.
class draw_mesh_tasks_indirect_command_nv
{
public:
  /// Default constructor.
  constexpr draw_mesh_tasks_indirect_command_nv() = default;

  /// Constructor.
  constexpr draw_mesh_tasks_indirect_command_nv(
    uint32_t initial_task_count, uint32_t initial_first_task) noexcept
  : _task_count(std::move(initial_task_count)),
    _first_task(std::move(initial_first_task))
  {
  }

  /// Copy constructor.
  constexpr draw_mesh_tasks_indirect_command_nv(
    const draw_mesh_tasks_indirect_command_nv& other) = default;

  /// Move constructor.
  constexpr draw_mesh_tasks_indirect_command_nv(
    draw_mesh_tasks_indirect_command_nv&& other) = default;

  /// Copy assignment operator.
  constexpr draw_mesh_tasks_indirect_command_nv& operator=(
    const draw_mesh_tasks_indirect_command_nv& other) = default;

  /// Move assignment operator.
  constexpr draw_mesh_tasks_indirect_command_nv& operator=(
    draw_mesh_tasks_indirect_command_nv&& other) = default;

  /// Conversion operator to original Vulkan type.
  operator const VkDrawMeshTasksIndirectCommandNV&() const
  {
    return *reinterpret_cast<const VkDrawMeshTasksIndirectCommandNV*>(this);
  }

  uint32_t& task_count()
  {
    return _task_count;
  }

  constexpr const uint32_t& task_count() const
  {
    return _task_count;
  }

  void task_count(uint32_t new_task_count)
  {
    _task_count = new_task_count;
  }

  uint32_t& first_task()
  {
    return _first_task;
  }

  constexpr const uint32_t& first_task() const
  {
    return _first_task;
  }

  void first_task(uint32_t new_first_task)
  {
    _first_task = new_first_task;
  }

private:
  uint32_t _task_count = 0;
  uint32_t _first_task = 0;
};
static_assert(sizeof(draw_mesh_tasks_indirect_command_nv) ==
                sizeof(::VkDrawMeshTasksIndirectCommandNV),
              "struct and wrapper have different size!");

inline void cmd_draw_mesh_tasks_nv(VkCommandBuffer command_buffer,
                                   uint32_t task_count, uint32_t first_task)
{
  vkCmdDrawMeshTasksNV(static_cast<VkCommandBuffer>(command_buffer),
                       static_cast<uint32_t>(task_count),
                       static_cast<uint32_t>(first_task));
}
inline void cmd_draw_mesh_tasks_indirect_nv(VkCommandBuffer command_buffer,
                                            VkBuffer buffer,
                                            VkDeviceSize offset,
                                            uint32_t draw_count,
                                            uint32_t stride)
{
  vkCmdDrawMeshTasksIndirectNV(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceSize>(offset), static_cast<uint32_t>(draw_count),
    static_cast<uint32_t>(stride));
}
inline void cmd_draw_mesh_tasks_indirect_count_nv(
  VkCommandBuffer command_buffer, VkBuffer buffer, VkDeviceSize offset,
  VkBuffer count_buffer, VkDeviceSize count_buffer_offset,
  uint32_t max_draw_count, uint32_t stride)
{
  vkCmdDrawMeshTasksIndirectCountNV(
    static_cast<VkCommandBuffer>(command_buffer), static_cast<VkBuffer>(buffer),
    static_cast<VkDeviceSize>(offset), static_cast<VkBuffer>(count_buffer),
    static_cast<VkDeviceSize>(count_buffer_offset),
    static_cast<uint32_t>(max_draw_count), static_cast<uint32_t>(stride));
}

/// Enhanced replacement type for
/// VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV.
class physical_device_fragment_shader_barycentric_features_nv
{
public:
  /// Default constructor.
  constexpr physical_device_fragment_shader_barycentric_features_nv() = default;

  /// Constructor.
  constexpr physical_device_fragment_shader_barycentric_features_nv(
    void* initial_next, VkBool32 initial_fragment_shader_barycentric) noexcept
  : _next(std::move(initial_next)),
    _fragment_shader_barycentric(std::move(initial_fragment_shader_barycentric))
  {
  }

  /// Copy constructor.
  constexpr physical_device_fragment_shader_barycentric_features_nv(
    const physical_device_fragment_shader_barycentric_features_nv&
      other) noexcept
  : _next(other._next),
    _fragment_shader_barycentric(other._fragment_shader_barycentric)
  {
  }

  /// Move constructor.
  constexpr physical_device_fragment_shader_barycentric_features_nv(
    physical_device_fragment_shader_barycentric_features_nv&& other) noexcept
  : _next(std::move(other._next)),
    _fragment_shader_barycentric(std::move(other._fragment_shader_barycentric))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_fragment_shader_barycentric_features_nv& operator=(
    const physical_device_fragment_shader_barycentric_features_nv&
      other) noexcept
  {
    _next = other._next;
    _fragment_shader_barycentric = other._fragment_shader_barycentric;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_fragment_shader_barycentric_features_nv& operator=(
    physical_device_fragment_shader_barycentric_features_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _fragment_shader_barycentric =
      std::move(other._fragment_shader_barycentric);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& fragment_shader_barycentric()
  {
    return _fragment_shader_barycentric;
  }

  constexpr const VkBool32& fragment_shader_barycentric() const
  {
    return _fragment_shader_barycentric;
  }

  void fragment_shader_barycentric(VkBool32 new_fragment_shader_barycentric)
  {
    _fragment_shader_barycentric = new_fragment_shader_barycentric;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_fragment_shader_barycentric_features_nv;
  void* _next = nullptr;
  VkBool32 _fragment_shader_barycentric = VK_FALSE;
};
static_assert(sizeof(physical_device_fragment_shader_barycentric_features_nv) ==
                sizeof(::VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPhysicalDeviceShaderImageFootprintFeaturesNV.
class physical_device_shader_image_footprint_features_nv
{
public:
  /// Default constructor.
  constexpr physical_device_shader_image_footprint_features_nv() = default;

  /// Constructor.
  constexpr physical_device_shader_image_footprint_features_nv(
    void* initial_next, VkBool32 initial_image_footprint) noexcept
  : _next(std::move(initial_next)),
    _image_footprint(std::move(initial_image_footprint))
  {
  }

  /// Copy constructor.
  constexpr physical_device_shader_image_footprint_features_nv(
    const physical_device_shader_image_footprint_features_nv& other) noexcept
  : _next(other._next), _image_footprint(other._image_footprint)
  {
  }

  /// Move constructor.
  constexpr physical_device_shader_image_footprint_features_nv(
    physical_device_shader_image_footprint_features_nv&& other) noexcept
  : _next(std::move(other._next)),
    _image_footprint(std::move(other._image_footprint))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_shader_image_footprint_features_nv& operator=(
    const physical_device_shader_image_footprint_features_nv& other) noexcept
  {
    _next = other._next;
    _image_footprint = other._image_footprint;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_shader_image_footprint_features_nv& operator=(
    physical_device_shader_image_footprint_features_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _image_footprint = std::move(other._image_footprint);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceShaderImageFootprintFeaturesNV&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceShaderImageFootprintFeaturesNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& image_footprint()
  {
    return _image_footprint;
  }

  constexpr const VkBool32& image_footprint() const
  {
    return _image_footprint;
  }

  void image_footprint(VkBool32 new_image_footprint)
  {
    _image_footprint = new_image_footprint;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_shader_image_footprint_features_nv;
  void* _next = nullptr;
  VkBool32 _image_footprint = VK_FALSE;
};
static_assert(sizeof(physical_device_shader_image_footprint_features_nv) ==
                sizeof(::VkPhysicalDeviceShaderImageFootprintFeaturesNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for
/// VkPipelineViewportExclusiveScissorStateCreateInfoNV.
class pipeline_viewport_exclusive_scissor_state_create_info_nv
{
public:
  /// Default constructor.
  constexpr pipeline_viewport_exclusive_scissor_state_create_info_nv() =
    default;

  /// Constructor.
  constexpr pipeline_viewport_exclusive_scissor_state_create_info_nv(
    const void* initial_next, uint32_t initial_exclusive_scissor_count,
    const vk::rect_2d* initial_exclusive_scissors) noexcept
  : _next(std::move(initial_next)),
    _exclusive_scissor_count(std::move(initial_exclusive_scissor_count)),
    _exclusive_scissors(std::move(initial_exclusive_scissors))
  {
  }

  /// Copy constructor.
  constexpr pipeline_viewport_exclusive_scissor_state_create_info_nv(
    const pipeline_viewport_exclusive_scissor_state_create_info_nv&
      other) noexcept
  : _next(other._next),
    _exclusive_scissor_count(other._exclusive_scissor_count),
    _exclusive_scissors(other._exclusive_scissors)
  {
  }

  /// Move constructor.
  constexpr pipeline_viewport_exclusive_scissor_state_create_info_nv(
    pipeline_viewport_exclusive_scissor_state_create_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _exclusive_scissor_count(std::move(other._exclusive_scissor_count)),
    _exclusive_scissors(std::move(other._exclusive_scissors))
  {
  }

  /// Copy assignment operator.
  constexpr pipeline_viewport_exclusive_scissor_state_create_info_nv& operator=(
    const pipeline_viewport_exclusive_scissor_state_create_info_nv&
      other) noexcept
  {
    _next = other._next;
    _exclusive_scissor_count = other._exclusive_scissor_count;
    _exclusive_scissors = other._exclusive_scissors;
    return *this;
  }

  /// Move assignment operator.
  constexpr pipeline_viewport_exclusive_scissor_state_create_info_nv& operator=(
    pipeline_viewport_exclusive_scissor_state_create_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _exclusive_scissor_count = std::move(other._exclusive_scissor_count);
    _exclusive_scissors = std::move(other._exclusive_scissors);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPipelineViewportExclusiveScissorStateCreateInfoNV&() const
  {
    return *reinterpret_cast<
      const VkPipelineViewportExclusiveScissorStateCreateInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& exclusive_scissor_count()
  {
    return _exclusive_scissor_count;
  }

  constexpr const uint32_t& exclusive_scissor_count() const
  {
    return _exclusive_scissor_count;
  }

  void exclusive_scissor_count(uint32_t new_exclusive_scissor_count)
  {
    _exclusive_scissor_count = new_exclusive_scissor_count;
  }

  const vk::rect_2d* exclusive_scissors()
  {
    return _exclusive_scissors;
  }

  constexpr const vk::rect_2d* exclusive_scissors() const
  {
    return _exclusive_scissors;
  }

  void exclusive_scissors(const vk::rect_2d* new_exclusive_scissors)
  {
    _exclusive_scissors = new_exclusive_scissors;
  }

  template <std::size_t Count>
  void exclusive_scissors(
    const std::array<vk::rect_2d, Count>& new_exclusive_scissors)
  {
    _exclusive_scissor_count =
      static_cast<uint32_t>(new_exclusive_scissors.size());
    _exclusive_scissors = new_exclusive_scissors.data();
  }

  void exclusive_scissors(
    const std::vector<vk::rect_2d>& new_exclusive_scissors)
  {
    _exclusive_scissor_count =
      static_cast<uint32_t>(new_exclusive_scissors.size());
    _exclusive_scissors = new_exclusive_scissors.data();
  }

private:
  const vk::structure_type _structure_type = vk::structure_type::
    pipeline_viewport_exclusive_scissor_state_create_info_nv;
  const void* _next = nullptr;
  uint32_t _exclusive_scissor_count = 0;
  const vk::rect_2d* _exclusive_scissors = nullptr;
};
static_assert(
  sizeof(pipeline_viewport_exclusive_scissor_state_create_info_nv) ==
    sizeof(::VkPipelineViewportExclusiveScissorStateCreateInfoNV),
  "struct and wrapper have different size!");

/// Enhanced replacement type for VkPhysicalDeviceExclusiveScissorFeaturesNV.
class physical_device_exclusive_scissor_features_nv
{
public:
  /// Default constructor.
  constexpr physical_device_exclusive_scissor_features_nv() = default;

  /// Constructor.
  constexpr physical_device_exclusive_scissor_features_nv(
    void* initial_next, VkBool32 initial_exclusive_scissor) noexcept
  : _next(std::move(initial_next)),
    _exclusive_scissor(std::move(initial_exclusive_scissor))
  {
  }

  /// Copy constructor.
  constexpr physical_device_exclusive_scissor_features_nv(
    const physical_device_exclusive_scissor_features_nv& other) noexcept
  : _next(other._next), _exclusive_scissor(other._exclusive_scissor)
  {
  }

  /// Move constructor.
  constexpr physical_device_exclusive_scissor_features_nv(
    physical_device_exclusive_scissor_features_nv&& other) noexcept
  : _next(std::move(other._next)),
    _exclusive_scissor(std::move(other._exclusive_scissor))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_exclusive_scissor_features_nv& operator=(
    const physical_device_exclusive_scissor_features_nv& other) noexcept
  {
    _next = other._next;
    _exclusive_scissor = other._exclusive_scissor;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_exclusive_scissor_features_nv& operator=(
    physical_device_exclusive_scissor_features_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _exclusive_scissor = std::move(other._exclusive_scissor);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceExclusiveScissorFeaturesNV&() const
  {
    return *reinterpret_cast<const VkPhysicalDeviceExclusiveScissorFeaturesNV*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& exclusive_scissor()
  {
    return _exclusive_scissor;
  }

  constexpr const VkBool32& exclusive_scissor() const
  {
    return _exclusive_scissor;
  }

  void exclusive_scissor(VkBool32 new_exclusive_scissor)
  {
    _exclusive_scissor = new_exclusive_scissor;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_exclusive_scissor_features_nv;
  void* _next = nullptr;
  VkBool32 _exclusive_scissor = VK_FALSE;
};
static_assert(sizeof(physical_device_exclusive_scissor_features_nv) ==
                sizeof(::VkPhysicalDeviceExclusiveScissorFeaturesNV),
              "struct and wrapper have different size!");

inline void cmd_set_exclusive_scissor_nv(VkCommandBuffer command_buffer,
                                         uint32_t first_exclusive_scissor,
                                         uint32_t exclusive_scissor_count,
                                         const vk::rect_2d* exclusive_scissors)
{
  vkCmdSetExclusiveScissorNV(
    static_cast<VkCommandBuffer>(command_buffer),
    static_cast<uint32_t>(first_exclusive_scissor),
    static_cast<uint32_t>(exclusive_scissor_count),
    reinterpret_cast<const VkRect2D*>(exclusive_scissors));
}

/// Enhanced replacement type for VkQueueFamilyCheckpointPropertiesNV.
class queue_family_checkpoint_properties_nv
{
public:
  /// Default constructor.
  constexpr queue_family_checkpoint_properties_nv() = default;

  /// Constructor.
  constexpr queue_family_checkpoint_properties_nv(
    void* initial_next,
    vk::pipeline_stage_flags initial_checkpoint_execution_stage_mask) noexcept
  : _next(std::move(initial_next)),
    _checkpoint_execution_stage_mask(
      std::move(initial_checkpoint_execution_stage_mask))
  {
  }

  /// Copy constructor.
  constexpr queue_family_checkpoint_properties_nv(
    const queue_family_checkpoint_properties_nv& other) noexcept
  : _next(other._next),
    _checkpoint_execution_stage_mask(other._checkpoint_execution_stage_mask)
  {
  }

  /// Move constructor.
  constexpr queue_family_checkpoint_properties_nv(
    queue_family_checkpoint_properties_nv&& other) noexcept
  : _next(std::move(other._next)),
    _checkpoint_execution_stage_mask(
      std::move(other._checkpoint_execution_stage_mask))
  {
  }

  /// Copy assignment operator.
  constexpr queue_family_checkpoint_properties_nv& operator=(
    const queue_family_checkpoint_properties_nv& other) noexcept
  {
    _next = other._next;
    _checkpoint_execution_stage_mask = other._checkpoint_execution_stage_mask;
    return *this;
  }

  /// Move assignment operator.
  constexpr queue_family_checkpoint_properties_nv& operator=(
    queue_family_checkpoint_properties_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _checkpoint_execution_stage_mask =
      std::move(other._checkpoint_execution_stage_mask);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkQueueFamilyCheckpointPropertiesNV&() const
  {
    return *reinterpret_cast<const VkQueueFamilyCheckpointPropertiesNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_stage_flags& checkpoint_execution_stage_mask()
  {
    return _checkpoint_execution_stage_mask;
  }

  constexpr const vk::pipeline_stage_flags& checkpoint_execution_stage_mask()
    const
  {
    return _checkpoint_execution_stage_mask;
  }

  void checkpoint_execution_stage_mask(
    vk::pipeline_stage_flags new_checkpoint_execution_stage_mask)
  {
    _checkpoint_execution_stage_mask = new_checkpoint_execution_stage_mask;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::queue_family_checkpoint_properties_nv;
  void* _next = nullptr;
  vk::pipeline_stage_flags _checkpoint_execution_stage_mask =
    vk::pipeline_stage_flag::none;
};
static_assert(sizeof(queue_family_checkpoint_properties_nv) ==
                sizeof(::VkQueueFamilyCheckpointPropertiesNV),
              "struct and wrapper have different size!");

/// Enhanced replacement type for VkCheckpointDataNV.
class checkpoint_data_nv
{
public:
  /// Default constructor.
  constexpr checkpoint_data_nv() = default;

  /// Constructor.
  constexpr checkpoint_data_nv(void* initial_next,
                               vk::pipeline_stage_flag initial_stage,
                               void* initial_checkpoint_marker) noexcept
  : _next(std::move(initial_next)),
    _stage(std::move(initial_stage)),
    _checkpoint_marker(std::move(initial_checkpoint_marker))
  {
  }

  /// Copy constructor.
  constexpr checkpoint_data_nv(const checkpoint_data_nv& other) noexcept
  : _next(other._next),
    _stage(other._stage),
    _checkpoint_marker(other._checkpoint_marker)
  {
  }

  /// Move constructor.
  constexpr checkpoint_data_nv(checkpoint_data_nv&& other) noexcept
  : _next(std::move(other._next)),
    _stage(std::move(other._stage)),
    _checkpoint_marker(std::move(other._checkpoint_marker))
  {
  }

  /// Copy assignment operator.
  constexpr checkpoint_data_nv& operator=(
    const checkpoint_data_nv& other) noexcept
  {
    _next = other._next;
    _stage = other._stage;
    _checkpoint_marker = other._checkpoint_marker;
    return *this;
  }

  /// Move assignment operator.
  constexpr checkpoint_data_nv& operator=(checkpoint_data_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _stage = std::move(other._stage);
    _checkpoint_marker = std::move(other._checkpoint_marker);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkCheckpointDataNV&() const
  {
    return *reinterpret_cast<const VkCheckpointDataNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::pipeline_stage_flag& stage()
  {
    return _stage;
  }

  constexpr const vk::pipeline_stage_flag& stage() const
  {
    return _stage;
  }

  void stage(vk::pipeline_stage_flag new_stage)
  {
    _stage = new_stage;
  }

  void* checkpoint_marker()
  {
    return _checkpoint_marker;
  }

  constexpr void* checkpoint_marker() const
  {
    return _checkpoint_marker;
  }

  void checkpoint_marker(void* new_checkpoint_marker)
  {
    _checkpoint_marker = new_checkpoint_marker;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::checkpoint_data_nv;
  void* _next = nullptr;
  vk::pipeline_stage_flag _stage = vk::pipeline_stage_flag::none;
  void* _checkpoint_marker = nullptr;
};
static_assert(sizeof(checkpoint_data_nv) == sizeof(::VkCheckpointDataNV),
              "struct and wrapper have different size!");

inline void cmd_set_checkpoint_nv(VkCommandBuffer command_buffer,
                                  const void* checkpoint_marker)
{
  vkCmdSetCheckpointNV(static_cast<VkCommandBuffer>(command_buffer),
                       reinterpret_cast<const void*>(checkpoint_marker));
}
inline void get_queue_checkpoint_data_nv(
  VkQueue queue, uint32_t* checkpoint_data_count,
  vk::checkpoint_data_nv* checkpoint_data)
{
  vkGetQueueCheckpointDataNV(
    static_cast<VkQueue>(queue),
    reinterpret_cast<uint32_t*>(checkpoint_data_count),
    reinterpret_cast<VkCheckpointDataNV*>(checkpoint_data));
}

/// Enhanced replacement type for VkPhysicalDeviceVulkanMemoryModelFeaturesKHR.
class physical_device_vulkan_memory_model_features_khr
{
public:
  /// Default constructor.
  constexpr physical_device_vulkan_memory_model_features_khr() = default;

  /// Constructor.
  constexpr physical_device_vulkan_memory_model_features_khr(
    void* initial_next, VkBool32 initial_vulkan_memory_model,
    VkBool32 initial_vulkan_memory_model_device_scope) noexcept
  : _next(std::move(initial_next)),
    _vulkan_memory_model(std::move(initial_vulkan_memory_model)),
    _vulkan_memory_model_device_scope(
      std::move(initial_vulkan_memory_model_device_scope))
  {
  }

  /// Copy constructor.
  constexpr physical_device_vulkan_memory_model_features_khr(
    const physical_device_vulkan_memory_model_features_khr& other) noexcept
  : _next(other._next),
    _vulkan_memory_model(other._vulkan_memory_model),
    _vulkan_memory_model_device_scope(other._vulkan_memory_model_device_scope)
  {
  }

  /// Move constructor.
  constexpr physical_device_vulkan_memory_model_features_khr(
    physical_device_vulkan_memory_model_features_khr&& other) noexcept
  : _next(std::move(other._next)),
    _vulkan_memory_model(std::move(other._vulkan_memory_model)),
    _vulkan_memory_model_device_scope(
      std::move(other._vulkan_memory_model_device_scope))
  {
  }

  /// Copy assignment operator.
  constexpr physical_device_vulkan_memory_model_features_khr& operator=(
    const physical_device_vulkan_memory_model_features_khr& other) noexcept
  {
    _next = other._next;
    _vulkan_memory_model = other._vulkan_memory_model;
    _vulkan_memory_model_device_scope = other._vulkan_memory_model_device_scope;
    return *this;
  }

  /// Move assignment operator.
  constexpr physical_device_vulkan_memory_model_features_khr& operator=(
    physical_device_vulkan_memory_model_features_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _vulkan_memory_model = std::move(other._vulkan_memory_model);
    _vulkan_memory_model_device_scope =
      std::move(other._vulkan_memory_model_device_scope);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkPhysicalDeviceVulkanMemoryModelFeaturesKHR&() const
  {
    return *reinterpret_cast<
      const VkPhysicalDeviceVulkanMemoryModelFeaturesKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkBool32& vulkan_memory_model()
  {
    return _vulkan_memory_model;
  }

  constexpr const VkBool32& vulkan_memory_model() const
  {
    return _vulkan_memory_model;
  }

  void vulkan_memory_model(VkBool32 new_vulkan_memory_model)
  {
    _vulkan_memory_model = new_vulkan_memory_model;
  }

  VkBool32& vulkan_memory_model_device_scope()
  {
    return _vulkan_memory_model_device_scope;
  }

  constexpr const VkBool32& vulkan_memory_model_device_scope() const
  {
    return _vulkan_memory_model_device_scope;
  }

  void vulkan_memory_model_device_scope(
    VkBool32 new_vulkan_memory_model_device_scope)
  {
    _vulkan_memory_model_device_scope = new_vulkan_memory_model_device_scope;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::physical_device_vulkan_memory_model_features_khr;
  void* _next = nullptr;
  VkBool32 _vulkan_memory_model = VK_FALSE;
  VkBool32 _vulkan_memory_model_device_scope = VK_FALSE;
};
static_assert(sizeof(physical_device_vulkan_memory_model_features_khr) ==
                sizeof(::VkPhysicalDeviceVulkanMemoryModelFeaturesKHR),
              "struct and wrapper have different size!");

#if defined(VK_USE_PLATFORM_XLIB_KHR)
#if defined(VK_USE_PLATFORM_XLIB_KHR)
using xlib_surface_create_flags_khr = VkFlags;
#endif
#if defined(VK_USE_PLATFORM_XLIB_KHR)

/// Enhanced replacement type for VkXlibSurfaceCreateInfoKHR.
class xlib_surface_create_info_khr
{
public:
  /// Default constructor.
  constexpr xlib_surface_create_info_khr() = default;

  /// Constructor.
  constexpr xlib_surface_create_info_khr(
    const void* initial_next, vk::xlib_surface_create_flags_khr initial_flags,
    Display* initial_dpy, Window initial_window) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _dpy(std::move(initial_dpy)),
    _window(std::move(initial_window))
  {
  }

  /// Copy constructor.
  constexpr xlib_surface_create_info_khr(
    const xlib_surface_create_info_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _dpy(other._dpy),
    _window(other._window)
  {
  }

  /// Move constructor.
  constexpr xlib_surface_create_info_khr(
    xlib_surface_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _dpy(std::move(other._dpy)),
    _window(std::move(other._window))
  {
  }

  /// Copy assignment operator.
  constexpr xlib_surface_create_info_khr& operator=(
    const xlib_surface_create_info_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _dpy = other._dpy;
    _window = other._window;
    return *this;
  }

  /// Move assignment operator.
  constexpr xlib_surface_create_info_khr& operator=(
    xlib_surface_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _dpy = std::move(other._dpy);
    _window = std::move(other._window);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkXlibSurfaceCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkXlibSurfaceCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::xlib_surface_create_flags_khr& flags()
  {
    return _flags;
  }

  constexpr const vk::xlib_surface_create_flags_khr& flags() const
  {
    return _flags;
  }

  void flags(vk::xlib_surface_create_flags_khr new_flags)
  {
    _flags = new_flags;
  }

  Display* dpy()
  {
    return _dpy;
  }

  constexpr Display* dpy() const
  {
    return _dpy;
  }

  void dpy(Display* new_dpy)
  {
    _dpy = new_dpy;
  }

  Window& window()
  {
    return _window;
  }

  constexpr const Window& window() const
  {
    return _window;
  }

  void window(Window new_window)
  {
    _window = new_window;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::xlib_surface_create_info_khr;
  const void* _next = nullptr;
  vk::xlib_surface_create_flags_khr _flags = 0;
  Display* _dpy = nullptr;
  Window _window = 0;
};
static_assert(sizeof(xlib_surface_create_info_khr) ==
                sizeof(::VkXlibSurfaceCreateInfoKHR),
              "struct and wrapper have different size!");

#endif
inline vk::result create_xlib_surface_khr(
  VkInstance instance, const vk::xlib_surface_create_info_khr* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateXlibSurfaceKHR(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkXlibSurfaceCreateInfoKHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}
inline VkBool32 get_physical_device_xlib_presentation_support_khr(
  VkPhysicalDevice physical_device, uint32_t queue_family_index, Display* dpy,
  VisualID visual_id)
{
  return static_cast<VkBool32>(vkGetPhysicalDeviceXlibPresentationSupportKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<uint32_t>(queue_family_index), reinterpret_cast<Display*>(dpy),
    static_cast<VisualID>(visual_id)));
}
#endif
#if defined(VK_USE_PLATFORM_XCB_KHR)
#if defined(VK_USE_PLATFORM_XCB_KHR)
using xcb_surface_create_flags_khr = VkFlags;
#endif
#if defined(VK_USE_PLATFORM_XCB_KHR)

/// Enhanced replacement type for VkXcbSurfaceCreateInfoKHR.
class xcb_surface_create_info_khr
{
public:
  /// Default constructor.
  constexpr xcb_surface_create_info_khr() = default;

  /// Constructor.
  constexpr xcb_surface_create_info_khr(
    const void* initial_next, vk::xcb_surface_create_flags_khr initial_flags,
    xcb_connection_t* initial_connection, xcb_window_t initial_window) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _connection(std::move(initial_connection)),
    _window(std::move(initial_window))
  {
  }

  /// Copy constructor.
  constexpr xcb_surface_create_info_khr(
    const xcb_surface_create_info_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _connection(other._connection),
    _window(other._window)
  {
  }

  /// Move constructor.
  constexpr xcb_surface_create_info_khr(
    xcb_surface_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _connection(std::move(other._connection)),
    _window(std::move(other._window))
  {
  }

  /// Copy assignment operator.
  constexpr xcb_surface_create_info_khr& operator=(
    const xcb_surface_create_info_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _connection = other._connection;
    _window = other._window;
    return *this;
  }

  /// Move assignment operator.
  constexpr xcb_surface_create_info_khr& operator=(
    xcb_surface_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _connection = std::move(other._connection);
    _window = std::move(other._window);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkXcbSurfaceCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkXcbSurfaceCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::xcb_surface_create_flags_khr& flags()
  {
    return _flags;
  }

  constexpr const vk::xcb_surface_create_flags_khr& flags() const
  {
    return _flags;
  }

  void flags(vk::xcb_surface_create_flags_khr new_flags)
  {
    _flags = new_flags;
  }

  xcb_connection_t* connection()
  {
    return _connection;
  }

  constexpr xcb_connection_t* connection() const
  {
    return _connection;
  }

  void connection(xcb_connection_t* new_connection)
  {
    _connection = new_connection;
  }

  xcb_window_t& window()
  {
    return _window;
  }

  constexpr const xcb_window_t& window() const
  {
    return _window;
  }

  void window(xcb_window_t new_window)
  {
    _window = new_window;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::xcb_surface_create_info_khr;
  const void* _next = nullptr;
  vk::xcb_surface_create_flags_khr _flags = 0;
  xcb_connection_t* _connection = nullptr;
  xcb_window_t _window = 0;
};
static_assert(sizeof(xcb_surface_create_info_khr) ==
                sizeof(::VkXcbSurfaceCreateInfoKHR),
              "struct and wrapper have different size!");

#endif
inline vk::result create_xcb_surface_khr(
  VkInstance instance, const vk::xcb_surface_create_info_khr* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateXcbSurfaceKHR(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkXcbSurfaceCreateInfoKHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}
inline VkBool32 get_physical_device_xcb_presentation_support_khr(
  VkPhysicalDevice physical_device, uint32_t queue_family_index,
  xcb_connection_t* connection, xcb_visualid_t visual_id)
{
  return static_cast<VkBool32>(vkGetPhysicalDeviceXcbPresentationSupportKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<uint32_t>(queue_family_index),
    reinterpret_cast<xcb_connection_t*>(connection),
    static_cast<xcb_visualid_t>(visual_id)));
}
#endif
#if defined(VK_USE_PLATFORM_WAYLAND_KHR)
#if defined(VK_USE_PLATFORM_WAYLAND_KHR)
using wayland_surface_create_flags_khr = VkFlags;
#endif
#if defined(VK_USE_PLATFORM_WAYLAND_KHR)

/// Enhanced replacement type for VkWaylandSurfaceCreateInfoKHR.
class wayland_surface_create_info_khr
{
public:
  /// Default constructor.
  constexpr wayland_surface_create_info_khr() = default;

  /// Constructor.
  constexpr wayland_surface_create_info_khr(
    const void* initial_next,
    vk::wayland_surface_create_flags_khr initial_flags,
    struct wl_display* initial_display,
    struct wl_surface* initial_surface) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _display(std::move(initial_display)),
    _surface(std::move(initial_surface))
  {
  }

  /// Copy constructor.
  constexpr wayland_surface_create_info_khr(
    const wayland_surface_create_info_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _display(other._display),
    _surface(other._surface)
  {
  }

  /// Move constructor.
  constexpr wayland_surface_create_info_khr(
    wayland_surface_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _display(std::move(other._display)),
    _surface(std::move(other._surface))
  {
  }

  /// Copy assignment operator.
  constexpr wayland_surface_create_info_khr& operator=(
    const wayland_surface_create_info_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _display = other._display;
    _surface = other._surface;
    return *this;
  }

  /// Move assignment operator.
  constexpr wayland_surface_create_info_khr& operator=(
    wayland_surface_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _display = std::move(other._display);
    _surface = std::move(other._surface);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkWaylandSurfaceCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkWaylandSurfaceCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::wayland_surface_create_flags_khr& flags()
  {
    return _flags;
  }

  constexpr const vk::wayland_surface_create_flags_khr& flags() const
  {
    return _flags;
  }

  void flags(vk::wayland_surface_create_flags_khr new_flags)
  {
    _flags = new_flags;
  }

  struct wl_display* display()
  {
    return _display;
  }

  constexpr struct wl_display* display() const
  {
    return _display;
  }

  void display(struct wl_display* new_display)
  {
    _display = new_display;
  }

  struct wl_surface* surface()
  {
    return _surface;
  }

  constexpr struct wl_surface* surface() const
  {
    return _surface;
  }

  void surface(struct wl_surface* new_surface)
  {
    _surface = new_surface;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::wayland_surface_create_info_khr;
  const void* _next = nullptr;
  vk::wayland_surface_create_flags_khr _flags = 0;
  struct wl_display* _display = nullptr;
  struct wl_surface* _surface = nullptr;
};
static_assert(sizeof(wayland_surface_create_info_khr) ==
                sizeof(::VkWaylandSurfaceCreateInfoKHR),
              "struct and wrapper have different size!");

#endif
inline vk::result create_wayland_surface_khr(
  VkInstance instance, const vk::wayland_surface_create_info_khr* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateWaylandSurfaceKHR(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkWaylandSurfaceCreateInfoKHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}
inline VkBool32 get_physical_device_wayland_presentation_support_khr(
  VkPhysicalDevice physical_device, uint32_t queue_family_index,
  struct wl_display* display)
{
  return static_cast<VkBool32>(vkGetPhysicalDeviceWaylandPresentationSupportKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<uint32_t>(queue_family_index),
    reinterpret_cast<wl_display*>(display)));
}
#endif
#if defined(VK_USE_PLATFORM_MIR_KHR)
#if defined(VK_USE_PLATFORM_MIR_KHR)
using mir_surface_create_flags_khr = VkFlags;
#endif
#if defined(VK_USE_PLATFORM_MIR_KHR)

/// Enhanced replacement type for VkMirSurfaceCreateInfoKHR.
class mir_surface_create_info_khr
{
public:
  /// Default constructor.
  constexpr mir_surface_create_info_khr() = default;

  /// Constructor.
  constexpr mir_surface_create_info_khr(
    const void* initial_next, vk::mir_surface_create_flags_khr initial_flags,
    MirConnection* initial_connection, MirSurface* initial_mir_surface) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _connection(std::move(initial_connection)),
    _mir_surface(std::move(initial_mir_surface))
  {
  }

  /// Copy constructor.
  constexpr mir_surface_create_info_khr(
    const mir_surface_create_info_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _connection(other._connection),
    _mir_surface(other._mir_surface)
  {
  }

  /// Move constructor.
  constexpr mir_surface_create_info_khr(
    mir_surface_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _connection(std::move(other._connection)),
    _mir_surface(std::move(other._mir_surface))
  {
  }

  /// Copy assignment operator.
  constexpr mir_surface_create_info_khr& operator=(
    const mir_surface_create_info_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _connection = other._connection;
    _mir_surface = other._mir_surface;
    return *this;
  }

  /// Move assignment operator.
  constexpr mir_surface_create_info_khr& operator=(
    mir_surface_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _connection = std::move(other._connection);
    _mir_surface = std::move(other._mir_surface);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMirSurfaceCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkMirSurfaceCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::mir_surface_create_flags_khr& flags()
  {
    return _flags;
  }

  constexpr const vk::mir_surface_create_flags_khr& flags() const
  {
    return _flags;
  }

  void flags(vk::mir_surface_create_flags_khr new_flags)
  {
    _flags = new_flags;
  }

  MirConnection* connection()
  {
    return _connection;
  }

  constexpr MirConnection* connection() const
  {
    return _connection;
  }

  void connection(MirConnection* new_connection)
  {
    _connection = new_connection;
  }

  MirSurface* mir_surface()
  {
    return _mir_surface;
  }

  constexpr MirSurface* mir_surface() const
  {
    return _mir_surface;
  }

  void mir_surface(MirSurface* new_mir_surface)
  {
    _mir_surface = new_mir_surface;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::mir_surface_create_info_khr;
  const void* _next = nullptr;
  vk::mir_surface_create_flags_khr _flags = 0;
  MirConnection* _connection = nullptr;
  MirSurface* _mir_surface = nullptr;
};
static_assert(sizeof(mir_surface_create_info_khr) ==
                sizeof(::VkMirSurfaceCreateInfoKHR),
              "struct and wrapper have different size!");

#endif
inline vk::result create_mir_surface_khr(
  VkInstance instance, const vk::mir_surface_create_info_khr* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateMirSurfaceKHR(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkMirSurfaceCreateInfoKHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}
inline VkBool32 get_physical_device_mir_presentation_support_khr(
  VkPhysicalDevice physical_device, uint32_t queue_family_index,
  MirConnection* connection)
{
  return static_cast<VkBool32>(vkGetPhysicalDeviceMirPresentationSupportKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<uint32_t>(queue_family_index),
    reinterpret_cast<MirConnection*>(connection)));
}
#endif
#if defined(VK_USE_PLATFORM_ANDROID_KHR)
#if defined(VK_USE_PLATFORM_ANDROID_KHR)
using android_surface_create_flags_khr = VkFlags;
#endif
#if defined(VK_USE_PLATFORM_ANDROID_KHR)

/// Enhanced replacement type for VkAndroidSurfaceCreateInfoKHR.
class android_surface_create_info_khr
{
public:
  /// Default constructor.
  constexpr android_surface_create_info_khr() = default;

  /// Constructor.
  constexpr android_surface_create_info_khr(
    const void* initial_next,
    vk::android_surface_create_flags_khr initial_flags,
    struct ANativeWindow* initial_window) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _window(std::move(initial_window))
  {
  }

  /// Copy constructor.
  constexpr android_surface_create_info_khr(
    const android_surface_create_info_khr& other) noexcept
  : _next(other._next), _flags(other._flags), _window(other._window)
  {
  }

  /// Move constructor.
  constexpr android_surface_create_info_khr(
    android_surface_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _window(std::move(other._window))
  {
  }

  /// Copy assignment operator.
  constexpr android_surface_create_info_khr& operator=(
    const android_surface_create_info_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _window = other._window;
    return *this;
  }

  /// Move assignment operator.
  constexpr android_surface_create_info_khr& operator=(
    android_surface_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _window = std::move(other._window);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkAndroidSurfaceCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkAndroidSurfaceCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::android_surface_create_flags_khr& flags()
  {
    return _flags;
  }

  constexpr const vk::android_surface_create_flags_khr& flags() const
  {
    return _flags;
  }

  void flags(vk::android_surface_create_flags_khr new_flags)
  {
    _flags = new_flags;
  }

  struct ANativeWindow* window()
  {
    return _window;
  }

  constexpr struct ANativeWindow* window() const
  {
    return _window;
  }

  void window(struct ANativeWindow* new_window)
  {
    _window = new_window;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::android_surface_create_info_khr;
  const void* _next = nullptr;
  vk::android_surface_create_flags_khr _flags = 0;
  struct ANativeWindow* _window = nullptr;
};
static_assert(sizeof(android_surface_create_info_khr) ==
                sizeof(::VkAndroidSurfaceCreateInfoKHR),
              "struct and wrapper have different size!");

#endif
inline vk::result create_android_surface_khr(
  VkInstance instance, const vk::android_surface_create_info_khr* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateAndroidSurfaceKHR(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkAndroidSurfaceCreateInfoKHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}
#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)
#if defined(VK_USE_PLATFORM_WIN32_KHR)
using win32_surface_create_flags_khr = VkFlags;
#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkWin32SurfaceCreateInfoKHR.
class win32_surface_create_info_khr
{
public:
  /// Default constructor.
  constexpr win32_surface_create_info_khr() = default;

  /// Constructor.
  constexpr win32_surface_create_info_khr(
    const void* initial_next, vk::win32_surface_create_flags_khr initial_flags,
    HINSTANCE initial_hinstance, HWND initial_hwnd) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _hinstance(std::move(initial_hinstance)),
    _hwnd(std::move(initial_hwnd))
  {
  }

  /// Copy constructor.
  constexpr win32_surface_create_info_khr(
    const win32_surface_create_info_khr& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _hinstance(other._hinstance),
    _hwnd(other._hwnd)
  {
  }

  /// Move constructor.
  constexpr win32_surface_create_info_khr(
    win32_surface_create_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _hinstance(std::move(other._hinstance)),
    _hwnd(std::move(other._hwnd))
  {
  }

  /// Copy assignment operator.
  constexpr win32_surface_create_info_khr& operator=(
    const win32_surface_create_info_khr& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _hinstance = other._hinstance;
    _hwnd = other._hwnd;
    return *this;
  }

  /// Move assignment operator.
  constexpr win32_surface_create_info_khr& operator=(
    win32_surface_create_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _hinstance = std::move(other._hinstance);
    _hwnd = std::move(other._hwnd);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkWin32SurfaceCreateInfoKHR&() const
  {
    return *reinterpret_cast<const VkWin32SurfaceCreateInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::win32_surface_create_flags_khr& flags()
  {
    return _flags;
  }

  constexpr const vk::win32_surface_create_flags_khr& flags() const
  {
    return _flags;
  }

  void flags(vk::win32_surface_create_flags_khr new_flags)
  {
    _flags = new_flags;
  }

  HINSTANCE& hinstance()
  {
    return _hinstance;
  }

  constexpr const HINSTANCE& hinstance() const
  {
    return _hinstance;
  }

  void hinstance(HINSTANCE new_hinstance)
  {
    _hinstance = new_hinstance;
  }

  HWND& hwnd()
  {
    return _hwnd;
  }

  constexpr const HWND& hwnd() const
  {
    return _hwnd;
  }

  void hwnd(HWND new_hwnd)
  {
    _hwnd = new_hwnd;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::win32_surface_create_info_khr;
  const void* _next = nullptr;
  vk::win32_surface_create_flags_khr _flags = 0;
  HINSTANCE _hinstance = 0;
  HWND _hwnd = 0;
};
static_assert(sizeof(win32_surface_create_info_khr) ==
                sizeof(::VkWin32SurfaceCreateInfoKHR),
              "struct and wrapper have different size!");

#endif
inline vk::result create_win32_surface_khr(
  VkInstance instance, const vk::win32_surface_create_info_khr* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateWin32SurfaceKHR(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkWin32SurfaceCreateInfoKHR*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}
inline VkBool32 get_physical_device_win32_presentation_support_khr(
  VkPhysicalDevice physical_device, uint32_t queue_family_index)
{
  return static_cast<VkBool32>(vkGetPhysicalDeviceWin32PresentationSupportKHR(
    static_cast<VkPhysicalDevice>(physical_device),
    static_cast<uint32_t>(queue_family_index)));
}
#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkImportMemoryWin32HandleInfoNV.
class import_memory_win32_handle_info_nv
{
public:
  /// Default constructor.
  constexpr import_memory_win32_handle_info_nv() = default;

  /// Constructor.
  constexpr import_memory_win32_handle_info_nv(
    const void* initial_next,
    vk::external_memory_handle_type_flags_nv initial_handle_type,
    HANDLE initial_handle) noexcept
  : _next(std::move(initial_next)),
    _handle_type(std::move(initial_handle_type)),
    _handle(std::move(initial_handle))
  {
  }

  /// Copy constructor.
  constexpr import_memory_win32_handle_info_nv(
    const import_memory_win32_handle_info_nv& other) noexcept
  : _next(other._next), _handle_type(other._handle_type), _handle(other._handle)
  {
  }

  /// Move constructor.
  constexpr import_memory_win32_handle_info_nv(
    import_memory_win32_handle_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _handle_type(std::move(other._handle_type)),
    _handle(std::move(other._handle))
  {
  }

  /// Copy assignment operator.
  constexpr import_memory_win32_handle_info_nv& operator=(
    const import_memory_win32_handle_info_nv& other) noexcept
  {
    _next = other._next;
    _handle_type = other._handle_type;
    _handle = other._handle;
    return *this;
  }

  /// Move assignment operator.
  constexpr import_memory_win32_handle_info_nv& operator=(
    import_memory_win32_handle_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_type = std::move(other._handle_type);
    _handle = std::move(other._handle);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImportMemoryWin32HandleInfoNV&() const
  {
    return *reinterpret_cast<const VkImportMemoryWin32HandleInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flags_nv& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_memory_handle_type_flags_nv& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_memory_handle_type_flags_nv new_handle_type)
  {
    _handle_type = new_handle_type;
  }

  HANDLE& handle()
  {
    return _handle;
  }

  constexpr const HANDLE& handle() const
  {
    return _handle;
  }

  void handle(HANDLE new_handle)
  {
    _handle = new_handle;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::import_memory_win32_handle_info_nv;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flags_nv _handle_type =
    vk::external_memory_handle_type_flag_nv::none;
  HANDLE _handle = 0;
};
static_assert(sizeof(import_memory_win32_handle_info_nv) ==
                sizeof(::VkImportMemoryWin32HandleInfoNV),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkExportMemoryWin32HandleInfoNV.
class export_memory_win32_handle_info_nv
{
public:
  /// Default constructor.
  constexpr export_memory_win32_handle_info_nv() = default;

  /// Constructor.
  constexpr export_memory_win32_handle_info_nv(
    const void* initial_next, const SECURITY_ATTRIBUTES* initial_attributes,
    DWORD initial_dw_access) noexcept
  : _next(std::move(initial_next)),
    _attributes(std::move(initial_attributes)),
    _dw_access(std::move(initial_dw_access))
  {
  }

  /// Copy constructor.
  constexpr export_memory_win32_handle_info_nv(
    const export_memory_win32_handle_info_nv& other) noexcept
  : _next(other._next),
    _attributes(other._attributes),
    _dw_access(other._dw_access)
  {
  }

  /// Move constructor.
  constexpr export_memory_win32_handle_info_nv(
    export_memory_win32_handle_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _attributes(std::move(other._attributes)),
    _dw_access(std::move(other._dw_access))
  {
  }

  /// Copy assignment operator.
  constexpr export_memory_win32_handle_info_nv& operator=(
    const export_memory_win32_handle_info_nv& other) noexcept
  {
    _next = other._next;
    _attributes = other._attributes;
    _dw_access = other._dw_access;
    return *this;
  }

  /// Move assignment operator.
  constexpr export_memory_win32_handle_info_nv& operator=(
    export_memory_win32_handle_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _attributes = std::move(other._attributes);
    _dw_access = std::move(other._dw_access);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExportMemoryWin32HandleInfoNV&() const
  {
    return *reinterpret_cast<const VkExportMemoryWin32HandleInfoNV*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  const SECURITY_ATTRIBUTES* attributes()
  {
    return _attributes;
  }

  constexpr const SECURITY_ATTRIBUTES* attributes() const
  {
    return _attributes;
  }

  void attributes(const SECURITY_ATTRIBUTES* new_attributes)
  {
    _attributes = new_attributes;
  }

  DWORD& dw_access()
  {
    return _dw_access;
  }

  constexpr const DWORD& dw_access() const
  {
    return _dw_access;
  }

  void dw_access(DWORD new_dw_access)
  {
    _dw_access = new_dw_access;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::export_memory_win32_handle_info_nv;
  const void* _next = nullptr;
  const SECURITY_ATTRIBUTES* _attributes = nullptr;
  DWORD _dw_access = 0;
};
static_assert(sizeof(export_memory_win32_handle_info_nv) ==
                sizeof(::VkExportMemoryWin32HandleInfoNV),
              "struct and wrapper have different size!");

#endif
inline vk::result get_memory_win32_handle_nv(
  VkDevice device, VkDeviceMemory memory,
  vk::external_memory_handle_type_flags_nv handle_type, HANDLE* handle)
{
  return static_cast<vk::result>(vkGetMemoryWin32HandleNV(
    static_cast<VkDevice>(device), static_cast<VkDeviceMemory>(memory),
    static_cast<VkExternalMemoryHandleTypeFlagsNV>(handle_type),
    reinterpret_cast<HANDLE*>(handle)));
}
#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkWin32KeyedMutexAcquireReleaseInfoNV.
class win32_keyed_mutex_acquire_release_info_nv
{
public:
  /// Default constructor.
  constexpr win32_keyed_mutex_acquire_release_info_nv() = default;

  /// Constructor.
  constexpr win32_keyed_mutex_acquire_release_info_nv(
    const void* initial_next, uint32_t initial_acquire_count,
    const VkDeviceMemory* initial_acquire_syncs,
    const uint64_t* initial_acquire_keys,
    const uint32_t* initial_acquire_timeout_milliseconds,
    uint32_t initial_release_count, const VkDeviceMemory* initial_release_syncs,
    const uint64_t* initial_release_keys) noexcept
  : _next(std::move(initial_next)),
    _acquire_count(std::move(initial_acquire_count)),
    _acquire_syncs(std::move(initial_acquire_syncs)),
    _acquire_keys(std::move(initial_acquire_keys)),
    _acquire_timeout_milliseconds(
      std::move(initial_acquire_timeout_milliseconds)),
    _release_count(std::move(initial_release_count)),
    _release_syncs(std::move(initial_release_syncs)),
    _release_keys(std::move(initial_release_keys))
  {
  }

  /// Copy constructor.
  constexpr win32_keyed_mutex_acquire_release_info_nv(
    const win32_keyed_mutex_acquire_release_info_nv& other) noexcept
  : _next(other._next),
    _acquire_count(other._acquire_count),
    _acquire_syncs(other._acquire_syncs),
    _acquire_keys(other._acquire_keys),
    _acquire_timeout_milliseconds(other._acquire_timeout_milliseconds),
    _release_count(other._release_count),
    _release_syncs(other._release_syncs),
    _release_keys(other._release_keys)
  {
  }

  /// Move constructor.
  constexpr win32_keyed_mutex_acquire_release_info_nv(
    win32_keyed_mutex_acquire_release_info_nv&& other) noexcept
  : _next(std::move(other._next)),
    _acquire_count(std::move(other._acquire_count)),
    _acquire_syncs(std::move(other._acquire_syncs)),
    _acquire_keys(std::move(other._acquire_keys)),
    _acquire_timeout_milliseconds(
      std::move(other._acquire_timeout_milliseconds)),
    _release_count(std::move(other._release_count)),
    _release_syncs(std::move(other._release_syncs)),
    _release_keys(std::move(other._release_keys))
  {
  }

  /// Copy assignment operator.
  constexpr win32_keyed_mutex_acquire_release_info_nv& operator=(
    const win32_keyed_mutex_acquire_release_info_nv& other) noexcept
  {
    _next = other._next;
    _acquire_count = other._acquire_count;
    _acquire_syncs = other._acquire_syncs;
    _acquire_keys = other._acquire_keys;
    _acquire_timeout_milliseconds = other._acquire_timeout_milliseconds;
    _release_count = other._release_count;
    _release_syncs = other._release_syncs;
    _release_keys = other._release_keys;
    return *this;
  }

  /// Move assignment operator.
  constexpr win32_keyed_mutex_acquire_release_info_nv& operator=(
    win32_keyed_mutex_acquire_release_info_nv&& other) noexcept
  {
    _next = std::move(other._next);
    _acquire_count = std::move(other._acquire_count);
    _acquire_syncs = std::move(other._acquire_syncs);
    _acquire_keys = std::move(other._acquire_keys);
    _acquire_timeout_milliseconds =
      std::move(other._acquire_timeout_milliseconds);
    _release_count = std::move(other._release_count);
    _release_syncs = std::move(other._release_syncs);
    _release_keys = std::move(other._release_keys);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkWin32KeyedMutexAcquireReleaseInfoNV&() const
  {
    return *reinterpret_cast<const VkWin32KeyedMutexAcquireReleaseInfoNV*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& acquire_count()
  {
    return _acquire_count;
  }

  constexpr const uint32_t& acquire_count() const
  {
    return _acquire_count;
  }

  void acquire_count(uint32_t new_acquire_count)
  {
    _acquire_count = new_acquire_count;
  }

  const VkDeviceMemory* acquire_syncs()
  {
    return _acquire_syncs;
  }

  constexpr const VkDeviceMemory* acquire_syncs() const
  {
    return _acquire_syncs;
  }

  void acquire_syncs(const VkDeviceMemory* new_acquire_syncs)
  {
    _acquire_syncs = new_acquire_syncs;
  }

  template <std::size_t Count>
  void acquire_syncs(const std::array<VkDeviceMemory, Count>& new_acquire_syncs)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_syncs.size());
    _acquire_syncs = new_acquire_syncs.data();
  }

  void acquire_syncs(const std::vector<VkDeviceMemory>& new_acquire_syncs)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_syncs.size());
    _acquire_syncs = new_acquire_syncs.data();
  }

  const uint64_t* acquire_keys()
  {
    return _acquire_keys;
  }

  constexpr const uint64_t* acquire_keys() const
  {
    return _acquire_keys;
  }

  void acquire_keys(const uint64_t* new_acquire_keys)
  {
    _acquire_keys = new_acquire_keys;
  }

  template <std::size_t Count>
  void acquire_keys(const std::array<uint64_t, Count>& new_acquire_keys)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_keys.size());
    _acquire_keys = new_acquire_keys.data();
  }

  void acquire_keys(const std::vector<uint64_t>& new_acquire_keys)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_keys.size());
    _acquire_keys = new_acquire_keys.data();
  }

  const uint32_t* acquire_timeout_milliseconds()
  {
    return _acquire_timeout_milliseconds;
  }

  constexpr const uint32_t* acquire_timeout_milliseconds() const
  {
    return _acquire_timeout_milliseconds;
  }

  void acquire_timeout_milliseconds(
    const uint32_t* new_acquire_timeout_milliseconds)
  {
    _acquire_timeout_milliseconds = new_acquire_timeout_milliseconds;
  }

  template <std::size_t Count>
  void acquire_timeout_milliseconds(
    const std::array<uint32_t, Count>& new_acquire_timeout_milliseconds)
  {
    _acquire_count =
      static_cast<uint32_t>(new_acquire_timeout_milliseconds.size());
    _acquire_timeout_milliseconds = new_acquire_timeout_milliseconds.data();
  }

  void acquire_timeout_milliseconds(
    const std::vector<uint32_t>& new_acquire_timeout_milliseconds)
  {
    _acquire_count =
      static_cast<uint32_t>(new_acquire_timeout_milliseconds.size());
    _acquire_timeout_milliseconds = new_acquire_timeout_milliseconds.data();
  }

  uint32_t& release_count()
  {
    return _release_count;
  }

  constexpr const uint32_t& release_count() const
  {
    return _release_count;
  }

  void release_count(uint32_t new_release_count)
  {
    _release_count = new_release_count;
  }

  const VkDeviceMemory* release_syncs()
  {
    return _release_syncs;
  }

  constexpr const VkDeviceMemory* release_syncs() const
  {
    return _release_syncs;
  }

  void release_syncs(const VkDeviceMemory* new_release_syncs)
  {
    _release_syncs = new_release_syncs;
  }

  template <std::size_t Count>
  void release_syncs(const std::array<VkDeviceMemory, Count>& new_release_syncs)
  {
    _release_count = static_cast<uint32_t>(new_release_syncs.size());
    _release_syncs = new_release_syncs.data();
  }

  void release_syncs(const std::vector<VkDeviceMemory>& new_release_syncs)
  {
    _release_count = static_cast<uint32_t>(new_release_syncs.size());
    _release_syncs = new_release_syncs.data();
  }

  const uint64_t* release_keys()
  {
    return _release_keys;
  }

  constexpr const uint64_t* release_keys() const
  {
    return _release_keys;
  }

  void release_keys(const uint64_t* new_release_keys)
  {
    _release_keys = new_release_keys;
  }

  template <std::size_t Count>
  void release_keys(const std::array<uint64_t, Count>& new_release_keys)
  {
    _release_count = static_cast<uint32_t>(new_release_keys.size());
    _release_keys = new_release_keys.data();
  }

  void release_keys(const std::vector<uint64_t>& new_release_keys)
  {
    _release_count = static_cast<uint32_t>(new_release_keys.size());
    _release_keys = new_release_keys.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::win32_keyed_mutex_acquire_release_info_nv;
  const void* _next = nullptr;
  uint32_t _acquire_count = 0;
  const VkDeviceMemory* _acquire_syncs = nullptr;
  const uint64_t* _acquire_keys = nullptr;
  const uint32_t* _acquire_timeout_milliseconds = nullptr;
  uint32_t _release_count = 0;
  const VkDeviceMemory* _release_syncs = nullptr;
  const uint64_t* _release_keys = nullptr;
};
static_assert(sizeof(win32_keyed_mutex_acquire_release_info_nv) ==
                sizeof(::VkWin32KeyedMutexAcquireReleaseInfoNV),
              "struct and wrapper have different size!");

#endif
#endif
#if defined(VK_USE_PLATFORM_VI_NN)
#if defined(VK_USE_PLATFORM_VI_NN)
using vi_surface_create_flags_nn = VkFlags;
#endif
#if defined(VK_USE_PLATFORM_VI_NN)

/// Enhanced replacement type for VkViSurfaceCreateInfoNN.
class vi_surface_create_info_nn
{
public:
  /// Default constructor.
  constexpr vi_surface_create_info_nn() = default;

  /// Constructor.
  constexpr vi_surface_create_info_nn(
    const void* initial_next, vk::vi_surface_create_flags_nn initial_flags,
    void* initial_window) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _window(std::move(initial_window))
  {
  }

  /// Copy constructor.
  constexpr vi_surface_create_info_nn(
    const vi_surface_create_info_nn& other) noexcept
  : _next(other._next), _flags(other._flags), _window(other._window)
  {
  }

  /// Move constructor.
  constexpr vi_surface_create_info_nn(
    vi_surface_create_info_nn&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _window(std::move(other._window))
  {
  }

  /// Copy assignment operator.
  constexpr vi_surface_create_info_nn& operator=(
    const vi_surface_create_info_nn& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _window = other._window;
    return *this;
  }

  /// Move assignment operator.
  constexpr vi_surface_create_info_nn& operator=(
    vi_surface_create_info_nn&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _window = std::move(other._window);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkViSurfaceCreateInfoNN&() const
  {
    return *reinterpret_cast<const VkViSurfaceCreateInfoNN*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::vi_surface_create_flags_nn& flags()
  {
    return _flags;
  }

  constexpr const vk::vi_surface_create_flags_nn& flags() const
  {
    return _flags;
  }

  void flags(vk::vi_surface_create_flags_nn new_flags)
  {
    _flags = new_flags;
  }

  void* window()
  {
    return _window;
  }

  constexpr void* window() const
  {
    return _window;
  }

  void window(void* new_window)
  {
    _window = new_window;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::vi_surface_create_info_nn;
  const void* _next = nullptr;
  vk::vi_surface_create_flags_nn _flags = 0;
  void* _window = nullptr;
};
static_assert(sizeof(vi_surface_create_info_nn) ==
                sizeof(::VkViSurfaceCreateInfoNN),
              "struct and wrapper have different size!");

#endif
inline vk::result create_vi_surface_nn(
  VkInstance instance, const vk::vi_surface_create_info_nn* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateViSurfaceNN(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkViSurfaceCreateInfoNN*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}
#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkImportMemoryWin32HandleInfoKHR.
class import_memory_win32_handle_info_khr
{
public:
  /// Default constructor.
  constexpr import_memory_win32_handle_info_khr() = default;

  /// Constructor.
  constexpr import_memory_win32_handle_info_khr(
    const void* initial_next,
    vk::external_memory_handle_type_flag initial_handle_type,
    HANDLE initial_handle, LPCWSTR initial_name) noexcept
  : _next(std::move(initial_next)),
    _handle_type(std::move(initial_handle_type)),
    _handle(std::move(initial_handle)),
    _name(std::move(initial_name))
  {
  }

  /// Copy constructor.
  constexpr import_memory_win32_handle_info_khr(
    const import_memory_win32_handle_info_khr& other) noexcept
  : _next(other._next),
    _handle_type(other._handle_type),
    _handle(other._handle),
    _name(other._name)
  {
  }

  /// Move constructor.
  constexpr import_memory_win32_handle_info_khr(
    import_memory_win32_handle_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _handle_type(std::move(other._handle_type)),
    _handle(std::move(other._handle)),
    _name(std::move(other._name))
  {
  }

  /// Copy assignment operator.
  constexpr import_memory_win32_handle_info_khr& operator=(
    const import_memory_win32_handle_info_khr& other) noexcept
  {
    _next = other._next;
    _handle_type = other._handle_type;
    _handle = other._handle;
    _name = other._name;
    return *this;
  }

  /// Move assignment operator.
  constexpr import_memory_win32_handle_info_khr& operator=(
    import_memory_win32_handle_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _handle_type = std::move(other._handle_type);
    _handle = std::move(other._handle);
    _name = std::move(other._name);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImportMemoryWin32HandleInfoKHR&() const
  {
    return *reinterpret_cast<const VkImportMemoryWin32HandleInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::external_memory_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_memory_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_memory_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

  HANDLE& handle()
  {
    return _handle;
  }

  constexpr const HANDLE& handle() const
  {
    return _handle;
  }

  void handle(HANDLE new_handle)
  {
    _handle = new_handle;
  }

  LPCWSTR& name()
  {
    return _name;
  }

  constexpr const LPCWSTR& name() const
  {
    return _name;
  }

  void name(LPCWSTR new_name)
  {
    _name = new_name;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::import_memory_win32_handle_info_khr;
  const void* _next = nullptr;
  vk::external_memory_handle_type_flag _handle_type =
    vk::external_memory_handle_type_flag::none;
  HANDLE _handle = 0;
  LPCWSTR _name = 0;
};
static_assert(sizeof(import_memory_win32_handle_info_khr) ==
                sizeof(::VkImportMemoryWin32HandleInfoKHR),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkExportMemoryWin32HandleInfoKHR.
class export_memory_win32_handle_info_khr
{
public:
  /// Default constructor.
  constexpr export_memory_win32_handle_info_khr() = default;

  /// Constructor.
  constexpr export_memory_win32_handle_info_khr(
    const void* initial_next, const SECURITY_ATTRIBUTES* initial_attributes,
    DWORD initial_dw_access, LPCWSTR initial_name) noexcept
  : _next(std::move(initial_next)),
    _attributes(std::move(initial_attributes)),
    _dw_access(std::move(initial_dw_access)),
    _name(std::move(initial_name))
  {
  }

  /// Copy constructor.
  constexpr export_memory_win32_handle_info_khr(
    const export_memory_win32_handle_info_khr& other) noexcept
  : _next(other._next),
    _attributes(other._attributes),
    _dw_access(other._dw_access),
    _name(other._name)
  {
  }

  /// Move constructor.
  constexpr export_memory_win32_handle_info_khr(
    export_memory_win32_handle_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _attributes(std::move(other._attributes)),
    _dw_access(std::move(other._dw_access)),
    _name(std::move(other._name))
  {
  }

  /// Copy assignment operator.
  constexpr export_memory_win32_handle_info_khr& operator=(
    const export_memory_win32_handle_info_khr& other) noexcept
  {
    _next = other._next;
    _attributes = other._attributes;
    _dw_access = other._dw_access;
    _name = other._name;
    return *this;
  }

  /// Move assignment operator.
  constexpr export_memory_win32_handle_info_khr& operator=(
    export_memory_win32_handle_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _attributes = std::move(other._attributes);
    _dw_access = std::move(other._dw_access);
    _name = std::move(other._name);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExportMemoryWin32HandleInfoKHR&() const
  {
    return *reinterpret_cast<const VkExportMemoryWin32HandleInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  const SECURITY_ATTRIBUTES* attributes()
  {
    return _attributes;
  }

  constexpr const SECURITY_ATTRIBUTES* attributes() const
  {
    return _attributes;
  }

  void attributes(const SECURITY_ATTRIBUTES* new_attributes)
  {
    _attributes = new_attributes;
  }

  DWORD& dw_access()
  {
    return _dw_access;
  }

  constexpr const DWORD& dw_access() const
  {
    return _dw_access;
  }

  void dw_access(DWORD new_dw_access)
  {
    _dw_access = new_dw_access;
  }

  LPCWSTR& name()
  {
    return _name;
  }

  constexpr const LPCWSTR& name() const
  {
    return _name;
  }

  void name(LPCWSTR new_name)
  {
    _name = new_name;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::export_memory_win32_handle_info_khr;
  const void* _next = nullptr;
  const SECURITY_ATTRIBUTES* _attributes = nullptr;
  DWORD _dw_access = 0;
  LPCWSTR _name = 0;
};
static_assert(sizeof(export_memory_win32_handle_info_khr) ==
                sizeof(::VkExportMemoryWin32HandleInfoKHR),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkMemoryWin32HandlePropertiesKHR.
class memory_win32_handle_properties_khr
{
public:
  /// Default constructor.
  constexpr memory_win32_handle_properties_khr() = default;

  /// Constructor.
  constexpr memory_win32_handle_properties_khr(
    void* initial_next, uint32_t initial_memory_type_bits) noexcept
  : _next(std::move(initial_next)),
    _memory_type_bits(std::move(initial_memory_type_bits))
  {
  }

  /// Copy constructor.
  constexpr memory_win32_handle_properties_khr(
    const memory_win32_handle_properties_khr& other) noexcept
  : _next(other._next), _memory_type_bits(other._memory_type_bits)
  {
  }

  /// Move constructor.
  constexpr memory_win32_handle_properties_khr(
    memory_win32_handle_properties_khr&& other) noexcept
  : _next(std::move(other._next)),
    _memory_type_bits(std::move(other._memory_type_bits))
  {
  }

  /// Copy assignment operator.
  constexpr memory_win32_handle_properties_khr& operator=(
    const memory_win32_handle_properties_khr& other) noexcept
  {
    _next = other._next;
    _memory_type_bits = other._memory_type_bits;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_win32_handle_properties_khr& operator=(
    memory_win32_handle_properties_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _memory_type_bits = std::move(other._memory_type_bits);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryWin32HandlePropertiesKHR&() const
  {
    return *reinterpret_cast<const VkMemoryWin32HandlePropertiesKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& memory_type_bits()
  {
    return _memory_type_bits;
  }

  constexpr const uint32_t& memory_type_bits() const
  {
    return _memory_type_bits;
  }

  void memory_type_bits(uint32_t new_memory_type_bits)
  {
    _memory_type_bits = new_memory_type_bits;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_win32_handle_properties_khr;
  void* _next = nullptr;
  uint32_t _memory_type_bits = 0;
};
static_assert(sizeof(memory_win32_handle_properties_khr) ==
                sizeof(::VkMemoryWin32HandlePropertiesKHR),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkMemoryGetWin32HandleInfoKHR.
class memory_get_win32_handle_info_khr
{
public:
  /// Default constructor.
  constexpr memory_get_win32_handle_info_khr() = default;

  /// Constructor.
  constexpr memory_get_win32_handle_info_khr(
    const void* initial_next, VkDeviceMemory initial_memory,
    vk::external_memory_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)),
    _memory(std::move(initial_memory)),
    _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr memory_get_win32_handle_info_khr(
    const memory_get_win32_handle_info_khr& other) noexcept
  : _next(other._next), _memory(other._memory), _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr memory_get_win32_handle_info_khr(
    memory_get_win32_handle_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _memory(std::move(other._memory)),
    _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr memory_get_win32_handle_info_khr& operator=(
    const memory_get_win32_handle_info_khr& other) noexcept
  {
    _next = other._next;
    _memory = other._memory;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_get_win32_handle_info_khr& operator=(
    memory_get_win32_handle_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _memory = std::move(other._memory);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryGetWin32HandleInfoKHR&() const
  {
    return *reinterpret_cast<const VkMemoryGetWin32HandleInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkDeviceMemory& memory()
  {
    return _memory;
  }

  constexpr const VkDeviceMemory& memory() const
  {
    return _memory;
  }

  void memory(VkDeviceMemory new_memory)
  {
    _memory = new_memory;
  }

  vk::external_memory_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_memory_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_memory_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_get_win32_handle_info_khr;
  const void* _next = nullptr;
  VkDeviceMemory _memory = nullptr;
  vk::external_memory_handle_type_flag _handle_type =
    vk::external_memory_handle_type_flag::none;
};
static_assert(sizeof(memory_get_win32_handle_info_khr) ==
                sizeof(::VkMemoryGetWin32HandleInfoKHR),
              "struct and wrapper have different size!");

#endif
inline vk::result get_memory_win32_handle_khr(
  VkDevice device,
  const vk::memory_get_win32_handle_info_khr* get_win32_handle_info,
  HANDLE* handle)
{
  return static_cast<vk::result>(vkGetMemoryWin32HandleKHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkMemoryGetWin32HandleInfoKHR*>(
      get_win32_handle_info),
    reinterpret_cast<HANDLE*>(handle)));
}
inline vk::result get_memory_win32_handle_properties_khr(
  VkDevice device, vk::external_memory_handle_type_flag handle_type,
  HANDLE handle,
  vk::memory_win32_handle_properties_khr* memory_win32_handle_properties)
{
  return static_cast<vk::result>(vkGetMemoryWin32HandlePropertiesKHR(
    static_cast<VkDevice>(device),
    static_cast<VkExternalMemoryHandleTypeFlagBits>(handle_type),
    static_cast<HANDLE>(handle),
    reinterpret_cast<VkMemoryWin32HandlePropertiesKHR*>(
      memory_win32_handle_properties)));
}
#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkWin32KeyedMutexAcquireReleaseInfoKHR.
class win32_keyed_mutex_acquire_release_info_khr
{
public:
  /// Default constructor.
  constexpr win32_keyed_mutex_acquire_release_info_khr() = default;

  /// Constructor.
  constexpr win32_keyed_mutex_acquire_release_info_khr(
    const void* initial_next, uint32_t initial_acquire_count,
    const VkDeviceMemory* initial_acquire_syncs,
    const uint64_t* initial_acquire_keys,
    const uint32_t* initial_acquire_timeouts, uint32_t initial_release_count,
    const VkDeviceMemory* initial_release_syncs,
    const uint64_t* initial_release_keys) noexcept
  : _next(std::move(initial_next)),
    _acquire_count(std::move(initial_acquire_count)),
    _acquire_syncs(std::move(initial_acquire_syncs)),
    _acquire_keys(std::move(initial_acquire_keys)),
    _acquire_timeouts(std::move(initial_acquire_timeouts)),
    _release_count(std::move(initial_release_count)),
    _release_syncs(std::move(initial_release_syncs)),
    _release_keys(std::move(initial_release_keys))
  {
  }

  /// Copy constructor.
  constexpr win32_keyed_mutex_acquire_release_info_khr(
    const win32_keyed_mutex_acquire_release_info_khr& other) noexcept
  : _next(other._next),
    _acquire_count(other._acquire_count),
    _acquire_syncs(other._acquire_syncs),
    _acquire_keys(other._acquire_keys),
    _acquire_timeouts(other._acquire_timeouts),
    _release_count(other._release_count),
    _release_syncs(other._release_syncs),
    _release_keys(other._release_keys)
  {
  }

  /// Move constructor.
  constexpr win32_keyed_mutex_acquire_release_info_khr(
    win32_keyed_mutex_acquire_release_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _acquire_count(std::move(other._acquire_count)),
    _acquire_syncs(std::move(other._acquire_syncs)),
    _acquire_keys(std::move(other._acquire_keys)),
    _acquire_timeouts(std::move(other._acquire_timeouts)),
    _release_count(std::move(other._release_count)),
    _release_syncs(std::move(other._release_syncs)),
    _release_keys(std::move(other._release_keys))
  {
  }

  /// Copy assignment operator.
  constexpr win32_keyed_mutex_acquire_release_info_khr& operator=(
    const win32_keyed_mutex_acquire_release_info_khr& other) noexcept
  {
    _next = other._next;
    _acquire_count = other._acquire_count;
    _acquire_syncs = other._acquire_syncs;
    _acquire_keys = other._acquire_keys;
    _acquire_timeouts = other._acquire_timeouts;
    _release_count = other._release_count;
    _release_syncs = other._release_syncs;
    _release_keys = other._release_keys;
    return *this;
  }

  /// Move assignment operator.
  constexpr win32_keyed_mutex_acquire_release_info_khr& operator=(
    win32_keyed_mutex_acquire_release_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _acquire_count = std::move(other._acquire_count);
    _acquire_syncs = std::move(other._acquire_syncs);
    _acquire_keys = std::move(other._acquire_keys);
    _acquire_timeouts = std::move(other._acquire_timeouts);
    _release_count = std::move(other._release_count);
    _release_syncs = std::move(other._release_syncs);
    _release_keys = std::move(other._release_keys);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkWin32KeyedMutexAcquireReleaseInfoKHR&() const
  {
    return *reinterpret_cast<const VkWin32KeyedMutexAcquireReleaseInfoKHR*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& acquire_count()
  {
    return _acquire_count;
  }

  constexpr const uint32_t& acquire_count() const
  {
    return _acquire_count;
  }

  void acquire_count(uint32_t new_acquire_count)
  {
    _acquire_count = new_acquire_count;
  }

  const VkDeviceMemory* acquire_syncs()
  {
    return _acquire_syncs;
  }

  constexpr const VkDeviceMemory* acquire_syncs() const
  {
    return _acquire_syncs;
  }

  void acquire_syncs(const VkDeviceMemory* new_acquire_syncs)
  {
    _acquire_syncs = new_acquire_syncs;
  }

  template <std::size_t Count>
  void acquire_syncs(const std::array<VkDeviceMemory, Count>& new_acquire_syncs)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_syncs.size());
    _acquire_syncs = new_acquire_syncs.data();
  }

  void acquire_syncs(const std::vector<VkDeviceMemory>& new_acquire_syncs)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_syncs.size());
    _acquire_syncs = new_acquire_syncs.data();
  }

  const uint64_t* acquire_keys()
  {
    return _acquire_keys;
  }

  constexpr const uint64_t* acquire_keys() const
  {
    return _acquire_keys;
  }

  void acquire_keys(const uint64_t* new_acquire_keys)
  {
    _acquire_keys = new_acquire_keys;
  }

  template <std::size_t Count>
  void acquire_keys(const std::array<uint64_t, Count>& new_acquire_keys)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_keys.size());
    _acquire_keys = new_acquire_keys.data();
  }

  void acquire_keys(const std::vector<uint64_t>& new_acquire_keys)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_keys.size());
    _acquire_keys = new_acquire_keys.data();
  }

  const uint32_t* acquire_timeouts()
  {
    return _acquire_timeouts;
  }

  constexpr const uint32_t* acquire_timeouts() const
  {
    return _acquire_timeouts;
  }

  void acquire_timeouts(const uint32_t* new_acquire_timeouts)
  {
    _acquire_timeouts = new_acquire_timeouts;
  }

  template <std::size_t Count>
  void acquire_timeouts(const std::array<uint32_t, Count>& new_acquire_timeouts)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_timeouts.size());
    _acquire_timeouts = new_acquire_timeouts.data();
  }

  void acquire_timeouts(const std::vector<uint32_t>& new_acquire_timeouts)
  {
    _acquire_count = static_cast<uint32_t>(new_acquire_timeouts.size());
    _acquire_timeouts = new_acquire_timeouts.data();
  }

  uint32_t& release_count()
  {
    return _release_count;
  }

  constexpr const uint32_t& release_count() const
  {
    return _release_count;
  }

  void release_count(uint32_t new_release_count)
  {
    _release_count = new_release_count;
  }

  const VkDeviceMemory* release_syncs()
  {
    return _release_syncs;
  }

  constexpr const VkDeviceMemory* release_syncs() const
  {
    return _release_syncs;
  }

  void release_syncs(const VkDeviceMemory* new_release_syncs)
  {
    _release_syncs = new_release_syncs;
  }

  template <std::size_t Count>
  void release_syncs(const std::array<VkDeviceMemory, Count>& new_release_syncs)
  {
    _release_count = static_cast<uint32_t>(new_release_syncs.size());
    _release_syncs = new_release_syncs.data();
  }

  void release_syncs(const std::vector<VkDeviceMemory>& new_release_syncs)
  {
    _release_count = static_cast<uint32_t>(new_release_syncs.size());
    _release_syncs = new_release_syncs.data();
  }

  const uint64_t* release_keys()
  {
    return _release_keys;
  }

  constexpr const uint64_t* release_keys() const
  {
    return _release_keys;
  }

  void release_keys(const uint64_t* new_release_keys)
  {
    _release_keys = new_release_keys;
  }

  template <std::size_t Count>
  void release_keys(const std::array<uint64_t, Count>& new_release_keys)
  {
    _release_count = static_cast<uint32_t>(new_release_keys.size());
    _release_keys = new_release_keys.data();
  }

  void release_keys(const std::vector<uint64_t>& new_release_keys)
  {
    _release_count = static_cast<uint32_t>(new_release_keys.size());
    _release_keys = new_release_keys.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::win32_keyed_mutex_acquire_release_info_khr;
  const void* _next = nullptr;
  uint32_t _acquire_count = 0;
  const VkDeviceMemory* _acquire_syncs = nullptr;
  const uint64_t* _acquire_keys = nullptr;
  const uint32_t* _acquire_timeouts = nullptr;
  uint32_t _release_count = 0;
  const VkDeviceMemory* _release_syncs = nullptr;
  const uint64_t* _release_keys = nullptr;
};
static_assert(sizeof(win32_keyed_mutex_acquire_release_info_khr) ==
                sizeof(::VkWin32KeyedMutexAcquireReleaseInfoKHR),
              "struct and wrapper have different size!");

#endif
#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkImportSemaphoreWin32HandleInfoKHR.
class import_semaphore_win32_handle_info_khr
{
public:
  /// Default constructor.
  constexpr import_semaphore_win32_handle_info_khr() = default;

  /// Constructor.
  constexpr import_semaphore_win32_handle_info_khr(
    const void* initial_next, VkSemaphore initial_semaphore,
    vk::semaphore_import_flags initial_flags,
    vk::external_semaphore_handle_type_flag initial_handle_type,
    HANDLE initial_handle, LPCWSTR initial_name) noexcept
  : _next(std::move(initial_next)),
    _semaphore(std::move(initial_semaphore)),
    _flags(std::move(initial_flags)),
    _handle_type(std::move(initial_handle_type)),
    _handle(std::move(initial_handle)),
    _name(std::move(initial_name))
  {
  }

  /// Copy constructor.
  constexpr import_semaphore_win32_handle_info_khr(
    const import_semaphore_win32_handle_info_khr& other) noexcept
  : _next(other._next),
    _semaphore(other._semaphore),
    _flags(other._flags),
    _handle_type(other._handle_type),
    _handle(other._handle),
    _name(other._name)
  {
  }

  /// Move constructor.
  constexpr import_semaphore_win32_handle_info_khr(
    import_semaphore_win32_handle_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _semaphore(std::move(other._semaphore)),
    _flags(std::move(other._flags)),
    _handle_type(std::move(other._handle_type)),
    _handle(std::move(other._handle)),
    _name(std::move(other._name))
  {
  }

  /// Copy assignment operator.
  constexpr import_semaphore_win32_handle_info_khr& operator=(
    const import_semaphore_win32_handle_info_khr& other) noexcept
  {
    _next = other._next;
    _semaphore = other._semaphore;
    _flags = other._flags;
    _handle_type = other._handle_type;
    _handle = other._handle;
    _name = other._name;
    return *this;
  }

  /// Move assignment operator.
  constexpr import_semaphore_win32_handle_info_khr& operator=(
    import_semaphore_win32_handle_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _semaphore = std::move(other._semaphore);
    _flags = std::move(other._flags);
    _handle_type = std::move(other._handle_type);
    _handle = std::move(other._handle);
    _name = std::move(other._name);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImportSemaphoreWin32HandleInfoKHR&() const
  {
    return *reinterpret_cast<const VkImportSemaphoreWin32HandleInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkSemaphore& semaphore()
  {
    return _semaphore;
  }

  constexpr const VkSemaphore& semaphore() const
  {
    return _semaphore;
  }

  void semaphore(VkSemaphore new_semaphore)
  {
    _semaphore = new_semaphore;
  }

  vk::semaphore_import_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::semaphore_import_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::semaphore_import_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::external_semaphore_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_semaphore_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_semaphore_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

  HANDLE& handle()
  {
    return _handle;
  }

  constexpr const HANDLE& handle() const
  {
    return _handle;
  }

  void handle(HANDLE new_handle)
  {
    _handle = new_handle;
  }

  LPCWSTR& name()
  {
    return _name;
  }

  constexpr const LPCWSTR& name() const
  {
    return _name;
  }

  void name(LPCWSTR new_name)
  {
    _name = new_name;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::import_semaphore_win32_handle_info_khr;
  const void* _next = nullptr;
  VkSemaphore _semaphore = nullptr;
  vk::semaphore_import_flags _flags = vk::semaphore_import_flag::none;
  vk::external_semaphore_handle_type_flag _handle_type =
    vk::external_semaphore_handle_type_flag::none;
  HANDLE _handle = 0;
  LPCWSTR _name = 0;
};
static_assert(sizeof(import_semaphore_win32_handle_info_khr) ==
                sizeof(::VkImportSemaphoreWin32HandleInfoKHR),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkExportSemaphoreWin32HandleInfoKHR.
class export_semaphore_win32_handle_info_khr
{
public:
  /// Default constructor.
  constexpr export_semaphore_win32_handle_info_khr() = default;

  /// Constructor.
  constexpr export_semaphore_win32_handle_info_khr(
    const void* initial_next, const SECURITY_ATTRIBUTES* initial_attributes,
    DWORD initial_dw_access, LPCWSTR initial_name) noexcept
  : _next(std::move(initial_next)),
    _attributes(std::move(initial_attributes)),
    _dw_access(std::move(initial_dw_access)),
    _name(std::move(initial_name))
  {
  }

  /// Copy constructor.
  constexpr export_semaphore_win32_handle_info_khr(
    const export_semaphore_win32_handle_info_khr& other) noexcept
  : _next(other._next),
    _attributes(other._attributes),
    _dw_access(other._dw_access),
    _name(other._name)
  {
  }

  /// Move constructor.
  constexpr export_semaphore_win32_handle_info_khr(
    export_semaphore_win32_handle_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _attributes(std::move(other._attributes)),
    _dw_access(std::move(other._dw_access)),
    _name(std::move(other._name))
  {
  }

  /// Copy assignment operator.
  constexpr export_semaphore_win32_handle_info_khr& operator=(
    const export_semaphore_win32_handle_info_khr& other) noexcept
  {
    _next = other._next;
    _attributes = other._attributes;
    _dw_access = other._dw_access;
    _name = other._name;
    return *this;
  }

  /// Move assignment operator.
  constexpr export_semaphore_win32_handle_info_khr& operator=(
    export_semaphore_win32_handle_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _attributes = std::move(other._attributes);
    _dw_access = std::move(other._dw_access);
    _name = std::move(other._name);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExportSemaphoreWin32HandleInfoKHR&() const
  {
    return *reinterpret_cast<const VkExportSemaphoreWin32HandleInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  const SECURITY_ATTRIBUTES* attributes()
  {
    return _attributes;
  }

  constexpr const SECURITY_ATTRIBUTES* attributes() const
  {
    return _attributes;
  }

  void attributes(const SECURITY_ATTRIBUTES* new_attributes)
  {
    _attributes = new_attributes;
  }

  DWORD& dw_access()
  {
    return _dw_access;
  }

  constexpr const DWORD& dw_access() const
  {
    return _dw_access;
  }

  void dw_access(DWORD new_dw_access)
  {
    _dw_access = new_dw_access;
  }

  LPCWSTR& name()
  {
    return _name;
  }

  constexpr const LPCWSTR& name() const
  {
    return _name;
  }

  void name(LPCWSTR new_name)
  {
    _name = new_name;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::export_semaphore_win32_handle_info_khr;
  const void* _next = nullptr;
  const SECURITY_ATTRIBUTES* _attributes = nullptr;
  DWORD _dw_access = 0;
  LPCWSTR _name = 0;
};
static_assert(sizeof(export_semaphore_win32_handle_info_khr) ==
                sizeof(::VkExportSemaphoreWin32HandleInfoKHR),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkD3D12FenceSubmitInfoKHR.
class d3d_12_fence_submit_info_khr
{
public:
  /// Default constructor.
  constexpr d3d_12_fence_submit_info_khr() = default;

  /// Constructor.
  constexpr d3d_12_fence_submit_info_khr(
    const void* initial_next, uint32_t initial_wait_semaphore_values_count,
    const uint64_t* initial_wait_semaphore_values,
    uint32_t initial_signal_semaphore_values_count,
    const uint64_t* initial_signal_semaphore_values) noexcept
  : _next(std::move(initial_next)),
    _wait_semaphore_values_count(
      std::move(initial_wait_semaphore_values_count)),
    _wait_semaphore_values(std::move(initial_wait_semaphore_values)),
    _signal_semaphore_values_count(
      std::move(initial_signal_semaphore_values_count)),
    _signal_semaphore_values(std::move(initial_signal_semaphore_values))
  {
  }

  /// Copy constructor.
  constexpr d3d_12_fence_submit_info_khr(
    const d3d_12_fence_submit_info_khr& other) noexcept
  : _next(other._next),
    _wait_semaphore_values_count(other._wait_semaphore_values_count),
    _wait_semaphore_values(other._wait_semaphore_values),
    _signal_semaphore_values_count(other._signal_semaphore_values_count),
    _signal_semaphore_values(other._signal_semaphore_values)
  {
  }

  /// Move constructor.
  constexpr d3d_12_fence_submit_info_khr(
    d3d_12_fence_submit_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _wait_semaphore_values_count(std::move(other._wait_semaphore_values_count)),
    _wait_semaphore_values(std::move(other._wait_semaphore_values)),
    _signal_semaphore_values_count(
      std::move(other._signal_semaphore_values_count)),
    _signal_semaphore_values(std::move(other._signal_semaphore_values))
  {
  }

  /// Copy assignment operator.
  constexpr d3d_12_fence_submit_info_khr& operator=(
    const d3d_12_fence_submit_info_khr& other) noexcept
  {
    _next = other._next;
    _wait_semaphore_values_count = other._wait_semaphore_values_count;
    _wait_semaphore_values = other._wait_semaphore_values;
    _signal_semaphore_values_count = other._signal_semaphore_values_count;
    _signal_semaphore_values = other._signal_semaphore_values;
    return *this;
  }

  /// Move assignment operator.
  constexpr d3d_12_fence_submit_info_khr& operator=(
    d3d_12_fence_submit_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _wait_semaphore_values_count =
      std::move(other._wait_semaphore_values_count);
    _wait_semaphore_values = std::move(other._wait_semaphore_values);
    _signal_semaphore_values_count =
      std::move(other._signal_semaphore_values_count);
    _signal_semaphore_values = std::move(other._signal_semaphore_values);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkD3D12FenceSubmitInfoKHR&() const
  {
    return *reinterpret_cast<const VkD3D12FenceSubmitInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  uint32_t& wait_semaphore_values_count()
  {
    return _wait_semaphore_values_count;
  }

  constexpr const uint32_t& wait_semaphore_values_count() const
  {
    return _wait_semaphore_values_count;
  }

  void wait_semaphore_values_count(uint32_t new_wait_semaphore_values_count)
  {
    _wait_semaphore_values_count = new_wait_semaphore_values_count;
  }

  const uint64_t* wait_semaphore_values()
  {
    return _wait_semaphore_values;
  }

  constexpr const uint64_t* wait_semaphore_values() const
  {
    return _wait_semaphore_values;
  }

  void wait_semaphore_values(const uint64_t* new_wait_semaphore_values)
  {
    _wait_semaphore_values = new_wait_semaphore_values;
  }

  template <std::size_t Count>
  void wait_semaphore_values(
    const std::array<uint64_t, Count>& new_wait_semaphore_values)
  {
    _wait_semaphore_values_count =
      static_cast<uint32_t>(new_wait_semaphore_values.size());
    _wait_semaphore_values = new_wait_semaphore_values.data();
  }

  void wait_semaphore_values(
    const std::vector<uint64_t>& new_wait_semaphore_values)
  {
    _wait_semaphore_values_count =
      static_cast<uint32_t>(new_wait_semaphore_values.size());
    _wait_semaphore_values = new_wait_semaphore_values.data();
  }

  uint32_t& signal_semaphore_values_count()
  {
    return _signal_semaphore_values_count;
  }

  constexpr const uint32_t& signal_semaphore_values_count() const
  {
    return _signal_semaphore_values_count;
  }

  void signal_semaphore_values_count(uint32_t new_signal_semaphore_values_count)
  {
    _signal_semaphore_values_count = new_signal_semaphore_values_count;
  }

  const uint64_t* signal_semaphore_values()
  {
    return _signal_semaphore_values;
  }

  constexpr const uint64_t* signal_semaphore_values() const
  {
    return _signal_semaphore_values;
  }

  void signal_semaphore_values(const uint64_t* new_signal_semaphore_values)
  {
    _signal_semaphore_values = new_signal_semaphore_values;
  }

  template <std::size_t Count>
  void signal_semaphore_values(
    const std::array<uint64_t, Count>& new_signal_semaphore_values)
  {
    _signal_semaphore_values_count =
      static_cast<uint32_t>(new_signal_semaphore_values.size());
    _signal_semaphore_values = new_signal_semaphore_values.data();
  }

  void signal_semaphore_values(
    const std::vector<uint64_t>& new_signal_semaphore_values)
  {
    _signal_semaphore_values_count =
      static_cast<uint32_t>(new_signal_semaphore_values.size());
    _signal_semaphore_values = new_signal_semaphore_values.data();
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::d3d_12_fence_submit_info_khr;
  const void* _next = nullptr;
  uint32_t _wait_semaphore_values_count = 0;
  const uint64_t* _wait_semaphore_values = nullptr;
  uint32_t _signal_semaphore_values_count = 0;
  const uint64_t* _signal_semaphore_values = nullptr;
};
static_assert(sizeof(d3d_12_fence_submit_info_khr) ==
                sizeof(::VkD3D12FenceSubmitInfoKHR),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkSemaphoreGetWin32HandleInfoKHR.
class semaphore_get_win32_handle_info_khr
{
public:
  /// Default constructor.
  constexpr semaphore_get_win32_handle_info_khr() = default;

  /// Constructor.
  constexpr semaphore_get_win32_handle_info_khr(
    const void* initial_next, VkSemaphore initial_semaphore,
    vk::external_semaphore_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)),
    _semaphore(std::move(initial_semaphore)),
    _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr semaphore_get_win32_handle_info_khr(
    const semaphore_get_win32_handle_info_khr& other) noexcept
  : _next(other._next),
    _semaphore(other._semaphore),
    _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr semaphore_get_win32_handle_info_khr(
    semaphore_get_win32_handle_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _semaphore(std::move(other._semaphore)),
    _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr semaphore_get_win32_handle_info_khr& operator=(
    const semaphore_get_win32_handle_info_khr& other) noexcept
  {
    _next = other._next;
    _semaphore = other._semaphore;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr semaphore_get_win32_handle_info_khr& operator=(
    semaphore_get_win32_handle_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _semaphore = std::move(other._semaphore);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSemaphoreGetWin32HandleInfoKHR&() const
  {
    return *reinterpret_cast<const VkSemaphoreGetWin32HandleInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkSemaphore& semaphore()
  {
    return _semaphore;
  }

  constexpr const VkSemaphore& semaphore() const
  {
    return _semaphore;
  }

  void semaphore(VkSemaphore new_semaphore)
  {
    _semaphore = new_semaphore;
  }

  vk::external_semaphore_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_semaphore_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_semaphore_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::semaphore_get_win32_handle_info_khr;
  const void* _next = nullptr;
  VkSemaphore _semaphore = nullptr;
  vk::external_semaphore_handle_type_flag _handle_type =
    vk::external_semaphore_handle_type_flag::none;
};
static_assert(sizeof(semaphore_get_win32_handle_info_khr) ==
                sizeof(::VkSemaphoreGetWin32HandleInfoKHR),
              "struct and wrapper have different size!");

#endif
inline vk::result import_semaphore_win32_handle_khr(
  VkDevice device, const vk::import_semaphore_win32_handle_info_khr*
                     import_semaphore_win32_handle_info)
{
  return static_cast<vk::result>(vkImportSemaphoreWin32HandleKHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkImportSemaphoreWin32HandleInfoKHR*>(
      import_semaphore_win32_handle_info)));
}
inline vk::result get_semaphore_win32_handle_khr(
  VkDevice device,
  const vk::semaphore_get_win32_handle_info_khr* get_win32_handle_info,
  HANDLE* handle)
{
  return static_cast<vk::result>(vkGetSemaphoreWin32HandleKHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkSemaphoreGetWin32HandleInfoKHR*>(
      get_win32_handle_info),
    reinterpret_cast<HANDLE*>(handle)));
}
#endif
#if defined(VK_USE_PLATFORM_XLIB_XRANDR_EXT)
inline vk::result acquire_xlib_display_ext(VkPhysicalDevice physical_device,
                                           Display* dpy, VkDisplayKHR display)
{
  return static_cast<vk::result>(vkAcquireXlibDisplayEXT(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<Display*>(dpy), static_cast<VkDisplayKHR>(display)));
}
inline vk::result get_rand_routput_display_ext(VkPhysicalDevice physical_device,
                                               Display* dpy, RROutput rr_output,
                                               VkDisplayKHR* display)
{
  return static_cast<vk::result>(vkGetRandROutputDisplayEXT(
    static_cast<VkPhysicalDevice>(physical_device),
    reinterpret_cast<Display*>(dpy), static_cast<RROutput>(rr_output),
    reinterpret_cast<VkDisplayKHR*>(display)));
}
#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkImportFenceWin32HandleInfoKHR.
class import_fence_win32_handle_info_khr
{
public:
  /// Default constructor.
  constexpr import_fence_win32_handle_info_khr() = default;

  /// Constructor.
  constexpr import_fence_win32_handle_info_khr(
    const void* initial_next, VkFence initial_fence,
    vk::fence_import_flags initial_flags,
    vk::external_fence_handle_type_flag initial_handle_type,
    HANDLE initial_handle, LPCWSTR initial_name) noexcept
  : _next(std::move(initial_next)),
    _fence(std::move(initial_fence)),
    _flags(std::move(initial_flags)),
    _handle_type(std::move(initial_handle_type)),
    _handle(std::move(initial_handle)),
    _name(std::move(initial_name))
  {
  }

  /// Copy constructor.
  constexpr import_fence_win32_handle_info_khr(
    const import_fence_win32_handle_info_khr& other) noexcept
  : _next(other._next),
    _fence(other._fence),
    _flags(other._flags),
    _handle_type(other._handle_type),
    _handle(other._handle),
    _name(other._name)
  {
  }

  /// Move constructor.
  constexpr import_fence_win32_handle_info_khr(
    import_fence_win32_handle_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _fence(std::move(other._fence)),
    _flags(std::move(other._flags)),
    _handle_type(std::move(other._handle_type)),
    _handle(std::move(other._handle)),
    _name(std::move(other._name))
  {
  }

  /// Copy assignment operator.
  constexpr import_fence_win32_handle_info_khr& operator=(
    const import_fence_win32_handle_info_khr& other) noexcept
  {
    _next = other._next;
    _fence = other._fence;
    _flags = other._flags;
    _handle_type = other._handle_type;
    _handle = other._handle;
    _name = other._name;
    return *this;
  }

  /// Move assignment operator.
  constexpr import_fence_win32_handle_info_khr& operator=(
    import_fence_win32_handle_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _fence = std::move(other._fence);
    _flags = std::move(other._flags);
    _handle_type = std::move(other._handle_type);
    _handle = std::move(other._handle);
    _name = std::move(other._name);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImportFenceWin32HandleInfoKHR&() const
  {
    return *reinterpret_cast<const VkImportFenceWin32HandleInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkFence& fence()
  {
    return _fence;
  }

  constexpr const VkFence& fence() const
  {
    return _fence;
  }

  void fence(VkFence new_fence)
  {
    _fence = new_fence;
  }

  vk::fence_import_flags& flags()
  {
    return _flags;
  }

  constexpr const vk::fence_import_flags& flags() const
  {
    return _flags;
  }

  void flags(vk::fence_import_flags new_flags)
  {
    _flags = new_flags;
  }

  vk::external_fence_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_fence_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_fence_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

  HANDLE& handle()
  {
    return _handle;
  }

  constexpr const HANDLE& handle() const
  {
    return _handle;
  }

  void handle(HANDLE new_handle)
  {
    _handle = new_handle;
  }

  LPCWSTR& name()
  {
    return _name;
  }

  constexpr const LPCWSTR& name() const
  {
    return _name;
  }

  void name(LPCWSTR new_name)
  {
    _name = new_name;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::import_fence_win32_handle_info_khr;
  const void* _next = nullptr;
  VkFence _fence = nullptr;
  vk::fence_import_flags _flags = vk::fence_import_flag::none;
  vk::external_fence_handle_type_flag _handle_type =
    vk::external_fence_handle_type_flag::none;
  HANDLE _handle = 0;
  LPCWSTR _name = 0;
};
static_assert(sizeof(import_fence_win32_handle_info_khr) ==
                sizeof(::VkImportFenceWin32HandleInfoKHR),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkExportFenceWin32HandleInfoKHR.
class export_fence_win32_handle_info_khr
{
public:
  /// Default constructor.
  constexpr export_fence_win32_handle_info_khr() = default;

  /// Constructor.
  constexpr export_fence_win32_handle_info_khr(
    const void* initial_next, const SECURITY_ATTRIBUTES* initial_attributes,
    DWORD initial_dw_access, LPCWSTR initial_name) noexcept
  : _next(std::move(initial_next)),
    _attributes(std::move(initial_attributes)),
    _dw_access(std::move(initial_dw_access)),
    _name(std::move(initial_name))
  {
  }

  /// Copy constructor.
  constexpr export_fence_win32_handle_info_khr(
    const export_fence_win32_handle_info_khr& other) noexcept
  : _next(other._next),
    _attributes(other._attributes),
    _dw_access(other._dw_access),
    _name(other._name)
  {
  }

  /// Move constructor.
  constexpr export_fence_win32_handle_info_khr(
    export_fence_win32_handle_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _attributes(std::move(other._attributes)),
    _dw_access(std::move(other._dw_access)),
    _name(std::move(other._name))
  {
  }

  /// Copy assignment operator.
  constexpr export_fence_win32_handle_info_khr& operator=(
    const export_fence_win32_handle_info_khr& other) noexcept
  {
    _next = other._next;
    _attributes = other._attributes;
    _dw_access = other._dw_access;
    _name = other._name;
    return *this;
  }

  /// Move assignment operator.
  constexpr export_fence_win32_handle_info_khr& operator=(
    export_fence_win32_handle_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _attributes = std::move(other._attributes);
    _dw_access = std::move(other._dw_access);
    _name = std::move(other._name);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExportFenceWin32HandleInfoKHR&() const
  {
    return *reinterpret_cast<const VkExportFenceWin32HandleInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  const SECURITY_ATTRIBUTES* attributes()
  {
    return _attributes;
  }

  constexpr const SECURITY_ATTRIBUTES* attributes() const
  {
    return _attributes;
  }

  void attributes(const SECURITY_ATTRIBUTES* new_attributes)
  {
    _attributes = new_attributes;
  }

  DWORD& dw_access()
  {
    return _dw_access;
  }

  constexpr const DWORD& dw_access() const
  {
    return _dw_access;
  }

  void dw_access(DWORD new_dw_access)
  {
    _dw_access = new_dw_access;
  }

  LPCWSTR& name()
  {
    return _name;
  }

  constexpr const LPCWSTR& name() const
  {
    return _name;
  }

  void name(LPCWSTR new_name)
  {
    _name = new_name;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::export_fence_win32_handle_info_khr;
  const void* _next = nullptr;
  const SECURITY_ATTRIBUTES* _attributes = nullptr;
  DWORD _dw_access = 0;
  LPCWSTR _name = 0;
};
static_assert(sizeof(export_fence_win32_handle_info_khr) ==
                sizeof(::VkExportFenceWin32HandleInfoKHR),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_WIN32_KHR)

/// Enhanced replacement type for VkFenceGetWin32HandleInfoKHR.
class fence_get_win32_handle_info_khr
{
public:
  /// Default constructor.
  constexpr fence_get_win32_handle_info_khr() = default;

  /// Constructor.
  constexpr fence_get_win32_handle_info_khr(
    const void* initial_next, VkFence initial_fence,
    vk::external_fence_handle_type_flag initial_handle_type) noexcept
  : _next(std::move(initial_next)),
    _fence(std::move(initial_fence)),
    _handle_type(std::move(initial_handle_type))
  {
  }

  /// Copy constructor.
  constexpr fence_get_win32_handle_info_khr(
    const fence_get_win32_handle_info_khr& other) noexcept
  : _next(other._next), _fence(other._fence), _handle_type(other._handle_type)
  {
  }

  /// Move constructor.
  constexpr fence_get_win32_handle_info_khr(
    fence_get_win32_handle_info_khr&& other) noexcept
  : _next(std::move(other._next)),
    _fence(std::move(other._fence)),
    _handle_type(std::move(other._handle_type))
  {
  }

  /// Copy assignment operator.
  constexpr fence_get_win32_handle_info_khr& operator=(
    const fence_get_win32_handle_info_khr& other) noexcept
  {
    _next = other._next;
    _fence = other._fence;
    _handle_type = other._handle_type;
    return *this;
  }

  /// Move assignment operator.
  constexpr fence_get_win32_handle_info_khr& operator=(
    fence_get_win32_handle_info_khr&& other) noexcept
  {
    _next = std::move(other._next);
    _fence = std::move(other._fence);
    _handle_type = std::move(other._handle_type);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkFenceGetWin32HandleInfoKHR&() const
  {
    return *reinterpret_cast<const VkFenceGetWin32HandleInfoKHR*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkFence& fence()
  {
    return _fence;
  }

  constexpr const VkFence& fence() const
  {
    return _fence;
  }

  void fence(VkFence new_fence)
  {
    _fence = new_fence;
  }

  vk::external_fence_handle_type_flag& handle_type()
  {
    return _handle_type;
  }

  constexpr const vk::external_fence_handle_type_flag& handle_type() const
  {
    return _handle_type;
  }

  void handle_type(vk::external_fence_handle_type_flag new_handle_type)
  {
    _handle_type = new_handle_type;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::fence_get_win32_handle_info_khr;
  const void* _next = nullptr;
  VkFence _fence = nullptr;
  vk::external_fence_handle_type_flag _handle_type =
    vk::external_fence_handle_type_flag::none;
};
static_assert(sizeof(fence_get_win32_handle_info_khr) ==
                sizeof(::VkFenceGetWin32HandleInfoKHR),
              "struct and wrapper have different size!");

#endif
inline vk::result import_fence_win32_handle_khr(
  VkDevice device,
  const vk::import_fence_win32_handle_info_khr* import_fence_win32_handle_info)
{
  return static_cast<vk::result>(vkImportFenceWin32HandleKHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkImportFenceWin32HandleInfoKHR*>(
      import_fence_win32_handle_info)));
}
inline vk::result get_fence_win32_handle_khr(
  VkDevice device,
  const vk::fence_get_win32_handle_info_khr* get_win32_handle_info,
  HANDLE* handle)
{
  return static_cast<vk::result>(vkGetFenceWin32HandleKHR(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkFenceGetWin32HandleInfoKHR*>(
      get_win32_handle_info),
    reinterpret_cast<HANDLE*>(handle)));
}
#endif
#if defined(VK_USE_PLATFORM_IOS_MVK)
#if defined(VK_USE_PLATFORM_IOS_MVK)
using iossurface_create_flags_mvk = VkFlags;
#endif
#if defined(VK_USE_PLATFORM_IOS_MVK)

/// Enhanced replacement type for VkIOSSurfaceCreateInfoMVK.
class iossurface_create_info_mvk
{
public:
  /// Default constructor.
  constexpr iossurface_create_info_mvk() = default;

  /// Constructor.
  constexpr iossurface_create_info_mvk(
    const void* initial_next, vk::iossurface_create_flags_mvk initial_flags,
    const void* initial_view) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _view(std::move(initial_view))
  {
  }

  /// Copy constructor.
  constexpr iossurface_create_info_mvk(
    const iossurface_create_info_mvk& other) noexcept
  : _next(other._next), _flags(other._flags), _view(other._view)
  {
  }

  /// Move constructor.
  constexpr iossurface_create_info_mvk(
    iossurface_create_info_mvk&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _view(std::move(other._view))
  {
  }

  /// Copy assignment operator.
  constexpr iossurface_create_info_mvk& operator=(
    const iossurface_create_info_mvk& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _view = other._view;
    return *this;
  }

  /// Move assignment operator.
  constexpr iossurface_create_info_mvk& operator=(
    iossurface_create_info_mvk&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _view = std::move(other._view);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkIOSSurfaceCreateInfoMVK&() const
  {
    return *reinterpret_cast<const VkIOSSurfaceCreateInfoMVK*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::iossurface_create_flags_mvk& flags()
  {
    return _flags;
  }

  constexpr const vk::iossurface_create_flags_mvk& flags() const
  {
    return _flags;
  }

  void flags(vk::iossurface_create_flags_mvk new_flags)
  {
    _flags = new_flags;
  }

  const void* view()
  {
    return _view;
  }

  constexpr const void* view() const
  {
    return _view;
  }

  void view(const void* new_view)
  {
    _view = new_view;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::ios_surface_create_info_mvk;
  const void* _next = nullptr;
  vk::iossurface_create_flags_mvk _flags = 0;
  const void* _view = nullptr;
};
static_assert(sizeof(iossurface_create_info_mvk) ==
                sizeof(::VkIOSSurfaceCreateInfoMVK),
              "struct and wrapper have different size!");

#endif
inline vk::result create_iossurface_mvk(
  VkInstance instance, const vk::iossurface_create_info_mvk* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateIOSSurfaceMVK(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkIOSSurfaceCreateInfoMVK*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}
#endif
#if defined(VK_USE_PLATFORM_MACOS_MVK)
#if defined(VK_USE_PLATFORM_MACOS_MVK)
using mac_ossurface_create_flags_mvk = VkFlags;
#endif
#if defined(VK_USE_PLATFORM_MACOS_MVK)

/// Enhanced replacement type for VkMacOSSurfaceCreateInfoMVK.
class mac_ossurface_create_info_mvk
{
public:
  /// Default constructor.
  constexpr mac_ossurface_create_info_mvk() = default;

  /// Constructor.
  constexpr mac_ossurface_create_info_mvk(
    const void* initial_next, vk::mac_ossurface_create_flags_mvk initial_flags,
    const void* initial_view) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _view(std::move(initial_view))
  {
  }

  /// Copy constructor.
  constexpr mac_ossurface_create_info_mvk(
    const mac_ossurface_create_info_mvk& other) noexcept
  : _next(other._next), _flags(other._flags), _view(other._view)
  {
  }

  /// Move constructor.
  constexpr mac_ossurface_create_info_mvk(
    mac_ossurface_create_info_mvk&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _view(std::move(other._view))
  {
  }

  /// Copy assignment operator.
  constexpr mac_ossurface_create_info_mvk& operator=(
    const mac_ossurface_create_info_mvk& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _view = other._view;
    return *this;
  }

  /// Move assignment operator.
  constexpr mac_ossurface_create_info_mvk& operator=(
    mac_ossurface_create_info_mvk&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _view = std::move(other._view);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMacOSSurfaceCreateInfoMVK&() const
  {
    return *reinterpret_cast<const VkMacOSSurfaceCreateInfoMVK*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::mac_ossurface_create_flags_mvk& flags()
  {
    return _flags;
  }

  constexpr const vk::mac_ossurface_create_flags_mvk& flags() const
  {
    return _flags;
  }

  void flags(vk::mac_ossurface_create_flags_mvk new_flags)
  {
    _flags = new_flags;
  }

  const void* view()
  {
    return _view;
  }

  constexpr const void* view() const
  {
    return _view;
  }

  void view(const void* new_view)
  {
    _view = new_view;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::macos_surface_create_info_mvk;
  const void* _next = nullptr;
  vk::mac_ossurface_create_flags_mvk _flags = 0;
  const void* _view = nullptr;
};
static_assert(sizeof(mac_ossurface_create_info_mvk) ==
                sizeof(::VkMacOSSurfaceCreateInfoMVK),
              "struct and wrapper have different size!");

#endif
inline vk::result create_mac_ossurface_mvk(
  VkInstance instance, const vk::mac_ossurface_create_info_mvk* create_info,
  const vk::allocation_callbacks* allocator, VkSurfaceKHR* surface)
{
  return static_cast<vk::result>(vkCreateMacOSSurfaceMVK(
    static_cast<VkInstance>(instance),
    reinterpret_cast<const VkMacOSSurfaceCreateInfoMVK*>(create_info),
    reinterpret_cast<const VkAllocationCallbacks*>(allocator),
    reinterpret_cast<VkSurfaceKHR*>(surface)));
}
#endif
#if defined(VK_USE_PLATFORM_ANDROID_KHR)
#if defined(VK_USE_PLATFORM_ANDROID_KHR)

/// Enhanced replacement type for VkAndroidHardwareBufferUsageANDROID.
class android_hardware_buffer_usage_android
{
public:
  /// Default constructor.
  constexpr android_hardware_buffer_usage_android() = default;

  /// Constructor.
  constexpr android_hardware_buffer_usage_android(
    void* initial_next, uint64_t initial_android_hardware_buffer_usage) noexcept
  : _next(std::move(initial_next)),
    _android_hardware_buffer_usage(
      std::move(initial_android_hardware_buffer_usage))
  {
  }

  /// Copy constructor.
  constexpr android_hardware_buffer_usage_android(
    const android_hardware_buffer_usage_android& other) noexcept
  : _next(other._next),
    _android_hardware_buffer_usage(other._android_hardware_buffer_usage)
  {
  }

  /// Move constructor.
  constexpr android_hardware_buffer_usage_android(
    android_hardware_buffer_usage_android&& other) noexcept
  : _next(std::move(other._next)),
    _android_hardware_buffer_usage(
      std::move(other._android_hardware_buffer_usage))
  {
  }

  /// Copy assignment operator.
  constexpr android_hardware_buffer_usage_android& operator=(
    const android_hardware_buffer_usage_android& other) noexcept
  {
    _next = other._next;
    _android_hardware_buffer_usage = other._android_hardware_buffer_usage;
    return *this;
  }

  /// Move assignment operator.
  constexpr android_hardware_buffer_usage_android& operator=(
    android_hardware_buffer_usage_android&& other) noexcept
  {
    _next = std::move(other._next);
    _android_hardware_buffer_usage =
      std::move(other._android_hardware_buffer_usage);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkAndroidHardwareBufferUsageANDROID&() const
  {
    return *reinterpret_cast<const VkAndroidHardwareBufferUsageANDROID*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint64_t& android_hardware_buffer_usage()
  {
    return _android_hardware_buffer_usage;
  }

  constexpr const uint64_t& android_hardware_buffer_usage() const
  {
    return _android_hardware_buffer_usage;
  }

  void android_hardware_buffer_usage(uint64_t new_android_hardware_buffer_usage)
  {
    _android_hardware_buffer_usage = new_android_hardware_buffer_usage;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::android_hardware_buffer_usage_android;
  void* _next = nullptr;
  uint64_t _android_hardware_buffer_usage = 0;
};
static_assert(sizeof(android_hardware_buffer_usage_android) ==
                sizeof(::VkAndroidHardwareBufferUsageANDROID),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_ANDROID_KHR)

/// Enhanced replacement type for VkAndroidHardwareBufferPropertiesANDROID.
class android_hardware_buffer_properties_android
{
public:
  /// Default constructor.
  constexpr android_hardware_buffer_properties_android() = default;

  /// Constructor.
  constexpr android_hardware_buffer_properties_android(
    void* initial_next, VkDeviceSize initial_allocation_size,
    uint32_t initial_memory_type_bits) noexcept
  : _next(std::move(initial_next)),
    _allocation_size(std::move(initial_allocation_size)),
    _memory_type_bits(std::move(initial_memory_type_bits))
  {
  }

  /// Copy constructor.
  constexpr android_hardware_buffer_properties_android(
    const android_hardware_buffer_properties_android& other) noexcept
  : _next(other._next),
    _allocation_size(other._allocation_size),
    _memory_type_bits(other._memory_type_bits)
  {
  }

  /// Move constructor.
  constexpr android_hardware_buffer_properties_android(
    android_hardware_buffer_properties_android&& other) noexcept
  : _next(std::move(other._next)),
    _allocation_size(std::move(other._allocation_size)),
    _memory_type_bits(std::move(other._memory_type_bits))
  {
  }

  /// Copy assignment operator.
  constexpr android_hardware_buffer_properties_android& operator=(
    const android_hardware_buffer_properties_android& other) noexcept
  {
    _next = other._next;
    _allocation_size = other._allocation_size;
    _memory_type_bits = other._memory_type_bits;
    return *this;
  }

  /// Move assignment operator.
  constexpr android_hardware_buffer_properties_android& operator=(
    android_hardware_buffer_properties_android&& other) noexcept
  {
    _next = std::move(other._next);
    _allocation_size = std::move(other._allocation_size);
    _memory_type_bits = std::move(other._memory_type_bits);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkAndroidHardwareBufferPropertiesANDROID&() const
  {
    return *reinterpret_cast<const VkAndroidHardwareBufferPropertiesANDROID*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  VkDeviceSize& allocation_size()
  {
    return _allocation_size;
  }

  constexpr const VkDeviceSize& allocation_size() const
  {
    return _allocation_size;
  }

  void allocation_size(VkDeviceSize new_allocation_size)
  {
    _allocation_size = new_allocation_size;
  }

  uint32_t& memory_type_bits()
  {
    return _memory_type_bits;
  }

  constexpr const uint32_t& memory_type_bits() const
  {
    return _memory_type_bits;
  }

  void memory_type_bits(uint32_t new_memory_type_bits)
  {
    _memory_type_bits = new_memory_type_bits;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::android_hardware_buffer_properties_android;
  void* _next = nullptr;
  VkDeviceSize _allocation_size = 0;
  uint32_t _memory_type_bits = 0;
};
static_assert(sizeof(android_hardware_buffer_properties_android) ==
                sizeof(::VkAndroidHardwareBufferPropertiesANDROID),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_ANDROID_KHR)

/// Enhanced replacement type for
/// VkAndroidHardwareBufferFormatPropertiesANDROID.
class android_hardware_buffer_format_properties_android
{
public:
  /// Default constructor.
  constexpr android_hardware_buffer_format_properties_android() = default;

  /// Constructor.
  constexpr android_hardware_buffer_format_properties_android(
    void* initial_next, vk::format initial_format,
    uint64_t initial_external_format,
    vk::format_feature_flags initial_format_features,
    vk::component_mapping initial_sampler_ycbcr_conversion_components,
    vk::sampler_ycbcr_model_conversion initial_suggested_ycbcr_model,
    vk::sampler_ycbcr_range initial_suggested_ycbcr_range,
    vk::chroma_location initial_suggested_xchroma_offset,
    vk::chroma_location initial_suggested_ychroma_offset) noexcept
  : _next(std::move(initial_next)),
    _format(std::move(initial_format)),
    _external_format(std::move(initial_external_format)),
    _format_features(std::move(initial_format_features)),
    _sampler_ycbcr_conversion_components(
      std::move(initial_sampler_ycbcr_conversion_components)),
    _suggested_ycbcr_model(std::move(initial_suggested_ycbcr_model)),
    _suggested_ycbcr_range(std::move(initial_suggested_ycbcr_range)),
    _suggested_xchroma_offset(std::move(initial_suggested_xchroma_offset)),
    _suggested_ychroma_offset(std::move(initial_suggested_ychroma_offset))
  {
  }

  /// Copy constructor.
  constexpr android_hardware_buffer_format_properties_android(
    const android_hardware_buffer_format_properties_android& other) noexcept
  : _next(other._next),
    _format(other._format),
    _external_format(other._external_format),
    _format_features(other._format_features),
    _sampler_ycbcr_conversion_components(
      other._sampler_ycbcr_conversion_components),
    _suggested_ycbcr_model(other._suggested_ycbcr_model),
    _suggested_ycbcr_range(other._suggested_ycbcr_range),
    _suggested_xchroma_offset(other._suggested_xchroma_offset),
    _suggested_ychroma_offset(other._suggested_ychroma_offset)
  {
  }

  /// Move constructor.
  constexpr android_hardware_buffer_format_properties_android(
    android_hardware_buffer_format_properties_android&& other) noexcept
  : _next(std::move(other._next)),
    _format(std::move(other._format)),
    _external_format(std::move(other._external_format)),
    _format_features(std::move(other._format_features)),
    _sampler_ycbcr_conversion_components(
      std::move(other._sampler_ycbcr_conversion_components)),
    _suggested_ycbcr_model(std::move(other._suggested_ycbcr_model)),
    _suggested_ycbcr_range(std::move(other._suggested_ycbcr_range)),
    _suggested_xchroma_offset(std::move(other._suggested_xchroma_offset)),
    _suggested_ychroma_offset(std::move(other._suggested_ychroma_offset))
  {
  }

  /// Copy assignment operator.
  constexpr android_hardware_buffer_format_properties_android& operator=(
    const android_hardware_buffer_format_properties_android& other) noexcept
  {
    _next = other._next;
    _format = other._format;
    _external_format = other._external_format;
    _format_features = other._format_features;
    _sampler_ycbcr_conversion_components =
      other._sampler_ycbcr_conversion_components;
    _suggested_ycbcr_model = other._suggested_ycbcr_model;
    _suggested_ycbcr_range = other._suggested_ycbcr_range;
    _suggested_xchroma_offset = other._suggested_xchroma_offset;
    _suggested_ychroma_offset = other._suggested_ychroma_offset;
    return *this;
  }

  /// Move assignment operator.
  constexpr android_hardware_buffer_format_properties_android& operator=(
    android_hardware_buffer_format_properties_android&& other) noexcept
  {
    _next = std::move(other._next);
    _format = std::move(other._format);
    _external_format = std::move(other._external_format);
    _format_features = std::move(other._format_features);
    _sampler_ycbcr_conversion_components =
      std::move(other._sampler_ycbcr_conversion_components);
    _suggested_ycbcr_model = std::move(other._suggested_ycbcr_model);
    _suggested_ycbcr_range = std::move(other._suggested_ycbcr_range);
    _suggested_xchroma_offset = std::move(other._suggested_xchroma_offset);
    _suggested_ychroma_offset = std::move(other._suggested_ychroma_offset);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkAndroidHardwareBufferFormatPropertiesANDROID&() const
  {
    return *reinterpret_cast<
      const VkAndroidHardwareBufferFormatPropertiesANDROID*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  vk::format& format()
  {
    return _format;
  }

  constexpr const vk::format& format() const
  {
    return _format;
  }

  void format(vk::format new_format)
  {
    _format = new_format;
  }

  uint64_t& external_format()
  {
    return _external_format;
  }

  constexpr const uint64_t& external_format() const
  {
    return _external_format;
  }

  void external_format(uint64_t new_external_format)
  {
    _external_format = new_external_format;
  }

  vk::format_feature_flags& format_features()
  {
    return _format_features;
  }

  constexpr const vk::format_feature_flags& format_features() const
  {
    return _format_features;
  }

  void format_features(vk::format_feature_flags new_format_features)
  {
    _format_features = new_format_features;
  }

  vk::component_mapping& sampler_ycbcr_conversion_components()
  {
    return _sampler_ycbcr_conversion_components;
  }

  constexpr const vk::component_mapping& sampler_ycbcr_conversion_components()
    const
  {
    return _sampler_ycbcr_conversion_components;
  }

  void sampler_ycbcr_conversion_components(
    vk::component_mapping new_sampler_ycbcr_conversion_components)
  {
    _sampler_ycbcr_conversion_components =
      new_sampler_ycbcr_conversion_components;
  }

  vk::sampler_ycbcr_model_conversion& suggested_ycbcr_model()
  {
    return _suggested_ycbcr_model;
  }

  constexpr const vk::sampler_ycbcr_model_conversion& suggested_ycbcr_model()
    const
  {
    return _suggested_ycbcr_model;
  }

  void suggested_ycbcr_model(
    vk::sampler_ycbcr_model_conversion new_suggested_ycbcr_model)
  {
    _suggested_ycbcr_model = new_suggested_ycbcr_model;
  }

  vk::sampler_ycbcr_range& suggested_ycbcr_range()
  {
    return _suggested_ycbcr_range;
  }

  constexpr const vk::sampler_ycbcr_range& suggested_ycbcr_range() const
  {
    return _suggested_ycbcr_range;
  }

  void suggested_ycbcr_range(vk::sampler_ycbcr_range new_suggested_ycbcr_range)
  {
    _suggested_ycbcr_range = new_suggested_ycbcr_range;
  }

  vk::chroma_location& suggested_xchroma_offset()
  {
    return _suggested_xchroma_offset;
  }

  constexpr const vk::chroma_location& suggested_xchroma_offset() const
  {
    return _suggested_xchroma_offset;
  }

  void suggested_xchroma_offset(
    vk::chroma_location new_suggested_xchroma_offset)
  {
    _suggested_xchroma_offset = new_suggested_xchroma_offset;
  }

  vk::chroma_location& suggested_ychroma_offset()
  {
    return _suggested_ychroma_offset;
  }

  constexpr const vk::chroma_location& suggested_ychroma_offset() const
  {
    return _suggested_ychroma_offset;
  }

  void suggested_ychroma_offset(
    vk::chroma_location new_suggested_ychroma_offset)
  {
    _suggested_ychroma_offset = new_suggested_ychroma_offset;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::android_hardware_buffer_format_properties_android;
  void* _next = nullptr;
  vk::format _format = vk::format::undefined;
  uint64_t _external_format = 0;
  vk::format_feature_flags _format_features = vk::format_feature_flag::none;
  vk::component_mapping _sampler_ycbcr_conversion_components =
    vk::component_mapping{};
  vk::sampler_ycbcr_model_conversion _suggested_ycbcr_model =
    vk::sampler_ycbcr_model_conversion::rgb_identity;
  vk::sampler_ycbcr_range _suggested_ycbcr_range =
    vk::sampler_ycbcr_range::itu_full;
  vk::chroma_location _suggested_xchroma_offset =
    vk::chroma_location::cosited_even;
  vk::chroma_location _suggested_ychroma_offset =
    vk::chroma_location::cosited_even;
};
static_assert(sizeof(android_hardware_buffer_format_properties_android) ==
                sizeof(::VkAndroidHardwareBufferFormatPropertiesANDROID),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_ANDROID_KHR)

/// Enhanced replacement type for VkImportAndroidHardwareBufferInfoANDROID.
class import_android_hardware_buffer_info_android
{
public:
  /// Default constructor.
  constexpr import_android_hardware_buffer_info_android() = default;

  /// Constructor.
  constexpr import_android_hardware_buffer_info_android(
    const void* initial_next, struct AHardwareBuffer* initial_buffer) noexcept
  : _next(std::move(initial_next)), _buffer(std::move(initial_buffer))
  {
  }

  /// Copy constructor.
  constexpr import_android_hardware_buffer_info_android(
    const import_android_hardware_buffer_info_android& other) noexcept
  : _next(other._next), _buffer(other._buffer)
  {
  }

  /// Move constructor.
  constexpr import_android_hardware_buffer_info_android(
    import_android_hardware_buffer_info_android&& other) noexcept
  : _next(std::move(other._next)), _buffer(std::move(other._buffer))
  {
  }

  /// Copy assignment operator.
  constexpr import_android_hardware_buffer_info_android& operator=(
    const import_android_hardware_buffer_info_android& other) noexcept
  {
    _next = other._next;
    _buffer = other._buffer;
    return *this;
  }

  /// Move assignment operator.
  constexpr import_android_hardware_buffer_info_android& operator=(
    import_android_hardware_buffer_info_android&& other) noexcept
  {
    _next = std::move(other._next);
    _buffer = std::move(other._buffer);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkImportAndroidHardwareBufferInfoANDROID&() const
  {
    return *reinterpret_cast<const VkImportAndroidHardwareBufferInfoANDROID*>(
      this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  struct AHardwareBuffer* buffer()
  {
    return _buffer;
  }

  constexpr struct AHardwareBuffer* buffer() const
  {
    return _buffer;
  }

  void buffer(struct AHardwareBuffer* new_buffer)
  {
    _buffer = new_buffer;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::import_android_hardware_buffer_info_android;
  const void* _next = nullptr;
  struct AHardwareBuffer* _buffer = nullptr;
};
static_assert(sizeof(import_android_hardware_buffer_info_android) ==
                sizeof(::VkImportAndroidHardwareBufferInfoANDROID),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_ANDROID_KHR)

/// Enhanced replacement type for VkMemoryGetAndroidHardwareBufferInfoANDROID.
class memory_get_android_hardware_buffer_info_android
{
public:
  /// Default constructor.
  constexpr memory_get_android_hardware_buffer_info_android() = default;

  /// Constructor.
  constexpr memory_get_android_hardware_buffer_info_android(
    const void* initial_next, VkDeviceMemory initial_memory) noexcept
  : _next(std::move(initial_next)), _memory(std::move(initial_memory))
  {
  }

  /// Copy constructor.
  constexpr memory_get_android_hardware_buffer_info_android(
    const memory_get_android_hardware_buffer_info_android& other) noexcept
  : _next(other._next), _memory(other._memory)
  {
  }

  /// Move constructor.
  constexpr memory_get_android_hardware_buffer_info_android(
    memory_get_android_hardware_buffer_info_android&& other) noexcept
  : _next(std::move(other._next)), _memory(std::move(other._memory))
  {
  }

  /// Copy assignment operator.
  constexpr memory_get_android_hardware_buffer_info_android& operator=(
    const memory_get_android_hardware_buffer_info_android& other) noexcept
  {
    _next = other._next;
    _memory = other._memory;
    return *this;
  }

  /// Move assignment operator.
  constexpr memory_get_android_hardware_buffer_info_android& operator=(
    memory_get_android_hardware_buffer_info_android&& other) noexcept
  {
    _next = std::move(other._next);
    _memory = std::move(other._memory);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkMemoryGetAndroidHardwareBufferInfoANDROID&() const
  {
    return *reinterpret_cast<
      const VkMemoryGetAndroidHardwareBufferInfoANDROID*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  VkDeviceMemory& memory()
  {
    return _memory;
  }

  constexpr const VkDeviceMemory& memory() const
  {
    return _memory;
  }

  void memory(VkDeviceMemory new_memory)
  {
    _memory = new_memory;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::memory_get_android_hardware_buffer_info_android;
  const void* _next = nullptr;
  VkDeviceMemory _memory = nullptr;
};
static_assert(sizeof(memory_get_android_hardware_buffer_info_android) ==
                sizeof(::VkMemoryGetAndroidHardwareBufferInfoANDROID),
              "struct and wrapper have different size!");

#endif
#if defined(VK_USE_PLATFORM_ANDROID_KHR)

/// Enhanced replacement type for VkExternalFormatANDROID.
class external_format_android
{
public:
  /// Default constructor.
  constexpr external_format_android() = default;

  /// Constructor.
  constexpr external_format_android(void* initial_next,
                                    uint64_t initial_external_format) noexcept
  : _next(std::move(initial_next)),
    _external_format(std::move(initial_external_format))
  {
  }

  /// Copy constructor.
  constexpr external_format_android(
    const external_format_android& other) noexcept
  : _next(other._next), _external_format(other._external_format)
  {
  }

  /// Move constructor.
  constexpr external_format_android(external_format_android&& other) noexcept
  : _next(std::move(other._next)),
    _external_format(std::move(other._external_format))
  {
  }

  /// Copy assignment operator.
  constexpr external_format_android& operator=(
    const external_format_android& other) noexcept
  {
    _next = other._next;
    _external_format = other._external_format;
    return *this;
  }

  /// Move assignment operator.
  constexpr external_format_android& operator=(
    external_format_android&& other) noexcept
  {
    _next = std::move(other._next);
    _external_format = std::move(other._external_format);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkExternalFormatANDROID&() const
  {
    return *reinterpret_cast<const VkExternalFormatANDROID*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint64_t& external_format()
  {
    return _external_format;
  }

  constexpr const uint64_t& external_format() const
  {
    return _external_format;
  }

  void external_format(uint64_t new_external_format)
  {
    _external_format = new_external_format;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::external_format_android;
  void* _next = nullptr;
  uint64_t _external_format = 0;
};
static_assert(sizeof(external_format_android) ==
                sizeof(::VkExternalFormatANDROID),
              "struct and wrapper have different size!");

#endif
inline vk::result get_android_hardware_buffer_properties_android(
  VkDevice device, const struct AHardwareBuffer* buffer,
  vk::android_hardware_buffer_properties_android* properties)
{
  return static_cast<vk::result>(vkGetAndroidHardwareBufferPropertiesANDROID(
    static_cast<VkDevice>(device),
    reinterpret_cast<const AHardwareBuffer*>(buffer),
    reinterpret_cast<VkAndroidHardwareBufferPropertiesANDROID*>(properties)));
}
inline vk::result get_memory_android_hardware_buffer_android(
  VkDevice device,
  const vk::memory_get_android_hardware_buffer_info_android* info,
  struct AHardwareBuffer** buffer)
{
  return static_cast<vk::result>(vkGetMemoryAndroidHardwareBufferANDROID(
    static_cast<VkDevice>(device),
    reinterpret_cast<const VkMemoryGetAndroidHardwareBufferInfoANDROID*>(info),
    reinterpret_cast<AHardwareBuffer**>(buffer)));
}
#endif
using descriptor_update_template_create_flags_khr = VkFlags;
enum class peer_memory_feature_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using peer_memory_feature_flags_khr =
  shift::core::bit_field<peer_memory_feature_flag_khr,
                         VkPeerMemoryFeatureFlagsKHR>;
inline constexpr peer_memory_feature_flags_khr operator|(
  peer_memory_feature_flag_khr lhs, peer_memory_feature_flag_khr rhs)
{
  return peer_memory_feature_flags_khr{lhs} | rhs;
}
enum class memory_allocate_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using memory_allocate_flags_khr =
  shift::core::bit_field<memory_allocate_flag_khr, VkMemoryAllocateFlagsKHR>;
inline constexpr memory_allocate_flags_khr operator|(
  memory_allocate_flag_khr lhs, memory_allocate_flag_khr rhs)
{
  return memory_allocate_flags_khr{lhs} | rhs;
}
enum class debug_report_flag_ext
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
  /// @see VK_DEBUG_REPORT_INFORMATION_BIT_EXT
  information_bit_ext = 1 << 0,
  /// @see VK_DEBUG_REPORT_WARNING_BIT_EXT
  warning_bit_ext = 1 << 1,
  /// @see VK_DEBUG_REPORT_PERFORMANCE_WARNING_BIT_EXT
  performance_warning_bit_ext = 1 << 2,
  /// @see VK_DEBUG_REPORT_ERROR_BIT_EXT
  error_bit_ext = 1 << 3,
  /// @see VK_DEBUG_REPORT_DEBUG_BIT_EXT
  debug_bit_ext = 1 << 4,
};
using debug_report_flags_ext =
  shift::core::bit_field<debug_report_flag_ext, VkDebugReportFlagsEXT>;
inline constexpr debug_report_flags_ext operator|(debug_report_flag_ext lhs,
                                                  debug_report_flag_ext rhs)
{
  return debug_report_flags_ext{lhs} | rhs;
}
using command_pool_trim_flags_khr = VkFlags;
enum class external_memory_feature_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using external_memory_feature_flags_khr =
  shift::core::bit_field<external_memory_feature_flag_khr,
                         VkExternalMemoryFeatureFlagsKHR>;
inline constexpr external_memory_feature_flags_khr operator|(
  external_memory_feature_flag_khr lhs, external_memory_feature_flag_khr rhs)
{
  return external_memory_feature_flags_khr{lhs} | rhs;
}
enum class external_semaphore_handle_type_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using external_semaphore_handle_type_flags_khr =
  shift::core::bit_field<external_semaphore_handle_type_flag_khr,
                         VkExternalSemaphoreHandleTypeFlagsKHR>;
inline constexpr external_semaphore_handle_type_flags_khr operator|(
  external_semaphore_handle_type_flag_khr lhs,
  external_semaphore_handle_type_flag_khr rhs)
{
  return external_semaphore_handle_type_flags_khr{lhs} | rhs;
}
enum class external_semaphore_feature_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using external_semaphore_feature_flags_khr =
  shift::core::bit_field<external_semaphore_feature_flag_khr,
                         VkExternalSemaphoreFeatureFlagsKHR>;
inline constexpr external_semaphore_feature_flags_khr operator|(
  external_semaphore_feature_flag_khr lhs,
  external_semaphore_feature_flag_khr rhs)
{
  return external_semaphore_feature_flags_khr{lhs} | rhs;
}
enum class semaphore_import_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using semaphore_import_flags_khr =
  shift::core::bit_field<semaphore_import_flag_khr, VkSemaphoreImportFlagsKHR>;
inline constexpr semaphore_import_flags_khr operator|(
  semaphore_import_flag_khr lhs, semaphore_import_flag_khr rhs)
{
  return semaphore_import_flags_khr{lhs} | rhs;
}
enum class external_fence_handle_type_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using external_fence_handle_type_flags_khr =
  shift::core::bit_field<external_fence_handle_type_flag_khr,
                         VkExternalFenceHandleTypeFlagsKHR>;
inline constexpr external_fence_handle_type_flags_khr operator|(
  external_fence_handle_type_flag_khr lhs,
  external_fence_handle_type_flag_khr rhs)
{
  return external_fence_handle_type_flags_khr{lhs} | rhs;
}
enum class external_fence_feature_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using external_fence_feature_flags_khr =
  shift::core::bit_field<external_fence_feature_flag_khr,
                         VkExternalFenceFeatureFlagsKHR>;
inline constexpr external_fence_feature_flags_khr operator|(
  external_fence_feature_flag_khr lhs, external_fence_feature_flag_khr rhs)
{
  return external_fence_feature_flags_khr{lhs} | rhs;
}
enum class fence_import_flag_khr
{
  /// Custom enumerant not available in Vulkan.
  none = 0,
};
using fence_import_flags_khr =
  shift::core::bit_field<fence_import_flag_khr, VkFenceImportFlagsKHR>;
inline constexpr fence_import_flags_khr operator|(fence_import_flag_khr lhs,
                                                  fence_import_flag_khr rhs)
{
  return fence_import_flags_khr{lhs} | rhs;
}
enum class system_allocation_scope
{
  /// @see VK_SYSTEM_ALLOCATION_SCOPE_COMMAND
  command = 0,
  /// @see VK_SYSTEM_ALLOCATION_SCOPE_OBJECT
  object = 1,
  /// @see VK_SYSTEM_ALLOCATION_SCOPE_CACHE
  cache = 2,
  /// @see VK_SYSTEM_ALLOCATION_SCOPE_DEVICE
  device = 3,
  /// @see VK_SYSTEM_ALLOCATION_SCOPE_INSTANCE
  instance = 4,
};
enum class internal_allocation_type
{
  /// @see VK_INTERNAL_ALLOCATION_TYPE_EXECUTABLE
  executable = 0,
};
enum class descriptor_update_template_type_khr
{
};
enum class point_clipping_behavior_khr
{
};
enum class tessellation_domain_origin_khr
{
};
enum class sampler_ycbcr_model_conversion_khr
{
};
enum class sampler_ycbcr_range_khr
{
};
enum class chroma_location_khr
{
};

/// Enhanced replacement type for VkDebugReportCallbackCreateInfoEXT.
class debug_report_callback_create_info_ext
{
public:
  /// Default constructor.
  constexpr debug_report_callback_create_info_ext() = default;

  /// Constructor.
  constexpr debug_report_callback_create_info_ext(
    const void* initial_next, vk::debug_report_flags_ext initial_flags,
    PFN_vkDebugReportCallbackEXT initial_pfn_callback,
    void* initial_user_data) noexcept
  : _next(std::move(initial_next)),
    _flags(std::move(initial_flags)),
    _pfn_callback(std::move(initial_pfn_callback)),
    _user_data(std::move(initial_user_data))
  {
  }

  /// Copy constructor.
  constexpr debug_report_callback_create_info_ext(
    const debug_report_callback_create_info_ext& other) noexcept
  : _next(other._next),
    _flags(other._flags),
    _pfn_callback(other._pfn_callback),
    _user_data(other._user_data)
  {
  }

  /// Move constructor.
  constexpr debug_report_callback_create_info_ext(
    debug_report_callback_create_info_ext&& other) noexcept
  : _next(std::move(other._next)),
    _flags(std::move(other._flags)),
    _pfn_callback(std::move(other._pfn_callback)),
    _user_data(std::move(other._user_data))
  {
  }

  /// Copy assignment operator.
  constexpr debug_report_callback_create_info_ext& operator=(
    const debug_report_callback_create_info_ext& other) noexcept
  {
    _next = other._next;
    _flags = other._flags;
    _pfn_callback = other._pfn_callback;
    _user_data = other._user_data;
    return *this;
  }

  /// Move assignment operator.
  constexpr debug_report_callback_create_info_ext& operator=(
    debug_report_callback_create_info_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _flags = std::move(other._flags);
    _pfn_callback = std::move(other._pfn_callback);
    _user_data = std::move(other._user_data);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkDebugReportCallbackCreateInfoEXT&() const
  {
    return *reinterpret_cast<const VkDebugReportCallbackCreateInfoEXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  const void* next()
  {
    return _next;
  }

  constexpr const void* next() const
  {
    return _next;
  }

  void next(const void* new_next)
  {
    _next = new_next;
  }

  vk::debug_report_flags_ext& flags()
  {
    return _flags;
  }

  constexpr const vk::debug_report_flags_ext& flags() const
  {
    return _flags;
  }

  void flags(vk::debug_report_flags_ext new_flags)
  {
    _flags = new_flags;
  }

  PFN_vkDebugReportCallbackEXT& pfn_callback()
  {
    return _pfn_callback;
  }

  constexpr const PFN_vkDebugReportCallbackEXT& pfn_callback() const
  {
    return _pfn_callback;
  }

  void pfn_callback(PFN_vkDebugReportCallbackEXT new_pfn_callback)
  {
    _pfn_callback = new_pfn_callback;
  }

  void* user_data()
  {
    return _user_data;
  }

  constexpr void* user_data() const
  {
    return _user_data;
  }

  void user_data(void* new_user_data)
  {
    _user_data = new_user_data;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::debug_report_callback_create_info_ext;
  const void* _next = nullptr;
  /// Indicates which events call this callback
  vk::debug_report_flags_ext _flags = vk::debug_report_flag_ext::none;
  /// Function pointer of a callback function
  PFN_vkDebugReportCallbackEXT _pfn_callback = nullptr;
  /// User data provided to callback function
  void* _user_data = nullptr;
};
static_assert(sizeof(debug_report_callback_create_info_ext) ==
                sizeof(::VkDebugReportCallbackCreateInfoEXT),
              "struct and wrapper have different size!");

using physical_device_features_2_khr = physical_device_features_2;

using physical_device_properties_2_khr = physical_device_properties_2;

using format_properties_2_khr = format_properties_2;

using image_format_properties_2_khr = image_format_properties_2;

using physical_device_image_format_info_2_khr =
  physical_device_image_format_info_2;

using queue_family_properties_2_khr = queue_family_properties_2;

using physical_device_memory_properties_2_khr =
  physical_device_memory_properties_2;

using sparse_image_format_properties_2_khr = sparse_image_format_properties_2;

using physical_device_sparse_image_format_info_2_khr =
  physical_device_sparse_image_format_info_2;

using physical_device_variable_pointer_features_khr =
  physical_device_variable_pointer_features;

using external_memory_properties_khr = external_memory_properties;

using physical_device_external_image_format_info_khr =
  physical_device_external_image_format_info;

using external_image_format_properties_khr = external_image_format_properties;

using physical_device_external_buffer_info_khr =
  physical_device_external_buffer_info;

using external_buffer_properties_khr = external_buffer_properties;

using physical_device_idproperties_khr = physical_device_idproperties;

using external_memory_image_create_info_khr = external_memory_image_create_info;

using external_memory_buffer_create_info_khr =
  external_memory_buffer_create_info;

using export_memory_allocate_info_khr = export_memory_allocate_info;

using physical_device_external_semaphore_info_khr =
  physical_device_external_semaphore_info;

using external_semaphore_properties_khr = external_semaphore_properties;

using export_semaphore_create_info_khr = export_semaphore_create_info;

using physical_device_external_fence_info_khr =
  physical_device_external_fence_info;

using external_fence_properties_khr = external_fence_properties;

using export_fence_create_info_khr = export_fence_create_info;

using physical_device_multiview_features_khr =
  physical_device_multiview_features;

using physical_device_multiview_properties_khr =
  physical_device_multiview_properties;

using render_pass_multiview_create_info_khr = render_pass_multiview_create_info;

/// Enhanced replacement type for VkSurfaceCapabilities2EXT.
class surface_capabilities_2_ext
{
public:
  /// Default constructor.
  constexpr surface_capabilities_2_ext() = default;

  /// Constructor.
  constexpr surface_capabilities_2_ext(
    void* initial_next, uint32_t initial_min_image_count,
    uint32_t initial_max_image_count, vk::extent_2d initial_current_extent,
    vk::extent_2d initial_min_image_extent,
    vk::extent_2d initial_max_image_extent,
    uint32_t initial_max_image_array_layers,
    vk::surface_transform_flags_khr initial_supported_transforms,
    vk::surface_transform_flag_khr initial_current_transform,
    vk::composite_alpha_flags_khr initial_supported_composite_alpha,
    vk::image_usage_flags initial_supported_usage_flags,
    vk::surface_counter_flags_ext initial_supported_surface_counters) noexcept
  : _next(std::move(initial_next)),
    _min_image_count(std::move(initial_min_image_count)),
    _max_image_count(std::move(initial_max_image_count)),
    _current_extent(std::move(initial_current_extent)),
    _min_image_extent(std::move(initial_min_image_extent)),
    _max_image_extent(std::move(initial_max_image_extent)),
    _max_image_array_layers(std::move(initial_max_image_array_layers)),
    _supported_transforms(std::move(initial_supported_transforms)),
    _current_transform(std::move(initial_current_transform)),
    _supported_composite_alpha(std::move(initial_supported_composite_alpha)),
    _supported_usage_flags(std::move(initial_supported_usage_flags)),
    _supported_surface_counters(std::move(initial_supported_surface_counters))
  {
  }

  /// Copy constructor.
  constexpr surface_capabilities_2_ext(
    const surface_capabilities_2_ext& other) noexcept
  : _next(other._next),
    _min_image_count(other._min_image_count),
    _max_image_count(other._max_image_count),
    _current_extent(other._current_extent),
    _min_image_extent(other._min_image_extent),
    _max_image_extent(other._max_image_extent),
    _max_image_array_layers(other._max_image_array_layers),
    _supported_transforms(other._supported_transforms),
    _current_transform(other._current_transform),
    _supported_composite_alpha(other._supported_composite_alpha),
    _supported_usage_flags(other._supported_usage_flags),
    _supported_surface_counters(other._supported_surface_counters)
  {
  }

  /// Move constructor.
  constexpr surface_capabilities_2_ext(
    surface_capabilities_2_ext&& other) noexcept
  : _next(std::move(other._next)),
    _min_image_count(std::move(other._min_image_count)),
    _max_image_count(std::move(other._max_image_count)),
    _current_extent(std::move(other._current_extent)),
    _min_image_extent(std::move(other._min_image_extent)),
    _max_image_extent(std::move(other._max_image_extent)),
    _max_image_array_layers(std::move(other._max_image_array_layers)),
    _supported_transforms(std::move(other._supported_transforms)),
    _current_transform(std::move(other._current_transform)),
    _supported_composite_alpha(std::move(other._supported_composite_alpha)),
    _supported_usage_flags(std::move(other._supported_usage_flags)),
    _supported_surface_counters(std::move(other._supported_surface_counters))
  {
  }

  /// Copy assignment operator.
  constexpr surface_capabilities_2_ext& operator=(
    const surface_capabilities_2_ext& other) noexcept
  {
    _next = other._next;
    _min_image_count = other._min_image_count;
    _max_image_count = other._max_image_count;
    _current_extent = other._current_extent;
    _min_image_extent = other._min_image_extent;
    _max_image_extent = other._max_image_extent;
    _max_image_array_layers = other._max_image_array_layers;
    _supported_transforms = other._supported_transforms;
    _current_transform = other._current_transform;
    _supported_composite_alpha = other._supported_composite_alpha;
    _supported_usage_flags = other._supported_usage_flags;
    _supported_surface_counters = other._supported_surface_counters;
    return *this;
  }

  /// Move assignment operator.
  constexpr surface_capabilities_2_ext& operator=(
    surface_capabilities_2_ext&& other) noexcept
  {
    _next = std::move(other._next);
    _min_image_count = std::move(other._min_image_count);
    _max_image_count = std::move(other._max_image_count);
    _current_extent = std::move(other._current_extent);
    _min_image_extent = std::move(other._min_image_extent);
    _max_image_extent = std::move(other._max_image_extent);
    _max_image_array_layers = std::move(other._max_image_array_layers);
    _supported_transforms = std::move(other._supported_transforms);
    _current_transform = std::move(other._current_transform);
    _supported_composite_alpha = std::move(other._supported_composite_alpha);
    _supported_usage_flags = std::move(other._supported_usage_flags);
    _supported_surface_counters = std::move(other._supported_surface_counters);
    return *this;
  }

  /// Conversion operator to original Vulkan type.
  operator const VkSurfaceCapabilities2EXT&() const
  {
    return *reinterpret_cast<const VkSurfaceCapabilities2EXT*>(this);
  }

  constexpr const vk::structure_type& structure_type() const
  {
    return _structure_type;
  }

  void* next()
  {
    return _next;
  }

  constexpr void* next() const
  {
    return _next;
  }

  void next(void* new_next)
  {
    _next = new_next;
  }

  uint32_t& min_image_count()
  {
    return _min_image_count;
  }

  constexpr const uint32_t& min_image_count() const
  {
    return _min_image_count;
  }

  void min_image_count(uint32_t new_min_image_count)
  {
    _min_image_count = new_min_image_count;
  }

  uint32_t& max_image_count()
  {
    return _max_image_count;
  }

  constexpr const uint32_t& max_image_count() const
  {
    return _max_image_count;
  }

  void max_image_count(uint32_t new_max_image_count)
  {
    _max_image_count = new_max_image_count;
  }

  vk::extent_2d& current_extent()
  {
    return _current_extent;
  }

  constexpr const vk::extent_2d& current_extent() const
  {
    return _current_extent;
  }

  void current_extent(vk::extent_2d new_current_extent)
  {
    _current_extent = new_current_extent;
  }

  vk::extent_2d& min_image_extent()
  {
    return _min_image_extent;
  }

  constexpr const vk::extent_2d& min_image_extent() const
  {
    return _min_image_extent;
  }

  void min_image_extent(vk::extent_2d new_min_image_extent)
  {
    _min_image_extent = new_min_image_extent;
  }

  vk::extent_2d& max_image_extent()
  {
    return _max_image_extent;
  }

  constexpr const vk::extent_2d& max_image_extent() const
  {
    return _max_image_extent;
  }

  void max_image_extent(vk::extent_2d new_max_image_extent)
  {
    _max_image_extent = new_max_image_extent;
  }

  uint32_t& max_image_array_layers()
  {
    return _max_image_array_layers;
  }

  constexpr const uint32_t& max_image_array_layers() const
  {
    return _max_image_array_layers;
  }

  void max_image_array_layers(uint32_t new_max_image_array_layers)
  {
    _max_image_array_layers = new_max_image_array_layers;
  }

  vk::surface_transform_flags_khr& supported_transforms()
  {
    return _supported_transforms;
  }

  constexpr const vk::surface_transform_flags_khr& supported_transforms() const
  {
    return _supported_transforms;
  }

  void supported_transforms(
    vk::surface_transform_flags_khr new_supported_transforms)
  {
    _supported_transforms = new_supported_transforms;
  }

  vk::surface_transform_flag_khr& current_transform()
  {
    return _current_transform;
  }

  constexpr const vk::surface_transform_flag_khr& current_transform() const
  {
    return _current_transform;
  }

  void current_transform(vk::surface_transform_flag_khr new_current_transform)
  {
    _current_transform = new_current_transform;
  }

  vk::composite_alpha_flags_khr& supported_composite_alpha()
  {
    return _supported_composite_alpha;
  }

  constexpr const vk::composite_alpha_flags_khr& supported_composite_alpha()
    const
  {
    return _supported_composite_alpha;
  }

  void supported_composite_alpha(
    vk::composite_alpha_flags_khr new_supported_composite_alpha)
  {
    _supported_composite_alpha = new_supported_composite_alpha;
  }

  vk::image_usage_flags& supported_usage_flags()
  {
    return _supported_usage_flags;
  }

  constexpr const vk::image_usage_flags& supported_usage_flags() const
  {
    return _supported_usage_flags;
  }

  void supported_usage_flags(vk::image_usage_flags new_supported_usage_flags)
  {
    _supported_usage_flags = new_supported_usage_flags;
  }

  vk::surface_counter_flags_ext& supported_surface_counters()
  {
    return _supported_surface_counters;
  }

  constexpr const vk::surface_counter_flags_ext& supported_surface_counters()
    const
  {
    return _supported_surface_counters;
  }

  void supported_surface_counters(
    vk::surface_counter_flags_ext new_supported_surface_counters)
  {
    _supported_surface_counters = new_supported_surface_counters;
  }

private:
  const vk::structure_type _structure_type =
    vk::structure_type::surface_capabilities_2_ext;
  void* _next = nullptr;
  /// Supported minimum number of images for the surface
  uint32_t _min_image_count = 0;
  /// Supported maximum number of images for the surface, 0 for unlimited
  uint32_t _max_image_count = 0;
  /// Current image width and height for the surface, (0, 0) if undefined
  vk::extent_2d _current_extent = vk::extent_2d{};
  /// Supported minimum image width and height for the surface
  vk::extent_2d _min_image_extent = vk::extent_2d{};
  /// Supported maximum image width and height for the surface
  vk::extent_2d _max_image_extent = vk::extent_2d{};
  /// Supported maximum number of image layers for the surface
  uint32_t _max_image_array_layers = 0;
  /// 1 or more bits representing the transforms supported
  vk::surface_transform_flags_khr _supported_transforms =
    vk::surface_transform_flag_khr::none;
  /// The surface's current transform relative to the device's natural
  /// orientation
  vk::surface_transform_flag_khr _current_transform =
    vk::surface_transform_flag_khr::none;
  /// 1 or more bits representing the alpha compositing modes supported
  vk::composite_alpha_flags_khr _supported_composite_alpha =
    vk::composite_alpha_flag_khr::none;
  /// Supported image usage flags for the surface
  vk::image_usage_flags _supported_usage_flags = vk::image_usage_flag::none;
  vk::surface_counter_flags_ext _supported_surface_counters =
    vk::surface_counter_flag_ext::none;
};
static_assert(sizeof(surface_capabilities_2_ext) ==
                sizeof(::VkSurfaceCapabilities2EXT),
              "struct and wrapper have different size!");

using physical_device_group_properties_khr = physical_device_group_properties;

using memory_allocate_flags_info_khr = memory_allocate_flags_info;

using bind_buffer_memory_info_khr = bind_buffer_memory_info;

using bind_buffer_memory_device_group_info_khr =
  bind_buffer_memory_device_group_info;

using bind_image_memory_info_khr = bind_image_memory_info;

using bind_image_memory_device_group_info_khr =
  bind_image_memory_device_group_info;

using device_group_render_pass_begin_info_khr =
  device_group_render_pass_begin_info;

using device_group_command_buffer_begin_info_khr =
  device_group_command_buffer_begin_info;

using device_group_submit_info_khr = device_group_submit_info;

using device_group_bind_sparse_info_khr = device_group_bind_sparse_info;

using device_group_device_create_info_khr = device_group_device_create_info;

using descriptor_update_template_entry_khr = descriptor_update_template_entry;

using descriptor_update_template_create_info_khr =
  descriptor_update_template_create_info;

using input_attachment_aspect_reference_khr = input_attachment_aspect_reference;

using render_pass_input_attachment_aspect_create_info_khr =
  render_pass_input_attachment_aspect_create_info;

using physical_device_16_bit_storage_features_khr =
  physical_device_16_bit_storage_features;

using buffer_memory_requirements_info_2_khr = buffer_memory_requirements_info_2;

using image_memory_requirements_info_2_khr = image_memory_requirements_info_2;

using image_sparse_memory_requirements_info_2_khr =
  image_sparse_memory_requirements_info_2;

using sparse_image_memory_requirements_2_khr =
  sparse_image_memory_requirements_2;

using physical_device_point_clipping_properties_khr =
  physical_device_point_clipping_properties;

using memory_dedicated_requirements_khr = memory_dedicated_requirements;

using memory_dedicated_allocate_info_khr = memory_dedicated_allocate_info;

using image_view_usage_create_info_khr = image_view_usage_create_info;

using pipeline_tessellation_domain_origin_state_create_info_khr =
  pipeline_tessellation_domain_origin_state_create_info;

using sampler_ycbcr_conversion_info_khr = sampler_ycbcr_conversion_info;

using sampler_ycbcr_conversion_create_info_khr =
  sampler_ycbcr_conversion_create_info;

using bind_image_plane_memory_info_khr = bind_image_plane_memory_info;

using image_plane_memory_requirements_info_khr =
  image_plane_memory_requirements_info;

using physical_device_sampler_ycbcr_conversion_features_khr =
  physical_device_sampler_ycbcr_conversion_features;

using sampler_ycbcr_conversion_image_format_properties_khr =
  sampler_ycbcr_conversion_image_format_properties;

using physical_device_maintenance_3_properties_khr =
  physical_device_maintenance_3_properties;

using descriptor_set_layout_support_khr = descriptor_set_layout_support;
}

#endif
